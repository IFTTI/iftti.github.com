---
layout: post
title: 'LogStash::Inputs::Syslog 性能测试与优化'
time: 2014-10-18 00:00:00 +0800
site_name: chenlinux.com
source_url: http://chenlinux.com/2014/10/18/performance-testing-tunning-for-logstash-inputs-syslog
---
{% raw %}

  
  <div style="background-color: #FFF;">
    <p>最近因为项目需要，必须想办法提高 logstash indexer 接收 rsyslog 转发数据的性能。首先，就是要了解 logstash 到底能收多快？</p>
<p>之前用 libev 库写过类似功能的程序，所以一开始也是打算找个能在 JRuby 上运行的 netty 封装。找到了 <a href="https://github.com/m0wfo/foxbat">foxbat</a> 库，不过最后发现效果跟官方的标准 socket 实现差不多。（这部分另篇讲述）</p>
<p>后来又发现另一个库：<a href="https://github.com/jordansissel/experiments/tree/master/ruby/jruby-netty/syslog-server">jruby-netty</a>，注意到这个作者就是 logstash 作者 jordansissel！</p>
<p>当然，最终并不是用上这个项目的代码来改写 logstash，而是从这里面学到了如何方便的进行 syslog server 性能压测。测试方式：</p>
<pre><code>yes "&lt;44&gt;May 19 18:30:17 snack jls: foo bar 32" | nc localhost 3000
</code></pre>
<p>或者</p>
<pre><code>loggen -r 500000 -iS -s 120 -I 50  localhost 3000
</code></pre>
<p>loggen 是 syslog-ng 带的工具，还得另外安装。而上面第一行的方式，这个 <code>yes</code> 用的真是绝妙！</p>
<p>就用这个测试方法，最终发现单机上 LogStash::Inputs::Syslog 的每秒处理能力只有 700 条：</p>
<pre><code>input {
    syslog {
        port =&gt; 3000
    }
}
output {
    stdout {
        codec =&gt; dots
    }
}
</code></pre>
<p>logstash 配置文件见上。然后测试启动命令如下：</p>
<pre><code>./bin/logstash -f syslog.conf | pv -abt &gt; /dev/null
</code></pre>
<p><em>注意，centos 上的 pv 命令可能还没有 <code>-a</code> 参数。</em></p>
<p>为了逐一排除性能瓶颈。我依次注释掉了 <code>lib/logstash/inputs/syslog.rb</code> 中 <code>@date_filters.filter(event)</code> 和 <code>@grok_filters.filter(event)</code> 两段，并重新运行上次的测试。结果发现：</p>
<ul>
  <li>TCPServer 接收的性能是每秒 50k 条</li>
  <li>TCPServer 接收并完成 grok filter 的性能是每秒 5k 条</li>
  <li>TCPServer 接收并完成 grok 和 date filter 的性能是每秒 700 条</li>
</ul>
<p>性能成几何级的下降！</p>
<p>而另外通过 <code>input { generator { count =&gt; 3000000 } }</code> 测试可以发现，logstash 本身空数据流转的性能也不过就是每秒钟几万条。所以，优化点就在后面的 filter 上。</p>
<p>LogStash::Inputs::Syslog 中，TCPServer 对每个 client 单独开一个 Thread，但是这个 Thread 内要顺序完成 <code>@codec.decode</code>，<code>@grok_filter.filter</code> 和 <code>@date_filter.filter</code> 三大步骤后，才算完成。而我们都知道：Logstash 配置中 filter 阶段的插件是可以多线程完成的。所以，解决办法就来了：</p>
<pre><code>input {
    tcp {
        port =&gt; 3000
    }
}
filter {
    grok {
        overwrite =&gt; "message"
        match =&gt; ["message", "&lt;\d+&gt;%{SYSLOGLINE}"]
    }
    date {
        locale =&gt; "en"
        match =&gt; ["timestamp", "MMM dd HH:mm:ss", "MMM  d HH:mm:ss"]
    }
}
output {
    stdout {
        codec =&gt; dots
    }
}
</code></pre>
<p>然后重新测试，发现性能提高到了每秒 4.5k。再用下面命令运行测试：</p>
<pre><code>  ./bin/logstash -f syslog.conf -w 20 | pv -bt &gt; /dev/null
</code></pre>
<p>发现性能提高到了每秒 30 k 条！</p>
<p>此外，还陆续完成了另外一些测试。</p>
<p>比如：</p>
<ul>
  <li>outputs/elasticsearch 的 protocol 使用 node 还是 http 的问题。测试在单台环境下，node 只有 5k 的 indexing 速度，而 http 有7k。</li>
  <li>在 inputs/file 的前提下，outputs/stdout{dots} 比 outputs/elasticsearch{http} 处理速度快一倍，即有 15k。</li>
  <li>下载了 heka 的二进制包，通过下面配置测试其接受 syslog 输入，并以 logstash 的 schema 输出到文件的性能。结果是每秒 30k，跟之前优化后的 logstash 基本一致。</li>
</ul>
<div class="highlight"><pre><code class="language-ini" data-lang="ini"><span class="k">[hekad]</span>
<span class="na">maxprocs</span> <span class="o">=</span> <span class="s">48</span>
<span class="k">[TcpInput]</span>
<span class="na">address</span> <span class="o">=</span> <span class="s">":5140"</span>
<span class="na">parser_type</span> <span class="o">=</span> <span class="s">"token"</span>
<span class="na">decoder</span> <span class="o">=</span> <span class="s">"RsyslogDecoder"</span>
<span class="k">[RsyslogDecoder]</span>
<span class="na">type</span> <span class="o">=</span> <span class="s">"SandboxDecoder"</span>
<span class="na">filename</span> <span class="o">=</span> <span class="s">"lua_decoders/rsyslog.lua"</span>
<span class="k">[RsyslogDecoder.config]</span>
<span class="na">type</span> <span class="o">=</span> <span class="s">"mweibo"</span>
<span class="na">template</span> <span class="o">=</span> <span class="s">'&lt;%pri%&gt;%TIMESTAMP% %HOSTNAME% %syslogtag%%msg:::sp-if-no-1st-sp%%msg:::drop-last-lf%\n'</span>
<span class="na">tz</span> <span class="o">=</span> <span class="s">"Asia/Shanghai"</span>
<span class="k">[ESLogstashV0Encoder]</span>
<span class="na">es_index_from_timestamp</span> <span class="o">=</span> <span class="s">true</span>
<span class="na">fields</span> <span class="o">=</span> <span class="s">["Timestamp", "Payload", "Hostname", "Fields"]</span>
<span class="na">type_name</span> <span class="o">=</span> <span class="s">"%{Type}"</span>
<span class="c1"># [ElasticSearchOutput]</span>
<span class="c1"># message_matcher = "Type == 'nginx.access'"</span>
<span class="c1"># server = "http://10.13.57.35:9200"</span>
<span class="c1"># encoder = "ESLogstashV0Encoder"</span>
<span class="c1"># flush_interval = 50</span>
<span class="c1"># flush_count = 5000</span>
<span class="k">[counter_output]</span>
<span class="na">type</span> <span class="o">=</span> <span class="s">"FileOutput"</span>
<span class="na">path</span> <span class="o">=</span> <span class="s">"/tmp/debug.log"</span>
<span class="na">message_matcher</span> <span class="o">=</span> <span class="s">"TRUE"</span>
<span class="na">encoder</span> <span class="o">=</span> <span class="s">"ESLogstashV0Encoder"</span></code></pre></div>
<p>heka 文档称 maxprocs 设置为 cpu 数的两倍。不过实际测试中，不配置跟配置总共也就差一倍的性能。</p>
    <hr>
    
    <hr>
  <!-- UY BEGIN -->


<!-- UY END -->
  </div>
{% endraw %}
