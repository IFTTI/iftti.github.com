---
layout: post
title: 'spark streaming 和 spark sql 结合示例'
time: 2015-02-13 00:00:00 +0800
site_name: chenlinux.com
source_url: http://chenlinux.com/2015/02/13/spark-streaming-sql
---
{% raw %}

  
  <div style="background-color: #FFF;">
    <p>之前在博客上演示过如果在 spark 里读取 elasticsearch 中的数据。自然往下一步想，是不是可以把一些原先需要定期请求 elasticsearch 的监控内容挪到 spark 里完成？这次就是探讨一下 spark streaming 环境上如何快速统计各维度的数据。期望目标是，可以实现对流数据的异常模式过滤。平常只需要简单调整模式即可。</p>
<h2 id="spark-">spark 基础预备</h2>
<p>之前作为示例，都是直接在 spark-shell 交互式命令行里完成的。这次说说在正式的情况下怎么做。</p>
<p>spark 是用 scala 写的，scala 的打包工具叫 sbt。首先通过 <code>sudo port install sbt</code> 安装好。然后创建目录：</p>
<pre><code>mkdir -p ./logstash/src/main/scala/
</code></pre>
<p>sbt 打包的配置文件则放在 <code>./logstash/logstash.sbt</code> 位置。内容如下(注意之间的空行是必须的)：</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">name</span> <span class="o">:=</span> <span class="s">"LogStash Project"</span>
<span class="n">version</span> <span class="o">:=</span> <span class="s">"1.0"</span>
<span class="n">scalaVersion</span> <span class="o">:=</span> <span class="s">"2.10.4"</span>
<span class="n">libraryDependencies</span> <span class="o">+=</span> <span class="s">"org.apache.spark"</span> <span class="o">%%</span> <span class="s">"spark-core"</span> <span class="o">%</span> <span class="s">"1.2.0"</span>
<span class="n">libraryDependencies</span> <span class="o">+=</span> <span class="s">"org.apache.spark"</span> <span class="o">%%</span> <span class="s">"spark-streaming"</span> <span class="o">%</span> <span class="s">"1.2.0"</span>
<span class="n">libraryDependencies</span> <span class="o">+=</span> <span class="s">"org.apache.spark"</span> <span class="o">%%</span> <span class="s">"spark-sql"</span> <span class="o">%</span> <span class="s">"1.2.0"</span></code></pre></div>
<p>然后是程序主文件 <code>./logstash/src/main/scala/LogStash.scala</code>，先来一个最简单的，从 logstash/output/tcp 收数据并解析出来。注意，因为 spark 只能用 pull 方式获取数据，所以 logstash/output/tcp 必须以 <code>mode =&gt; 'server'</code> 方式运行。 </p>
<pre><code>output {
    tcp {
        codec =&gt; json_lines
        mode  =&gt; 'server'
        port  =&gt; 8888
    }
}
</code></pre>
<h2 id="spark-streaming-">spark streaming 基础示例</h2>
<p>编辑主文件如下：</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.spark.SparkConf</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.</span><span class="o">{</span><span class="n">Seconds</span><span class="o">,</span> <span class="n">StreamingContext</span><span class="o">}</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.StreamingContext._</span>
<span class="kn">import</span> <span class="nn">scala.util.parsing.json.JSON</span>
<span class="n">object</span> <span class="n">LogStash</span> <span class="o">{</span>
  <span class="n">def</span> <span class="nf">main</span><span class="o">(</span><span class="nl">args:</span> <span class="n">Array</span><span class="o">[</span><span class="n">String</span><span class="o">])</span> <span class="o">{</span>
    <span class="n">val</span> <span class="n">sparkConf</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">SparkConf</span><span class="o">().</span><span class="na">setMaster</span><span class="o">(</span><span class="s">"local[2]"</span><span class="o">).</span><span class="na">setAppName</span><span class="o">(</span><span class="s">"LogStash"</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">sc</span>  <span class="o">=</span> <span class="k">new</span> <span class="nf">SparkContext</span><span class="o">(</span><span class="n">sparkConf</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">ssc</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">StreamingContext</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="n">Seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">))</span>
    <span class="n">val</span> <span class="n">lines</span> <span class="o">=</span> <span class="n">ssc</span><span class="o">.</span><span class="na">socketTextStream</span><span class="o">(</span><span class="s">"localhost"</span><span class="o">,</span> <span class="mi">8888</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">jsonf</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">JSON</span><span class="o">.</span><span class="na">parseFull</span><span class="o">(</span><span class="n">_</span><span class="o">)).</span><span class="na">map</span><span class="o">(</span><span class="n">_</span><span class="o">.</span><span class="na">get</span><span class="o">.</span><span class="na">asInstanceOf</span><span class="o">[</span><span class="n">scala</span><span class="o">.</span><span class="na">collection</span><span class="o">.</span><span class="na">immutable</span><span class="o">.</span><span class="na">Map</span><span class="o">[</span><span class="n">String</span><span class="o">,</span> <span class="n">Any</span><span class="o">]])</span>
    <span class="n">jsonf</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="n">l</span> <span class="o">=&gt;</span> <span class="n">l</span><span class="o">(</span><span class="s">"lineno"</span><span class="o">)==</span><span class="mi">75</span><span class="o">).</span><span class="na">window</span><span class="o">(</span><span class="n">Seconds</span><span class="o">(</span><span class="mi">30</span><span class="o">)).</span><span class="na">foreachRDD</span><span class="o">(</span> <span class="n">rdd</span> <span class="o">=&gt;</span> <span class="o">{</span>
      <span class="n">rdd</span><span class="o">.</span><span class="na">foreach</span><span class="o">(</span> <span class="n">r</span> <span class="o">=&gt;</span> <span class="o">{</span>
        <span class="n">println</span><span class="o">(</span><span class="n">r</span><span class="o">(</span><span class="s">"path"</span><span class="o">))</span>
      <span class="o">})</span>
    <span class="o">})</span>
    <span class="n">ssc</span><span class="o">.</span><span class="na">start</span><span class="o">()</span>
    <span class="n">ssc</span><span class="o">.</span><span class="na">awaitTermination</span><span class="o">()</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>
<p>非常一目了然，每 10 秒挪动一次 window，window 宽度是 30 秒，把 JSON 数据解析出来以后，做过滤和循环输出。这里需要提示一下的是 <code>.foreachRDD</code> 方法。这是一个 output 方法。spark streaming 里对 input 收到的 DStream 一定要有 output 处理，那么最常见的就是用 foreachRDD 把 DStream 里的 RDDs 循环一遍，做 save 啊，print 啊等等后续。</p>
<p>然后用 sbt 工具编译后就可以运行了：</p>
<pre><code>sbt package &amp;&amp; ./spark-1.2.0-bin-hadoop2.4/bin/spark-submit --class "LogStash" --master local[2] target/scala-2.10/logstash-project_2.10-1.0.jar
</code></pre>
<h2 id="sql-">进阶：数据映射和 SQL 处理</h2>
<p>下面看如何在 spark streaming 上使用 spark SQL。前面通过解析 JSON，得到的是 Map 类型的数据，这个无法直接被 SQL 使用。通常的做法是，通过预定的 scala 里的 <code>cast class</code>，来转换成 spark SQL 支持的表类型。主文件改成这样：</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.spark.SparkConf</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.</span><span class="o">{</span><span class="n">Seconds</span><span class="o">,</span> <span class="n">StreamingContext</span><span class="o">}</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.StreamingContext._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SQLContext</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql._</span>
<span class="kn">import</span> <span class="nn">scala.util.parsing.json.JSON</span>
<span class="n">object</span> <span class="n">LogStash</span> <span class="o">{</span>
  <span class="k">case</span> <span class="kd">class</span> <span class="nf">LogStashV1</span><span class="o">(</span><span class="nl">message:</span><span class="n">String</span><span class="o">,</span> <span class="nl">path:</span><span class="n">String</span><span class="o">,</span> <span class="nl">host:</span><span class="n">String</span><span class="o">,</span> <span class="nl">lineno:</span><span class="n">Double</span><span class="o">,</span> <span class="nl">timestamp:</span><span class="n">String</span><span class="o">)</span>
  <span class="k">case</span> <span class="kd">class</span> <span class="nf">AlertMsg</span><span class="o">(</span><span class="nl">host:</span><span class="n">String</span><span class="o">,</span> <span class="nl">count:</span><span class="n">Int</span><span class="o">,</span> <span class="nl">value:</span><span class="n">Double</span><span class="o">)</span>
  <span class="n">def</span> <span class="nf">main</span><span class="o">(</span><span class="nl">args:</span> <span class="n">Array</span><span class="o">[</span><span class="n">String</span><span class="o">])</span> <span class="o">{</span>
    <span class="n">val</span> <span class="n">sparkConf</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">SparkConf</span><span class="o">().</span><span class="na">setMaster</span><span class="o">(</span><span class="s">"local[2]"</span><span class="o">).</span><span class="na">setAppName</span><span class="o">(</span><span class="s">"LogStash"</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">sc</span>  <span class="o">=</span> <span class="k">new</span> <span class="nf">SparkContext</span><span class="o">(</span><span class="n">sparkConf</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">ssc</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">StreamingContext</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="n">Seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">))</span>
    <span class="n">val</span> <span class="n">sqc</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">SQLContext</span><span class="o">(</span><span class="n">sc</span><span class="o">)</span>
    <span class="kn">import</span> <span class="nn">sqc._</span>
    <span class="n">val</span> <span class="n">lines</span> <span class="o">=</span> <span class="n">ssc</span><span class="o">.</span><span class="na">socketTextStream</span><span class="o">(</span><span class="s">"localhost"</span><span class="o">,</span> <span class="mi">8888</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">jsonf</span> <span class="o">=</span> <span class="n">lines</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">JSON</span><span class="o">.</span><span class="na">parseFull</span><span class="o">(</span><span class="n">_</span><span class="o">)).</span><span class="na">map</span><span class="o">(</span><span class="n">_</span><span class="o">.</span><span class="na">get</span><span class="o">.</span><span class="na">asInstanceOf</span><span class="o">[</span><span class="n">scala</span><span class="o">.</span><span class="na">collection</span><span class="o">.</span><span class="na">immutable</span><span class="o">.</span><span class="na">Map</span><span class="o">[</span><span class="n">String</span><span class="o">,</span> <span class="n">Any</span><span class="o">]])</span>
    <span class="n">val</span> <span class="n">logs</span> <span class="o">=</span> <span class="n">jsonf</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">data</span> <span class="o">=&gt;</span> <span class="n">LogStashV1</span><span class="o">(</span><span class="n">data</span><span class="o">(</span><span class="s">"message"</span><span class="o">).</span><span class="na">toString</span><span class="o">,</span> <span class="n">data</span><span class="o">(</span><span class="s">"path"</span><span class="o">).</span><span class="na">toString</span><span class="o">,</span> <span class="n">data</span><span class="o">(</span><span class="s">"host"</span><span class="o">).</span><span class="na">toString</span><span class="o">,</span> <span class="n">data</span><span class="o">(</span><span class="s">"lineno"</span><span class="o">).</span><span class="na">toString</span><span class="o">.</span><span class="na">toDouble</span><span class="o">,</span> <span class="n">data</span><span class="o">(</span><span class="s">"@timestamp"</span><span class="o">).</span><span class="na">toString</span><span class="o">))</span>
    <span class="n">logs</span><span class="o">.</span><span class="na">foreachRDD</span><span class="o">(</span> <span class="n">rdd</span> <span class="o">=&gt;</span> <span class="o">{</span>
      <span class="n">rdd</span><span class="o">.</span><span class="na">registerAsTable</span><span class="o">(</span><span class="s">"logstash"</span><span class="o">)</span>
      <span class="n">val</span> <span class="n">sqlreport</span> <span class="o">=</span> <span class="n">sqc</span><span class="o">.</span><span class="na">sql</span><span class="o">(</span><span class="s">"SELECT message, COUNT(message) AS host_c, SUM(lineno) AS line_a FROM logstash WHERE path = '/var/log/system.log' AND lineno &gt; 70 GROUP BY message ORDER BY host_c DESC LIMIT 100"</span><span class="o">)</span>
      <span class="n">sqlreport</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">t</span> <span class="o">=&gt;</span> <span class="n">AlertMsg</span><span class="o">(</span><span class="n">t</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="na">toString</span><span class="o">,</span> <span class="n">t</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="na">toString</span><span class="o">.</span><span class="na">toInt</span><span class="o">,</span> <span class="n">t</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="na">toString</span><span class="o">.</span><span class="na">toDouble</span><span class="o">)).</span><span class="na">collect</span><span class="o">().</span><span class="na">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
    <span class="o">})</span>
    <span class="n">ssc</span><span class="o">.</span><span class="na">start</span><span class="o">()</span>
    <span class="n">ssc</span><span class="o">.</span><span class="na">awaitTermination</span><span class="o">()</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>
<p>通过加载 SQLContext，就可以把 RDD 转换成 table，然后通过 SQL 方式写请求了。这里有一个地方需要注意的是，因为最开始转换 JSON 的时候，键值对的 value 类型是 Any(因为要兼容复杂结构)，所以后面赋值的时候需要具体转换成合适的类型。于是悲催的就有了 <code>.toString.toInt</code> 这样的写法。。。</p>
<h2 id="sql--1">同样效果的非 SQL 实现</h2>
<p>不用 spark SQL 当然也能做到，而且如果需要复杂处理的时候，还少不了自己写。如果把上例中那段 foreachRDD 替换成下面这样，效果是完全一样的：</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="n">val</span> <span class="n">r</span> <span class="o">=</span> <span class="n">logs</span><span class="o">.</span><span class="na">filter</span><span class="o">(</span><span class="n">l</span> <span class="o">=&gt;</span> <span class="n">l</span><span class="o">.</span><span class="na">path</span><span class="o">.</span><span class="na">equals</span><span class="o">(</span><span class="s">"/var/log/system.log"</span><span class="o">)).</span><span class="na">filter</span><span class="o">(</span><span class="n">l</span> <span class="o">=&gt;</span> <span class="n">l</span><span class="o">.</span><span class="na">lineno</span> <span class="o">&gt;</span> <span class="mi">70</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">host_c</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">l</span> <span class="o">=&gt;</span> <span class="n">l</span><span class="o">.</span><span class="na">message</span> <span class="o">-&gt;</span> <span class="mi">1</span><span class="o">).</span><span class="na">reduceByKey</span><span class="o">(</span><span class="n">_</span><span class="o">+</span><span class="n">_</span><span class="o">).</span><span class="na">groupByKey</span><span class="o">()</span>
    <span class="n">r</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">l</span> <span class="o">=&gt;</span> <span class="n">l</span><span class="o">.</span><span class="na">message</span> <span class="o">-&gt;</span> <span class="n">l</span><span class="o">.</span><span class="na">lineno</span><span class="o">).</span><span class="na">reduceByKey</span><span class="o">(</span><span class="n">_</span><span class="o">+</span><span class="n">_</span><span class="o">).</span><span class="na">groupByKey</span><span class="o">().</span><span class="na">join</span><span class="o">(</span><span class="n">host_c</span><span class="o">).</span><span class="na">foreachRDD</span><span class="o">(</span> <span class="n">rdd</span> <span class="o">=&gt;</span> <span class="o">{</span>
        <span class="n">rdd</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">t</span> <span class="o">=&gt;</span> <span class="n">AlertMsg</span><span class="o">(</span><span class="n">t</span><span class="o">.</span><span class="na">_1</span><span class="o">,</span> <span class="n">t</span><span class="o">.</span><span class="na">_2</span><span class="o">.</span><span class="na">_2</span><span class="o">.</span><span class="na">head</span><span class="o">,</span> <span class="n">t</span><span class="o">.</span><span class="na">_2</span><span class="o">.</span><span class="na">_1</span><span class="o">.</span><span class="na">head</span><span class="o">)).</span><span class="na">collect</span><span class="o">().</span><span class="na">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
    <span class="o">})</span></code></pre></div>
<p>这里面用到的 <code>.groupByKey</code> 和 <code>.reduceByKey</code> 方法，都是专门针对 PairsDStream 对象的，所以前面必须通过 <code>.map</code> 方法把普通 DStream 转换一下。</p>
<p>这里还有一个很厉害的方法，叫 <code>.updatestateByKey</code> 。可以有一个 checkpoint 存上一个 window 的数据，具体示例稍后更新。</p>
<h2 id="jsonrdd-">更简洁的 jsonRDD 方法</h2>
<p>在简单需求的时候，可能还是觉得能用 SQL 就用 SQL 比较好。但是提前定义 cast class 真的比较麻烦。其实对于 JSON 数据，spark SQL 是有提供更简洁的处理接口的。可以直接写成这样：</p>
<div class="highlight"><pre><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.spark.SparkConf</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.SparkContext._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.</span><span class="o">{</span><span class="n">Seconds</span><span class="o">,</span> <span class="n">StreamingContext</span><span class="o">}</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.streaming.StreamingContext._</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql.SQLContext</span>
<span class="kn">import</span> <span class="nn">org.apache.spark.sql._</span>
<span class="n">object</span> <span class="n">LogStash</span> <span class="o">{</span>
  <span class="k">case</span> <span class="kd">class</span> <span class="nf">AlertMsg</span><span class="o">(</span><span class="nl">host:</span><span class="n">String</span><span class="o">,</span> <span class="nl">count:</span><span class="n">String</span><span class="o">,</span> <span class="nl">value:</span><span class="n">String</span><span class="o">)</span>
  <span class="n">def</span> <span class="nf">main</span><span class="o">(</span><span class="nl">args:</span> <span class="n">Array</span><span class="o">[</span><span class="n">String</span><span class="o">])</span> <span class="o">{</span>
    <span class="n">val</span> <span class="n">sparkConf</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">SparkConf</span><span class="o">().</span><span class="na">setMaster</span><span class="o">(</span><span class="s">"local[2]"</span><span class="o">).</span><span class="na">setAppName</span><span class="o">(</span><span class="s">"LogStash"</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">sc</span>  <span class="o">=</span> <span class="k">new</span> <span class="nf">SparkContext</span><span class="o">(</span><span class="n">sparkConf</span><span class="o">)</span>
    <span class="n">val</span> <span class="n">ssc</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">StreamingContext</span><span class="o">(</span><span class="n">sc</span><span class="o">,</span> <span class="n">Seconds</span><span class="o">(</span><span class="mi">10</span><span class="o">))</span>
    <span class="n">val</span> <span class="n">sqc</span> <span class="o">=</span> <span class="k">new</span> <span class="nf">SQLContext</span><span class="o">(</span><span class="n">sc</span><span class="o">)</span>
    <span class="kn">import</span> <span class="nn">sqc._</span>
    <span class="n">val</span> <span class="n">lines</span> <span class="o">=</span> <span class="n">ssc</span><span class="o">.</span><span class="na">socketTextStream</span><span class="o">(</span><span class="s">"localhost"</span><span class="o">,</span> <span class="mi">8888</span><span class="o">)</span>
    <span class="n">lines</span><span class="o">.</span><span class="na">foreachRDD</span><span class="o">(</span> <span class="n">rdd</span> <span class="o">=&gt;</span> <span class="o">{</span>
      <span class="k">if</span> <span class="o">(</span><span class="n">rdd</span><span class="o">.</span><span class="na">count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
        <span class="n">val</span> <span class="n">t</span> <span class="o">=</span> <span class="n">sqc</span><span class="o">.</span><span class="na">jsonRDD</span><span class="o">(</span><span class="n">rdd</span><span class="o">)</span>
<span class="c1">//        t.printSchema()</span>
        <span class="n">t</span><span class="o">.</span><span class="na">registerTempTable</span><span class="o">(</span><span class="s">"logstash"</span><span class="o">)</span>
        <span class="n">val</span> <span class="n">sqlreport</span> <span class="o">=</span><span class="n">sqc</span><span class="o">.</span><span class="na">sql</span><span class="o">(</span><span class="s">"SELECT host, COUNT(host) AS host_c, AVG(lineno) AS line_a FROM logstash WHERE path = '/var/log/system.log' AND lineno &gt; 70 GROUP BY host ORDER BY host_c DESC LIMIT 100"</span><span class="o">)</span>
        <span class="n">sqlreport</span><span class="o">.</span><span class="na">map</span><span class="o">(</span><span class="n">t</span><span class="o">=&gt;</span> <span class="n">AlertMsg</span><span class="o">(</span><span class="n">t</span><span class="o">(</span><span class="mi">0</span><span class="o">).</span><span class="na">toString</span><span class="o">,</span><span class="n">t</span><span class="o">(</span><span class="mi">1</span><span class="o">).</span><span class="na">toString</span><span class="o">,</span><span class="n">t</span><span class="o">(</span><span class="mi">2</span><span class="o">).</span><span class="na">toString</span><span class="o">)).</span><span class="na">collect</span><span class="o">().</span><span class="na">foreach</span><span class="o">(</span><span class="n">println</span><span class="o">)</span>
      <span class="o">}</span>
    <span class="o">})</span>
    <span class="n">ssc</span><span class="o">.</span><span class="na">start</span><span class="o">()</span>
    <span class="n">ssc</span><span class="o">.</span><span class="na">awaitTermination</span><span class="o">()</span>
  <span class="o">}</span>
<span class="o">}</span></code></pre></div>
<p>这样，不用自己解析 JSON，直接加载到 SQLContext 里。可以通过 <code>.printSchema</code> 方法查看到 JSON 被转换成了什么样的表结构。</p>
<h2 id="todo">TODO</h2>
<p>SQL 的方式可以很方便的做到对实时数据的阈值监控处理，但是 SQL 是建立在 RDD 上的如何利用 DStream 的上一个 window 的 state 状态实现比如环比变化处理，移动均线处理，还没找到途径。</p>
<h2 id="see-also">See Also</h2>
<p>spark 目前文档不多，尤其是 streaming 和 SQL 方面的。感谢下面两个网址，对我上手帮助颇多：</p>
<ul>
  <li><a href="http://apache-spark-user-list.1001560.n3.nabble.com/Spark-Streaming-Json-file-groupby-function-td9618.html">http://apache-spark-user-list.1001560.n3.nabble.com/Spark-Streaming-Json-file-groupby-function-td9618.html</a></li>
  <li><a href="http://databricks.gitbooks.io/databricks-spark-reference-applications/content/logs_analyzer/chapter1/windows.html">http://databricks.gitbooks.io/databricks-spark-reference-applications/content/logs_analyzer/chapter1/windows.html</a></li>
</ul>
    <hr>
    
    <hr>
  <!-- JiaThis Button BEGIN -->
<div class="jiathis_style">
<span class="jiathis_txt">分享到：</span>
<a class="jiathis_button_tsina">新浪微博</a>
<a class="jiathis_button_weixin">微信</a>
<a class="jiathis_button_renren">人人网</a>
<a class="jiathis_button_ydnote">有道云笔记</a>
<a class="jiathis_button_gmail">Gmail邮箱</a>
<a class="jiathis_button_twitter">Twitter</a>
<a class="jiathis_button_googleplus">Google+</a>
<a class="jiathis_button_hi">百度空间</a>
<a class="jiathis_button_fb">Facebook</a>
<a class="jiathis_button_douban">豆瓣</a>
<a href="http://www.jiathis.com/share?uid=1589850" class="jiathis jiathis_txt jiathis_separator jtico jtico_jiathis" target="_blank">更多</a>
<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript">
var jiathis_config={
	data_track_clickback:true,
	summary:"",
	ralateuid:{
		"tsina":"1035836154"
	},
	shortUrl:false,
	hideMore:false
}
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1589850" charset="utf-8"></script>
<!-- JiaThis Button END -->
<!-- UY BEGIN -->


<!-- UY END -->
  </div>
{% endraw %}
