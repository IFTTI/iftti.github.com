---
layout: post
title: '小米运维—互联网企业级监控系统实践'
time: 2015-02-09 08:58:00 +0800
site_name: noops.me
source_url: http://noops.me/?p=1798
images:
  e91c0418abdf19f5f12ced0652c143c2: http://upload-images.jianshu.io/upload_images/3678-502bbef299826b63.png
  5c6604b3080db006cd9ccaf07b061133: http://upload-images.jianshu.io/upload_images/3678-57753ccac6dff8f8.png
  d1008cd7cb1bbabf15e65559d406292f: http://upload-images.jianshu.io/upload_images/3678-7f6705e51ea59611.png
  2cac60f1cb29e1fb65d6ba028020de0d: http://upload-images.jianshu.io/upload_images/3678-8279c8ed2ed39396.png
  dd4a9bda274eb51aa28c89ff4bc429e6: http://upload-images.jianshu.io/upload_images/3678-96f777c1363585bb.png
  7fba6afa172f442b636f7b6e73820035: http://upload-images.jianshu.io/upload_images/3678-1ff6cc744bdd8076.png
  a7bf857c5daae27e47c10ec8f67261b8: http://upload-images.jianshu.io/upload_images/3678-7b0f317788687f1d.png
  6d28f75a8e343858e13c85c9beb69613: http://upload-images.jianshu.io/upload_images/3678-9b636e99d19df16d.png
---
{% raw %}

                <h2># Introduction</h2>
<p>监控系统是整个运维环节，乃至整个产品生命周期中最重要的一环，事前及时预警发现故障，事后提供翔实的数据用于追查定位问题。监控系统作为一个成熟的运维产品，业界有很多开源的实现可供选择。当公司刚刚起步，业务规模较小，运维团队也刚刚建立的初期，选择一款开源的监控系统，是一个省时省力，效率最高的方案。之后，随着业务规模的持续快速增长，监控的对象也越来越多，越来越复杂，监控系统的使用对象也从最初少数的几个SRE，扩大为更多的DEVS，SRE。这时候，监控系统的容量和用户的“使用效率”成了最为突出的问题。</p>
<p>监控系统业界有很多杰出的开源监控系统。我们在早期，一直在用zabbix，不过随着业务的快速发展，以及互联网公司特有的一些需求，现有的开源的监控系统在性能、扩展性、和用户的使用效率方面，已经无法支撑了。</p>
<p>因此，我们在过去的一年里，从互联网公司的一些需求出发，从各位SRE、SA、DEVS的使用经验和反馈出发，结合业界的一些大的互联网公司做监控，用监控的一些思考出发，设计开发了小米的监控系统：open-falcon。</p>
<p><strong>open-falcon的目标是做最开放、最好用的互联网企业级监控产品。</strong></p>
<h2># Highlights and features</h2>
<ul>
<li>
<strong>强大灵活的数据采集</strong>：自动发现，支持falcon-agent、snmp、支持用户主动push、用户自定义插件支持、opentsdb data model like（timestamp、endpoint、metric、key-value tags）</li>
<li>
<strong>水平扩展能力</strong>：支持每个周期上亿次的数据采集、告警判定、历史数据存储和查询</li>
<li>
<strong>高效率的告警策略管理</strong>：高效的portal、支持策略模板、模板继承和覆盖、多种告警方式、支持callback调用</li>
<li>
<strong>人性化的告警设置</strong>：最大告警次数、告警级别、告警恢复通知、告警暂停、不同时段不同阈值、支持维护周期</li>
<li>
<strong>高效率的graph组件</strong>：单机支撑200万metric的上报、归档、存储（周期为1分钟）</li>
<li>
<strong>高效的历史数据query组件</strong>：采用rrdtool的数据归档策略，秒级返回上百个metric一年的历史数据</li>
<li>
<strong>dashboard</strong>：多维度的数据展示，用户自定义Screen</li>
<li>
<strong>高可用</strong>：整个系统无核心单点，易运维，易部署，可水平扩展</li>
<li>
<strong>开发语言</strong>： 整个系统的后端，全部golang编写，portal和dashboard使用python编写。</li>
</ul>
<h2># Architecture</h2>
<p><img src="/images/noops.me/e91c0418abdf19f5f12ced0652c143c2.jpg" alt="open-falcon architecture"><br>
备注：虚线所在的aggregator组件还在设计开发阶段。</p>
<p>每台服务器，都有安装falcon-agent，falcon-agent是一个golang开发的daemon程序，用于自发现的采集单机的各种数据和指标，这些指标包括不限于以下几个方面，共计400多项指标。<br>
   – CPU相关<br>
   – 磁盘相关<br>
   – IO<br>
   – Load<br>
   – 内存相关<br>
   – 网络相关<br>
   – 端口存活、进程存活<br>
   – ntp offset（插件）<br>
   – 某个进程资源消耗（插件）<br>
   – netstat、ss 等相关统计项采集<br>
   – 机器内核配置参数</p>
<p>只要安装了falcon-agent的机器，就会自动开始采集各项指标，主动上报，不需要用户在server做任何配置（这和zabbix有很大的不同），这样做的好处，就是用户维护方便，覆盖率高。当然这样做也会server端造成较大的压力，不过open-falcon的服务端组件单机性能足够高，同时都可以水平扩展，所以自动多采集足够多的数据，反而是一件好事情，对于SRE和DEV来讲，事后追查问题，不再是难题。</p>
<p>另外，falcon-agent提供了一个proxy-gateway，用户可以方便的通过http接口，push数据到本机的gateway，gateway会帮忙高效率的转发到server端。</p>
<p>falcon-agent，可以在我们的github上找到 （https://github.com/open-falcon/agent）</p>
<h2># Data model</h2>
<p>Data Model是否强大，是否灵活，对于监控系统用户的“使用效率”至关重要。比如以zabbix为例，上报的数据为hostname（或者ip）、metric，那么用户添加告警策略、管理告警策略的时候，就只能以这两个维度进行。举一个最常见的场景：</p>
<p>hostA的磁盘空间，小于5%，就告警。一般的服务器上，都会有两个主要的分区，根分区和home分区，在zabbix里面，就得加两条规则；如果是hadoop的机器，一般还会有十几块的数据盘，还得再加10多条规则，这样就会痛苦，不幸福，不利于自动化。</p>
<p>open-falcon，采用和opentsdb相同的数据格式：metric加多组key value tags，举两个例子：<br>
<code>{<br>
    metric: load.1min,<br>
    endpoint: open-falcon-host,<br>
    tags: srv=falcon,idc=aws-sgp,group=az1,<br>
    value: 1.5,<br>
    timestamp: `date +%s`,<br>
    counterType: GAUGE,<br>
    step: 60<br>
}<br>
{<br>
    metric: net.port.listen,<br>
    endpoint: open-falcon-host,<br>
    tags: port=3306,<br>
    value: 1,<br>
    timestamp: `date +%s`,<br>
    counterType: GAUGE,<br>
    step: 60<br>
}</code><br>
通过这样的数据结构，我们就可以从多个维度来配置告警，配置dashboard等等。<br>
备注：endpoint是一个特殊的tag。</p>
<h2># Data collection</h2>
<p>transfer，接收客户端发送的数据，做一些数据规整，检查之后，转发到多个后端系统去处理。在转发到每个后端业务系统的时候，transfer会根据一致性hash算法，进行数据分片，来达到后端业务系统的水平扩展。</p>
<p>transfer 提供jsonRpc接口和telnet接口两种方式，transfer自身是无状态的，挂掉一台或者多台不会有任何影响，同时transfer性能很高，每分钟可以转发超过500万条数据。</p>
<p>transfer目前支持的业务后端，有三种，judge、graph、opentsdb。judge是我们开发的高性能告警判定组件，graph是我们开发的高性能数据存储、归档、查询组件，opentsdb是开源的时间序列数据存储服务。可以通过transfer的配置文件来开启。</p>
<p>transfer的数据来源，一般有三种：<br>
1. falcon-agent采集的基础监控数据<br>
2. falcon-agent执行用户自定义的插件返回的数据<br>
3. client library：线上的业务系统，都嵌入使用了统一的perfcounter.jar，对于业务系统中每个RPC接口的qps、latency都会主动采集并上报</p>
<p>说明：上面这三种数据，都会先发送给本机的proxy-gateway，再由gateway转发给transfer。</p>
<h2># Alerting</h2>
<p>报警判定，是由judge组件来完成。用户在web portal来配置相关的报警策略，存储在MySQL中。heartbeat server 会定期加载MySQL中的内容。judge也会定期和heartbeat server保持沟通，来获取相关的报警策略。</p>
<p>heartbeat sever不仅仅是单纯的加载MySQL中的内容，根据模板继承、模板项覆盖、报警动作覆盖、模板和hostGroup绑定，计算出最终关联到每个endpoint的告警策略，提供给judge组件来使用。</p>
<p>transfer转发到judge的每条数据，都会触发相关策略的判定，来决定是否满足报警条件，如果满足条件，则会发送给alarm，alarm再以邮件、短信、米聊等形式通知相关用户，也可以执行用户预先配置好的callback地址。</p>
<p>用户可以很灵活的来配置告警判定策略，比如连续n次都满足条件、连续n次的最大值满足条件、不同的时间段不同的阈值、如果处于维护周期内则忽略 等等。</p>
<h2># Query</h2>
<p>到这里，数据已经成功的存储在了graph里。如何快速的读出来呢，读过去1小时的，过去1天的，过去一月的，过去一年的，都需要在1秒之内返回。</p>
<p>这些都是靠graph和query组件来实现的，transfer会将数据往graph组件转发一份，graph收到数据以后，会以rrdtool的数据归档方式来存储，同时提供查询RPC接口。</p>
<p>query面向终端用户，收到查询请求后，会去多个graph里面，查询不同metric的数据，汇总后统一返回给用户。</p>
<h2># Dashboard</h2>
<p>dashboard首页，用户可以以多个维度来搜索endpoint列表，即可以根据上报的tags来搜索关联的endpoint。<br>
<img src="/images/noops.me/5c6604b3080db006cd9ccaf07b061133.jpg" alt="open-falcon  dashboard homepage"></p>
<p>用户可以自定义多个metric，添加到某个screen中，这样每天早上只需要打开screen看一眼，服务的运行情况便尽在掌握了。<br>
<img src="/images/noops.me/d1008cd7cb1bbabf15e65559d406292f.jpg" alt="open-falcon dashboard screen"></p>
<p>当然，也可以查看清晰大图，横坐标上zoom in/out，快速筛选反选。总之用户的“使用效率”是第一要务。<br>
<img src="/images/noops.me/2cac60f1cb29e1fb65d6ba028020de0d.jpg" alt="open-falcon big graph"></p>
<h2># Web portal</h2>
<p>一个高效的portal，对于提升用户的“使用效率”，加成很大，平时大家都这么忙，能给各位SRE、Devs减轻一些负担，那是再好不过了。</p>
<p>这是host group的管理页面，可以和服务树结合，机器进出服务树节点，相关的模板会自动关联或者解除。这样服务上下线，都不需要手动来变更监控，大大提高效率，降低遗漏和误报警。<br>
<img src="/images/noops.me/dd4a9bda274eb51aa28c89ff4bc429e6.jpg" alt="open-falcon portal HostGroup"></p>
<p>一个最简单的模板的例子，模板支持继承和策略覆盖，模板和host group绑定后，host group下的机器会自动应用该模板的所有策略。<br>
<img src="/images/noops.me/7fba6afa172f442b636f7b6e73820035.jpg" alt="open-falcon template"></p>
<p>当然，也可以写一个简单的表达式，就能达到监控的目的，这对于那些endpoint不是机器名的场景非常方便。<br>
<img src="/images/noops.me/a7bf857c5daae27e47c10ec8f67261b8.jpg" alt="open-falcon expression"></p>
<p>添加一个表达式也是很简单的。<br>
<img src="/images/noops.me/6d28f75a8e343858e13c85c9beb69613.jpg" alt="open-falcon add an expression"></p>
<h2># Storage</h2>
<p>对于监控系统来讲，历史数据的存储和高效率查询，永远是个很难的问题！<br>
1. 数据量大：目前我们的监控系统，每个周期，大概有2000万次数据上报（上报周期为1分钟和5分钟两种，各占50%），一天24小时里，从来不会有业务低峰，不管是白天和黑夜，每个周期，总会有那么多的数据要更新。<br>
2. 写操作多：一般的业务系统，通常都是读多写少，可以方便的使用各种缓存技术，再者各类数据库，对于查询操作的处理效率远远高于写操作。而监控系统恰恰相反，写操作远远高于读。每个周期几千万次的更新操作，对于常用数据库（MySQL、postgresql、mongodb）都是无法完成的。<br>
3. 高效率的查：我们说监控系统读操作少，是说相对写入来讲。监控系统本身对于读的要求很高，用户经常会有查询上百个meitric，在过去一天、一周、一月、一年的数据。如何在1秒内返回给用户并绘图，这是一个不小的挑战。</p>
<p>open-falcon在这块，投入了较大的精力。我们把数据按照用途分成两类，一类是用来绘图的，一类是用户做数据挖掘的。</p>
<p>对于绘图的数据来讲，查询要快是关键，同时不能丢失信息量。对于用户要查询100个metric，在过去一年里的数据时，数据量本身就在那里了，很难1秒之类能返回，另外就算返回了，前端也无法渲染这么多的数据，还得采样，造成很多无谓的消耗和浪费。我们参考rrdtool的理念，在数据每次存入的时候，会自动进行采样、归档。我们的归档策略如下，历史数据保存5年。同时为了不丢失信息量，数据归档的时候，会按照平均值采样、最大值采样、最小值采样存三份。<br>
“`<br>
// 1分钟一个点存 12小时<br>
c.RRA(“AVERAGE”, 0.5, 1, 720)</p>
<p>// 5m一个点存2d<br>
c.RRA(“AVERAGE”, 0.5, 5, 576)<br>
c.RRA(“MAX”, 0.5, 5, 576)<br>
c.RRA(“MIN”, 0.5, 5, 576)</p>
<p>// 20m一个点存7d<br>
c.RRA(“AVERAGE”, 0.5, 20, 504)<br>
c.RRA(“MAX”, 0.5, 20, 504)<br>
c.RRA(“MIN”, 0.5, 20, 504)</p>
<p>// 3小时一个点存3个月<br>
c.RRA(“AVERAGE”, 0.5, 180, 766)<br>
c.RRA(“MAX”, 0.5, 180, 766)<br>
c.RRA(“MIN”, 0.5, 180, 766)</p>
<p>// 1天一个点存5year<br>
c.RRA(“AVERAGE”, 0.5, 720, 730)<br>
c.RRA(“MAX”, 0.5, 720, 730)<br>
c.RRA(“MIN”, 0.5, 720, 730)<br>
“`</p>
<p>对于原始数据，transfer会打一份到hbase，也可以直接使用opentsdb，transfer支持往opentsdb写入数据。</p>
<h2># Committers</h2>
<ul>
<li>laiwei:  https://github.com/laiwei     来炜没睡醒@微博 / hellolaiwei@微信</li>
<li>秦晓辉: https://github.com/ulricqin  Ulricqin@微博 cnperl@微信</li>
</ul>
<h2># Contributors</h2>
<ul>
<li>近期我们会把绝大数的组件整理到 http://github.com/open-falcon ， 期待大家一起贡献，推动，做最开放、最好用的企业级监控系统。</li>
</ul>
<h2># TODO</h2>
<ul>
<li>metric的聚合</li>
<li>环比、同比报警判定</li>
<li>流量的突升突降判定</li>
</ul>
<h2># License</h2>
<p>Copyright 2014-2015 Xiaomi, Inc.<br>
Licensed under the Apache License,<br>
Version 2.0:</p>
<p>http://www.apache.org/licenses/LICENSE-2.0</p>
            
{% endraw %}
