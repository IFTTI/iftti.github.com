---
layout: post
title: '用MeCab打造一套实用的中文分词系统(三)：MeCab-Chinese'
time: 2015-04-28
site_name: 52nlp.cn
source_url: http://www.52nlp.cn/%e7%94%a8mecab%e6%89%93%e9%80%a0%e4%b8%80%e5%a5%97%e5%ae%9e%e7%94%a8%e7%9a%84%e4%b8%ad%e6%96%87%e5%88%86%e8%af%8d%e7%b3%bb%e7%bb%9f%e4%b8%89%ef%bc%9amecab-chinese
---
{% raw %}

						<p>我在Github上发布了一个MeCab中文分词项目: <a href="https://github.com/panyang/MeCab-Chinese" target="_blank">MeCab-Chinese</a> , 目的是提供一个用于中文分词和词性标注的MeCab词典和模型数据，类似MeCab日文IPA词典（mecab-ipadic），并且提供一些我自己用到的特征模板和脚本，方便大家从源头开始训练一个MeCab中文分词系统。</p>
<p>自从上次在愚人节的时候发布了一个mecab中文词典和数据模型之后（《<a href="http://www.52nlp.cn/%E7%94%A8mecab%E6%89%93%E9%80%A0%E4%B8%80%E5%A5%97%E5%AE%9E%E7%94%A8%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E7%B3%BB%E7%BB%9F%E4%BA%8C">用MeCab打造一套实用的中文分词系统(二)</a>》), 收到了一些反馈，而这些反馈又促使我深入的review了一下mecab，重新设计特征及特征模板，加入了一些新的词典数据，重新训练模型，感兴趣的同学可以先试试这个0.2版本： mecab-chinesedic-binary （链接: <a href="http://pan.baidu.com/s/1gdxnvFX">http://pan.baidu.com/s/1gdxnvFX</a> 密码: kq9g）<br>
注：目前所有发布的版本均默认utf-8编码，并且在Mac OS和Linux Ubuntu下测试有效，windows没有测试，感兴趣的同学可自行测试）</p>
<p>了解和安装mecab仍请参考：<br>
<a href="http://www.52nlp.cn/%E6%97%A5%E6%96%87%E5%88%86%E8%AF%8D%E5%99%A8-mecab-%E6%96%87%E6%A1%A3">日文分词器 Mecab 文档</a><br>
<a href="http://www.52nlp.cn/%E7%94%A8mecab%E6%89%93%E9%80%A0%E4%B8%80%E5%A5%97%E5%AE%9E%E7%94%A8%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E7%B3%BB%E7%BB%9F">用MeCab打造一套实用的中文分词系统</a></p>
<p>这里再补充一点，由于google code废弃的缘故，MeCab这个项目已经搬迁至github，但是一些资源反而不如之前那么好找了，可参考两个MeCab作者维护的页面:<br>
MeCab日文文档： <a href="http://taku910.github.io/mecab/">http://taku910.github.io/mecab/</a><br>
MeCab github 页面：<a href="https://github.com/taku910/mecab">https://github.com/taku910/mecab</a></p>
<p>MeCab目前最新的版本是2013-02-18更新的MeCab 0.996，我在Mac OS和Linux Ubuntu下用的是这个版本，在MeCab-Chinese下，做了一个备份，感兴趣的同学可以从这里下载: <a href="https://github.com/panyang/MeCab-Chinese/blob/master/mecab/mecab-0.996.tar.gz">MeCab 0.996</a><br>
<span id="more-8278"></span></p>
<p>在安装完毕MeCab之后，请下载这个模型词典数据，解压之后，可以这样执行：<br>
mecab -d mecab-chinesedic-binary<br>
自从上次在愚人节的时候发布了一个mecab中文词典和数据模型之后<br>
自从	p,p,BE,2,自从,zi_cong,自從<br>
上次	t,t,BE,2,上次,shang_ci,上次<br>
在	p,p,S,1,在,zai,在<br>
愚人	n,n,BE,2,愚人,yu_ren,愚人<br>
节	n,n,S,1,节,jie,節<br>
的	u,u,S,1,的,de,的<br>
时候	n,n,BE,2,时候,shi_hou,時候<br>
发布	v,v,BE,2,发布,fa_bu,發佈<br>
了	u,u,S,1,了,le,了<br>
一个	m,m,BE,2,一个,yi_ge,一個<br>
mecab	unk,unk,*,*,*,*,*<br>
中文	n,nz,BE,2,中文,zhong_wen,中文<br>
词典	n,n,BE,2,词典,ci_dian,詞典<br>
和	c,c,S,1,和,he,和<br>
数据	n,n,BE,2,数据,shu_ju,數據<br>
模型	n,n,BE,2,模型,mo_xing,模型<br>
之后	f,f,BE,2,之后,zhi_hou,之後<br>
EOS</p>
<p>如果想得到单行的中文分词输出结果，可以这样执行：<br>
mecab -d mecab-chinesedic-binary -O wakati<br>
自从上次在愚人节的时候发布了一个mecab中文词典和数据模型之后<br>
自从 上次 在 愚人 节 的 时候 发布 了 一个 mecab 中文 词典 和 数据 模型 之后 </p>
<p>如果想得到词性标注的输出结果，可以这样执行：<br>
mecab -d mecab-chinesedic-binary -O pos<br>
自从上次在愚人节的时候发布了一个mecab中文词典和数据模型之后<br>
自从/p 上次/t 在/p 愚人/n 节/n 的/u 时候/n 发布/v 了/u 一个/m mecab/unk 中文/nz 词典/n 和/c 数据/n 模型/n 之后/f </p>
<p>注意词性标记可以参考：《<a href="http://wenku.baidu.com/view/ded725fafab069dc502201bc.html">现代汉语语料库加工规范——词语切分与词性标注</a>》。</p>
<p>由于增加了拼音和繁体两个特征，这里还有两个副产品可以输出，一个是输出中文分词之后的对应拼音：<br>
mecab -d mecab-chinesedic-binary -O pinyin<br>
自从上次在愚人节的时候发布了一个mecab中文词典和数据模型之后<br>
自从/zi_cong 上次/shang_ci 在/zai 愚人/yu_ren 节/jie 的/de 时候/shi_hou 发布/fa_bu 了/le 一个/yi_ge mecab/unk 中文/zhong_wen 词典/ci_dian 和/he 数据/shu_ju 模型/mo_xing 之后/zhi_hou </p>
<p>另外一个是输出中文分词之后简体词到繁体词的转换:<br>
mecab -d mecab-chinesedic-binary -O fan<br>
自从上次在愚人节的时候发布了一个mecab中文词典和数据模型之后<br>
自从/自從 上次/上次 在/在 愚人/愚人 节/節 的/的 时候/時候 发布/發佈 了/了 一个/一個 mecab/unk 中文/中文 词典/詞典 和/和 数据/數據 模型/模型 之后/之後 </p>
<p>因为之前有同学留言如何输出词性标记，这个输出时可以指定格式或者在dicrc里面自定义，所以我在这个版本的dicrc里加了上述三种类型的输出：</p>
<div class="codecolorer-container text default" style="overflow:auto;white-space:nowrap;width:620px;"><table cellspacing="0" cellpadding="0"><tbody><tr>
<td class="line-numbers"><div>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>
</div></td>
<td><div class="text codecolorer">cost-factor = 800<br>
bos-feature = BOS/EOS,*,*,*,*,*,*<br>
eval-size = 7<br>
unk-eval-size = 4<br>
config-charset = UTF-8<br>
<br>
; pos<br>
node-format-pos = %m/%f[1]\s<br>
unk-format-pos = %m/unk\s<br>
eos-format-pos  = \n<br>
<br>
; pinyin<br>
node-format-pinyin = %m/%f[5]\s<br>
unk-format-pinyin = %m/unk\s<br>
eos-format-pinyin  = \n<br>
<br>
; fan<br>
node-format-fan = %m/%f[6]\s<br>
unk-format-fan = %m/unk\s<br>
eos-format-fan  = \n</div></td>
</tr></tbody></table></div>
<p>感兴趣的同学可以参考《<a href="http://www.52nlp.cn/%E6%97%A5%E6%96%87%E5%88%86%E8%AF%8D%E5%99%A8-mecab-%E6%96%87%E6%A1%A3#format.html">日文分词器 Mecab 文档</a>》里第四节关于输出格式的一些说明。</p>
<p>在backoff2005 人民日报语料库上的测试结果：</p>
<p>=== SUMMARY:<br>
=== TOTAL INSERTIONS:	3637<br>
=== TOTAL DELETIONS:	1643<br>
=== TOTAL SUBSTITUTIONS:	4969<br>
=== TOTAL NCHANGE:	10249<br>
=== TOTAL TRUE WORD COUNT:	104372<br>
=== TOTAL TEST WORD COUNT:	106366<br>
=== TOTAL TRUE WORDS RECALL:	0.937<br>
=== TOTAL TEST WORDS PRECISION:	0.919<br>
=== F MEASURE:	0.928<br>
=== OOV Rate:	0.058<br>
=== OOV Recall Rate:	0.495<br>
=== IV Recall Rate:	0.964<br>
###	pku_test.result	3637	1643	4969	10249	104372	106366	0.937	0.919	0.928	0.058	0.495	0.964</p>
<p>召回率93.7%，准确率91.9%, F值为92.8%, 比上一个版本略好一些，另外感兴趣的同学也可以通过这个版本的<a href="http://www.52nlp.com/zhong-wen-fen-ci">中文分词Demo</a> 进行测试。</p>
<p>==============================================================</p>
<p>如果觉得仅仅使用MeCab进行中文分词和词性标注还不过瘾，想自己train一个mecab分词所用的模型和词典，那么可以继续。之前在这里写过一篇<a href="http://www.52nlp.cn/%E7%94%A8mecab%E6%89%93%E9%80%A0%E4%B8%80%E5%A5%97%E5%AE%9E%E7%94%A8%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E7%B3%BB%E7%BB%9F">《用MeCab打造一套实用的中文分词系统》</a> ，但是回过头来再看，其实问题多多，特别是特征模板这块儿，有很多歉考虑的地方，不过整个套路应该是没问题的，所以依然有一定的参考价值。</p>
<p>这个版本里定义了7个特征：<br>
*词性1级分类（其实仅仅为了方便，取词性标记首字母而已）<br>
*词性2（这是真实的词性）<br>
*字标注tag(BEMS)<br>
*中文词字数<br>
*中文词基本型<br>
*拼音<br>
*繁体</p>
<p>所以训练语料需转换为如下的形式：</p>
<div class="codecolorer-container text default" style="overflow:auto;white-space:nowrap;width:620px;"><table cellspacing="0" cellpadding="0"><tbody><tr>
<td class="line-numbers"><div>1<br>2<br>3<br>4<br>5<br>6<br>7<br>
</div></td>
<td><div class="text codecolorer">中文  n,nz,BE,2,中文,zhong_wen,中文<br>
词典  n,n,BE,2,词典,ci_dian,詞典<br>
和 c,c,S,1,和,he,和<br>
数据  n,n,BE,2,数据,shu_ju,數據<br>
模型  n,n,BE,2,模型,mo_xing,模型<br>
之后  f,f,BE,2,之后,zhi_hou,之後<br>
EOS</div></td>
</tr></tbody></table></div>
<p>而词典文件需转换为如下的形式：</p>
<div class="codecolorer-container text default" style="overflow:auto;white-space:nowrap;width:620px;"><table cellspacing="0" cellpadding="0"><tbody><tr>
<td class="line-numbers"><div>1<br>2<br>3<br>4<br>5<br>6<br>
</div></td>
<td><div class="text codecolorer">中文,0,0,0,n,nz,BE,2,中文,zhong_wen,中文<br>
词典,0,0,0,n,n,BE,2,词典,ci_dian,詞典<br>
和,0,0,0,c,c,S,1,和,he,和<br>
数据,0,0,0,n,BE,2,数据,shu_ju,數據<br>
模型,0,0,0,n,n,BE,2,模型,mo_xing,模型<br>
之后,0,0,0,f,f,BE,2,之后,zhi_hou,之後</div></td>
</tr></tbody></table></div>
<p>关于这个版本对应的配置文件可以在<a href="https://github.com/panyang/MeCab-Chinese/tree/master/train/v0.2/seed">MeCab-Chinese</a>上查看, 其中dicrc和上述一致，这里就不说了。这里分别说一下几个配置文件。</p>
<p><a href="https://github.com/panyang/MeCab-Chinese/blob/master/train/v0.2/seed/char.def">char.def</a> 和 <a href="https://github.com/panyang/MeCab-Chinese/blob/master/train/v0.2/seed/unk.def">unk.def</a> 用于未登录词的处理，这里基本复用了mecab日文ipadic里的两个文件，做了少许修改：</p>
<div class="codecolorer-container text default" style="overflow:auto;white-space:nowrap;width:620px;"><table cellspacing="0" cellpadding="0"><tbody><tr>
<td class="line-numbers"><div>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>
</div></td>
<td><div class="text codecolorer">DEFAULT,0,0,0,unk,unk,*,*,*,*,*<br>
SPACE,0,0,0,unk,unk,*,*,*,*,*<br>
KANJI,0,0,0,unk,unk,*,*,*,*,*<br>
SYMBOL,0,0,0,unk,unk,*,*,*,*,*<br>
NUMERIC,0,0,0,unk,unk,*,*,*,*,*<br>
ALPHA,0,0,0,unk,unk,*,*,*,*,*<br>
HIRAGANA,0,0,0,unk,unk,*,*,*,*,*<br>
GREEK,0,0,0,unk,unk,*,*,*,*,*<br>
CYRILLIC,0,0,0,unk,unk,*,*,*,*,*<br>
KANJINUMERIC,0,0,0,unk,unk,*,*,*,*,*<br>
KATAKANA,0,0,0,unk,unk,*,*,*,*,*</div></td>
</tr></tbody></table></div>
<p><a href="https://github.com/panyang/MeCab-Chinese/blob/master/train/v0.2/seed/rewrite.def">rewrite.def</a>， 做了最小化的精简:</p>
<div class="codecolorer-container text default" style="overflow:auto;white-space:nowrap;width:620px;"><table cellspacing="0" cellpadding="0"><tbody><tr>
<td class="line-numbers"><div>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>
</div></td>
<td><div class="text codecolorer">[unigram rewrite]<br>
*,*,*,*,*,*,* \$1,\$2,\$3,\$4,\$5,\$6,\$7<br>
<br>
[left rewrite]<br>
*,*,*,*  \$1,\$2,\$3,\$4<br>
<br>
[right rewrite]<br>
*,*,*,*  \$1,\$2,\$3,\$4</div></td>
</tr></tbody></table></div>
<p><a href="https://github.com/panyang/MeCab-Chinese/blob/master/train/v0.2/seed/feature.def">feature.def</a>是crf特征模板，重新基于特征定义了一下：</p>
<div class="codecolorer-container text default" style="overflow:auto;white-space:nowrap;width:620px;height:450px;"><table cellspacing="0" cellpadding="0"><tbody><tr>
<td class="line-numbers"><div>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>69<br>70<br>71<br>72<br>73<br>74<br>75<br>76<br>77<br>78<br>79<br>80<br>81<br>82<br>83<br>84<br>85<br>86<br>87<br>
</div></td>
<td><div class="text codecolorer"># POS Unigram<br>
UNIGRAM U1:%F[0]<br>
UNIGRAM U2:%F[0],%F?[1]<br>
UNIGRAM U3:%F[0],%F[1],%F[2]<br>
<br>
# Word-POS<br>
UNIGRAM W0:%F[4]<br>
UNIGRAM W1:%F[0]/%F[4]<br>
UNIGRAM W2:%F[1]/%F[4]<br>
UNIGRAM W3:%F[2]/%F[4]<br>
UNIGRAM W4:%F[0],%F?[1]/%F[4]<br>
UNIGRAM W5:%F[1],%F?[2]/%F[4]<br>
UNIGRAM W6:%F[0],%F[1],%F?[2]/%F[4]<br>
<br>
# Word-Freq<br>
UNIGRAM WF0:%F[3]<br>
UNIGRAM WF1:%F[3]/%F[4]<br>
<br>
# POS-Freq<br>
UNIGRAM PF1:%F[0]/%F[3]<br>
UNIGRAM PF2:%F[1]/%F[3]<br>
UNIGRAM PF3:%F[0],%F?[1]/%F[3]<br>
UNIGRAM PF4:%F[1],%F?[2]/%F[3]<br>
UNIGRAM PF5:%F[0],%F[1],%F?[2]/%F[3]<br>
<br>
# Read-POS<br>
UNIGRAM RP0:%F[5]<br>
UNIGRAM RP1:%F[0]/%F[5]<br>
UNIGRAM RP2:%F[1]/%F[5]<br>
UNIGRAM RP3:%F[2]/%F[5]<br>
UNIGRAM RP4:%F[0],%F?[1]/%F[5]<br>
UNIGRAM RP5:%F[1],%F?[2]/%F[5]<br>
UNIGRAM RP6:%F[0],%F[1],%F?[2]/%F[5]<br>
<br>
# Fan-POS<br>
UNIGRAM RP0:%F[6]<br>
UNIGRAM RP1:%F[0]/%F[6]<br>
UNIGRAM RP2:%F[1]/%F[6]<br>
UNIGRAM RP3:%F[2]/%F[6]<br>
UNIGRAM RP4:%F[0],%F?[1]/%F[6]<br>
UNIGRAM RP5:%F[1],%F?[2]/%F[6]<br>
UNIGRAM RP6:%F[0],%F[1],%F?[2]/%F[6]<br>
<br>
# Word-Read-POS<br>
UNIGRAM R1:%F[4],%F[5]<br>
UNIGRAM R2:%F[0],%F[4],%F[5]<br>
UNIGRAM R3:%F[1],%F[4],%F[5]<br>
UNIGRAM R4:%F[2],%F[4],%F[5]<br>
UNIGRAM R5:%F[0],%F?[1],%F[4],%F[5]<br>
UNIGRAM R6:%F[1],%F?[2],%F[4],%F[5]<br>
UNIGRAM R7:%F[0],%F[1],%F?[2],%F[4],%F[5]<br>
<br>
# Word-Fan-POS<br>
UNIGRAM F1:%F[4],%F[6]<br>
UNIGRAM F2:%F[0],%F[4],%F[6]<br>
UNIGRAM F3:%F[1],%F[4],%F[6]<br>
UNIGRAM F4:%F[2],%F[4],%F[6]<br>
UNIGRAM F5:%F[0],%F?[1],%F[4],%F[6]<br>
UNIGRAM F6:%F[1],%F?[2],%F[4],%F[6]<br>
UNIGRAM F7:%F[0],%F[1],%F?[2],%F[4],%F[6]<br>
<br>
# char type<br>
UNIGRAM T0:%t<br>
UNIGRAM T1:%F[0]/%t<br>
UNIGRAM T2:%F[0],%F?[1]/%t<br>
UNIGRAM T3:%F[0],%F[1],%F?[2]/%t<br>
UNIGRAM T4:%F[0],%F[1],%F[2],%F?[3]/%t<br>
UNIGRAM T5:%F[0],%F[1],%F[2],%F[3],%F[4]/%t<br>
<br>
#<br>
# bigram<br>
#<br>
<br>
BIGRAM B00:%L[0]/%R[0]<br>
BIGRAM B01:%L[0],%L?[1]/%R[0]<br>
BIGRAM B02:%L[0]/%R[0],%R?[1]<br>
BIGRAM B03:%L[0]/%R[0],%R[1],%R?[2]<br>
BIGRAM B04:%L[0],%L?[1]/%R[0],%R[1],%R?[2]<br>
BIGRAM B05:%L[0]/%R[0],%R[1],%R[2],%R?[3]<br>
BIGRAM B06:%L[0],%L?[1]/%R[0],%R[1],%R[2],%R?[3]<br>
BIGRAM B07:%L[0],%L[1],%L?[2]/%R[0]<br>
BIGRAM B08:%L[0],%L[1],%L?[2]/%R[0],%R?[1]<br>
BIGRAM B09:%L[0],%L[1],%L[2],%L?[3]/%R[0]<br>
BIGRAM B10:%L[0],%L[1],%L[2],%L?[3]/%R[0],%R?[1]<br>
BIGRAM B11:%L[0],%L[1],%L?[2]/%R[0],%R[1],%R?[2]<br>
BIGRAM B12:%L[0],%L[1],%L?[2]/%R[0],%R[1],%R[2],%R?[3]<br>
BIGRAM B13:%L[0],%L[1],%L[2],%L?[3]/%R[0],%R[1],%R?[2]</div></td>
</tr></tbody></table></div>
<p>最后提供两个脚本，你只需按如下形式准备词典和训练语料即可：</p>
<p>词典格式：中文词/中文词性标记（这里不限制使用某个特定的词性标记）, 例如：<br>
中文/n<br>
词典/n<br>
和/c<br>
数据/n<br>
模型/n</p>
<p>语料格式：带词性标注即可<br>
中文/n 词典/n 和/c 数据/n 模型/n</p>
<p>具体可以参考<a href="https://github.com/panyang/MeCab-Chinese/tree/master/train/v0.2/script">script</a>的两个脚本文件: make_mecab_seed_data.py 和 make_mecab_train_data.py</p>
<p>注意，这里用的是这个汉字到拼音的转换方案，使用脚本前需要先安装: <a href="https://github.com/cleverdeng/pinyin.py">https://github.com/cleverdeng/pinyin.py</a></p>
<p>另外汉字简体到繁体的转换代码已经拷贝和数据已经放到script目录下，不需要安装了，这个来源于：<a href="https://github.com/skydark/nstools">https://github.com/skydark/nstools</a></p>
<p>执行上述两个脚本的时候都需要在script目录下执行，需要load一些数据。</p>
<p>ok，MeCab-Chinese的一些介绍就到此为止了，欢迎大家一起参与共建MeCab-Chinese。</p>
<p>注：原创文章，转载请注明出处“<a href="http://www.52nlp.cn">我爱自然语言处理</a>”：<a href="http://www.52nlp.cn">www.52nlp.cn</a></p>
<p>本文链接地址：<a href="http://www.52nlp.cn/?p=8278">用mecab打造一套实用的中文分词系统三：mecab-chinese</a></p>

											
{% endraw %}
