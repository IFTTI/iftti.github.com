---
layout: post
title: '中英文维基百科语料上的Word2Vec实验'
time: 2015-03-12
site_name: 52nlp.cn
source_url: http://www.52nlp.cn/%e4%b8%ad%e8%8b%b1%e6%96%87%e7%bb%b4%e5%9f%ba%e7%99%be%e7%a7%91%e8%af%ad%e6%96%99%e4%b8%8a%e7%9a%84word2vec%e5%ae%9e%e9%aa%8c
---
{% raw %}

						<p>最近试了一下<a href="https://code.google.com/p/word2vec/">Word2Vec</a>, <a href="http://nlp.stanford.edu/projects/glove/">GloVe</a> 以及对应的python版本 <a href="http://radimrehurek.com/gensim/models/word2vec.html">gensim word2vec</a> 和 <a href="https://github.com/maciejkula/glove-python">python-glove</a>，就有心在一个更大规模的语料上测试一下，自然而然维基百科的语料进入了视线。维基百科官方提供了一个很好的维基百科数据源：<a href="https://dumps.wikimedia.org">https://dumps.wikimedia.org</a>，可以方便的下载多种语言多种格式的维基百科数据。此前通过gensim的玩过英文的维基百科语料并训练LSI，LDA模型来<a href="http://www.52nlp.cn/%E5%A6%82%E4%BD%95%E8%AE%A1%E7%AE%97%E4%B8%A4%E4%B8%AA%E6%96%87%E6%A1%A3%E7%9A%84%E7%9B%B8%E4%BC%BC%E5%BA%A6%E4%B8%80">计算两个文档的相似度</a>，所以想看看gensim有没有提供一种简便的方式来处理维基百科数据，训练word2vec模型，用于计算词语之间的语义相似度。感谢Google，在gensim的google group下，找到了一个很长的讨论帖：<a href="https://groups.google.com/forum/#!topic/gensim/MJWrDw_IvXw">training word2vec on full Wikipedia</a> ，这个帖子基本上把如何使用gensim在维基百科语料上训练word2vec模型的问题说清楚了，甚至参与讨论的gensim的作者Radim Řehůřek博士还在新的gensim版本里加了一点修正，而对于我来说，所做的工作就是做一下验证而已。虽然github上有一个<a href="https://github.com/idio/wiki2vec">wiki2vec</a>的项目也是做得这个事，不过我更喜欢用python gensim的方式解决问题。</p>
<p>关于word2vec，这方面无论中英文的参考资料相当的多，英文方面既可以看官方推荐的论文，也可以看gensim作者Radim Řehůřek博士写得一些<a href="http://radimrehurek.com/category/gensim/">文章</a>。而中文方面，推荐 <a href="http://weibo.com/licstar">@licstar</a>的《<a href="http://licstar.net/archives/328">Deep Learning in NLP （一）词向量和语言模型</a>》，有道技术沙龙的《<a href="http://techblog.youdao.com/?p=915">Deep Learning实战之word2vec</a>》，<a href="http://weibo.com/lovekym">@飞林沙</a> 的《<a href="http://www.douban.com/note/298095260/">word2vec的学习思路</a>》, falao_beiliu 的《<a href="http://blog.csdn.net/mytestmy/article/details/26961315">深度学习word2vec笔记之基础篇</a>》和《<a href="http://blog.csdn.net/mytestmy/article/details/26969149">深度学习word2vec笔记之算法篇</a>》等。<br>
<span id="more-8198"></span></p>
<p><strong>一、英文维基百科的Word2Vec测试</strong></p>
<p>首先测试了英文维基百科的数据，下载的是xml压缩后的最新数据（下载日期是2015年3月1号），大概11G，下载地址：</p>
<p><a href="https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2">https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-pages-articles.xml.bz2</a></p>
<p>处理包括两个阶段，首先将xml的wiki数据转换为text格式，通过下面这个脚本(process_wiki.py)实现：</p>

<div class="wp_syntax"><table><tr><td class="code"><pre class="python" style="font-family:monospace;"><span style="color: #808080; font-style: italic;">#!/usr/bin/env python</span>
<span style="color: #808080; font-style: italic;"># -*- coding: utf-8 -*-</span>
 
<span style="color: #ff7700;font-weight:bold;">import</span> <span style="color: #dc143c;">logging</span>
<span style="color: #ff7700;font-weight:bold;">import</span> <span style="color: #dc143c;">os</span>.<span style="color: black;">path</span>
<span style="color: #ff7700;font-weight:bold;">import</span> <span style="color: #dc143c;">sys</span>
 
<span style="color: #ff7700;font-weight:bold;">from</span> gensim.<span style="color: black;">corpora</span> <span style="color: #ff7700;font-weight:bold;">import</span> WikiCorpus
 
<span style="color: #ff7700;font-weight:bold;">if</span> __name__ <span style="color: #66cc66;">==</span> <span style="color: #483d8b;">'__main__'</span>:
    program <span style="color: #66cc66;">=</span> <span style="color: #dc143c;">os</span>.<span style="color: black;">path</span>.<span style="color: black;">basename</span><span style="color: black;">(</span><span style="color: #dc143c;">sys</span>.<span style="color: black;">argv</span><span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: black;">)</span>
    logger <span style="color: #66cc66;">=</span> <span style="color: #dc143c;">logging</span>.<span style="color: black;">getLogger</span><span style="color: black;">(</span>program<span style="color: black;">)</span>
 
    <span style="color: #dc143c;">logging</span>.<span style="color: black;">basicConfig</span><span style="color: black;">(</span>format<span style="color: #66cc66;">=</span><span style="color: #483d8b;">'%(asctime)s: %(levelname)s: %(message)s'</span><span style="color: black;">)</span>
    <span style="color: #dc143c;">logging</span>.<span style="color: black;">root</span>.<span style="color: black;">setLevel</span><span style="color: black;">(</span>level<span style="color: #66cc66;">=</span><span style="color: #dc143c;">logging</span>.<span style="color: black;">INFO</span><span style="color: black;">)</span>
    logger.<span style="color: black;">info</span><span style="color: black;">(</span><span style="color: #483d8b;">"running %s"</span> % <span style="color: #483d8b;">' '</span>.<span style="color: black;">join</span><span style="color: black;">(</span><span style="color: #dc143c;">sys</span>.<span style="color: black;">argv</span><span style="color: black;">)</span><span style="color: black;">)</span>
 
    <span style="color: #808080; font-style: italic;"># check and process input arguments</span>
    <span style="color: #ff7700;font-weight:bold;">if</span> <span style="color: #008000;">len</span><span style="color: black;">(</span><span style="color: #dc143c;">sys</span>.<span style="color: black;">argv</span><span style="color: black;">)</span> <span style="color: #66cc66;">&lt;</span> <span style="color: #ff4500;">3</span>:
        <span style="color: #ff7700;font-weight:bold;">print</span> <span style="color: #008000;">globals</span><span style="color: black;">(</span><span style="color: black;">)</span><span style="color: black;">[</span><span style="color: #483d8b;">'__doc__'</span><span style="color: black;">]</span> % <span style="color: #008000;">locals</span><span style="color: black;">(</span><span style="color: black;">)</span>
        <span style="color: #dc143c;">sys</span>.<span style="color: black;">exit</span><span style="color: black;">(</span><span style="color: #ff4500;">1</span><span style="color: black;">)</span>
    inp<span style="color: #66cc66;">,</span> outp <span style="color: #66cc66;">=</span> <span style="color: #dc143c;">sys</span>.<span style="color: black;">argv</span><span style="color: black;">[</span><span style="color: #ff4500;">1</span>:<span style="color: #ff4500;">3</span><span style="color: black;">]</span>
    space <span style="color: #66cc66;">=</span> <span style="color: #483d8b;">" "</span>
    i <span style="color: #66cc66;">=</span> <span style="color: #ff4500;">0</span>
 
    output <span style="color: #66cc66;">=</span> <span style="color: #008000;">open</span><span style="color: black;">(</span>outp<span style="color: #66cc66;">,</span> <span style="color: #483d8b;">'w'</span><span style="color: black;">)</span>
    wiki <span style="color: #66cc66;">=</span> WikiCorpus<span style="color: black;">(</span>inp<span style="color: #66cc66;">,</span> lemmatize<span style="color: #66cc66;">=</span><span style="color: #008000;">False</span><span style="color: #66cc66;">,</span> dictionary<span style="color: #66cc66;">=</span><span style="color: black;">{</span><span style="color: black;">}</span><span style="color: black;">)</span>
    <span style="color: #ff7700;font-weight:bold;">for</span> text <span style="color: #ff7700;font-weight:bold;">in</span> wiki.<span style="color: black;">get_texts</span><span style="color: black;">(</span><span style="color: black;">)</span>:
        output.<span style="color: black;">write</span><span style="color: black;">(</span>space.<span style="color: black;">join</span><span style="color: black;">(</span>text<span style="color: black;">)</span> + <span style="color: #483d8b;">"<span style="color: #000099; font-weight: bold;">\n</span>"</span><span style="color: black;">)</span>
        i <span style="color: #66cc66;">=</span> i + <span style="color: #ff4500;">1</span>
        <span style="color: #ff7700;font-weight:bold;">if</span> <span style="color: black;">(</span>i % <span style="color: #ff4500;">10000</span> <span style="color: #66cc66;">==</span> <span style="color: #ff4500;">0</span><span style="color: black;">)</span>:
            logger.<span style="color: black;">info</span><span style="color: black;">(</span><span style="color: #483d8b;">"Saved "</span> + <span style="color: #008000;">str</span><span style="color: black;">(</span>i<span style="color: black;">)</span> + <span style="color: #483d8b;">" articles"</span><span style="color: black;">)</span>
 
    output.<span style="color: black;">close</span><span style="color: black;">(</span><span style="color: black;">)</span>
    logger.<span style="color: black;">info</span><span style="color: black;">(</span><span style="color: #483d8b;">"Finished Saved "</span> + <span style="color: #008000;">str</span><span style="color: black;">(</span>i<span style="color: black;">)</span> + <span style="color: #483d8b;">" articles"</span><span style="color: black;">)</span></pre></td></tr></table></div>

<p>这里利用了gensim里的维基百科处理类WikiCorpus，通过get_texts将维基里的每篇文章转换位1行text文本，并且去掉了标点符号等内容，注意这里“wiki = WikiCorpus(inp, lemmatize=False, dictionary={})”将lemmatize设置为False的主要目的是不使用pattern模块来进行英文单词的词干化处理，无论你的电脑是否已经安装了pattern，因为使用pattern会严重影响这个处理过程，变得很慢。</p>
<p>执行”python process_wiki.py enwiki-latest-pages-articles.xml.bz2 wiki.en.text”:</p>

<div class="wp_syntax"><table><tr><td class="code"><pre class="python" style="font-family:monospace;"><span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">08</span>:<span style="color: #ff4500;">39</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">181</span>: INFO: running process_enwiki.<span style="color: black;">py</span> enwiki-latest-pages-articles.<span style="color: #dc143c;">xml</span>.<span style="color: #dc143c;">bz2</span> wiki.<span style="color: black;">en</span>.<span style="color: black;">text</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">11</span>:<span style="color: #ff4500;">12</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">860</span>: INFO: Saved <span style="color: #ff4500;">10000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">13</span>:<span style="color: #ff4500;">25</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">369</span>: INFO: Saved <span style="color: #ff4500;">20000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">19</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">771</span>: INFO: Saved <span style="color: #ff4500;">30000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">16</span>:<span style="color: #ff4500;">58</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">424</span>: INFO: Saved <span style="color: #ff4500;">40000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">12</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">374</span>: INFO: Saved <span style="color: #ff4500;">50000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">03</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">213</span>: INFO: Saved <span style="color: #ff4500;">60000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">47</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">656</span>: INFO: Saved <span style="color: #ff4500;">70000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">20</span>:<span style="color: #ff4500;">29</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">135</span>: INFO: Saved <span style="color: #ff4500;">80000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">02</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">365</span>: INFO: Saved <span style="color: #ff4500;">90000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">40</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">141</span>: INFO: Saved <span style="color: #ff4500;">100000</span> articles
.....
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">33</span>:<span style="color: #ff4500;">16</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">549</span>: INFO: Saved <span style="color: #ff4500;">3700000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">33</span>:<span style="color: #ff4500;">49</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">493</span>: INFO: Saved <span style="color: #ff4500;">3710000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">34</span>:<span style="color: #ff4500;">23</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">442</span>: INFO: Saved <span style="color: #ff4500;">3720000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">34</span>:<span style="color: #ff4500;">57</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">984</span>: INFO: Saved <span style="color: #ff4500;">3730000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">35</span>:<span style="color: #ff4500;">31</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">976</span>: INFO: Saved <span style="color: #ff4500;">3740000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">36</span>:<span style="color: #ff4500;">05</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">790</span>: INFO: Saved <span style="color: #ff4500;">3750000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">36</span>:<span style="color: #ff4500;">32</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">392</span>: INFO: finished iterating over Wikipedia corpus of <span style="color: #ff4500;">3758076</span> documents <span style="color: #ff7700;font-weight:bold;">with</span> <span style="color: #ff4500;">2018886604</span> positions <span style="color: black;">(</span>total <span style="color: #ff4500;">15271374</span> articles<span style="color: #66cc66;">,</span> <span style="color: #ff4500;">2075130438</span> positions before pruning articles shorter than <span style="color: #ff4500;">50</span> words<span style="color: black;">)</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">07</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">36</span>:<span style="color: #ff4500;">32</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">394</span>: INFO: Finished Saved <span style="color: #ff4500;">3758076</span> articles</pre></td></tr></table></div>

<p>在我的macpro（4核16G机器）大约跑了4个半小时，处理了375万的文章后，我们得到了一个12G的text格式的英文维基百科数据wiki.en.text，格式类似这样的：</p>
<blockquote><p>anarchism is collection of movements and ideologies that hold the state to be undesirable unnecessary or harmful these movements advocate some form of stateless society instead often based on self governed voluntary institutions or non hierarchical free associations although anti statism is central to anarchism as political philosophy anarchism also entails rejection of and often hierarchical organisation in general as an anti dogmatic philosophy anarchism draws on many currents of thought and strategy anarchism does not offer fixed body of doctrine from single particular world view instead fluxing and flowing as philosophy there are many types and traditions of anarchism not all of which are mutually exclusive anarchist schools of thought can differ fundamentally supporting anything from extreme individualism to complete collectivism strains of anarchism have often been divided into the categories of social and individualist anarchism or similar dual classifications anarchism is usually considered radical left wing ideology and much of anarchist economics and anarchist legal philosophy reflect anti authoritarian interpretations of communism collectivism syndicalism mutualism or participatory economics etymology and terminology the term anarchism is compound word composed from the word anarchy and the suffix ism themselves derived respectively from the greek anarchy from anarchos meaning one without rulers from the privative prefix ἀν an without and archos leader ruler cf archon or arkhē authority sovereignty realm magistracy and the suffix or ismos isma from the verbal infinitive suffix…</p></blockquote>
<p>有了这个数据后，无论用原始的word2vec binary版本还是gensim中的python word2vec版本，都可以用来训练word2vec模型，不过我们试了一下前者，发现很慢，所以还是采用google group 讨论帖中的gensim word2vec方式的训练脚本，不过做了一点修改，保留了vector text格式的输出，方便debug, 脚本train_word2vec_model.py如下：</p>

<div class="wp_syntax"><table><tr><td class="code"><pre class="python" style="font-family:monospace;"><span style="color: #808080; font-style: italic;">#!/usr/bin/env python</span>
<span style="color: #808080; font-style: italic;"># -*- coding: utf-8 -*-</span>
 
<span style="color: #ff7700;font-weight:bold;">import</span> <span style="color: #dc143c;">logging</span>
<span style="color: #ff7700;font-weight:bold;">import</span> <span style="color: #dc143c;">os</span>.<span style="color: black;">path</span>
<span style="color: #ff7700;font-weight:bold;">import</span> <span style="color: #dc143c;">sys</span>
<span style="color: #ff7700;font-weight:bold;">import</span> multiprocessing
 
<span style="color: #ff7700;font-weight:bold;">from</span> gensim.<span style="color: black;">corpora</span> <span style="color: #ff7700;font-weight:bold;">import</span> WikiCorpus
<span style="color: #ff7700;font-weight:bold;">from</span> gensim.<span style="color: black;">models</span> <span style="color: #ff7700;font-weight:bold;">import</span> Word2Vec
<span style="color: #ff7700;font-weight:bold;">from</span> gensim.<span style="color: black;">models</span>.<span style="color: black;">word2vec</span> <span style="color: #ff7700;font-weight:bold;">import</span> LineSentence
 
<span style="color: #ff7700;font-weight:bold;">if</span> __name__ <span style="color: #66cc66;">==</span> <span style="color: #483d8b;">'__main__'</span>:
    program <span style="color: #66cc66;">=</span> <span style="color: #dc143c;">os</span>.<span style="color: black;">path</span>.<span style="color: black;">basename</span><span style="color: black;">(</span><span style="color: #dc143c;">sys</span>.<span style="color: black;">argv</span><span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: black;">)</span>
    logger <span style="color: #66cc66;">=</span> <span style="color: #dc143c;">logging</span>.<span style="color: black;">getLogger</span><span style="color: black;">(</span>program<span style="color: black;">)</span>
 
    <span style="color: #dc143c;">logging</span>.<span style="color: black;">basicConfig</span><span style="color: black;">(</span>format<span style="color: #66cc66;">=</span><span style="color: #483d8b;">'%(asctime)s: %(levelname)s: %(message)s'</span><span style="color: black;">)</span>
    <span style="color: #dc143c;">logging</span>.<span style="color: black;">root</span>.<span style="color: black;">setLevel</span><span style="color: black;">(</span>level<span style="color: #66cc66;">=</span><span style="color: #dc143c;">logging</span>.<span style="color: black;">INFO</span><span style="color: black;">)</span>
    logger.<span style="color: black;">info</span><span style="color: black;">(</span><span style="color: #483d8b;">"running %s"</span> % <span style="color: #483d8b;">' '</span>.<span style="color: black;">join</span><span style="color: black;">(</span><span style="color: #dc143c;">sys</span>.<span style="color: black;">argv</span><span style="color: black;">)</span><span style="color: black;">)</span>
 
    <span style="color: #808080; font-style: italic;"># check and process input arguments</span>
    <span style="color: #ff7700;font-weight:bold;">if</span> <span style="color: #008000;">len</span><span style="color: black;">(</span><span style="color: #dc143c;">sys</span>.<span style="color: black;">argv</span><span style="color: black;">)</span> <span style="color: #66cc66;">&lt;</span> <span style="color: #ff4500;">4</span>:
        <span style="color: #ff7700;font-weight:bold;">print</span> <span style="color: #008000;">globals</span><span style="color: black;">(</span><span style="color: black;">)</span><span style="color: black;">[</span><span style="color: #483d8b;">'__doc__'</span><span style="color: black;">]</span> % <span style="color: #008000;">locals</span><span style="color: black;">(</span><span style="color: black;">)</span>
        <span style="color: #dc143c;">sys</span>.<span style="color: black;">exit</span><span style="color: black;">(</span><span style="color: #ff4500;">1</span><span style="color: black;">)</span>
    inp<span style="color: #66cc66;">,</span> outp1<span style="color: #66cc66;">,</span> outp2 <span style="color: #66cc66;">=</span> <span style="color: #dc143c;">sys</span>.<span style="color: black;">argv</span><span style="color: black;">[</span><span style="color: #ff4500;">1</span>:<span style="color: #ff4500;">4</span><span style="color: black;">]</span>
 
    model <span style="color: #66cc66;">=</span> Word2Vec<span style="color: black;">(</span>LineSentence<span style="color: black;">(</span>inp<span style="color: black;">)</span><span style="color: #66cc66;">,</span> size<span style="color: #66cc66;">=</span><span style="color: #ff4500;">400</span><span style="color: #66cc66;">,</span> window<span style="color: #66cc66;">=</span><span style="color: #ff4500;">5</span><span style="color: #66cc66;">,</span> min_count<span style="color: #66cc66;">=</span><span style="color: #ff4500;">5</span><span style="color: #66cc66;">,</span>
            workers<span style="color: #66cc66;">=</span>multiprocessing.<span style="color: black;">cpu_count</span><span style="color: black;">(</span><span style="color: black;">)</span><span style="color: black;">)</span>
 
    <span style="color: #808080; font-style: italic;"># trim unneeded model memory = use(much) less RAM</span>
    <span style="color: #808080; font-style: italic;">#model.init_sims(replace=True)</span>
    model.<span style="color: black;">save</span><span style="color: black;">(</span>outp1<span style="color: black;">)</span>
    model.<span style="color: black;">save_word2vec_format</span><span style="color: black;">(</span>outp2<span style="color: #66cc66;">,</span> binary<span style="color: #66cc66;">=</span><span style="color: #008000;">False</span><span style="color: black;">)</span></pre></td></tr></table></div>

<p>执行 “python train_word2vec_model.py wiki.en.text wiki.en.text.model wiki.en.text.vector”:</p>

<div class="wp_syntax"><table><tr><td class="code"><pre class="python" style="font-family:monospace;"><span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">48</span>:<span style="color: #ff4500;">29</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">588</span>: INFO: running train_word2vec_model.<span style="color: black;">py</span> wiki.<span style="color: black;">en</span>.<span style="color: black;">text</span> wiki.<span style="color: black;">en</span>.<span style="color: black;">text</span>.<span style="color: black;">model</span> wiki.<span style="color: black;">en</span>.<span style="color: black;">text</span>.<span style="color: black;">vector</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">48</span>:<span style="color: #ff4500;">29</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">593</span>: INFO: collecting <span style="color: #008000;">all</span> words <span style="color: #ff7700;font-weight:bold;">and</span> their counts
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">48</span>:<span style="color: #ff4500;">29</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">607</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#0, processed 0 words and 0 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">48</span>:<span style="color: #ff4500;">50</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">686</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#10000, processed 29353579 words and 430650 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">49</span>:<span style="color: #ff4500;">08</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">476</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#20000, processed 54695775 words and 610833 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">49</span>:<span style="color: #ff4500;">22</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">985</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#30000, processed 75344844 words and 742274 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">49</span>:<span style="color: #ff4500;">35</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">607</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#40000, processed 93430415 words and 859131 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">49</span>:<span style="color: #ff4500;">44</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">125</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#50000, processed 106057188 words and 935606 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">49</span>:<span style="color: #ff4500;">49</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">185</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#60000, processed 114319016 words and 952771 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">49</span>:<span style="color: #ff4500;">53</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">316</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#70000, processed 121263134 words and 969526 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">49</span>:<span style="color: #ff4500;">57</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">268</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#80000, processed 127773799 words and 984130 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">50</span>:<span style="color: #ff4500;">07</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">593</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#90000, processed 142688762 words and 1062932 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">50</span>:<span style="color: #ff4500;">19</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">162</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#100000, processed 159550824 words and 1157644 word </span>
<span style="color: #dc143c;">types</span>
......
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">11</span>:<span style="color: #ff4500;">52</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">977</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#3700000, processed 1999452503 words and 7990138 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">11</span>:<span style="color: #ff4500;">55</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">367</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#3710000, processed 2002777270 words and 8002903 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">11</span>:<span style="color: #ff4500;">57</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">842</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#3720000, processed 2006213923 words and 8019620 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">12</span>:<span style="color: #ff4500;">00</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">439</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#3730000, processed 2009762733 words and 8035408 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">12</span>:<span style="color: #ff4500;">02</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">793</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#3740000, processed 2013066196 words and 8045218 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">12</span>:<span style="color: #ff4500;">05</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">178</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#3750000, processed 2016363087 words and 8057784 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">12</span>:<span style="color: #ff4500;">07</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">013</span>: INFO: collected <span style="color: #ff4500;">8069236</span> word <span style="color: #dc143c;">types</span> <span style="color: #ff7700;font-weight:bold;">from</span> a corpus of <span style="color: #ff4500;">2018886604</span> words <span style="color: #ff7700;font-weight:bold;">and</span> <span style="color: #ff4500;">3758076</span> sentences
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">12</span>:<span style="color: #ff4500;">12</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">230</span>: INFO: total <span style="color: #ff4500;">1969354</span> word <span style="color: #dc143c;">types</span> after removing those <span style="color: #ff7700;font-weight:bold;">with</span> count<span style="color: #66cc66;">&lt;</span><span style="color: #ff4500;">5</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">12</span>:<span style="color: #ff4500;">12</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">230</span>: INFO: constructing a huffman tree <span style="color: #ff7700;font-weight:bold;">from</span> <span style="color: #ff4500;">1969354</span> words
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">14</span>:<span style="color: #ff4500;">07</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">415</span>: INFO: built huffman tree <span style="color: #ff7700;font-weight:bold;">with</span> maximum node depth <span style="color: #ff4500;">29</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">14</span>:<span style="color: #ff4500;">09</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">790</span>: INFO: resetting layer weights
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">04</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">506</span>: INFO: training model <span style="color: #ff7700;font-weight:bold;">with</span> <span style="color: #ff4500;">4</span> workers on <span style="color: #ff4500;">1969354</span> vocabulary <span style="color: #ff7700;font-weight:bold;">and</span> <span style="color: #ff4500;">400</span> features<span style="color: #66cc66;">,</span> using <span style="color: #483d8b;">'skipgram'</span><span style="color: #66cc66;">=</span><span style="color: #ff4500;">1</span> <span style="color: #483d8b;">'hierarchical softmax'</span><span style="color: #66cc66;">=</span><span style="color: #ff4500;">1</span> <span style="color: #483d8b;">'subsample'</span><span style="color: #66cc66;">=</span><span style="color: #ff4500;">0</span> <span style="color: #ff7700;font-weight:bold;">and</span> <span style="color: #483d8b;">'negative sampling'</span><span style="color: #66cc66;">=</span><span style="color: #ff4500;">0</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">19</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">112</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.01</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02500</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">19098</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">20</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">224</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.03</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02500</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">37671</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">22</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">305</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.07</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02500</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">75393</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">27</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">712</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.08</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02499</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">65618</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">29</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">452</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.09</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02500</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">70966</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">34</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">032</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.11</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02498</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">77369</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">37</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">249</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.12</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02498</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">74935</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">40</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">618</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.14</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02498</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">75399</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">42</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">301</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.16</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02497</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">86029</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">46</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">283</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.17</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02497</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">83033</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">48</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">374</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.18</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02497</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">83370</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">51</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">398</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.19</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02496</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">82794</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">55</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">069</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.21</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02496</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">83753</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">15</span>:<span style="color: #ff4500;">57</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">718</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.23</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02496</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">85031</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">16</span>:<span style="color: #ff4500;">00</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">106</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.24</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02495</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">86567</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">16</span>:<span style="color: #ff4500;">05</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">523</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.26</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02495</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">84850</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">16</span>:<span style="color: #ff4500;">06</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">596</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.27</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02495</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">87926</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">16</span>:<span style="color: #ff4500;">09</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">500</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.29</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02494</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">88618</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">16</span>:<span style="color: #ff4500;">10</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">714</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.30</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02494</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">91023</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">16</span>:<span style="color: #ff4500;">18</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">467</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.32</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02494</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">85960</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">16</span>:<span style="color: #ff4500;">19</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">547</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.33</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02493</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">89140</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">16</span>:<span style="color: #ff4500;">23</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">500</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.36</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02493</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">92026</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">16</span>:<span style="color: #ff4500;">29</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">738</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.37</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02491</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">88180</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">16</span>:<span style="color: #ff4500;">32</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">000</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.40</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02492</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">92734</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">16</span>:<span style="color: #ff4500;">34</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">392</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.42</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02491</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">93300</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">09</span> <span style="color: #ff4500;">23</span>:<span style="color: #ff4500;">16</span>:<span style="color: #ff4500;">41</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">018</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.43</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02490</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">89727</span> words/s
.......
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">03</span>:<span style="color: #ff4500;">31</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">849</span>: INFO: PROGRESS: at <span style="color: #ff4500;">99.20</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.00020</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">95350</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">03</span>:<span style="color: #ff4500;">32</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">901</span>: INFO: PROGRESS: at <span style="color: #ff4500;">99.21</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.00020</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">95350</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">03</span>:<span style="color: #ff4500;">34</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">296</span>: INFO: PROGRESS: at <span style="color: #ff4500;">99.21</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.00020</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">95350</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">03</span>:<span style="color: #ff4500;">35</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">635</span>: INFO: PROGRESS: at <span style="color: #ff4500;">99.22</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.00020</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">95349</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">03</span>:<span style="color: #ff4500;">36</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">730</span>: INFO: PROGRESS: at <span style="color: #ff4500;">99.22</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.00020</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">95350</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">03</span>:<span style="color: #ff4500;">37</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">489</span>: INFO: reached the end of <span style="color: #008000;">input</span><span style="color: #66cc66;">;</span> waiting to finish <span style="color: #ff4500;">8</span> outstanding jobs
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">03</span>:<span style="color: #ff4500;">37</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">908</span>: INFO: PROGRESS: at <span style="color: #ff4500;">99.23</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.00019</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">95350</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">03</span>:<span style="color: #ff4500;">39</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">028</span>: INFO: PROGRESS: at <span style="color: #ff4500;">99.23</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.00019</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">95350</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">03</span>:<span style="color: #ff4500;">40</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">127</span>: INFO: PROGRESS: at <span style="color: #ff4500;">99.24</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.00019</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">95350</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">03</span>:<span style="color: #ff4500;">40</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">910</span>: INFO: training on <span style="color: #ff4500;">1994415728</span> words took 20916.4s<span style="color: #66cc66;">,</span> <span style="color: #ff4500;">95352</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">03</span>:<span style="color: #ff4500;">41</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">058</span>: INFO: saving Word2Vec <span style="color: #008000;">object</span> under wiki.<span style="color: black;">en</span>.<span style="color: black;">text</span>.<span style="color: black;">model</span><span style="color: #66cc66;">,</span> separately <span style="color: #008000;">None</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">03</span>:<span style="color: #ff4500;">41</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">209</span>: INFO: <span style="color: #ff7700;font-weight:bold;">not</span> storing attribute syn0norm
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">03</span>:<span style="color: #ff4500;">41</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">209</span>: INFO: storing numpy <span style="color: #dc143c;">array</span> <span style="color: #483d8b;">'syn0'</span> to wiki.<span style="color: black;">en</span>.<span style="color: black;">text</span>.<span style="color: black;">model</span>.<span style="color: black;">syn0</span>.<span style="color: black;">npy</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">04</span>:<span style="color: #ff4500;">35</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">199</span>: INFO: storing numpy <span style="color: #dc143c;">array</span> <span style="color: #483d8b;">'syn1'</span> to wiki.<span style="color: black;">en</span>.<span style="color: black;">text</span>.<span style="color: black;">model</span>.<span style="color: black;">syn1</span>.<span style="color: black;">npy</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">10</span> <span style="color: #ff4500;">05</span>:<span style="color: #ff4500;">11</span>:<span style="color: #ff4500;">25</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">400</span>: INFO: storing 1969354x400 projection weights into wiki.<span style="color: black;">en</span>.<span style="color: black;">text</span>.<span style="color: black;">vector</span></pre></td></tr></table></div>

<p>大约跑了7个小时，我们得到了一个gensim中默认格式的word2vec model和一个原始c版本word2vec的vector格式的模型: wiki.en.text.vector，格式如下：</p>
<blockquote><p>1969354 400<br>
the 0.129255 0.015725 0.049174 -0.016438 -0.018912 0.032752 0.079885 0.033669 -0.077722 -0.025709 0.012775 0.044153 0.134307 0.070499 -0.002243 0.105198 -0.016832 -0.028631 -0.124312 -0.123064 -0.116838 0.051181 -0.096058 -0.049734 0.017380 -0.101221 0.058945 0.013669 -0.012755 0.061053 0.061813 0.083655 -0.069382 -0.069868 0.066529 -0.037156 -0.072935 -0.009470 0.037412 -0.004406 0.047011 0.005033 -0.066270 -0.031815 0.023160 -0.080117 0.172918 0.065486 -0.072161 0.062875 0.019939 -0.048380 0.198152 -0.098525 0.023434 0.079439 0.045150 -0.079479 -0.051441 -0.021556 -0.024981 -0.045291 0.040284 -0.082500 0.014618 -0.071998 0.031887 0.043916 0.115783 -0.174898 0.086603 -0.023124 0.007293 -0.066576 -0.164817 -0.081223 0.058412 0.000132 0.064160 0.055848 0.029776 -0.103420 -0.007541 -0.031742 0.082533 -0.061760 -0.038961 0.001754 -0.023977 0.069616 0.095920 0.017136 0.067126 -0.111310 0.053632 0.017633 -0.003875 -0.005236 0.063151 0.039729 -0.039158 0.001415 0.021754 -0.012540 0.015070 -0.062636 -0.013605 -0.031770 0.005296 -0.078119 -0.069303 -0.080634 -0.058377 0.024398 -0.028173 0.026353 0.088662 0.018755 -0.113538 0.055538 -0.086012 -0.027708 -0.028788 0.017759 0.029293 0.047674 -0.106734 -0.134380 0.048605 -0.089583 0.029426 0.030552 0.141916 -0.022653 0.017204 -0.036059 0.061045 -0.000077 -0.076579 0.066747 0.060884 -0.072817…<br>
…</p></blockquote>
<p>在ipython中，我们通过gensim来加载和测试这个模型，因为这个模型大约有7G，所以加载的时间也稍长一些：</p>

<div class="wp_syntax"><table><tr><td class="code"><pre class="python" style="font-family:monospace;">In <span style="color: black;">[</span><span style="color: #ff4500;">2</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">import</span> gensim
 
In <span style="color: black;">[</span><span style="color: #ff4500;">3</span><span style="color: black;">]</span>: model <span style="color: #66cc66;">=</span> gensim.<span style="color: black;">models</span>.<span style="color: black;">Word2Vec</span>.<span style="color: black;">load_word2vec_format</span><span style="color: black;">(</span><span style="color: #483d8b;">"wiki.en.text.vector"</span><span style="color: #66cc66;">,</span> binary<span style="color: #66cc66;">=</span><span style="color: #008000;">False</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">4</span><span style="color: black;">]</span>: model.<span style="color: black;">most_similar</span><span style="color: black;">(</span><span style="color: #483d8b;">"queen"</span><span style="color: black;">)</span>
Out<span style="color: black;">[</span><span style="color: #ff4500;">4</span><span style="color: black;">]</span>: 
<span style="color: black;">[</span><span style="color: black;">(</span>u<span style="color: #483d8b;">'princess'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5760838389396667</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'hyoui'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5671186447143555</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'janggyung'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5598698854446411</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'king'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5556215047836304</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'dollallolla'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5540223121643066</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'loranella'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5522741079330444</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'ramphaiphanni'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5310937166213989</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'jeheon'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5298476219177246</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'soheon'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5243583917617798</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'coronation'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5217245221138</span><span style="color: black;">)</span><span style="color: black;">]</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">5</span><span style="color: black;">]</span>: model.<span style="color: black;">most_similar</span><span style="color: black;">(</span><span style="color: #483d8b;">"man"</span><span style="color: black;">)</span>
Out<span style="color: black;">[</span><span style="color: #ff4500;">5</span><span style="color: black;">]</span>: 
<span style="color: black;">[</span><span style="color: black;">(</span>u<span style="color: #483d8b;">'woman'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.7120707035064697</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'girl'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.58659827709198</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'handsome'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5637181997299194</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'boy'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5425317287445068</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'villager'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5084836483001709</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'mustachioed'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.49287813901901245</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'mcgucket'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.48355430364608765</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'spider'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.4804879426956177</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'policeman'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.4780033826828003</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'stranger'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.4750771224498749</span><span style="color: black;">)</span><span style="color: black;">]</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">6</span><span style="color: black;">]</span>: model.<span style="color: black;">most_similar</span><span style="color: black;">(</span><span style="color: #483d8b;">"woman"</span><span style="color: black;">)</span>
Out<span style="color: black;">[</span><span style="color: #ff4500;">6</span><span style="color: black;">]</span>: 
<span style="color: black;">[</span><span style="color: black;">(</span>u<span style="color: #483d8b;">'man'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.7120705842971802</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'girl'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.6736541986465454</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'prostitute'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5765659809112549</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'divorcee'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5429972410202026</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'person'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5276163816452026</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'schoolgirl'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5102938413619995</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'housewife'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.48748138546943665</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'lover'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.4858251214027405</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'handsome'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.4773051142692566</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'boy'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.47445783019065857</span><span style="color: black;">)</span><span style="color: black;">]</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">8</span><span style="color: black;">]</span>: model.<span style="color: black;">similarity</span><span style="color: black;">(</span><span style="color: #483d8b;">"woman"</span><span style="color: #66cc66;">,</span> <span style="color: #483d8b;">"man"</span><span style="color: black;">)</span>
Out<span style="color: black;">[</span><span style="color: #ff4500;">8</span><span style="color: black;">]</span>: <span style="color: #ff4500;">0.71207063453821218</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">10</span><span style="color: black;">]</span>: model.<span style="color: black;">doesnt_match</span><span style="color: black;">(</span><span style="color: #483d8b;">"breakfast cereal dinner lunch"</span>.<span style="color: black;">split</span><span style="color: black;">(</span><span style="color: black;">)</span><span style="color: black;">)</span>
Out<span style="color: black;">[</span><span style="color: #ff4500;">10</span><span style="color: black;">]</span>: <span style="color: #483d8b;">'cereal'</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">11</span><span style="color: black;">]</span>: model.<span style="color: black;">similarity</span><span style="color: black;">(</span><span style="color: #483d8b;">"woman"</span><span style="color: #66cc66;">,</span> <span style="color: #483d8b;">"girl"</span><span style="color: black;">)</span>
Out<span style="color: black;">[</span><span style="color: #ff4500;">11</span><span style="color: black;">]</span>: <span style="color: #ff4500;">0.67365416785207421</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">13</span><span style="color: black;">]</span>: model.<span style="color: black;">most_similar</span><span style="color: black;">(</span><span style="color: #483d8b;">"frog"</span><span style="color: black;">)</span>
Out<span style="color: black;">[</span><span style="color: #ff4500;">13</span><span style="color: black;">]</span>: 
<span style="color: black;">[</span><span style="color: black;">(</span>u<span style="color: #483d8b;">'toad'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.6868536472320557</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'barycragus'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.6607867479324341</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'grylio'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.626731276512146</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'heckscheri'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.6208407878875732</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'clamitans'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.6150864362716675</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'coplandi'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.612680196762085</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'pseudacris'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.6108512878417969</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'litoria'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.6084023714065552</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'raniformis'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.6044802665710449</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'watjulumensis'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.6043726205825806</span><span style="color: black;">)</span><span style="color: black;">]</span></pre></td></tr></table></div>

<p>一切ok，但是当加载gensim默认的基于numpy格式的模型时，却遇到了问题：</p>

<div class="wp_syntax"><table><tr><td class="code"><pre class="python" style="font-family:monospace;">In <span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">import</span> gensim 
 
In <span style="color: black;">[</span><span style="color: #ff4500;">2</span><span style="color: black;">]</span>: model <span style="color: #66cc66;">=</span> gensim.<span style="color: black;">models</span>.<span style="color: black;">Word2Vec</span>.<span style="color: black;">load</span><span style="color: black;">(</span><span style="color: #483d8b;">"wiki.en.text.model"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">3</span><span style="color: black;">]</span>: model.<span style="color: black;">most_similar</span><span style="color: black;">(</span><span style="color: #483d8b;">"man"</span><span style="color: black;">)</span>
... <span style="color: #008000;">RuntimeWarning</span>: invalid value encountered <span style="color: #ff7700;font-weight:bold;">in</span> divide
  <span style="color: #008000;">self</span>.<span style="color: black;">syn0norm</span> <span style="color: #66cc66;">=</span> <span style="color: black;">(</span><span style="color: #008000;">self</span>.<span style="color: black;">syn0</span> / sqrt<span style="color: black;">(</span><span style="color: black;">(</span><span style="color: #008000;">self</span>.<span style="color: black;">syn0</span> ** <span style="color: #ff4500;">2</span><span style="color: black;">)</span>.<span style="color: #008000;">sum</span><span style="color: black;">(</span>-<span style="color: #ff4500;">1</span><span style="color: black;">)</span><span style="color: black;">)</span><span style="color: black;">[</span>...<span style="color: #66cc66;">,</span> newaxis<span style="color: black;">]</span><span style="color: black;">)</span>.<span style="color: black;">astype</span><span style="color: black;">(</span>REAL<span style="color: black;">)</span>
 
Out<span style="color: black;">[</span><span style="color: #ff4500;">3</span><span style="color: black;">]</span>: 
<span style="color: black;">[</span><span style="color: black;">(</span>u<span style="color: #483d8b;">'ahsns'</span><span style="color: #66cc66;">,</span> nan<span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'ny<span style="color: #000099; font-weight: bold;">\x</span>edl'</span><span style="color: #66cc66;">,</span> nan<span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'indradeo'</span><span style="color: #66cc66;">,</span> nan<span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'jaimovich'</span><span style="color: #66cc66;">,</span> nan<span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'addlepate'</span><span style="color: #66cc66;">,</span> nan<span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'jagello'</span><span style="color: #66cc66;">,</span> nan<span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'festenburg'</span><span style="color: #66cc66;">,</span> nan<span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'picatic'</span><span style="color: #66cc66;">,</span> nan<span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'tolosanum'</span><span style="color: #66cc66;">,</span> nan<span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'mithoo'</span><span style="color: #66cc66;">,</span> nan<span style="color: black;">)</span><span style="color: black;">]</span></pre></td></tr></table></div>

<p>这也是我修改前面这个脚本的原因所在，这个脚本在训练小一些的数据，譬如前10万条text的时候没任何问题，无论原始格式还是gensim格式，但是当跑完这个英文维基百科的时候，却存在这个问题，试了一些方法解决，还没有成功，如果大家有好的建议或解决方案，欢迎提出。</p>
<p><strong>二、中文维基百科的Word2Vec测试</strong></p>
<p>测试完英文维基百科之后，自然想试试中文的维基百科数据，与英文处理过程相似，也分两个步骤，不过这里需要对中文维基百科数据特殊处理一下，包括繁简转换，中文分词，去除非utf-8字符等。中文数据的下载地址是：<a href="https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2">https://dumps.wikimedia.org/zhwiki/latest/zhwiki-latest-pages-articles.xml.bz2</a>。</p>
<p>中文维基百科的数据比较小，整个xml的压缩文件大约才1G，相对英文数据小了很多。首先用 process_wiki.py处理这个XML压缩文件，执行：python process_wiki.py zhwiki-latest-pages-articles.xml.bz2 wiki.zh.text</p>

<div class="wp_syntax"><table><tr><td class="code"><pre class="python" style="font-family:monospace;"><span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">17</span>:<span style="color: #ff4500;">39</span>:<span style="color: #ff4500;">22</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">739</span>: INFO: running process_wiki.<span style="color: black;">py</span> zhwiki-latest-pages-articles.<span style="color: #dc143c;">xml</span>.<span style="color: #dc143c;">bz2</span> wiki.<span style="color: black;">zh</span>.<span style="color: black;">text</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">17</span>:<span style="color: #ff4500;">40</span>:<span style="color: #ff4500;">08</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">329</span>: INFO: Saved <span style="color: #ff4500;">10000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">17</span>:<span style="color: #ff4500;">40</span>:<span style="color: #ff4500;">45</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">501</span>: INFO: Saved <span style="color: #ff4500;">20000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">17</span>:<span style="color: #ff4500;">41</span>:<span style="color: #ff4500;">23</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">659</span>: INFO: Saved <span style="color: #ff4500;">30000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">17</span>:<span style="color: #ff4500;">42</span>:<span style="color: #ff4500;">01</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">748</span>: INFO: Saved <span style="color: #ff4500;">40000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">17</span>:<span style="color: #ff4500;">42</span>:<span style="color: #ff4500;">33</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">779</span>: INFO: Saved <span style="color: #ff4500;">50000</span> articles
......
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">17</span>:<span style="color: #ff4500;">55</span>:<span style="color: #ff4500;">23</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">094</span>: INFO: Saved <span style="color: #ff4500;">200000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">17</span>:<span style="color: #ff4500;">56</span>:<span style="color: #ff4500;">14</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">692</span>: INFO: Saved <span style="color: #ff4500;">210000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">17</span>:<span style="color: #ff4500;">57</span>:<span style="color: #ff4500;">04</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">614</span>: INFO: Saved <span style="color: #ff4500;">220000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">17</span>:<span style="color: #ff4500;">57</span>:<span style="color: #ff4500;">57</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">979</span>: INFO: Saved <span style="color: #ff4500;">230000</span> articles
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">17</span>:<span style="color: #ff4500;">58</span>:<span style="color: #ff4500;">16</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">621</span>: INFO: finished iterating over Wikipedia corpus of <span style="color: #ff4500;">232894</span> documents <span style="color: #ff7700;font-weight:bold;">with</span> <span style="color: #ff4500;">51603419</span> positions <span style="color: black;">(</span>total <span style="color: #ff4500;">2581444</span> articles<span style="color: #66cc66;">,</span> <span style="color: #ff4500;">62177405</span> positions before pruning articles shorter than <span style="color: #ff4500;">50</span> words<span style="color: black;">)</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">17</span>:<span style="color: #ff4500;">58</span>:<span style="color: #ff4500;">16</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">622</span>: INFO: Finished Saved <span style="color: #ff4500;">232894</span> articles</pre></td></tr></table></div>

<p>得到了大约23万多篇中文语料的text格式的语料:wiki.zh.text，大概750多M。不过查看之后发现，除了加杂一些英文词汇外，还有很多繁体字混迹其中，这里还是参考了 <a href="http://weibo.com/licstar">@licstar</a> <a href="http://licstar.net/archives/262">《维基百科简体中文语料的获取》</a>中的方法，安装opencc，然后将wiki.zh.text中的繁体字转化位简体字：</p>
<p>opencc -i wiki.zh.text -o wiki.zh.text.jian -c zht2zhs.ini</p>
<p>然后就是分词处理了，这次我用基于MeCab训练的一套中文分词系统来进行中文分词，目前虽还没有达到实用的状态，但是性能和分词结果基本能达到这次的使用要求：</p>
<p>mecab -d ../data/ -O wakati wiki.zh.text.jian -o wiki.zh.text.jian.seg -b 10000000</p>
<p>注意这里data目录下是给mecab训练好的分词模型和词典文件等，详细可参考《<a href="http://www.52nlp.cn/%E7%94%A8mecab%E6%89%93%E9%80%A0%E4%B8%80%E5%A5%97%E5%AE%9E%E7%94%A8%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E7%B3%BB%E7%BB%9F">用MeCab打造一套实用的中文分词系统</a>》。</p>
<p>有了中文维基百科的分词数据，还以为就可以执行word2vec模型训练了：</p>
<p>python train_word2vec_model.py wiki.zh.text.jian.seg wiki.zh.text.model wiki.zh.text.vector</p>
<p>不过仍然遇到了问题，提示的错误是：</p>
<p>UnicodeDecodeError: ‘utf8′ codec can’t decode bytes in position 5394-5395: invalid continuation byte</p>
<p>google了一下，大致是文件中包含非utf-8字符，又用iconv处理了一下这个问题：</p>
<p>iconv -c -t UTF-8  wiki.zh.text.jian.seg.utf-8</p>
<p>这样基本上就没问题了，执行：</p>
<p>python train_word2vec_model.py wiki.zh.text.jian.seg.utf-8 wiki.zh.text.model wiki.zh.text.vector</p>

<div class="wp_syntax"><table><tr><td class="code"><pre class="python" style="font-family:monospace;"><span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">50</span>:<span style="color: #ff4500;">02</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">586</span>: INFO: running train_word2vec_model.<span style="color: black;">py</span> wiki.<span style="color: black;">zh</span>.<span style="color: black;">text</span>.<span style="color: black;">jian</span>.<span style="color: black;">seg</span>.<span style="color: black;">utf</span>-<span style="color: #ff4500;">8</span> wiki.<span style="color: black;">zh</span>.<span style="color: black;">text</span>.<span style="color: black;">model</span> wiki.<span style="color: black;">zh</span>.<span style="color: black;">text</span>.<span style="color: black;">vector</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">50</span>:<span style="color: #ff4500;">02</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">592</span>: INFO: collecting <span style="color: #008000;">all</span> words <span style="color: #ff7700;font-weight:bold;">and</span> their counts
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">50</span>:<span style="color: #ff4500;">02</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">592</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#0, processed 0 words and 0 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">50</span>:<span style="color: #ff4500;">12</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">476</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#10000, processed 12914562 words and 254662 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">50</span>:<span style="color: #ff4500;">20</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">215</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#20000, processed 22308801 words and 373573 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">50</span>:<span style="color: #ff4500;">28</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">448</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#30000, processed 30724902 words and 460837 word types</span>
...
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">03</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">498</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#210000, processed 143804601 words and 1483608 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">07</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">772</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#220000, processed 149352283 words and 1521199 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">11</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">639</span>: INFO: PROGRESS: at sentence <span style="color: #808080; font-style: italic;">#230000, processed 154741839 words and 1563584 word types</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">12</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">746</span>: INFO: collected <span style="color: #ff4500;">1575172</span> word <span style="color: #dc143c;">types</span> <span style="color: #ff7700;font-weight:bold;">from</span> a corpus of <span style="color: #ff4500;">156430908</span> words <span style="color: #ff7700;font-weight:bold;">and</span> <span style="color: #ff4500;">232894</span> sentences
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">13</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">672</span>: INFO: total <span style="color: #ff4500;">278291</span> word <span style="color: #dc143c;">types</span> after removing those <span style="color: #ff7700;font-weight:bold;">with</span> count<span style="color: #66cc66;">&lt;</span><span style="color: #ff4500;">5</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">13</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">673</span>: INFO: constructing a huffman tree <span style="color: #ff7700;font-weight:bold;">from</span> <span style="color: #ff4500;">278291</span> words
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">29</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">323</span>: INFO: built huffman tree <span style="color: #ff7700;font-weight:bold;">with</span> maximum node depth <span style="color: #ff4500;">25</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">29</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">683</span>: INFO: resetting layer weights
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">38</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">805</span>: INFO: training model <span style="color: #ff7700;font-weight:bold;">with</span> <span style="color: #ff4500;">4</span> workers on <span style="color: #ff4500;">278291</span> vocabulary <span style="color: #ff7700;font-weight:bold;">and</span> <span style="color: #ff4500;">400</span> features<span style="color: #66cc66;">,</span> using <span style="color: #483d8b;">'skipgram'</span><span style="color: #66cc66;">=</span><span style="color: #ff4500;">1</span> <span style="color: #483d8b;">'hierarchical softmax'</span><span style="color: #66cc66;">=</span><span style="color: #ff4500;">1</span> <span style="color: #483d8b;">'subsample'</span><span style="color: #66cc66;">=</span><span style="color: #ff4500;">0</span> <span style="color: #ff7700;font-weight:bold;">and</span> <span style="color: #483d8b;">'negative sampling'</span><span style="color: #66cc66;">=</span><span style="color: #ff4500;">0</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">49</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">504</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.10</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02500</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">15008</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">51</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">935</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.38</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02500</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">44434</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">54</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">779</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.56</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02500</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">53965</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">57</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">240</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.62</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02491</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">52116</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">52</span>:<span style="color: #ff4500;">58</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">823</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.72</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02494</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">55804</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">53</span>:<span style="color: #ff4500;">03</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">649</span>: INFO: PROGRESS: at <span style="color: #ff4500;">0.94</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02486</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">58277</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">18</span>:<span style="color: #ff4500;">53</span>:<span style="color: #ff4500;">07</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">357</span>: INFO: PROGRESS: at <span style="color: #ff4500;">1.03</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.02479</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">56036</span> words/s
......
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">09</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">002</span>: INFO: PROGRESS: at <span style="color: #ff4500;">98.38</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.00044</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">85936</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">10</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">321</span>: INFO: PROGRESS: at <span style="color: #ff4500;">98.50</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.00044</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">85971</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">11</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">934</span>: INFO: PROGRESS: at <span style="color: #ff4500;">98.55</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.00039</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">85940</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">13</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">384</span>: INFO: PROGRESS: at <span style="color: #ff4500;">98.65</span>% words<span style="color: #66cc66;">,</span> alpha <span style="color: #ff4500;">0.00036</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">85960</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">13</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">883</span>: INFO: training on <span style="color: #ff4500;">152625573</span> words took 1775.1s<span style="color: #66cc66;">,</span> <span style="color: #ff4500;">85982</span> words/s
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">13</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">883</span>: INFO: saving Word2Vec <span style="color: #008000;">object</span> under wiki.<span style="color: black;">zh</span>.<span style="color: black;">text</span>.<span style="color: black;">model</span><span style="color: #66cc66;">,</span> separately <span style="color: #008000;">None</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">13</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">884</span>: INFO: <span style="color: #ff7700;font-weight:bold;">not</span> storing attribute syn0norm
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">13</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">884</span>: INFO: storing numpy <span style="color: #dc143c;">array</span> <span style="color: #483d8b;">'syn0'</span> to wiki.<span style="color: black;">zh</span>.<span style="color: black;">text</span>.<span style="color: black;">model</span>.<span style="color: black;">syn0</span>.<span style="color: black;">npy</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">20</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">797</span>: INFO: storing numpy <span style="color: #dc143c;">array</span> <span style="color: #483d8b;">'syn1'</span> to wiki.<span style="color: black;">zh</span>.<span style="color: black;">text</span>.<span style="color: black;">model</span>.<span style="color: black;">syn1</span>.<span style="color: black;">npy</span>
<span style="color: #ff4500;">2015</span>-<span style="color: #ff4500;">03</span>-<span style="color: #ff4500;">11</span> <span style="color: #ff4500;">19</span>:<span style="color: #ff4500;">22</span>:<span style="color: #ff4500;">40</span><span style="color: #66cc66;">,</span><span style="color: #ff4500;">667</span>: INFO: storing 278291x400 projection weights into wiki.<span style="color: black;">zh</span>.<span style="color: black;">text</span>.<span style="color: black;">vector</span></pre></td></tr></table></div>

<p>让我们看一下训练好的中文维基百科word2vec模型“wiki.zh.text.vector”的效果：</p>

<div class="wp_syntax"><table><tr><td class="code"><pre class="python" style="font-family:monospace;">In <span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">import</span> gensim
 
In <span style="color: black;">[</span><span style="color: #ff4500;">2</span><span style="color: black;">]</span>: model <span style="color: #66cc66;">=</span> gensim.<span style="color: black;">models</span>.<span style="color: black;">Word2Vec</span>.<span style="color: black;">load</span><span style="color: black;">(</span><span style="color: #483d8b;">"wiki.zh.text.model"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">3</span><span style="color: black;">]</span>: model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"足球"</span><span style="color: black;">)</span>
Out<span style="color: black;">[</span><span style="color: #ff4500;">3</span><span style="color: black;">]</span>: 
<span style="color: black;">[</span><span style="color: black;">(</span>u<span style="color: #483d8b;">'<span style="color: #000099; font-weight: bold;">\u</span>8054<span style="color: #000099; font-weight: bold;">\u</span>8d5b'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.6553816199302673</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'<span style="color: #000099; font-weight: bold;">\u</span>7532<span style="color: #000099; font-weight: bold;">\u</span>7ea7'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.6530429720878601</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'<span style="color: #000099; font-weight: bold;">\u</span>7bee<span style="color: #000099; font-weight: bold;">\u</span>7403'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5967546701431274</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'<span style="color: #000099; font-weight: bold;">\u</span>4ff1<span style="color: #000099; font-weight: bold;">\u</span>4e50<span style="color: #000099; font-weight: bold;">\u</span>90e8'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5872289538383484</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'<span style="color: #000099; font-weight: bold;">\u</span>4e59<span style="color: #000099; font-weight: bold;">\u</span>7ea7'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5840631723403931</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'<span style="color: #000099; font-weight: bold;">\u</span>8db3<span style="color: #000099; font-weight: bold;">\u</span>7403<span style="color: #000099; font-weight: bold;">\u</span>961f'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5560152530670166</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'<span style="color: #000099; font-weight: bold;">\u</span>4e9a<span style="color: #000099; font-weight: bold;">\u</span>8db3<span style="color: #000099; font-weight: bold;">\u</span>8054'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5308005809783936</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'allsvenskan'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5249762535095215</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'<span style="color: #000099; font-weight: bold;">\u</span>4ee3<span style="color: #000099; font-weight: bold;">\u</span>8868<span style="color: #000099; font-weight: bold;">\u</span>961f'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5214947462081909</span><span style="color: black;">)</span><span style="color: #66cc66;">,</span>
 <span style="color: black;">(</span>u<span style="color: #483d8b;">'<span style="color: #000099; font-weight: bold;">\u</span>7532<span style="color: #000099; font-weight: bold;">\u</span>7ec4'</span><span style="color: #66cc66;">,</span> <span style="color: #ff4500;">0.5177896022796631</span><span style="color: black;">)</span><span style="color: black;">]</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">4</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"足球"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">5</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
联赛 <span style="color: #ff4500;">0.65538161993</span>
甲级 <span style="color: #ff4500;">0.653042972088</span>
篮球 <span style="color: #ff4500;">0.596754670143</span>
俱乐部 <span style="color: #ff4500;">0.587228953838</span>
乙级 <span style="color: #ff4500;">0.58406317234</span>
足球队 <span style="color: #ff4500;">0.556015253067</span>
亚足联 <span style="color: #ff4500;">0.530800580978</span>
allsvenskan <span style="color: #ff4500;">0.52497625351</span>
代表队 <span style="color: #ff4500;">0.521494746208</span>
甲组 <span style="color: #ff4500;">0.51778960228</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">6</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"男人"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">7</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
女人 <span style="color: #ff4500;">0.77537125349</span>
家伙 <span style="color: #ff4500;">0.617369174957</span>
妈妈 <span style="color: #ff4500;">0.567102909088</span>
漂亮 <span style="color: #ff4500;">0.560832381248</span>
잘했어 <span style="color: #ff4500;">0.540875017643</span>
谎言 <span style="color: #ff4500;">0.538448691368</span>
爸爸 <span style="color: #ff4500;">0.53660941124</span>
傻瓜 <span style="color: #ff4500;">0.535608053207</span>
예쁘다 <span style="color: #ff4500;">0.535151124001</span>
mc刘 <span style="color: #ff4500;">0.529670000076</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">8</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"女人"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">9</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
男人 <span style="color: #ff4500;">0.77537125349</span>
我的某 <span style="color: #ff4500;">0.589010596275</span>
妈妈 <span style="color: #ff4500;">0.576344847679</span>
잘했어 <span style="color: #ff4500;">0.562340974808</span>
美丽 <span style="color: #ff4500;">0.555426716805</span>
爸爸 <span style="color: #ff4500;">0.543958246708</span>
新娘 <span style="color: #ff4500;">0.543640494347</span>
谎言 <span style="color: #ff4500;">0.540272831917</span>
妞儿 <span style="color: #ff4500;">0.531066179276</span>
老婆 <span style="color: #ff4500;">0.528521537781</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">10</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"青蛙"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">11</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
老鼠 <span style="color: #ff4500;">0.559612870216</span>
乌龟 <span style="color: #ff4500;">0.489831030369</span>
蜥蜴 <span style="color: #ff4500;">0.478990525007</span>
猫 <span style="color: #ff4500;">0.46728849411</span>
鳄鱼 <span style="color: #ff4500;">0.461885392666</span>
蟾蜍 <span style="color: #ff4500;">0.448014199734</span>
猴子 <span style="color: #ff4500;">0.436584025621</span>
白雪公主 <span style="color: #ff4500;">0.434905380011</span>
蚯蚓 <span style="color: #ff4500;">0.433413207531</span>
螃蟹 <span style="color: #ff4500;">0.4314712286</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">12</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"姨夫"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">13</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
堂伯 <span style="color: #ff4500;">0.583935439587</span>
祖父 <span style="color: #ff4500;">0.574735701084</span>
妃所生 <span style="color: #ff4500;">0.569327116013</span>
内弟 <span style="color: #ff4500;">0.562012672424</span>
早卒 <span style="color: #ff4500;">0.558042645454</span>
曕 <span style="color: #ff4500;">0.553856015205</span>
胤祯 <span style="color: #ff4500;">0.553288519382</span>
陈潜 <span style="color: #ff4500;">0.550716996193</span>
愔之 <span style="color: #ff4500;">0.550510883331</span>
叔父 <span style="color: #ff4500;">0.550032019615</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">14</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"衣服"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">15</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
鞋子 <span style="color: #ff4500;">0.686688780785</span>
穿着 <span style="color: #ff4500;">0.672499775887</span>
衣物 <span style="color: #ff4500;">0.67173999548</span>
大衣 <span style="color: #ff4500;">0.667605519295</span>
裤子 <span style="color: #ff4500;">0.662670075893</span>
内裤 <span style="color: #ff4500;">0.662210345268</span>
裙子 <span style="color: #ff4500;">0.659705817699</span>
西装 <span style="color: #ff4500;">0.648508131504</span>
洋装 <span style="color: #ff4500;">0.647238850594</span>
围裙 <span style="color: #ff4500;">0.642895817757</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">16</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"公安局"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">17</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
司法局 <span style="color: #ff4500;">0.730189085007</span>
公安厅 <span style="color: #ff4500;">0.634275555611</span>
公安 <span style="color: #ff4500;">0.612798035145</span>
房管局 <span style="color: #ff4500;">0.597343325615</span>
商业局 <span style="color: #ff4500;">0.597183346748</span>
军管会 <span style="color: #ff4500;">0.59476184845</span>
体育局 <span style="color: #ff4500;">0.59283208847</span>
财政局 <span style="color: #ff4500;">0.588721752167</span>
戒毒所 <span style="color: #ff4500;">0.575558543205</span>
新闻办 <span style="color: #ff4500;">0.573395550251</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">18</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"铁道部"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">19</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
盛光祖 <span style="color: #ff4500;">0.565509021282</span>
交通部 <span style="color: #ff4500;">0.548688530922</span>
批复 <span style="color: #ff4500;">0.546967327595</span>
刘志军 <span style="color: #ff4500;">0.541010737419</span>
立项 <span style="color: #ff4500;">0.517836689949</span>
报送 <span style="color: #ff4500;">0.510296344757</span>
计委 <span style="color: #ff4500;">0.508456230164</span>
水利部 <span style="color: #ff4500;">0.503531932831</span>
国务院 <span style="color: #ff4500;">0.503227233887</span>
经贸委 <span style="color: #ff4500;">0.50156635046</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">20</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"清华大学"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">21</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
北京大学 <span style="color: #ff4500;">0.763922810555</span>
化学系 <span style="color: #ff4500;">0.724210739136</span>
物理系 <span style="color: #ff4500;">0.694550514221</span>
数学系 <span style="color: #ff4500;">0.684280991554</span>
中山大学 <span style="color: #ff4500;">0.677202701569</span>
复旦 <span style="color: #ff4500;">0.657914161682</span>
师范大学 <span style="color: #ff4500;">0.656435549259</span>
哲学系 <span style="color: #ff4500;">0.654701948166</span>
生物系 <span style="color: #ff4500;">0.654403865337</span>
中文系 <span style="color: #ff4500;">0.653147578239</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">22</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"卫视"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">23</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
湖南 <span style="color: #ff4500;">0.676812887192</span>
中文台 <span style="color: #ff4500;">0.626506924629</span>
収蔵 <span style="color: #ff4500;">0.621356606483</span>
黄金档 <span style="color: #ff4500;">0.582251906395</span>
cctv <span style="color: #ff4500;">0.536769032478</span>
安徽 <span style="color: #ff4500;">0.536752820015</span>
非同凡响 <span style="color: #ff4500;">0.534517168999</span>
唱响 <span style="color: #ff4500;">0.533438682556</span>
最强音 <span style="color: #ff4500;">0.532605051994</span>
金鹰 <span style="color: #ff4500;">0.531676828861</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">24</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"习近平"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">25</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
胡锦涛 <span style="color: #ff4500;">0.809472680092</span>
江泽民 <span style="color: #ff4500;">0.754633367062</span>
李克强 <span style="color: #ff4500;">0.739740967751</span>
贾庆林 <span style="color: #ff4500;">0.737033963203</span>
曾庆红 <span style="color: #ff4500;">0.732847094536</span>
吴邦国 <span style="color: #ff4500;">0.726941585541</span>
总书记 <span style="color: #ff4500;">0.719057679176</span>
李瑞环 <span style="color: #ff4500;">0.716384887695</span>
温家宝 <span style="color: #ff4500;">0.711952567101</span>
王岐山 <span style="color: #ff4500;">0.703570842743</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">26</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"林丹"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">27</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
黄综翰 <span style="color: #ff4500;">0.538035452366</span>
蒋燕皎 <span style="color: #ff4500;">0.52646958828</span>
刘鑫 <span style="color: #ff4500;">0.522252976894</span>
韩晶娜 <span style="color: #ff4500;">0.516120731831</span>
王晓理 <span style="color: #ff4500;">0.512289524078</span>
王适 <span style="color: #ff4500;">0.508560419083</span>
杨影 <span style="color: #ff4500;">0.508159279823</span>
陈跃 <span style="color: #ff4500;">0.507353425026</span>
龚智超 <span style="color: #ff4500;">0.503159761429</span>
李敬元 <span style="color: #ff4500;">0.50262516737</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">28</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"语言学"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">29</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
社会学 <span style="color: #ff4500;">0.632598280907</span>
人类学 <span style="color: #ff4500;">0.623406708241</span>
历史学 <span style="color: #ff4500;">0.618442356586</span>
比较文学 <span style="color: #ff4500;">0.604823827744</span>
心理学 <span style="color: #ff4500;">0.600066184998</span>
人文科学 <span style="color: #ff4500;">0.577783346176</span>
社会心理学 <span style="color: #ff4500;">0.575571238995</span>
政治学 <span style="color: #ff4500;">0.574541330338</span>
地理学 <span style="color: #ff4500;">0.573896467686</span>
哲学 <span style="color: #ff4500;">0.573873817921</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">30</span><span style="color: black;">]</span>: result <span style="color: #66cc66;">=</span> model.<span style="color: black;">most_similar</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"计算机"</span><span style="color: black;">)</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">31</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">for</span> e <span style="color: #ff7700;font-weight:bold;">in</span> result:
    <span style="color: #ff7700;font-weight:bold;">print</span> e<span style="color: black;">[</span><span style="color: #ff4500;">0</span><span style="color: black;">]</span><span style="color: #66cc66;">,</span> e<span style="color: black;">[</span><span style="color: #ff4500;">1</span><span style="color: black;">]</span>
   ....:     
自动化 <span style="color: #ff4500;">0.674171924591</span>
应用 <span style="color: #ff4500;">0.614087462425</span>
自动化系 <span style="color: #ff4500;">0.611132860184</span>
材料科学 <span style="color: #ff4500;">0.607891201973</span>
集成电路 <span style="color: #ff4500;">0.600370049477</span>
技术 <span style="color: #ff4500;">0.597518980503</span>
电子学 <span style="color: #ff4500;">0.591316461563</span>
建模 <span style="color: #ff4500;">0.577238917351</span>
工程学 <span style="color: #ff4500;">0.572855889797</span>
微电子 <span style="color: #ff4500;">0.570086717606</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">32</span><span style="color: black;">]</span>: model.<span style="color: black;">similarity</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"计算机"</span><span style="color: #66cc66;">,</span> u<span style="color: #483d8b;">"自动化"</span><span style="color: black;">)</span>
Out<span style="color: black;">[</span><span style="color: #ff4500;">32</span><span style="color: black;">]</span>: <span style="color: #ff4500;">0.67417196002404789</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">33</span><span style="color: black;">]</span>: model.<span style="color: black;">similarity</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"女人"</span><span style="color: #66cc66;">,</span> u<span style="color: #483d8b;">"男人"</span><span style="color: black;">)</span>
Out<span style="color: black;">[</span><span style="color: #ff4500;">33</span><span style="color: black;">]</span>: <span style="color: #ff4500;">0.77537125129824813</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">34</span><span style="color: black;">]</span>: model.<span style="color: black;">doesnt_match</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"早餐 晚餐 午餐 中心"</span>.<span style="color: black;">split</span><span style="color: black;">(</span><span style="color: black;">)</span><span style="color: black;">)</span>
Out<span style="color: black;">[</span><span style="color: #ff4500;">34</span><span style="color: black;">]</span>: u<span style="color: #483d8b;">'<span style="color: #000099; font-weight: bold;">\u</span>4e2d<span style="color: #000099; font-weight: bold;">\u</span>5fc3'</span>
 
In <span style="color: black;">[</span><span style="color: #ff4500;">35</span><span style="color: black;">]</span>: <span style="color: #ff7700;font-weight:bold;">print</span> model.<span style="color: black;">doesnt_match</span><span style="color: black;">(</span>u<span style="color: #483d8b;">"早餐 晚餐 午餐 中心"</span>.<span style="color: black;">split</span><span style="color: black;">(</span><span style="color: black;">)</span><span style="color: black;">)</span>
中心</pre></td></tr></table></div>

<p>有好的也有坏的case，甚至bad case可能会更多一些，这和语料库的规模有关，还和分词器的效果有关等等，不过这个实验暂且就到这里了。至于word2vec有什么用，目前除了用来来计算词语相似度外，业界更关注的是word2vec在具体的应用任务中的效果，这个才是更有意思的东东，也欢迎大家一起探讨。</p>
<p>注：原创文章，转载请注明出处“<a href="http://www.52nlp.cn">我爱自然语言处理</a>”：<a href="http://www.52nlp.cn">www.52nlp.cn</a></p>
<p>本文链接地址：<a href="http://www.52nlp.cn/?p=8198">http://www.52nlp.cn/中英文维基百科语料上的word2vec实验</a></p>

											
{% endraw %}
