<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>PRML读书会第六章   Kernel Methods | IT技术干货</title>
    <meta name="viewport" content="width=device-width">
    <meta name="description" content="IT技术干货 KernelHacks 最好的技术站点 技术信息 纯干货">
    <link rel="canonical" href="http://iftti.com/posts/2015/2015-01-28-prml%25e8%25af%25bb%25e4%25b9%25a6%25e4%25bc%259a%25e7%25ac%25ac%25e5%2585%25ad%25e7%25ab%25a0-kernel-methods-70bdfcff9.html">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/main.css">

</head>

    <body>

    <header class="site-header">

  <div class="wrap">

    <a class="site-title" href="/">IT技术干货</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
           viewBox="0 0 18 15" enable-background="new 0 0 18 15" xml:space="preserve">
          <path fill="#505050" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0
            h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#505050" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484
            h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#505050" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0
            c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>
      <div class="trigger">

          <a class="page-link" href="/about/">About</a>

      </div>
    </nav>

  </div>

</header>

    <div class="page-content">
      <div class="wrap">
      <div class="post">

  <header class="post-header">
    <h1>PRML读书会第六章   Kernel Methods</h1>
    <p class="meta"><span class="time">Jan 28, 2015</span><span class="source_url"> • 来自 52nlp.cn <a name="52nlp.cn" href="http://www.52nlp.cn/prml%e8%af%bb%e4%b9%a6%e4%bc%9a%e7%ac%ac%e5%85%ad%e7%ab%a0-kernel-methods" target="_blank">[原文链接]</a></span></p>
  </header>

  <article class="post-content">

						<p style="text-align: center"><strong>PRML</strong><strong>读书会第六章 </strong> <strong>Kernel Methods</strong></p>
<p style="text-align: center"><strong>主讲人 网络上的尼采</strong></p>
<p style="text-align: center"><strong>（新浪微博:<a href="http://weibo.com/dmalgorithms">@Nietzsche_复杂网络机器学习</a>）</strong></p>
<p>网络上的尼采(813394698) 9:16:05</p>
<p>今天的主要内容：Kernel的基本知识，高斯过程。边思考边打字，有点慢，各位稍安勿躁。<br>
机器学习里面对待训练数据有的是训练完得到参数后就可以抛弃了，比如神经网络；有的是还需要原来的训练数据比如KNN，SVM也需要保留一部分数据–支持向量。<br>
很多线性参数模型都可以通过dual representation的形式表达为核函数的形式。所谓线性参数模型是通过非线性的基函数的线性组合来表达非线性的东西，模型还是线性的。比如线性回归模型是y=<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-0.png"><img class="alignnone wp-image-7284" src="/images/52nlp.cn/f69bf3291baa22562dc0307d19ce45c8.jpg" alt="prml6-0" width="66" height="20"></a>，<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-1.png"><img class="alignnone wp-image-7285" src="/images/52nlp.cn/ab655185988d45d9adad9096b0ef807a.jpg" alt="prml6-1" width="45" height="26"></a>是一组非线性基函数，我们可以通过线性的模型来表达非线性的结构。</p>
<p>核函数的形式：<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-3.png"><img class="alignnone wp-image-7286" src="/images/52nlp.cn/f1f79680d42ebb575ec08736033b45b9.jpg" alt="prml6-3" width="150" height="26"></a>，也就是映射后高维特征空间的内积可以通过原来低维的特征得到。因此kernel methods用途广泛。</p>
<p>核函数有很多种，有平移不变的stationary kernels  <a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-4.png"><img class="alignnone wp-image-7287" src="/images/52nlp.cn/a44fe7b7b0b5a8d89da153c34de1a511.jpg" alt="prml6-4" width="160" height="20"></a>还有仅依赖欧氏距离的径向基核：<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-5.png"><img class="alignnone wp-image-7288" src="/images/52nlp.cn/f32073eb6f8a77372ed8625b23466393.jpg" alt="prml6-5" width="160" height="23"></a><span id="more-7282"></span></p>
<p>非线性转化为线性的形式的好处不言而喻，各种变换推导、闭式解就出来了。 下面推导下线性回归模型的dual representation，有助于我们理解核函数的作用：</p>
<p>根据最小二乘，我们得到下面的目标函数<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-7.png"><img class="alignnone wp-image-7289" src="/images/52nlp.cn/5ecedeb9e5e4a0034dcfb76486db037b.jpg" alt="prml6-7" width="250" height="43"></a>，加了L2正则。我们对w求导，令J(w)的梯度等于0，得到以下解：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-8.png"><img class="aligncenter wp-image-7290" src="/images/52nlp.cn/6a88ba41a438470fab044492fab637e4.jpg" alt="prml6-8" width="400" height="63"></a></p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-9.png"><img class="alignnone wp-image-7291" src="/images/52nlp.cn/a1bf0bc770bd32ff433b20fc8f354c99.jpg" alt="prml6-9" width="25" height="22"></a>是个由基函数构成的样本矩阵，<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-10.png"><img class="alignnone wp-image-7292" src="/images/52nlp.cn/4e3e314f21e297c9e29d20daed3ec734.jpg" alt="prml6-10" width="25" height="29"></a>向量里面的元素由<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-11.png"><img class="alignnone wp-image-7293" src="/images/52nlp.cn/38a1fe6ac08c663c397e57dcc2a980a0.jpg" alt="prml6-11" width="200" height="40"></a>组成：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-12.png"><img class="aligncenter wp-image-7294" src="/images/52nlp.cn/379a061c6a43f73456cd481953b10745.jpg" alt="prml6-12" width="400" height="69"></a></p>
<p>我们把<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-13.png"><img class="alignnone wp-image-7295" src="/images/52nlp.cn/e14ddcbd720aa06797b162982f22101a.jpg" alt="prml6-13" width="60" height="19"></a>代入最初的J(w)得到：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-14.png"><img class="aligncenter wp-image-7296" src="/images/52nlp.cn/577d2747905ebd74ef31ed46a9af8dc2.jpg" alt="prml6-14" width="400" height="47"></a><br>
咱们用核矩阵K来替换<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-16.png"><img class="alignnone wp-image-7297" src="/images/52nlp.cn/8af87d4cc48564e8cc0b4ef3d1b43f3f.jpg" alt="prml6-16" width="35" height="21"></a>，其中矩阵K里面的元素是<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-17.png"><img class="alignnone wp-image-7298" src="/images/52nlp.cn/6c70142a76a13e63359f16b9778a02a4.jpg" alt="prml6-17" width="200" height="28"></a><br>
于是得到<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-20.png"><img class="alignnone wp-image-7301" src="/images/52nlp.cn/0bfacc4fba3cd57e5e2bd38cad5ce647.jpg" alt="prml6-20" width="250" height="35"></a><br>
然后<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-21.png"><img class="alignnone wp-image-7302" src="/images/52nlp.cn/e5cfb4fc6d15a7a12d4dc4e05350a58b.jpg" alt="prml6-21" width="30" height="17"></a>对<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-10.png"><img class="alignnone wp-image-7292" src="/images/52nlp.cn/4e3e314f21e297c9e29d20daed3ec734.jpg" alt="prml6-10" width="20" height="23"></a>求导，令其梯度等于0，得到解<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-23.png"><img class="alignnone wp-image-7303" src="/images/52nlp.cn/cc6ac4ad7eefef631f64feb08fb598fb.jpg" alt="prml6-23" width="120" height="28"></a><br>
所以原来的线性回归方程就变成了<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-24.png"><img class="alignnone wp-image-7304" src="/images/52nlp.cn/97354754bf06beb11e5116638e026e7c.jpg" alt="prml6-24" width="350" height="30"></a><br>
K(X)的含义：<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-25.png"><img class="alignnone wp-image-7305" src="/images/52nlp.cn/62563682c6e5fef04e0d222d41bf2b20.jpg" alt="prml6-25" width="380" height="17"></a>，上面的DUAL形式的含义非常明显，就是根据已知的的训练数据来做预测。至此原来线性回归方程的参数w消失，由核函数来表示回归方程，以上方式把基于特征的学习转换成了基于样本的学习。 这是线性回归的DUAL表示，svm等很多模型都有DUAL表示。<br>
80(850639048) 10:09:50<br>
professor 核函数其实是为了求基函数的内积对吗？<br>
网络上的尼采(813394698) 10:12:57</p>
<p>如果有很多基的话维度势必会很高，计算内积的花销会很大，有些是无限维的，核函数能绕过高维的内积计算，直接用核函数得到内积。</p>
<p>接下来看下核函数的性质及构造方法。核函数的一般形式：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-26.png"><img class="aligncenter wp-image-7306" src="/images/52nlp.cn/d3b6ed5c4051029b7462385fb53b1605.jpg" alt="prml6-26" width="400" height="89"></a></p>
<p>下面是个简单的例子说明<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-27.png"><img class="alignnone wp-image-7307" src="/images/52nlp.cn/f555c093aeccecc4d5d2e62928ce2b7c.jpg" alt="prml6-27" width="120" height="31"></a>为什么是个核函数：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-29.png"><img class="aligncenter wp-image-7308" src="/images/52nlp.cn/b75216a4234a0e89139156d1fb86407b.jpg" alt="prml6-29" width="400" height="127"></a><br>
很明显 <a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-30.png"><img class="alignnone wp-image-7309" src="/images/52nlp.cn/f85c384e4ac7fbdaf57d135a874eaa96.jpg" alt="prml6-30" width="100" height="26"></a> 是个核函数，它能写成核函数的一般形式。</p>
<p>核函数的一个充分必要定理也就是mercer定理：核矩阵是半正定的：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-31.png"><img class="aligncenter wp-image-7310" src="/images/52nlp.cn/08ad61872577230b8516fd599bc6dd10.jpg" alt="prml6-31" width="400" height="94"></a><br>
我们可以通过以下规则用简单的核函数来构造复杂的核函数：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-32.png"><img class="aligncenter wp-image-7311" src="/images/52nlp.cn/cb61ade2759454cb07e0ab649bd364fb.jpg" alt="prml6-32" width="400" height="311"></a><br>
过会我们讲高斯过程时再举个核函数线性组合的例子。<br>
介绍一个经常用到的径向基核函数，高斯核：<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-36.png"><img class="alignnone wp-image-7313" src="/images/52nlp.cn/f1e1f9a9ccc4aec333988ee594f36597.jpg" alt="prml6-36" width="257" height="41"></a>，这个核函数能把数据映射到无限维的空间：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-37.png"><img class="aligncenter wp-image-7314" src="/images/52nlp.cn/22f4ca139b80c2651078e16a93f789ab.jpg" alt="prml6-37" width="400" height="96"></a></p>
<p>中间<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-38.png"><img class="alignnone wp-image-7315" src="/images/52nlp.cn/e9aa6627eb2c2084062cbfcfe9149dc8.jpg" alt="prml6-38" width="100" height="31"></a>可以展开成无限维的，然后核函数可以表示成内积的形式。<br>
内积的含义就是表示相似性，所以核函数还有其他的用法。比如我们可以通过生成模型来构造核。</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-39.png"><img class="aligncenter wp-image-7316" src="/images/52nlp.cn/757b9f7cb880a47a3e8bdc21441a077c.jpg" alt="prml6-39" width="349" height="52"></a></p>
<p>两个变量的概率都很高相似性就越大，其实这样做就是映射到一维的内积。<br>
我们可以引入离散的隐变量：<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-40.png"><img class="alignnone wp-image-7317" src="/images/52nlp.cn/5a319aae49956cf73bc228c1b37dd284.jpg" alt="prml6-40" width="243" height="51"></a><br>
连续的隐变量：<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-41.png"><img class="alignnone wp-image-7318" src="/images/52nlp.cn/b83bb1452d305932a5dc7796048ae797.jpg" alt="prml6-41" width="274" height="49"></a><br>
举个这样做有啥用的例子，我们可以用来比较HMM由同一条隐马尔科夫链生成的两条序列的相似性：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-42.png"><img class="aligncenter wp-image-7319" src="/images/52nlp.cn/21c737d26ac53f73854646e6e9759784.jpg" alt="prml6-42" width="400" height="150"></a></p>
<p>网络上的尼采(813394698) 10:40:34<br>
接下来讲我们今天的重点Gaussian Processes<br>
牧云(1106207961) 10:41:02</p>
<p>数据海洋(1009129701) 10:41:14<br>
我先再理解，理解这些。<br>
网络上的尼采(813394698) 10:42:41<br>
Gaussian Processes是贝叶斯学派的一个大杀器，用处很广。不同于参数模型，Gaussian Processes认为函数在函数空间里存在一个先验分布。</p>
<p>高斯过程和很多模型是等价的：ARMA (autoregressive moving average) models, Kalman filters, radial basis function networks ，还有特定情况下的神经网络。<br>
现在我们从贝叶斯线性回归自然的引出高斯过程：<br>
前面我们提到的线性回归的形式 <a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-43.png"><img class="alignnone wp-image-7321" src="/images/52nlp.cn/b32754c949b65ed446adbd979014a435.jpg" alt="prml6-43" width="100" height="25"></a><br>
贝叶斯方法为参数加了一个高斯分布 <a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-44.png"><img class="alignnone wp-image-7322" src="/images/52nlp.cn/aea8d22b11fe9bea31975f9b22aa8149.jpg" alt="prml6-44" width="150" height="31"></a><br>
大家发现了没有，这样做直接导致了函数有个预测分布，并且也是高斯的，因为方程是线性的并且参数是高斯分布。线性的东西和高斯分布总是不分家的。<br>
我们定义向量：y，</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-45.png"><img class="aligncenter wp-image-7323" src="/images/52nlp.cn/a3426d2ea69a33712460e6303cf268f2.jpg" alt="prml6-45" width="400" height="35"></a></p>
<p>y就是个多元的高斯分布。<br>
它的每一维 <a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-46.png"><img class="alignnone wp-image-7324" src="/images/52nlp.cn/69dd688dfe3fc8cf50b1ad5a35baf217.jpg" alt="prml6-46" width="45" height="22"></a>都是个高斯分布，这也是高斯过程的由来。<br>
y可以表示为 <a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-47.png"><img class="alignnone wp-image-7325" src="/images/52nlp.cn/aa074df6fea20ee1c73806a03b34ce36.jpg" alt="prml6-47" width="67" height="19"></a></p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-48.png"><img class="alignnone wp-image-7326" src="/images/52nlp.cn/6e5b4ef8924c0d17716965b7a864a8bf.jpg" alt="prml6-48" width="300" height="26"></a></p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-49.png"><img class="alignnone wp-image-7327" src="/images/52nlp.cn/af732bfb85ee71047a35d203f431d357.jpg" alt="prml6-49" width="23" height="18"></a>是基函数组成的样本矩阵。<br>
高斯过程可以由均值和协方差矩阵完全决定。由于w的均值是0，所以我们也认为高斯过程的均值是0，<br>
剩下的就是根据定义求它的协方差矩阵，很自然地就得出来了：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-50.png"><img class="aligncenter wp-image-7328" src="/images/52nlp.cn/d04dfd4d8e9c60289cc6d93364c8498b.jpg" alt="prml6-50" width="400" height="85"></a><br>
矩阵K里的元素<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-51.png"><img class="alignnone wp-image-7329" src="/images/52nlp.cn/7f0d72a944951fc5ff152df038399c50.jpg" alt="prml6-51" width="277" height="44"></a>都是核函数的形式。<br>
选用什么样的核函数也是问题，下面的图是对采用高斯核和指数核的高斯过程的取样，一共取了5条，可以看到两者的区别：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-52.png"><img class="aligncenter wp-image-7330 size-full" src="/images/52nlp.cn/490aeda99d6a1243f8260aafd93629f7.jpg" alt="prml6-52" width="441" height="129"></a><br>
接下来我们就用GP来做回归 ：<br>
我们观测的目标值是包含噪音的，噪音是高斯分布。</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-60.png"><img class="aligncenter wp-image-7332" src="/images/52nlp.cn/395e3305130c3c96c0536ac22789cd6b.jpg" alt="prml6-60" width="186" height="54"></a></p>
<p>那么根据线性高斯模型的性质，<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-65.png"><img class="alignnone wp-image-7334" src="/images/52nlp.cn/f35c82cdae8826e9de9ec51bc7632b4e.jpg" alt="prml6-65" width="180" height="31"></a>，其中<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-66.png"><img class="alignnone wp-image-7335" src="/images/52nlp.cn/bd6593d1b905edb5b58ce88dc9ef9cea.jpg" alt="prml6-66" width="26" height="29"></a>是噪音的参数<br>
对于向量<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-63.png"><img class="alignnone wp-image-7336" src="/images/52nlp.cn/69aaf5f00cbda42782600e349c08eb1f.jpg" alt="prml6-63" width="120" height="23"></a>和向量<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-64.png"><img class="alignnone wp-image-7337" src="/images/52nlp.cn/bb0bb0128ea9e7ac88813d40bca1edb7.jpg" alt="prml6-64" width="120" height="23"></a></p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-68.png"><img class="alignnone wp-image-7338" src="/images/52nlp.cn/64a6cddece36f9c2c75feed536c507b2.jpg" alt="prml6-68" width="150" height="30"></a></p>
<p>咱们前面说过了，<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-61.png"><img class="alignnone wp-image-7333" src="/images/52nlp.cn/b9cc209c7df789950e8be3e79ea22f1c.jpg" alt="prml6-61" width="30" height="25"></a>可以表示为<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-62.png"><img class="alignnone wp-image-7339" src="/images/52nlp.cn/202c2aa03a886e372b958d82cbd119f5.jpg" alt="prml6-62" width="120" height="29"></a><br>
所以marginal distribution：<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-69.png"><img class="alignnone wp-image-7340" src="/images/52nlp.cn/a60c5157a752ec3ef8a5f745ddbf3a7f.jpg" alt="prml6-69" width="266" height="40"></a><br>
其中矩阵C的元素<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-70.png"><img class="alignnone wp-image-7341" src="/images/52nlp.cn/9bcb289464ee4ab65a1c50559c9eacbf.jpg" alt="prml6-70" width="255" height="38"></a>，<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-72.png"><img class="alignnone wp-image-7342" src="/images/52nlp.cn/5f7741d35e88fc5e971ffce2de50f2d8.jpg" alt="prml6-72" width="35" height="25"></a>是单位矩阵的元素，其实就是把<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-73.png"><img class="alignnone wp-image-7343" src="/images/52nlp.cn/b1dd9869e453a6ee6346fb7bdf5d8f40.jpg" alt="prml6-73" width="38" height="29"></a>加在了矩阵K的对角线上。这个不难理解，一开始<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml7-75.png"><img class="alignnone wp-image-7344" src="/images/52nlp.cn/33a6889bc19d94b121c13f81b9f2206f.jpg" alt="prml7-75" width="100" height="25"></a>，都是高斯的，协方差是两者的相加，噪音每次取都是独立的，所以只在协方差矩阵对角线上有。<br>
现在确定下用什么核的问题，举个例子，下面这个核函数用了高斯核，线性核，以及常数的线性组合，这样做是为了更灵活，过会再讲如何确定里面的这些超参：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-77.png"><img class="aligncenter wp-image-7345" src="/images/52nlp.cn/f51b2f19f4d5de3ae43c364017e966f6.jpg" alt="prml6-77" width="400" height="63"></a></p>
<p>下图是不同的超参对高斯过程的影响：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-78.png"><img class="aligncenter wp-image-7346" src="/images/52nlp.cn/229007048f4f801ab005dcba861c8442.jpg" alt="prml6-78" width="400" height="292"></a><br>
解决了核函数的问题，我们再回来，通过前面的结论，不难得出 <a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-79.png"><img class="alignnone wp-image-7347" src="/images/52nlp.cn/cb40489f63f1ee13bbc9525edc10ee13.jpg" alt="prml6-79" width="180" height="31"></a><br>
如何确定矩阵<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-80.png"><img class="alignnone wp-image-7348" src="/images/52nlp.cn/a0fc15383d796ea863529f05733c3f53.jpg" alt="prml6-80" width="43" height="23"></a>呢，其实我们在原来矩阵<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-81.png"><img class="alignnone wp-image-7349" src="/images/52nlp.cn/f436e5f2e52babca3b9dfd95cc620f58.jpg" alt="prml6-81" width="31" height="19"></a>的基础上补上就行。</p>
<p>k和c比较容易理解：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-82.png"><img class="aligncenter wp-image-7350" src="/images/52nlp.cn/47224f22088bfc96df440d2472333d3e.jpg" alt="prml6-82" width="400" height="21"></a> <a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-83.png"><img class="aligncenter wp-image-7351" src="/images/52nlp.cn/d4f9a61ceed77129c7d54fedc8aa2a4a.jpg" alt="prml6-83" width="300" height="43"></a></p>
<p>咱们的最终目标就是得<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-85.png"><img class="alignnone wp-image-7352" src="/images/52nlp.cn/c5a6dde91d487e32d1b23bc2995c6c0c.jpg" alt="prml6-85" width="68" height="26"></a>，由于这两个都是高斯分布，用第二章条件高斯分布的公式套一下，其中均值是0：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-89.png"><img class="aligncenter wp-image-7353" src="/images/52nlp.cn/855da7e7d64275144bdb626d0dbdd9f5.jpg" alt="prml6-89" width="400" height="85"></a></p>
<p>就会得到<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-85.png"><img class="alignnone wp-image-7352" src="/images/52nlp.cn/c5a6dde91d487e32d1b23bc2995c6c0c.jpg" alt="prml6-85" width="68" height="26"></a>的均值和方差：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-86.png"><img class="aligncenter wp-image-7354" src="/images/52nlp.cn/3dc90e5709a3e604915a009dd472ee1a.jpg" alt="prml6-86" width="400" height="77"></a></p>
<p>可以看出均值和方差都是<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-90.png"><img class="alignnone wp-image-7356" src="/images/52nlp.cn/ae1c4222dfa5812b4da4352f1219485c.jpg" alt="prml6-90" width="46" height="23"></a>的函数，我们做预测时用均值就行了。<br>
最后一个问题就是高斯过程是由它的协方差矩阵完全决定的，我们如何学习矩阵里面的超参呢？包括我们刚才提到的核函数里面的参数以及噪音的参数。<br>
其实由于高斯分布的原因，我们可以方便的利用log最大似然：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-91.png"><img class="aligncenter wp-image-7357" src="/images/52nlp.cn/738fc937451fb62e97e8026ec381f768.jpg" alt="prml6-91" width="400" height="52"></a><br>
求最优解时可以用共轭梯度等方法，梯度：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-92.png"><img class="aligncenter wp-image-7358" src="/images/52nlp.cn/0d2f291815e0ecba579bf2c662925ad4.jpg" alt="prml6-92" width="400" height="55"></a><br>
到这里，用高斯过程做回归就结束了。<br>
有了做回归的基础，咱们再看下如何做分类。<br>
类似逻辑回归，加个sigmoid函数就能做分类了：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-93.png"><img class="aligncenter wp-image-7359" src="/images/52nlp.cn/a78912791a05ada28cc8bcc1c0b70347.jpg" alt="prml6-93" width="400" height="84"></a><br>
分类与回归不同的是<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-94.png"><img class="alignnone wp-image-7360" src="/images/52nlp.cn/2a1f0d69da48b0734e0aefa7bdc3ab67.jpg" alt="prml6-94" width="247" height="47"></a>是个伯努利分布。<br>
<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-95.png"><img class="alignnone wp-image-7361" src="/images/52nlp.cn/d5ff2c5d39d8b8b75d1c149e5801abd6.jpg" alt="prml6-95" width="258" height="47"></a>这里还和前面一样。</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-96.png"><img class="alignnone wp-image-7362" src="/images/52nlp.cn/feb3771c2915b0b4b715843cd138540a.jpg" alt="prml6-96" width="265" height="40"></a></p>
<p>对于二分类问题，最后我们要得到是：</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-97.png"><img class="aligncenter wp-image-7363" src="/images/52nlp.cn/40677fabc142bad32874e16247fd246e.jpg" alt="prml6-97" width="400" height="45"></a><br>
但是这个积分是不容易求的，<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-98.png"><img class="alignnone size-full wp-image-7364" src="/images/52nlp.cn/5204d7f71f3a349bdedd346e39b1f8fb.jpg" alt="prml6-98" width="15" height="14"></a>是伯努利分布，<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-99.png"><img class="alignnone size-full wp-image-7365" src="/images/52nlp.cn/ef0a4125c6e5c6c41938ecc2119106fc.jpg" alt="prml6-99" width="31" height="19"></a>是高斯分布，不是共轭的。求积分的方法有很多，可以用MCMC，也可以用变分的方法。书上用的是Laplace approximation。</p>
<p>今天就到这里吧，我去吃饭，各位先讨论下吧。</p>
<p>上面Gaussian Processes的公式推导虽然有点多，但都是高斯分布所以并不复杂，并且GP在算法实现上也不难。</p>
<p>另外给大家推荐一个机器学习视频的网站，http://blog.videolectures.net/100-most-popular-machine-learning-talks-at-videolectures-net/ 里面有很多牛人比如Jordan的talks，第一个视频就是剑桥的David MacKay讲高斯过程，他的一本书 Information Theory, Inference and Learning Algorithms也很出名。</p>
<p>两栖动物(9219642) 14:35:09<br>
<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-49.png"><img class="alignnone wp-image-7327" src="/images/52nlp.cn/af732bfb85ee71047a35d203f431d357.jpg" alt="prml6-49" width="23" height="18"></a>是个由基函数构成的矩阵，向量a里面的元素由<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-100.png"><img class="alignnone wp-image-7366" src="/images/52nlp.cn/0b3feaa488279e746c4575090732914c.jpg" alt="prml6-100" width="200" height="40"></a>组成。<br>
<a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-9.png"><img class="alignnone wp-image-7291" src="/images/52nlp.cn/a1bf0bc770bd32ff433b20fc8f354c99.jpg" alt="prml6-9" width="25" height="22"></a>的维度是基函数的个数，an的维度是样本的个数把?<br>
网络上的尼采(813394698) 14:36:44<br>
对<br>
两栖动物(9219642) 14:37:48</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-101.png"><img class="alignnone wp-image-7367" src="/images/52nlp.cn/523a3f38b98b6933e0365f4be6a203f4.jpg" alt="prml6-101" width="381" height="60"></a></p>
<p>哪这2个怎么后来乘在一起了？维度不是不一样吗？</p>
<p>网络上的尼采(813394698) 14:49:01<br>
@两栖动物 <a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-9.png"><img class="alignnone wp-image-7291" src="/images/52nlp.cn/a1bf0bc770bd32ff433b20fc8f354c99.jpg" alt="prml6-9" width="25" height="22"></a>不是方阵，可以相乘</p>
<p><a href="http://www.52nlp.cn/wp-content/uploads/2015/01/prml6-102.png"><img class="alignnone wp-image-7368" src="/images/52nlp.cn/ae02b63ed922acd2861fe1f99f26a016.jpg" alt="prml6-102" width="354" height="29"></a><br>
明白了吧，另外这个由基函数表示的样本矩阵只在推导里存在。<br>
两栖动物(9219642) 14:56:08<br>
明白了，谢谢</p>
<p> </p>
<p>注：PRML读书会系列文章由 <a href="http://weibo.com/dmalgorithms">@Nietzsche_复杂网络机器学习</a> 同学授权发布，转载请注明原作者和相关的主讲人，谢谢。</p>
<p>PRML读书会讲稿PDF版本以及更多资源下载地址：<a href="http://vdisk.weibo.com/u/1841149974">http://vdisk.weibo.com/u/1841149974</a></p>
<p>本文链接地址：<a href="http://www.52nlp.cn/prml%E8%AF%BB%E4%B9%A6%E4%BC%9A%E7%AC%AC%E5%85%AD%E7%AB%A0-kernel-methods">http://www.52nlp.cn/prml读书会第六章-kernel-methods</a></p>
<p> </p>

  </article>

  <div class="meta">

    <a class="basic-alignment left" href="/posts/2015/2015-01-28-83821-cb2ee3ffb.html" title="Previous Post: .NET中使用Redis" data-instant>&laquo; .NET中使用Redis</a>

    <a class="basic-alignment right" href="/posts/2015/2015-01-30-prml%25e8%25af%25bb%25e4%25b9%25a6%25e4%25bc%259a%25e7%25ac%25ac%25e4%25b8%2583%25e7%25ab%25a0-sparse-kernel-machines-9458d994d.html" title="Next Post: PRML读书会第七章 Sparse Kernel Machines" data-instant>PRML读书会第七章 Sparse Kernel Machines &raquo;</a>

</div>
  <div id="related">
  <h2 class="subheader">Related Posts <small>They might be useful</small></h2>
  <ul class="posts">

      <li><span>23 Jan 2017</span> &raquo; <a href="http://iftti.com/posts/2017/2017-01-23-109970-be7a95583.html">每天一个 Linux 命令（46）： vmstat 命令</a></li>

      <li><span>22 Jan 2017</span> &raquo; <a href="http://iftti.com/posts/2017/2017-01-22-109965-c5dfb9397.html">每天一个 Linux 命令（45）： free 命令</a></li>

      <li><span>21 Jan 2017</span> &raquo; <a href="http://iftti.com/posts/2017/2017-01-21-109951-09f1179a7.html">每天一个 Linux 命令（44）： top 命令</a></li>

  </ul>
</div>

<comments>

<!-- UY BEGIN -->
<div id="uyan_frame"></div>
<script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=1936498"></script>
<!-- UY END -->

</comments>

</div>
      <!-- JiaThis Button BEGIN -->
<div class="jiathis_share_slide jiathis_share_24x24" id="jiathis_share_slide">
<div class="jiathis_share_slide_top" id="jiathis_share_title"></div>
<div class="jiathis_share_slide_inner">
<div class="jiathis_style_24x24">
<a class="jiathis_button_tsina"></a>
<a class="jiathis_button_googleplus"></a>
<a class="jiathis_button_twitter"></a>
<a class="jiathis_button_linkedin"></a>
<a class="jiathis_button_weixin"></a>
<a class="jiathis_button_cqq"></a>
<a class="jiathis_button_renren"></a>
<a class="jiathis_button_evernote"></a>
<a class="jiathis_button_pocket"></a>
<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
<script type="text/javascript">
var jiathis_config = {data_track_clickback:'true'
	,slide:{
		divid:'wrap',
		pos:'left',
		gt:'true'
	}
};
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1936498" charset="utf-8"></script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jiathis_slide.js" charset="utf-8"></script>
</div></div></div>
<!-- JiaThis Button END -->
      </div>
    </div>

    <footer class="site-footer">

  <div class="wrap">

    <h2 class="footer-heading">IT技术干货</h2>

    <div class="footer-col-1 column">
      <p class="text">IT技术干货 KernelHacks 最好的技术站点 技术信息 纯干货</p>
      <ul>
        <li>科技与互联网信息</li>
        <li>Liu Lantao</li>
        <li><a href="mailto:iftti@iftti.com">iftti@iftti.com</a></li>
      </ul>
    </div>

    <div class="footer-col-2 column">
      <ul>
        <li>
          <a href="https://github.com/Lax">
            <span class="icon github">
              <svg version="1.1" class="github-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill-rule="evenodd" clip-rule="evenodd" fill="#C2C2C2" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761
                c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32
                c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472
                c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037
                C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65
                c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261
                c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082
                c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129
                c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            <span class="username">Lax</span>
          </a>
        </li>
        <li>
          <a href="https://twitter.com/liulantao">
            <span class="icon twitter">
              <svg version="1.1" class="twitter-icon-svg" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                 viewBox="0 0 16 16" enable-background="new 0 0 16 16" xml:space="preserve">
                <path fill="#C2C2C2" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809
                c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27
                c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767
                c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206
                C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271
                c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469
                c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/>
              </svg>
            </span>
            <span class="username">@liulantao</span>
          </a>
        </li>
        <li>
          <a href="https://plus.google.com/+LiuLantao">
            <span class="icon googleplus">
              <svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
                width="16px" height="16px" viewBox="0 0 134.658 131.646" enable-background="new 0 0 134.658 131.646"
                xml:space="preserve">
                <g>
                  <path fill="#C2C2C2" d="M126.515,4.109H8.144c-2.177,0-3.94,1.763-3.94,3.938v115.546c0,2.179,1.763,3.942,3.94,3.942h118.371
                  c2.177,0,3.94-1.764,3.94-3.942V8.048C130.455,5.872,128.691,4.109,126.515,4.109z"/>
                  <g>
                    <path fill="#FFFFFF" d="M70.479,71.845l-3.983-3.093c-1.213-1.006-2.872-2.334-2.872-4.765c0-2.441,1.659-3.993,3.099-5.43
                    c4.64-3.652,9.276-7.539,9.276-15.73c0-8.423-5.3-12.854-7.84-14.956h6.849l7.189-4.517H60.418
                    c-5.976,0-14.588,1.414-20.893,6.619c-4.752,4.1-7.07,9.753-7.07,14.842c0,8.639,6.633,17.396,18.346,17.396
                    c1.106,0,2.316-0.109,3.534-0.222c-0.547,1.331-1.1,2.439-1.1,4.32c0,3.431,1.763,5.535,3.317,7.528
                    c-4.977,0.342-14.268,0.893-21.117,5.103c-6.523,3.879-8.508,9.525-8.508,13.51c0,8.202,7.731,15.842,23.762,15.842
                    c19.01,0,29.074-10.519,29.074-20.932C79.764,79.709,75.344,75.943,70.479,71.845z M56,59.107
                    c-9.51,0-13.818-12.294-13.818-19.712c0-2.888,0.547-5.87,2.428-8.199c1.773-2.218,4.861-3.657,7.744-3.657
                    c9.168,0,13.923,12.404,13.923,20.382c0,1.996-0.22,5.533-2.762,8.09C61.737,57.785,58.762,59.107,56,59.107z M56.109,103.65
                    c-11.826,0-19.452-5.657-19.452-13.523c0-7.864,7.071-10.524,9.504-11.405c4.64-1.561,10.611-1.779,11.607-1.779
                    c1.105,0,1.658,0,2.538,0.111c8.407,5.983,12.056,8.965,12.056,14.629C72.362,98.542,66.723,103.65,56.109,103.65z"/>
                    <polygon fill="#FFFFFF" points="98.393,58.938 98.393,47.863 92.923,47.863 92.923,58.938 81.866,58.938 81.866,64.469
                    92.923,64.469 92.923,75.612 98.393,75.612 98.393,64.469 109.506,64.469 109.506,58.938"/>
                  </g>
                </g>
              </svg>
            </span>
            <span class="username">+LiuLantao</span>
          </a>
        </li>
      </ul>
    </div>

    <div class="footer-col-3 column">

<!--以下是QQ邮件列表订阅嵌入代码--><script >var nId = "6be92ef3590ee662cd5e6381ab2044c328716364f684cf3e",nWidth="auto",sColor="light",sText="填写您的邮件地址，订阅我们的精彩内容：" ;</script><script src="http://list.qq.com/zh_CN/htmledition/js/qf/page/qfcode.js" charset="gb18030"></script>

    </div>

  </div>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-1658815-7', 'iftti.com');
  ga('require', 'displayfeatures');
  ga('send', 'pageview');

</script>

</footer>

    </body>
</html>