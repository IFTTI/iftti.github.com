<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>IT技术干货</title>
    <description>[IT技术干货iftti.com] @KernelHacks</description>
    <link>http://iftti.com/</link>
    <atom:link href="http://iftti.com/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Tue, 02 Jun 2015 20:15:26 +0800</pubDate>
    <lastBuildDate>Tue, 02 Jun 2015 20:15:26 +0800</lastBuildDate>
    <generator>Jekyll v2.2.0</generator>
    
      <item>
        <title>浅谈排队论</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;p&gt;&lt;strong&gt;伯乐在线补充：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;排队论（Queueing Theory），或称随机服务系统理论、排队理论，是数学运筹学的分支学科。它是研究服务系统中排队现象随机规律的学科。广泛应用于电信，交通工程，计算机网络、生产、运输、库存等各项资源共享的随机服务系统，和工厂，商店，办公室和医院的设计。&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/db130ebc669e4bf5d84aa70a4935e266.jpg&quot; width=&quot;630&quot; height=&quot;309&quot;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;（天通苑地铁早高峰入口处的排队。&lt;a href=&quot;http://weibo.com/2093492691/AzRN2u33Z&quot; target=&quot;_blank&quot;&gt;图来自网友老歌&lt;/a&gt; ）&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;现在社会到处都有队列，队列无处不在。比如生活中的超市与机场，到工作中的Web服务器和数据库。因此，研究一下队列行为，还是很有帮助的。&lt;/p&gt;
&lt;p&gt;问题在于排队行为实际上与我们直觉相背离。在实际生活中碰到的大多数排队现象，通常都是在充满不确定性和随机性的情况下发生的。这就是统计概率领域的话题了，而人类的思维能力无法很直观的来处理它。&lt;/p&gt;
&lt;p&gt;在排队论领域有一些工具可以规避这种问题：一种结合可视化的计量方法可以弥补我们直觉上的不足。这篇文章会讨论一些我在阅读排队论时发现的比较有趣的东西。&lt;/p&gt;
&lt;h2&gt;产品开发中的排队&lt;/h2&gt;
&lt;p&gt;本文中提出的大多数观点都是基于 Donald G. Reinertsen 的《产品开发流程的原理 | &lt;a href=&quot;http://www.amazon.com/The-Principles-Product-Development-Flow/dp/1935401009&quot;&gt;The Principles of Product Development Flow&lt;/a&gt;》，顺便说一句，这本算是我所看过的关于产品开发流程写得最好的书。&lt;/p&gt;
&lt;p&gt;在这本书中，Reinertsen 检查了在开发新产品时，组织可能会面临的挑战，并给出了一种计量经济学框架来应对这些挑战。这个框架系统性的推翻了我们在管理产品开发时的一些固有理念。比如说“应该消除方差”、“系统应该满负荷运转”以及“集中化控制有好处”等。这些都被基于经济原理的新观点所取代，而不再基于业务原理和个人直觉。&lt;/p&gt;
&lt;p&gt;在 Reinertsen 的书中，其中心主题有一条就是关于排队的重要性。具体来说，Reinertsen 多次提到这样的现象：产品管理员往往忽略排队的问题，而只关注到时间线和效率。当然，对时间线和效率的度量对我们是有帮助，但是对于那些高度不确定的活动，比如产品开发来说，我们其实可以做的更好。队列就是一个更好的度量工具。最起码，它们非常重要，不容忽视。&lt;/p&gt;
&lt;p&gt;虽然在 Reinertsen 的书中这些观点都应用于产品开发领域，不过许多观点同样也同样适用于其他出现排队和随机性的场合。比如说交通管理、百货商店以及饭店的厨房，还有服务器资源管理和软件架构等。接下来，我们详细阐述。&lt;/p&gt;
&lt;h2&gt;马尔可夫过程&lt;/h2&gt;
&lt;p&gt;就像我们之前所讨论的， 真实世界中产生排队的环境中同样也存在随机性。然而，我们不会讨论关于随机性的内容。在我们推论排队的过程中，所使用的最有用的工具就是基于随机性建模的马尔可夫过程。&lt;/p&gt;
&lt;p&gt;马尔可夫过程是一段时间内随机事件的集合，具有以下两种独特而有趣的属性：&lt;/p&gt;
&lt;p&gt;1&lt;span style=&quot;font-family: 宋体;&quot;&gt;、下一个事件迟早会发生&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;2&lt;span style=&quot;font-family: 宋体;&quot;&gt;、将来事件的发生不依赖于之前的事件，即无后效性。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;下图描绘出一段时间内的马尔可夫过程：&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d878ad881a4956ee39615bc38b22f13d.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;(原图为交互图，可在原文查看)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;马尔可夫过程和泊松过程都很适合用来给真实世界中的事件建模，其中泊松过程是一种连续时间的特殊马尔可夫过程。 我们可以用它们来模拟事件加入排队队列这一过程。&lt;/p&gt;
&lt;p&gt;当我们使用马尔可夫过程来给入队事件建模时，&lt;span style=&quot;font-family: 宋体;&quot;&gt;比如说上报&lt;/span&gt;&lt;span style=&quot;font-family: Verdana;&quot;&gt;bug&lt;/span&gt;&lt;span style=&quot;font-family: 宋体;&quot;&gt;、餐馆的订单、&lt;/span&gt;&lt;span style=&quot;font-family: Verdana;&quot;&gt;HTTP&lt;/span&gt;&lt;span style=&quot;font-family: 宋体;&quot;&gt;请求等，都可以通过绘制累积图来表示：&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0a2575f8e4215e7aa169d61a95f39942.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;(原图为交互图，可在原文查看)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这种图每次都会重新模拟一条新的马尔科夫链。不过，它的总体形状是一样的。&lt;/p&gt;
&lt;h2&gt;可视化队列&lt;/h2&gt;
&lt;p&gt;马尔可夫过程自身并不能形成排队，它只是一堆持续增长的任务。不过可以通过结合两种马尔可夫过程来制造出排队：其中到达过程不断产生任务，服务过程处理这些任务。&lt;/p&gt;
&lt;p&gt;虽然服务过程也可以建模为马尔可夫过程，但它与到达过程却并不一样：当队列是空的情况下，服务过程什么事都不做。没有消费者，就没有什么事情需要做的。当任务到达的时候，服务过程会遵循马尔可夫过程准则来提供服务。&lt;/p&gt;
&lt;p&gt;我们可以将两种过程叠加来绘制到达过程和服务过程：&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f6f70bd9dbcd5e3fa3b3e2199961158d.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;(原图为交互图，可在原文查看)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如果我们将图中的到达过程去掉，剩下的就是到达过程与服务过程之间的那一小块区域。也就是队列：&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/30b2f981ca62260e4c437d0a73f3e9fb.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;(原图为交互图，可在原文查看)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这种可视化工具被称为累积流程图，非常适用于展示排队情况。其本质就是绘制出队列大小随着时间推移发生的变化，具有下面这些非常有用的属性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于任意时间变量 t&lt;span style=&quot;font-family: 宋体;&quot;&gt;，线条高度就代表当前时间的队列大小&lt;/span&gt;
&lt;/li&gt;
&lt;li&gt;对于任意队列大小 &lt;span style=&quot;font-family: &#39;Times New Roman&#39;;&quot;&gt;y&lt;/span&gt;&lt;span style=&quot;font-family: 宋体;&quot;&gt;，图中长条的宽度代表系统中完成单元任务所需要的时间，这个时间由任务在队列中的等待时间和处理时间合并而成。&lt;/span&gt;
&lt;/li&gt;
&lt;li&gt;到达过程的边缘坡度（上面的那条斜线）表现了系统对队列的加入请求。&lt;/li&gt;
&lt;li&gt;服务过程的边缘坡度（下面）展现出服务过程处理任务的能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;产能利用率最大化的问题&lt;/h2&gt;
&lt;p&gt;在了解可视化队列的机制之后，我们再来仔细看看这些数据究竟代表什么意思。上图中展示了具有相同频率的到达过程和服务过程而形成的排队。服务的能力与入队请求相匹配。&lt;/p&gt;
&lt;p&gt;乍一看，创建这样一个队列似乎很合理：因为毕竟资源很昂贵，所以要将资源与请求准确的匹配——不多不少。让程序员或者客服人员闲坐着没有任何意义，对吧？&lt;/p&gt;
&lt;p&gt;然而，如果你仔细看这种资源匹配产生的排队情况，你可能会注意到那些相对较宽的部分，这是由于服务进程被困在某个非常慢的任务上时，又有连续不断的任务请求加入而形成的。而且，这种情况并不会很快缓解。&lt;/p&gt;
&lt;p&gt;这种现象被称为diffusion，大多数人都无法凭直觉来感知它（当然其中并不包括我——作者）：如果你将到达进程和服务进程的资源相匹配，你期望的可能是队列大小尽可能的接近0.&lt;span style=&quot;font-family: 宋体;&quot;&gt;但是实际情况不是这样。只要一个耗时的任务就可以使得队列增长的很快，而且它还不会立即“自我修正”为空。排队时间迅速飙升。客户们在着急的等待，&lt;/span&gt;&lt;span style=&quot;font-family: Verdana;&quot;&gt;bug&lt;/span&gt;&lt;span style=&quot;font-family: 宋体;&quot;&gt;报告堆积如山。&lt;/span&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;我们可以通过一些统计数据来更进一步了解这种情况：&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/398f5cd2e3dae47e5e545f076bb81216.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;(原图为交互图，可在原文查看)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;通过每一次的模拟情况，我们收集到了一些数据：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;产能利用率——服务进程的工作时间（非空闲状态）。如图中所示，如果两种过程的资源能力匹配，这个值接近于100%&lt;span style=&quot;font-family: 宋体;&quot;&gt;。&lt;/span&gt;
&lt;/li&gt;
&lt;li&gt;非阻塞状态百分比——服务进程非阻塞状态的时间（可立即工作的状态）。值为“100% – &lt;span style=&quot;font-family: 宋体;&quot;&gt;产能利用率&lt;/span&gt;”（几乎为0）.&lt;/li&gt;
&lt;li&gt;队列中平均任务数——队列中等待被处理的任务平均数。可由公式估算”(产能利用率)2 / (1 – 产能利用率)” 。由于服务进程工作时间接近于&lt;span style=&quot;font-family: Verdana;&quot;&gt;100%&lt;/span&gt;&lt;span style=&quot;font-family: 宋体;&quot;&gt;，导致队列大小成指数级增长。&lt;/span&gt;
&lt;/li&gt;
&lt;li&gt;排队时间百分比——相对于任务的整个周期时间来说，在队列中时间的所占百分比。它的值约等于产能利用率。这是一个非常值得注意的现象：如果你的系统产能负载率达到&lt;span style=&quot;font-family: Verdana;&quot;&gt;95%&lt;/span&gt;&lt;span style=&quot;font-family: 宋体;&quot;&gt;，那么对每个任务来说，它的整个生命周期有&lt;/span&gt;&lt;span style=&quot;font-family: Verdana;&quot;&gt;95%&lt;/span&gt;&lt;span style=&quot;font-family: 宋体;&quot;&gt;的时间都将会在排队中度过。&lt;/span&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;增加额外产能&lt;/h2&gt;
&lt;p&gt;如果我们能将服务过程和到达过程的资源匹配程度做一些变化，那么这些数据看起来就会大有不同。&lt;/p&gt;
&lt;p&gt;例如，如果我们给服务过程增加额外产能，那么上文提到的麻烦就会减弱不少：排队时间所占百分比下降，而且服务进程能很轻松的应对系统负载。即使发生了卡顿的情况，也可以很快清理这种问题。&lt;/p&gt;
&lt;p&gt;不过，随之而来的问题是产能利用率下降了。当排队时间降低，产能利用率也会随之降低。我们会多出许多闲置的资源：&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8b2fc3686acb18f9779159bb9ce787ae.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;(原图为交互图，可在原文查看)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;同时兼有较高产能利用率和较少排队时间的情况几乎是不太可能出现的。在上面的模拟情境中，我们对服务频率和到达频率做出的不同组合，通常会出现要么产能利用率过低要么排队时间太长的情况。当然，由于过程的随机性，我们偶尔也会得到幸运之神的光顾。不过仅靠运气不是长远之计。&lt;/p&gt;
&lt;h2&gt;消除可变性&lt;/h2&gt;
&lt;p&gt;&lt;span style=&quot;color: #000000;&quot;&gt;如果你处于这样一种困境——由于可变队列中排队时间与产能利用率不可兼得，从而无法达到预期目标。&lt;/span&gt;那么或许尝试去消除过程中的随机性会有所帮助？&lt;/p&gt;
&lt;p&gt;当然， 说起来容易做起来难。怎样保证准确预测到达请求呢？你能控制客户的到来或者控制&lt;span style=&quot;font-family: Verdana;&quot;&gt;http&lt;/span&gt;&lt;span style=&quot;font-family: 宋体;&quot;&gt;请求吗？你该怎样安排工作任务从而使得每个任务花费时间是确定的呢？这些事情听起来挺吸引人，但是事实上很难以实现。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;而且在某些情况下，消除可变性甚至可能是不可取的。Reinertsen在他的书中就断言：无论 Six Sigma 之类的工具怎么说，在产品研发中，你无法完全的消除可变性，甚至实际上你也并不会想要完全消除它。你可以通过一些技术手段来限制可变性带来的后果，比如说用一种可变性来替换另一个。在投入与回报不对等的情况下，你甚至可以使得可变性给你带来利益——当可变性带来当成功的价值远远高于失败的成本时。&lt;/p&gt;
&lt;p&gt;但是，即使你有能力而且同时也想要消除可变性，队列又会发生怎样的变化？&lt;/p&gt;
&lt;h3&gt;确定的到达过程&lt;/h3&gt;
&lt;p&gt;从下图可以看出，即使我们完全消除到达过程的不确定性，使得每个任务的到达时间是确定的，排队现象也依然会出现，除非服务过程有明显的产能过剩才不会产生排队。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/4a68efff2417e47fce1cebcff4dbdf58.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;(原图为交互图，可在原文查看)&lt;/span&gt;&lt;/p&gt;
&lt;h3&gt;确定的服务过程&lt;/h3&gt;
&lt;p&gt;如果我们双方互换，使得服务过程确定（这种情形在现实世界中很容易想象出来），如下图：&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5d2441929ee55eed45aa62cf0124f443.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;(原图为交互图，可在原文查看)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;看来只降低或消除某一个过程的不确定性并不能解决我们的问题。可能问题的严重性是降低了，但是相应的我们付出的代价是多少？&lt;/p&gt;
&lt;p&gt;实际上，可变性与队列大小之间的关系是线性的（然而产能利用率和队列大小是指数级的关系）。如果你只在单方面完全消除可变性，你所能期待的结果也仅仅是排队数减半而已。&lt;/p&gt;
&lt;h3&gt;完全确定的队列&lt;/h3&gt;
&lt;p&gt;只有我们将服务过程和到达过程的不确定性都完全消除，我们才能获取真正想要的成功——&lt;span style=&quot;font-family: Verdana;&quot;&gt;100%&lt;/span&gt;&lt;span style=&quot;font-family: 宋体;&quot;&gt;的产能利用率并且排队时间为&lt;/span&gt;&lt;span style=&quot;font-family: Verdana;&quot;&gt;0.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/7ad27a1f4074d18db576287de7e48c49.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;(原图为交互图，可在原文查看)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;然而，在现实世界中出现排队的情况下——当然是人参与的那种排队，这种完全确定的过程超出我们的能力范围。同时就像之前讨论的那样，在某些产品设计研发的活动中，我们也并不想要这种完全确定的过程。&lt;/p&gt;
&lt;h2&gt;限制在制品数量&lt;/h2&gt;
&lt;p&gt;若队列大小和产能利用率之间存在指数级的关系，那么如果我们选择限制队列大小，或者换句说话，我们对在制品数量做限制呢？排队时间和产能利用率又会发生怎样的变化？&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/31146bb9b8b0568d1063482927c19b10.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;(原图为交互图，可在原文查看)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这似乎是一个合理有效的策略。如果我们对频繁的到达过程做出比较严格的&lt;span style=&quot;font-family: Verdana;&quot;&gt;WIP&lt;/span&gt;&lt;span style=&quot;font-family: 宋体;&quot;&gt;限制，就能很有效的打破产能利用率和队列大小之间的指数关系。我们可以高负荷运转，同时任务的排队时间也比较短。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;当然，这样做的代价是得拒绝一些到达的请求。对在制品数目作出限制的情况下，我们只能选择丢弃一些到达的请求任务，不对这些请求做处理。对于这些HTTP&lt;span style=&quot;font-family: 宋体;&quot;&gt;请求只能返回一个网关超时的错误。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;当然，对在制品做限制的手段并不只有简单丢弃请求这一种方式。相反，这种WIP&lt;span style=&quot;font-family: 宋体;&quot;&gt;限制技术是其他更高级策略的重要构建块。&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当队列大小达到上限时，你可以引入其他兼职资源从实质上支援服务过程（或者给同一队列增加额外的服务过程）。当队列大小降下来之后，你可以去掉这些额外资源。这种策略在超市中很常见，当开始出现排队的时候，就会增加收银员来收银。IT&lt;span style=&quot;font-family: 宋体;&quot;&gt;从业人员对这种情况也比较熟悉，当某项目落后于计划时，他们就会被“召唤”过去帮忙。&lt;/span&gt;
&lt;/li&gt;
&lt;li&gt;当你打算不再接新任务时可以给上游发送信号，上游过程可以停止任务或者将在制品加入成本较低的队列池中&lt;span style=&quot;color: #000000;&quot;&gt;。这种WIP&lt;span style=&quot;font-family: 宋体;&quot;&gt;信号机制是&lt;/span&gt;Eli Goldratt瓶颈理论(&lt;a href=&quot;http://en.wikipedia.org/wiki/Theory_of_constraints&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;Theory of Constraints&lt;/span&gt;&lt;/a&gt;)的基础，该理论中瓶颈的WIP&lt;/span&gt;&lt;span style=&quot;font-family: 宋体;&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;约束用来限制整个系统的操作速度。&lt;/span&gt;它同样也是丰田制造系统（&lt;/span&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Toyota_Production_System&quot;&gt;Toyota Production System&lt;/a&gt;）中看板系统的基础，在这个系统中，过程间的在制品都在本地控制，一旦在制品数量达到上限就给上游发送信号。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;队列如此的普遍而又如此重要，&lt;span style=&quot;color: #000000;&quot;&gt;对它们做定量的推理以及给它们的概率系统建模就显得很有意义。&lt;/span&gt;希望在这篇文章中我给你们传达出了这种意思。&lt;/p&gt;
&lt;p&gt;鉴于这个话题的广度和深度，在文中我只做了一些简单的说明，并不完整。&lt;span style=&quot;color: #000000;&quot;&gt;可能最大的疏漏点在于忽略了排队带来的经济效益：&lt;/span&gt;听起来好像排队都是不好的并且需要将排队问题最小化。不过，这就跟简单的说“产能利用率应该最大化”一样。实际上，可以基于经济决策来对队列大小和产能利用率做出权衡。如果你能从相同的角度来量化这二者的成本，你就可以做出这样的决策。&lt;/p&gt;
&lt;p&gt;这一点，以及队列的其他方面，可变性，在制品等概念都在这本书《产品开发过程原理》（&lt;a href=&quot;http://www.amazon.com/The-Principles-Product-Development-Flow/dp/1935401009&quot;&gt;The Principles of Product Development Flow&lt;/a&gt;）中涵盖了，如果各位对这些话题感兴趣的话，我真心推荐你们阅读这本书。&lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87158&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87158votetotal&quot;&gt;2&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87158&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt; 2 评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;

&lt;div id=&quot;author-bio&quot;&gt;
	
	&lt;h3 class=&quot;widget-title&quot;&gt;
	关于作者：&lt;a target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/fengzhixun&quot;&gt;巽离&lt;/a&gt;
	&lt;/h3&gt;
	&lt;div class=&quot;alignleft&quot;&gt;
		&lt;a target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/fengzhixun&quot;&gt;
			&lt;img src=&quot;/images/jobbole.com/4d8ad0b6e65624d1c18aac0963063eaf.jpg&quot;&gt;
		&lt;/a&gt;
	&lt;/div&gt;

    &lt;div class=&quot;author-bio-info&quot;&gt;

        &lt;span class=&quot;author-bio-info-block&quot;&gt;
            坐标北京， linux应用程序开发，家乡安徽巢湖。@饕餮巽离        &lt;/span&gt;
        &lt;span class=&quot;author-bio-info-block&quot;&gt;
            &lt;a href=&quot;http://www.jobbole.com/members/fengzhixun&quot; target=&quot;_blank&quot;&gt;&lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt; 个人主页&lt;/a&gt; ·
            &lt;a href=&quot;http://blog.jobbole.com/author/fengzhixun/&quot; target=&quot;_blank&quot;&gt;&lt;i class=&quot;fa fa-file-text-o&quot;&gt;&lt;/i&gt; 我的文章&lt;/a&gt; ·
            &lt;a title=&quot;声望值&quot; target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/fengzhixun/reputation/&quot;&gt;&lt;i class=&quot;fa fa-graduation-cap&quot;&gt;&lt;/i&gt; 11&lt;/a&gt;        &lt;/span&gt;
    &lt;/div&gt;
	&lt;div class=&quot;clear&quot;&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Fri, 29 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-29-87158-45c4542f0.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-29-87158-45c4542f0.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>林仕鼎：系统架构领域的一些学习材料</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;p&gt;系统架构是一个工程和研究相结合的领域，既注重实践又依赖理论指导，入门容易但精通很难，有时候还要讲点悟性，很具有“伪科学”的特征。要在此领域进阶，除了要不断设计并搭建实际系统，也要注意方法论和设计理念的学习和提炼。&lt;/p&gt;
&lt;p&gt;经常有同学询问如何学习，特贴一篇学习材料，供大家参考。09年时写的，在系统领域浩如烟海的文献中提取了一些我认为值得研究和学习的项目，没包括近几年出现的一些工作，也不够全面。不过，其实也足够了，看paper是一个从少到多再到少的过程。对问题本质、背景和发展历史有大致了解，再辅以hands-on的实践（长期的真正的实践），足以摸到本领域的门径。&lt;/p&gt;
&lt;p&gt;此文在网上转载不少，但多数没有说明出处。今天在这里重发，也顺便向315致敬。&lt;/p&gt;
&lt;p&gt;—&lt;/p&gt;
&lt;p&gt;对于工程师来说，到一定阶段后往往会遇到成长瓶颈。要突破此瓶颈，需要在所属技术领域更深入学习，了解本领域的问题本质、方法论与设计理念、发展历史等。以下提供一些架构相关领域的学习材料，附上简单点评，供有兴趣的工程师参考。希望大家能通过对这些领域的了解和学习，掌握更多system design principles，在自己的工作中得心应手，步入自由王国。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Operating Systems&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Mach&lt;/strong&gt; [Intro: &lt;a href=&quot;http://www-2.cs.cmu.edu/afs/cs/project/mach/public/www/mach.html&quot;&gt;http://www-2.cs.cmu.edu/afs/cs/project/mach/public/www/mach.html&lt;/a&gt;,Paper: &lt;a href=&quot;http://www-2.cs.cmu.edu/afs/cs/project/mach/public/www/doc/publications.html&quot;&gt;http://www-2.cs.cmu.edu/afs/cs/project/mach/public/www/doc/publications.html&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;传统的kernel实现中，对中断的响应是在一个“大函数”里实现的。称为大函数的原因是从中断的入口到出口都是同一个控制流，当有中断重入发生的时候，实现逻辑将变得非常复杂。大多数的OS，如UNIX，都采用这种monolithic kernel architecture。&lt;/p&gt;
&lt;p&gt;1985年开始的Mach项目，提出了一种全新的microkernel结构，使得由于70年代UNIX的发展到了极致而觉得后续无枝可依的学术界顿时找到了兴奋点，也开始了沸沸扬扬的monokernel与microkernel的争论。&lt;/p&gt;
&lt;p&gt;插播一个花絮：Mach的主导者Richard Rashid，彼时是CMU的教授，受BillGates之托去游说JimGray加盟MS。结果把自己也被绕了进来，组建了Microsoft Research。他到中国来做过几次21Century Computing的keynotes。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Exokernel&lt;/strong&gt;  [Intro:&lt;a href=&quot;http://pdos.csail.mit.edu/exo/&quot;&gt;http://pdos.csail.mit.edu/exo/&lt;/a&gt;，Paper:&lt;a href=&quot;http://pdos.csail.mit.edu/PDOS-papers.html#Exokernels&quot;&gt;http://pdos.csail.mit.edu/PDOS-papers.html#Exokernels&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;虽然microkernel的结构很好，但实际中并没有广泛应用，因为performance太差，而且大家逐渐发现OS的问题并不在于实现的复杂性，而更多在于如何提高application使用资源的灵活性。这也就是在kernel extension（例如loadable module in Linux）出现后，有关OS kernel architecture的争论就慢慢淡出人们视线的原因。&lt;/p&gt;
&lt;p&gt;Exokernel正是在这样的背景中出现的，它并不提供传统OS的abstraction（process,virtual memory等），而是专注于资源隔离与复用（resource isolation and multiplexing），由MIT提出。在exokernel之上，提供了一套库，著名的libOS，用于实现各种OS的interface。这样的结构为application提供了最大的灵活度，使不同的application可以或专注于调度公平性或响应实时性，或专注于提高资源使用效率以优化性能。以今天的眼光来看，exokernel更像是一个virtual machine monitor。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Singularity&lt;/strong&gt; [Intro:&lt;a href=&quot;http://research.microsoft.com/os/Singularity/&quot;&gt;http://research.microsoft.com/os/Singularity/&lt;/a&gt;,Paper: &lt;a href=&quot;http://www.research.microsoft.com/os/singularity/publications/HotOS2005_BroadNewResearch.pdf&quot;&gt;http://www.&lt;br&gt;
research.microsoft.com/os/singularity/publications/HotOS2005_BroadNewResearch.pdf&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;Singularity出现在virus，spyware取之不尽、杀之不绝的21世纪初期，由Microsoft Research提出。学术界和工业界都在讨论如何提供一个trust-worthy computing环境，如何使计算机系统更具有manage-ability。Singularity认为要解决这些问题，底层系统必须提供hardisolation，而以前人们都依赖的硬件virtual memory机制并无法提供高灵活性和良好性能。在.Net和Java等runtime出现之后，一个软件级的解决方案成为可能。&lt;/p&gt;
&lt;p&gt;Singularity在microkernel的基础上，通过.Net构建了一套type-safed assembly作为ABI，同时规定了数据交换的message passing机制，从根本上防止了修改隔离数据的可能。再加上对application的安全性检查，从而提供一个可控、可管理的操作系统。由于.NetCLR的持续优化以及硬件的发展，加了这些检查后的Singularity在性能上的损失相对于它提供的这些良好特性，仍是可以接受的。&lt;/p&gt;
&lt;p&gt;这种设计目前还处于实验室阶段，是否能最终胜出，还需要有当年UNIX的机遇。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Virtual Machines&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;VMWare&lt;/strong&gt; [&quot;&lt;a href=&quot;http://www.usenix.org/events/osdi02/tech/waldspurger/waldspurger.pdf&quot;&gt;MemoryResource Management in VMware ESX Server&lt;/a&gt;&quot;，OSDI’02,Best paper award]&lt;br&gt;
耳熟能详的vmware，无需多说。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;XEN&lt;/strong&gt;  [“&lt;a href=&quot;http://www.cl.cam.ac.uk/research/srg/netos/papers/2003-xensosp.pdf&quot;&gt;Xen and the Art of Virtualization&lt;/a&gt;”, OSDI’04]&lt;br&gt;
性能极好的VMM，来自Cambridge。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Denali&lt;/strong&gt;  [“&lt;a href=&quot;http://denali.cs.washington.edu/pubs/distpubs/papers/denali_osdi.pdf&quot;&gt;Scaleand Performance in the Denali Isolation Kernel&lt;/a&gt;”, OSDI’02, UW]&lt;br&gt;
为internetservices而设计的application level virtual machine，在普通机器上可运行数千个VMs。其VMM基于isolation kernel，提供隔离，但并不要求资源分配绝对公平，以此减少性能消耗。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Entropia [“&lt;a href=&quot;http://www-csag.ucsd.edu/papers/Entropia-VM.pdf&quot;&gt;The Entropia VirtualMachine for Desktop Grids&lt;/a&gt;”, VEE’05]&lt;/strong&gt;&lt;br&gt;
要统一利用公司内桌面机器资源来进行计算，需要对计算任务进行良好的包装，以保证不影响机器正常使用并与用户数据隔离。Entropia就提供了这样的一个计算环境，基于windows实现了一个application level virtual machine。其基本做法就是对计算任务所调用的syscall进行重定向以保证隔离。类似的工作还有FVM：“&lt;a href=&quot;http://www.usenix.org/events/vee06/full_papers/p24-yu.pdf&quot;&gt;AFeather-weight Virtual Machine for Windows Applications&lt;/a&gt;”。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. Design Revisited&lt;/strong&gt;&lt;br&gt;
“&lt;a href=&quot;http://www.usenix.org/event/hotos05/final_papers/full_papers/hand/hand.pdf&quot;&gt;Are Virtual Machine Monitors Microkernels Done Right?&lt;/a&gt;”，HotOS’05&lt;/p&gt;
&lt;p&gt;这个题目乍听起来，十分费解，其意思是VMMs其实就是Microkernel的正确实现方法。里面详细讨论了VMM和Microkernel，是了解这两个概念的极好参考。&lt;/p&gt;
&lt;p&gt;“&lt;a href=&quot;http://www.usenix.org/events/hotos05/final_papers/full_papers/brewer/brewer.pdf&quot;&gt;Thirty Years Is Long Enough: Getting Beyond C&lt;/a&gt;”, HotOS’05&lt;/p&gt;
&lt;p&gt;C可能是这个世界上最成功的编程语言，但其缺点也十分明显。比如不支持thread，在今天高度并行的硬件结构中显得有点力不从心，而这方面则是functional programming language的长处，如何结合二者的优点，是一个很promising的领域。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. Programming Model&lt;/strong&gt;&lt;br&gt;
“&lt;a href=&quot;http://www.stanford.edu/class/cs240/readings/threads-bad-usenix96.pdf&quot;&gt;Why Threads Are a Bad Idea&lt;/a&gt;”&lt;/p&gt;
&lt;p&gt;单使用thread结构的server是很难真正做到高性能的，原因在于内存使用、切换开销、同步开销和保证锁正确性带来的编程复杂度等。&lt;/p&gt;
&lt;p&gt;“&lt;a href=&quot;http://www.eecs.harvard.edu/~mdw/papers/seda-sosp01.pdf&quot;&gt;SEDA: An Architecture for Well-Conditioned, Scalable Internet Services&lt;/a&gt;”，OSDI’01&lt;/p&gt;
&lt;p&gt;Thread不好，但event也没法解决所有问题，于是我们寻找一个结合的方法。SEDA将应用拆分为多个stage，不同stage通过queue相连接，同一个stage内可以启动多个thread来执行queue中的event，并且可通过反馈来自动调整thread数量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Software Transactional Memory&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果内存可以提供transaction语义，那么我们面对的世界将完全两样，language, compiler, OS, runtime都将发生根本变化。虽然intel现在正在做hardware transactional memory，但估计可预见的将来不会商用，所以人们转而寻求软件解决方案。可想而知，这个方案无法base在native assembly上，目前有C#,haskell等语言的实现版本。资料比较多，参见&lt;a href=&quot;http://en.wikipedia.org/wiki/Software_transactional_memory&quot;&gt;Wikipedia&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5. Distributed Algorithms&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Logical clock&lt;/strong&gt;, [“&lt;a href=&quot;http://portal.acm.org/ft_gateway.cfm?id=359563&amp;amp;type=pdf&amp;amp;coll=GUIDE&amp;amp;dl=GUIDE&amp;amp;CFID=12744388&amp;amp;CFTOKEN=15273596&quot;&gt;Time,clocks, and the ordering of events in a distributed system&lt;/a&gt;”, Leslie Lamport, 1978]&lt;/p&gt;
&lt;p&gt;这是一篇关于Logic clock, time stamp, distributed synchronization的经典paper。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Byzantine&lt;/strong&gt;  [“&lt;a href=&quot;http://research.microsoft.com/users/lamport/pubs/byz.pdf&quot;&gt;The ByzantineGenerals Problem&lt;/a&gt;”, Leslie Lamport, 1982]&lt;/p&gt;
&lt;p&gt;分布式系统中的错误各种各样，有出错就能停机的，有出错了拖后腿的，更严重的是出错了会做出恶意行为的。最后的这种malicious behavior，就好像出征将军的叛变，将会对系统造成严重影响。对于这类问题，Lamport提出了Byzantine failure model，对于一个由3f+1个replica组成的statemachine，只要叛变的replica数量小于等于f，整个state machine还能正常工作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Paxos [“&lt;a href=&quot;http://portal.acm.org/ft_gateway.cfm?id=279229&amp;amp;type=pdf&amp;amp;coll=GUIDE&amp;amp;dl=GUIDE&amp;amp;CFID=12744388&amp;amp;CFTOKEN=15273596&quot;&gt;The part-time parliament&lt;/a&gt;”, Leslie Lamport, 1998]&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如何在一个异步的分布式环境中达成consensus，这是分布式算法研究的最根本问题。Paxos是这类算法的顶峰。不过这篇paper太难了，据说全世界就3.5人能看懂，所以Lamport后来又写了一篇普及版paper：“&lt;a href=&quot;http://research.microsoft.com/users/lamport/pubs/paxos-simple.pdf&quot;&gt;Paxos Made Simple&lt;/a&gt;” ，不过还是很难懂。另外，也可参看Butler Lampson写的“&lt;a href=&quot;http://portal.acm.org/citation.cfm?id=383962.383969&amp;amp;coll=GUIDE&amp;amp;dl=GUIDE&amp;amp;CFID=12744978&amp;amp;CFTOKEN=60475496&quot;&gt;The ABCD’s of Paxos&lt;/a&gt;”（PODC’01），其中关于replicated state machine的描述会严重启发你对并行世界本质的认识，图灵奖的实力可不是盖的。&lt;/p&gt;
&lt;p&gt;这上面反复出现了一个名字：&lt;a href=&quot;http://research.microsoft.com/users/lamport/&quot;&gt;Leslie Lamport&lt;/a&gt;，他在distributed computing这个领域挖坑不辍，终成一代宗师。关于他，也有几则轶事。记得以前他在MSR的主页是这么写的，“当我在研究logicalclock的时候，BillGates还穿着开裆裤(in diaper)…”（大意如此，原文现在找不到了）。另外，他在写paper的时候，很喜欢把其他牛人的名字变换一下编排进去。这可能也是他还没拿到图灵奖的原因。[注1]&lt;/p&gt;
&lt;p&gt;关于Lamport的其他成就，还可以参见这篇向他60岁生日献礼的paper：“&lt;a href=&quot;http://portal.acm.org/ft_gateway.cfm?id=383967&amp;amp;type=pdf&amp;amp;coll=GUIDE&amp;amp;dl=GUIDE&amp;amp;CFID=12744388&amp;amp;CFTOKEN=15273596&quot;&gt;Lamport on mutual exclusion: 27 years of planting seeds&lt;/a&gt;”, PODC’01。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6. Overlay Networking, and P2P DHT&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RON&lt;/strong&gt;  [“&lt;a href=&quot;http://nms.lcs.mit.edu/papers/ron-sosp2001.html&quot;&gt;Resilient Overlay Networks&lt;/a&gt;”, SOSP’01]&lt;/p&gt;
&lt;p&gt;RON描述了如何在应用层搭建一个overlay，以提供秒级广域网网络层故障恢复速度，而现有的通过路由协议来恢复通信的时间至少在几十分钟。这种快速恢复特性和灵活性使得overlay networking现在被广泛应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Application Level Multicast&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;“&lt;a href=&quot;http://www.cs.cmu.edu/~hzhang/papers/sigmetrics-2000.ps.gz&quot;&gt;End System Multicast&lt;/a&gt;”, SigMetrics’00&lt;/p&gt;
&lt;p&gt;“&lt;a href=&quot;http://pages.cs.wisc.edu/~suman/pubs/sigcomm02.pdf&quot;&gt;Scalable Application Layer Multicast&lt;/a&gt;”, SigComm’02&lt;/p&gt;
&lt;p&gt;关于ALM的paper很多，基本上都是描述如何搭建一个mesh network用以鲁棒的传输控制信息，另外再搭建一个multicast tree用以高效传输数据，然后再根据多媒体数据的特点做一些layered delivery。前几年出现的coolstream, pplive等系统都是这类系统的商业化产品。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;P2P&lt;/strong&gt;&lt;br&gt;
P2P的出现改变了网络。按照各种P2P网络的结构，可以分为三种。&lt;br&gt;
1. Napster式，集中式目录服务，数据传输Peer to peer。&lt;br&gt;
2. Gnutella式，通过在邻居间gossip来查询，也被称为unstructured P2P。&lt;br&gt;
3. DHT，与unstructured P2P不同的是，DHT进行的查询有保证，如果数据存在，可在一定的hop数内返回。这个hop数通常为logN，N为系统节点数。&lt;/p&gt;
&lt;p&gt;典型的DHT有&lt;a href=&quot;http://berkeley.intel-research.net/sylvia/cans.pdf&quot;&gt;CAN&lt;/a&gt;, &lt;a href=&quot;http://pdos.csail.mit.edu/papers/chord:sigcomm01/chord_sigcomm.pdf&quot;&gt;Chord&lt;/a&gt;,&lt;a href=&quot;http://research.microsoft.com/~antr/PAST/pastry.pdf&quot;&gt;Pastry&lt;/a&gt;, &lt;a href=&quot;http://oceanstore.cs.berkeley.edu/publications/papers/pdf/tapestry_sigcomm_tr.pdf&quot;&gt;Tapestry&lt;/a&gt;等四种。这些研究主要在算法层面，系统方面的工作主要是在其上建立广域网存储系统。还有一些人在机制层面进行研究，例如如何激励用户共享、防止作弊等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7. Distributed Systems&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GFS/MapReduce/BigTable/Chubby/Sawzall&lt;/strong&gt;&lt;br&gt;
Google的系列paper，大家比较熟悉，不再多说。在此可查。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Storage&lt;/strong&gt;&lt;br&gt;
Distributed storage system的paper太多了。下面列出几篇最相关的。&lt;/p&gt;
&lt;p&gt;“&lt;a href=&quot;http://www.cs.cornell.edu/fbs/publications/chainreplicosdi.pdf&quot;&gt;Chain Replication for Supporting High Throughput and Availability&lt;/a&gt;”, OSDI’04。&lt;/p&gt;
&lt;p&gt;“&lt;a href=&quot;http://s3.amazonaws.com/AllThingsDistributed/sosp/amazon-dynamo-sosp2007.pdf&quot;&gt;Dynamo: Amazon’s Highly Available Key-value Store&lt;/a&gt;”，SOSP’07。&lt;/p&gt;
&lt;p&gt;“&lt;a href=&quot;http://research.microsoft.com/asia/dload_files/group/system/2007/BitVault-SigOpsOSR0704.pdf&quot;&gt;BitVault: a Highly Reliable Distributed Data Retention Platform&lt;/a&gt;”, SIGOPS OSR’07。&lt;/p&gt;
&lt;p&gt;“&lt;a&gt;PacificA: Replication inLog-Based Distributed Storage Systems&lt;/a&gt;”, MSR-TR。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Distributed Simulation&lt;/strong&gt;&lt;br&gt;
“&lt;a href=&quot;http://research.microsoft.com/asia/dload_files/group/system/wids-mascots.pdf&quot;&gt;Simulating Large-Scale P2P Systems with the WiDS Toolkit&lt;/a&gt;”, MASCOTS’05。Distributed simulation有意思的地方是simulated protocol是distributed的，而这个simulation engine本身也是distributed的。Logical和physical的time和event交杂在系统中，需要仔细处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8. Controversial Computing Models&lt;/strong&gt;&lt;br&gt;
现在的软件系统已经复杂到了人已经无法掌握的程度，很多系统在发布时都仍然带着许多确定性(deterministic)或非确定性(non-deterministic)的bugs，只能不断的patch。既然作为人类，不够精细的特性决定了我们无法把系统的bug fix干净，我们只能从其他角度入手研究一种让系统在这令人沮丧的环境中仍能工作的方法。这就像一个分布式系统，故障无法避免，我们选择让系统作为整体来提供高可靠性。&lt;/p&gt;
&lt;p&gt;以下3个便是典型代表。基本上，主要研究内容都集中于1) 如何正确保存状态；2)如何捕捉错误并恢复状态；3)在进行单元级恢复时，如何做到不影响整体。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://roc.cs.berkeley.edu/&quot;&gt;Recovery Oriented Computing&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.cag.lcs.mit.edu/~rinard/paper/osdi04.pdf&quot;&gt;Failure oblivious computing&lt;/a&gt;, OSDI’04&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://opera.cs.uiuc.edu/paper/Rx-SOSP05.pdf&quot;&gt;Treating Bugs as Allergies&lt;/a&gt;, SOSP’05&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9. Debugging&lt;/strong&gt;&lt;br&gt;
系统很复杂，人类无法从逻辑上直接分析，只能通过data mining的方法在宏观上进行观察。&lt;br&gt;
Black box debugging[“&lt;a href=&quot;http://pdos.csail.mit.edu/~athicha/papers/blackboxes:sosp03.pdf&quot;&gt;Performance debugging for distributed systems of black boxes&lt;/a&gt;”, SOSP’03]&lt;br&gt;
对大型系统的performance debugging非常困难，因为里面的问题很多都是非确定性的，而且无法重现。只能通过对log的挖掘，找出配对的调用/消息以定位问题。&lt;/p&gt;
&lt;p&gt;CP-miner [“A Tool for Finding Copy-paste and Related Bugs in Operating System Code”, OSDI’04]&lt;br&gt;
很多人在重用代码的时候，都使用copy-paste。但有时候简单的CP会带来严重的问题，例如局部变量的重名等。CP-miner通过分析代码，建立语法树结构，然后mine出这类错误。&lt;/p&gt;
&lt;p&gt;—&lt;/p&gt;
&lt;p&gt;注1：2014年3月19日，Lamport获得2013年度图灵奖，也是Microsoft Research的第5位图灵奖获得者。一代宗师，实至名归，功德圆满，可喜可贺。&lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87194&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87194votetotal&quot;&gt;2&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87194&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt;  评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Thu, 28 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-28-87194-29f8034d0.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-28-87194-29f8034d0.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL on Hadoop 的真相（2）</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;p&gt;这是一组系列博客，目的是详尽介绍 SQL-on-Hadoop 。&lt;a href=&quot;http://blog.jobbole.com/86710/&quot; target=&quot;_blank&quot;&gt;该系列的第一篇会介绍一些存储引擎和在线事务处理（简称 OLTP ）相关话题&lt;/a&gt;，这一篇将介绍联机分析处理（简称 OLAP ），第三篇将介绍对 Hadoop 引擎改造以及在相关替代产品中如何选型等话题。&lt;/p&gt;
&lt;h3&gt;数据处理与联机分析处理 ( OLAP )&lt;/h3&gt;
&lt;p&gt;联机分析处理是那些为了支持商业智能，报表和数据挖掘与探索等业务而开展的工作。这类工作的例子有零售商按地区和季度两个维度计算门店销售额，银行按语言和月份两个维度计算手机银行装机量，设备制造商定位有哪些零部件的故障率比期望值高，以及医院研究有哪些事件会引起高危婴儿紧张等。&lt;/p&gt;
&lt;p&gt;如果原始数据来源于 OLTP 系统，典型的做法是将这些数据拷贝到 OLAP 数据库中，再进行这类“离线”分析任务的处理，这么做有很多原因，但考虑最多的还是性能因素。&lt;/p&gt;
&lt;p&gt;假设一下，如果一个实体店使用他们的事务处理系统来承担数据分析工作，这种情况下分析师提交的粗暴查询就可能会实实在在地影响并拉低门店对于那些已经记录在册等待结算的订单结算率。另外用于事务中的查询类型从根本上就不同于数据分析类查询。&lt;/p&gt;
&lt;p&gt;事务系统典型的查询是基于某个独立的实体，比如某一个客户或某一个用户。例如当一个在线零售网站创建一个交易订单状态页时，数据的查询是针对某一个客户已经提交的特定订单。然而在数据分析的用例中，分析师最感兴趣的却是那些根据时间维度划分查询本身已跨越了订单或用户数据的汇总信息。就如前面提到的那样，根据区域和季度两个维度统计的门店销售额会查询给定时间段内所有订单数据。&lt;/p&gt;
&lt;p&gt;行动之前还有最后一个注意要点，本篇中的数据库并不提供传统关系型数据库用户所期望的那类增删改操作。与事务系统不同的是，分析类型的查询主要是那些涉及到数百万甚至数亿行数据的 SELECT 查询。分析型数据库的优化也主要围绕着这类负载进行，而这些优化措施却会导致针对小批量数据的增删改操作执行起来代价昂贵。&lt;/p&gt;
&lt;p&gt;即便这类数据库在接口和语义方面都与关系型数据库不同，但他们也确实提供了增加行 （ INSERT ），更新行（ UPDATE ）和删除行（ DELETE ）操作的功能支持。有些读者或许正在问 Hive 系统里最近新增加的 “ ACID ” 相关的问题，容后详禀。&lt;/p&gt;
&lt;p&gt;在 Hive 系统的 “ACID” 功能之外，处理更新操作有两种方式可选，一种是使用数据所在的 HBase 系统本身提供的更新功能。尽管 HBase 经常主要用于 OLTP 业务，但有些 OLAP 系统会使用 HBase 来存储一些小表，典型的称为维度表，这类表需要周期性地更新。第二种处理更新操作的方式是执行一次合并操作。&lt;/p&gt;
&lt;p&gt;从一个 ETL 开发者角度出发，一个合并过程会引入额外工作量。因此有个问题一定会被问到，那就是既然 HBase 系统已经提供了更新功能，那这类合并工作就不是必须的，那为什么不直接都用 HBase 呢？原因是扫描查询的处理性能，如果要在基于尾部追加模式的 HDFS 文件系统提供随机更新的功能，HBase 就得在它读取每一行时都做少量的合并操作，这个架构决定了能提供较高的写和随机读性能，但与 HDFS 相比，只能提供较差的扫描查询和顺序读操作性能。这样一来 HBase 就只能用于存储那些需要频繁更新的小表场合；&lt;/p&gt;
&lt;p&gt;这个领域包含几个子目录：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apache Hive&lt;/li&gt;
&lt;li&gt;Dremel clones&lt;/li&gt;
&lt;li&gt;Spark SQL&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Apache Hive&lt;/h3&gt;
&lt;p&gt;本项目最初由脸谱公司创建，Hive 是第一个基于 Hadoop 之上的 SQL 引擎，且至今仍是最成熟的。Hive 原先是构建在MapReduce之上的，也曾经被改造过以便运行在 Apache Tez 上，现在正在进行的是为适应 Apache Spark 而进行的改造，基于 Spark 的Hive 改造被称为是最后的工作，但不能与 Spark 项目上的其他 SQL 支持项目相互混淆，关于 Spark 上的其他 SQL 支持项目我会再找个合适时机进行讨论。&lt;/p&gt;
&lt;p&gt;到目前为止，Hive 拥有最完整的 SQL 功能支持，并且也是拥有最多贡献者的项目，几乎所有的 Hadoop 用户都会部署Hive，同时几乎 Hadoop 上其他 SQL 引擎使用者也都会部署 Hive ，事实上大多数 SQL 引擎都以这种或那种方式依赖于Hive 。&lt;/p&gt;
&lt;p&gt;大多数 Hadoop 赞助商，包括 Cloudera 和 Hortonworks，都一致认同 Hive 是唯一有能力处理大批量任务和集成多种非标准数据格式的组件。Hortonworks 与 Cloudera 意见相左的地方在于对 Hive 的性能评价，Clourdera 觉得 Hive 的性能简直不能与 Dremel clones 相比，而 Hortonworks 则觉得 Hive 可以和 Dremel Clones 一较高下。&lt;/p&gt;
&lt;h3&gt;Dremel Clones&lt;/h3&gt;
&lt;p&gt;就像开源界一样，谷歌内部也创立了多个 SQL 引擎，他们有一个类似于 Hive 的 SQL 引擎叫 Tenzing，还有另外一个系统叫 Dremel。Hive 的创立者 Facebook 公司也创建了一个 Dremel 的克隆版本叫 Presto。&lt;/p&gt;
&lt;p&gt;Cloudera Impala 和 Apache Drill 是最杰出的两个 Dremel 克隆版本，Cloudera 将 Impala 市场定位为最成熟的开源 Dremel 分支，Impala 在2013年年中发布 GA 版本，MapR 是 Drill 背后的主要赞助商，他把 Drill 的市场角色定位为最灵活的 Dremel 分支， Impala 能满足在 Hive 系统中存储元数据表的需求，而 Drill 可以直接查询 JSON 和自定义格式文件，比如 Apache Parquet 和 Avro 文件格式等。&lt;/p&gt;
&lt;h3&gt;Spark SQL&lt;/h3&gt;
&lt;p&gt;尽管有 Hadoop 上有其他多个 SQL 引擎，但 Spark SQL 却有着对其感兴趣的最广泛受众。Spark SQL 是 Spark 引擎上的榜眼，而状元是 Shark， Shark 因为顾及 Spark SQL 和 Hive on Spark 项目，Shark 目前已经终止开发，与 Shark 项目曾近是加州伯克利大学的一个研究项目不同，Spark SQL 和 Hive on Spark 已经在 Spark 赞助商们的支持下建立了各自的开源项目；&lt;/p&gt;
&lt;p&gt;基于 Spark 的 Hive 可以简单地说成是前端是 Hive 后端是 Spark ，基于 MR 或 Tez 的 Hive 既有用户可以在原系统与 Hive on Spark 系统之间轻松切换，切换工作仅仅只需要简单地修改下配置参数。&lt;/p&gt;
&lt;p&gt;Spark SQL 是一个完整的新引擎，今天的 Spark SQL 对那些希望把 SQL 嵌入到他们的 Scala，Java 或者 Python 程序的Spark 开发者而言是最有用的，但 Spark SQL 的主要赞助商 Databricks 对 Spark SQL 还有着更大的雄心，并指望将 Spark SQL 的使用范围扩展到非 Spark 开发者中去；&lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87159&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87159votetotal&quot;&gt;&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87159&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt;  评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;

&lt;div id=&quot;author-bio&quot;&gt;
	
	&lt;h3 class=&quot;widget-title&quot;&gt;
	关于作者：&lt;a target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/sunny4715&quot;&gt;jerry&lt;/a&gt;
	&lt;/h3&gt;
	&lt;div class=&quot;alignleft&quot;&gt;
		&lt;a target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/sunny4715&quot;&gt;
			&lt;img src=&quot;/images/jobbole.com/4d8ad0b6e65624d1c18aac0963063eaf.jpg&quot;&gt;
		&lt;/a&gt;
	&lt;/div&gt;

    &lt;div class=&quot;author-bio-info&quot;&gt;

        &lt;span class=&quot;author-bio-info-block&quot;&gt;
            西电通信工程本硕；熟悉监控设备SDK和流媒体服务器；原MySQL/NTSE内核组开发人员，熟悉MySQL内核与架构以及运维调优；现杭州某公司...        &lt;/span&gt;
        &lt;span class=&quot;author-bio-info-block&quot;&gt;
            &lt;a href=&quot;http://www.jobbole.com/members/sunny4715&quot; target=&quot;_blank&quot;&gt;&lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt; 个人主页&lt;/a&gt; ·
            &lt;a href=&quot;http://blog.jobbole.com/author/sunny4715/&quot; target=&quot;_blank&quot;&gt;&lt;i class=&quot;fa fa-file-text-o&quot;&gt;&lt;/i&gt; 我的文章&lt;/a&gt; ·
            &lt;a title=&quot;声望值&quot; target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/sunny4715/reputation/&quot;&gt;&lt;i class=&quot;fa fa-graduation-cap&quot;&gt;&lt;/i&gt; 10&lt;/a&gt;        &lt;/span&gt;
    &lt;/div&gt;
	&lt;div class=&quot;clear&quot;&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Thu, 28 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-28-87159-b9487b125.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-28-87159-b9487b125.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>我用 Go 语言做了一个红白机模拟器</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;译注：Family Computer（简称 FC）是任天堂（Nintendo）公司发行的家用游戏主机。日版 FC 机身以红色和白色为主，因此在华人圈中又有“红白机”的俗称；欧美版 FC 在欧美则称 Nintendo Entertainment System（简称 NES）。&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/bae393881c2ab1e2a30102da727eb1b2.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;（游戏截图）&lt;/p&gt;
&lt;p&gt;最近我编写了一个 &lt;a title=&quot;FC 模拟器&quot; href=&quot;https://github.com/fogleman/nes&quot;&gt;FC 模拟器&lt;/a&gt;。制作这样一个模拟器主要是出于兴趣以及为了从中学习 FC 的工作原理。在这个过程中我学到了很多有趣的知识，于是写下这篇文章同诸位分享我所学到的内容。由于相关的文档已经有很多了，所以这里我只打算讲述一些有趣的特性。请注意，接下来都将是些技术方面的内容。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/e37c04debfb4a37dfc1f83cca346f793.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图1 我的模拟器可以将画面录制成 GIF。这是我正在玩《大金刚》（Donkey Kong）的画面。&lt;/p&gt;
&lt;h2&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;CPU&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;FC 使用 MOS 6502（主频1.79MHz）作为其CPU。6502 是一枚诞生于 1975 年（距今已有 40 年之久了）的 8位微处理器。在当时这款芯片非常流行，不仅应用于 FC，还被广泛应用于雅达利 2600 &amp;amp; 800、Apple I &amp;amp; II、Commodore 64、VIC-20、BBC Micro等机器上。事实上，直到今天6502的修订版（&lt;a title=&quot;65C02&quot; href=&quot;http://en.wikipedia.org/wiki/WDC_65C02&quot;&gt;65C02&lt;/a&gt;）还依然在生产。&lt;/p&gt;
&lt;p&gt;6502 的寄存器相对较少，只有寄存器 A、 X 和 Y ，而且它们都是专用寄存器。尽管如此，其指令却有多种寻址模式。这其中包括一种称为“零页”（Zero Page）的寻址模式，使开发人员可以访问内存中最初的256个字（$0000～ $00FF）。6502 的操作码占用的程序内存较少，执行时花费的 CPU 周期也较短。这样理解，&lt;span style=&quot;color: #000000;&quot;&gt; 开发人员可以把零页上的 256 个存储单元看作是 256 个寄存器。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;6502 中没有乘法和除法指令，当然也没有浮点数运算指令。虽然有 BCD 码模式，但是在 FC 版的6502中，可能是由于专利问题该模式被禁用了。&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;译注：Binary-Coded Decimal，简称BCD，中国大陆称BCD码或二-十进制编码，是一种十进制的数字编码形式。在这种编码下，每个十进制数字用一串单独的二进制比特来存储表示。通常 4 个二进制数表示 1 个十进制数。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;6502 还具有一块不带溢出检测的 256 字节的栈空间。&lt;/p&gt;
&lt;p&gt;6502 拥有 151 条指令（理论上有 256 条指令）。剩余的 105 条都是非法或没有文档的指令，多数会使导致处理器崩溃。但是其中也有一些可能会碰巧产生某种作用，于是大部分这样的指令也会有与其作用相应的名称。&lt;/p&gt;
&lt;p&gt;6502 至少有一个已知的硬件上的缺陷，例如间接跳转指令的缺陷在于，当 &lt;code style=&quot;font-style: inherit;&quot;&gt;JMP &amp;lt;addr&amp;gt;&lt;/code&gt; 指令的操作数为形如 $xxFF 的地址时就无法正常工作。因为当从这样的地址读出 2 字节的数据时，该指令无法将低字节 FF 加 1 后（FF -&amp;gt; 00）产生的进位加到高字节上。例如，当从 $10FF 读出2字节的数据时，读取的其实是 $10FF 和 $1000 中的数据，而不是 $10FF 和 $1100 中的数据。&lt;/p&gt;
&lt;h2&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;内存映射&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;6502 拥有 16 位地址空间，寻址能力为 64 KB。但是 FC 实际只有 2 KB的 RAM（Internal RAM），对应的地址范围是 $0000～$0799。而剩余的地址空间则用于访问 PPU、 APU、游戏卡以及输入设备等。&lt;/p&gt;
&lt;p&gt;6502 上有些地址总线的引脚并没有布线，所以有很大的一块内存空间实际上都映射到了之前的空间。例如 RAM 中的 $1000～$17FF 就映射到了 $0000～$07FF，这意味着向 $1000 写数据等价于向 $0000 写数据。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/4eb364704ef254c1a2b215517a69bebf.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图2 “IT’S DANGEROUS TO GO ALONE! TAKE THIS.”（《塞尔达传说》中的游戏对白）&lt;/p&gt;
&lt;h2&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;PPU（图形处理器）&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;PPU 为 FC 生成视频输出。与 CPU 不同，PPU 芯片是为 FC 定制的，其运行频率是 CPU 的 3 倍。渲染时 PPU 在每个周期输出1个像素。&lt;/p&gt;
&lt;p&gt;PPU 能够渲染游戏中的背景层和最多 64 个子画面（Sprite）。子画面可以由 8 x 8 或 8 x 16 像素构成。而背景则既可以延水平（X轴）方向卷动，又可以延竖直（Y轴）方向卷动。并且 PPU 还支持一种称为微调（Fine）的卷动模式，即每次只卷动 1 像素。&lt;span style=&quot;color: #000000;&quot;&gt;这种卷动模式在当年可是非常了不起的技术。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;背景和子画面都是由 8 x 8 像素的图形块（Tile）构成的，而图形块是定义在游戏卡 ROM 中的 Pattern Table 里的。Pattern Table 中的图形块仅指定了其所用颜色中的最后 2 比特，剩余的 2 比特来自 Attribute Table。Nametable 则指定了图形块在背景上的位置。总之，这一切看起来都要比今天的标准复杂得多，所以我不得不和合作者解释说“这不是简单的位图”。&lt;/p&gt;
&lt;p&gt;背景的分辨率为 32 x 30 = 960 像素，由 8 x 8 像素的图形块构成。背景卷动的实现方法是再额外渲染多幅 32 x 30 像素的背景，且每幅背景都加上一个偏移量。如果同时沿 X 轴和 Y 轴卷动背景，那么最多可以有 4 幅背景处于可见状态。但是 FC 只支持 2 幅背景，因此游戏中经常使用不同的镜像模式（Mirroring Mode）来实现水平镜像或竖直镜像。&lt;/p&gt;
&lt;p&gt;PPU 包含 256 字节的 OAM（Object Attribute Memory）用于存储全部 64 个子画面的属性。属性包括子画面的 X 和 Y 坐标、对应的图形块编号以及一组标志位。在这组标志位中，有 2 比特用于指定子画面的颜色，还有用于指定子画面是显示在背景层之前还是之后，是否允许沿水平和/或竖直方向翻转子画面的标志位。FC 支持 DMA 复制，可以快速地将 256 字节从 CPU 可寻址的某段内存&lt;span style=&quot;color: #888888;&quot;&gt;（译注：通常是 $0200 – $02FF）&lt;/span&gt;填充到整个 OAM。像这样直接访问比手工逐字节拷贝大约快 3 倍左右。&lt;/p&gt;
&lt;p&gt;虽然 PPU 支持 64 个卡通图形，但是在一条扫描线（Scan Line）上只能显示 8 个子画面。当一条扫描线上有过多的子画面时，PPU 的溢出（Overflow）标志位将被置位，程序可以依此做出相应的处理。这也就是当画面中有很多的子画面时，这些子画面会发生闪烁的原因。另外，由于一个硬件上的缺陷，会导致溢出标志位有时不能正常工作。&lt;/p&gt;
&lt;p&gt;很多游戏会使用一种叫做 mid-frame 的技术，使 PPU 可以在屏幕的一部分做一件事而在另一部分做另一件事。这项技术经常用于分屏滚动画面或刷新分数条。这需要精确的时间掐算以及对每条指令所需 CPU 周期的详细了解。实现类似这样的功能将会加大编写模拟器的难度。&lt;/p&gt;
&lt;p&gt;PPU 具有一个原始形态的碰撞检测机制。如果第 1 个（编号为0的）子画面和背景相交，那么一个标志位将会被置位，表示“子画面0 发生了碰撞”。这种碰撞在每一帧只会发生一次。&lt;/p&gt;
&lt;p&gt;FC 具有一个内置的 54 色调色板，游戏只能使用这里面的颜色。这些颜色不是 RGB 颜色，基本上只会向电视输出特定的色度（Chroma）和亮度（Luminance）信号。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/185694862d0bd047747bf4423e0e6628.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图3 FC的调色板。&lt;/p&gt;
&lt;h2&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;APU（音频处理器）&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;APU 支持 5 个声道，包括 2 个方波声道，1 个三角波声道，1 个噪声声道和 1 个增量调制声道（DMC）。&lt;/p&gt;
&lt;p&gt;游戏程序需要向指定的寄存器（已映射到内存）写入数据以驱动这些声道发出声音。&lt;/p&gt;
&lt;p&gt;方波声道支持对频率和时值的控制，以及频率扫描（Frequency Sweep）和音量包络（Volume Envelope）。&lt;/p&gt;
&lt;p&gt;噪声声道可以利用线性反馈移位（Linear Feedback Shift）寄存器生成伪随机的噪声。&lt;/p&gt;
&lt;p&gt;增量调制声道（DMC）可以播放内存中的声音样本。例如在《超级马里奥3》中金属鼓的敲击声以及《忍者神龟3》中的语音“cowabunga”使用的都是DMC。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/46307fc1af8e2d1dbba3bcbb445f1043.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图4 打气球游戏&lt;/p&gt;
&lt;h2&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;内存映射器&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;预留给游戏卡的地址空间是有限的，游戏卡的程序内存（Program Memory）被限制在 32 KB，角色内存（Character Memory）被限制在 8 KB。为了突破这种限制，人们发明了内存映射器（Mapper）。&lt;/p&gt;
&lt;p&gt;内存映射器是游戏卡中的一个硬件，具有存储体空间切换（Bank Switching）的功能，以将新的程序或角色内存引入到可寻址的内存空间。程序可以通过向指向内存映射器的特定的地址写入数据来控制存储体空间的切换。&lt;/p&gt;
&lt;p&gt;不同的游戏卡实现了不同的存储体空间切换方案，所以会有十几种不同的内存映射器。既然模拟器要模拟 FC 的硬件，也就必须能够模拟游戏卡的 内存映射器。尽管如此，实际上 90% 的 FC 游戏使用的都是六种最常见的内存映射器中的一种。&lt;/p&gt;
&lt;h2&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;ROM文件&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;一个扩展名为 .nes 的 ROM 文件包含游戏卡中的一个或多个程序内存 Bank 和角色内存 Bank。除此之外还有一个简单的头部用于说明游戏中使用了哪种 Mapper 和视频镜像模式，以及是否存在带蓄电池后备电源的 RAM。&lt;/p&gt;
&lt;h2&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;结尾&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;学习 FC 很有意思，当时的人们能够用如此有限的硬件完成这样一款游戏机给我留下了深刻的印象。接下来我都想开始编写一个 8 比特风格的游戏了。&lt;/p&gt;
&lt;p&gt;我用 Go 语言编写了我的模拟器，用 OpenGL 和 GLFW 处理视频，PortAudio 处理音频。模拟器的代码都放到了 GitHub 上，欢迎诸位下载：&lt;a href=&quot;https://github.com/fogleman/nes&quot;&gt;https://github.com/fogleman/nes&lt;/a&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/deb084b22d8e8a0c9b86a566aecf68e2.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图5 我的最爱：《超级马里奥3》&lt;/p&gt;
&lt;h3&gt;了解更多&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://nesdev.com/NESDoc.pdf&quot;&gt;NES Documentation (PDF)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://wiki.nesdev.com/w/index.php/NES_reference_guide&quot;&gt;NES Reference Guide (Wiki)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.obelisk.demon.co.uk/6502/&quot;&gt;6502 CPU Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87068&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87068votetotal&quot;&gt;4&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87068&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt; 1 收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt; 1 评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;

&lt;div id=&quot;author-bio&quot;&gt;
	
	&lt;h3 class=&quot;widget-title&quot;&gt;
	关于作者：&lt;a target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/jackalhu&quot;&gt;JackalHu&lt;/a&gt;
	&lt;/h3&gt;
	&lt;div class=&quot;alignleft&quot;&gt;
		&lt;a target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/jackalhu&quot;&gt;
			&lt;img src=&quot;/images/jobbole.com/ca44b272678408d3e2650ac448de62da.jpg&quot;&gt;
		&lt;/a&gt;
	&lt;/div&gt;

    &lt;div class=&quot;author-bio-info&quot;&gt;

        &lt;span class=&quot;author-bio-info-block&quot;&gt;
            热爱编程，关注设计模式，致力于提升软件开发的质量。新浪微博：@Jackal-Hu        &lt;/span&gt;
        &lt;span class=&quot;author-bio-info-block&quot;&gt;
            &lt;a href=&quot;http://www.jobbole.com/members/jackalhu&quot; target=&quot;_blank&quot;&gt;&lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt; 个人主页&lt;/a&gt; ·
            &lt;a href=&quot;http://blog.jobbole.com/author/jackalhu/&quot; target=&quot;_blank&quot;&gt;&lt;i class=&quot;fa fa-file-text-o&quot;&gt;&lt;/i&gt; 我的文章&lt;/a&gt; ·
            &lt;a title=&quot;声望值&quot; target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/jackalhu/reputation/&quot;&gt;&lt;i class=&quot;fa fa-graduation-cap&quot;&gt;&lt;/i&gt; 11&lt;/a&gt;        &lt;/span&gt;
    &lt;/div&gt;
	&lt;div class=&quot;clear&quot;&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Thu, 28 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-28-87068-d4c8911d3.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-28-87068-d4c8911d3.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>实时处理日均50亿会话，解析Twitter Answers的架构</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;p&gt;去年我们&lt;a title=&quot;发布了Answers&quot; href=&quot;http://www.crashlytics.com/blog/launching-answers-by-crashlytics/&quot; target=&quot;_blank&quot;&gt;发布了Answers&lt;/a&gt;，至今移动社区产生了惊人的使用量，让我们感到兴奋不已。现在Answers每天处理50亿次会话，并且这个数量在持续增加。上亿设备每秒向Answers端点发送数以百万计的请求。在你已经阅读到此处的这段时间里，Answers后台收到并处理了一千万次分析事件。&lt;/p&gt;
&lt;p&gt;其中的挑战是如何利用这些信息向移动开发者提供可靠的、实时的、有实际价值的洞见（视角）去了解他们的移动应用。&lt;/p&gt;
&lt;p&gt;在高层，我们依靠 组件解耦、异步通信、在应对灾难性故障时优雅地服务降级等原则来帮助架构决策。我们使用Lambda架构将数据完整性和实时数据更新结合起来。&lt;/p&gt;
&lt;p&gt;在实践过程中，我们需要设计一个能够接收并保存事件、执行离线和实时计算且能将上述两种计算结果整合成相关信息的系统。这些行为全部都要以百万次每秒的规模执行。&lt;/p&gt;
&lt;p&gt;让我们从第一个挑战开始：接受并处理这些事件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;事件接收&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在设计设备-服务器通信的时候，我们的目标是：减少对电池和网络使用的影响；确保数据的可靠性；接近实时地获取数据。为了减少对设备的影响，我们批量地发送分析数据并且在发送前对数据进行压缩。为了保证这些宝贵的数据始终能够到达我们的服务器，在传输失败随机退避后以及达到设备存储达到上限时，设备会进行重传。为了确保数据能够尽快到达服务器，我们设置来多个触发器来使设备尝试发送：当程序运行于前台的时候，事件触发器每分钟触发一次；一个消息数量触发器和程序转入后台触发器。&lt;/p&gt;
&lt;p&gt;这样的通信协议导致设备每秒发送来数以万计压缩过的有效载荷。每一个载荷都包含数十条事件。为了能够可靠的、易于线性伸缩的方式去处理载荷，接收事件的服务必须极度简单。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/0c1dc8a6fe083dcce2ac0a3f6ca51c24.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个服务使用GO语言编写，这个服务使用了亚马逊弹性负载均衡器（ELB），并将每一个消息负荷放入一个持久化的Kafka队列。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;存储&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Kafka是一个持久存储器，因为它把收到的消息写入磁盘并且每个消息都有多份冗余。因此一旦我们知道信息到了&lt;a title=&quot;kafka&quot; href=&quot;http://kafka.apache.org/&quot; target=&quot;_blank&quot;&gt;Kafka&lt;/a&gt;队列，我们就可以通过延迟处理、再处理来容忍下游延迟和下游失败。然而，Kafka不是我们历史数据的永久真理之源——按照上文提到的速度，仅仅是几天的数据，我们也需要数以百计的box来存储。因此我们把Kafka集群配置为将消息只保留几个小时（这些时间足够我们处理不期而至的重大故障）并且将数据尽快地存入永久存储——亚马逊简易存储服务（Amazon S3）。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/6556de24d546f0ebc4871ac2a50b3cc5.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们广泛地使用&lt;a title=&quot;storm&quot; href=&quot;https://storm.apache.org/&quot; target=&quot;_blank&quot;&gt;Storm&lt;/a&gt;来进行实时数据处理，第一个相关的Topology就是从Kafka读取信息并存储到Amazon S3上。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;批量计算&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一旦这些数据存到了S3上，我们可以使用亚马逊弹性MapReduce（Amazon EMR）来计算我们的数据能够计算的任何东西。这既包括要展示在客户的仪表盘上的数据，也包括我们为了开发新功能而开发的实验性的任务。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/c58e27a2c6b407329238fb4092b7456f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们使用&lt;a title=&quot;http://www.cascading.org/&quot; href=&quot;http://www.cascading.org/&quot; target=&quot;_blank&quot;&gt;Cascading&lt;/a&gt;框架编写、Amazon EMR执行MapReduce程序。 Amazon EMR将我们存储到S3上的数据作为输入，处理完毕后，再将结果存入S3。我们通过运行在Storm上的调度topology来探测程序执行完毕，并将结果灌入&lt;a title=&quot;http://cassandra.apache.org/&quot; href=&quot;http://cassandra.apache.org/&quot; target=&quot;_blank&quot;&gt;Cassandra&lt;/a&gt;集群，这样结果就能用于亚秒级查询API。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;实时计算&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;迄今，我们描述的是一个能够执行分析计算的持久的容错的框架。然而，存在一个显眼的问题——这个框架不是实时的。一些计算每小时计算一次，有的计算需要一整天的数据作为输入。计算时间从几分钟到几小时不等，把S3上的输出导入到服务层也需要这么多时间。因此，在最好情况下，我们的数据也总是拖后几个小时，显然不能满足实时和可操作的目标。&lt;/p&gt;
&lt;p&gt;为了达成实时的目标，数据涌入后进行存档的同时，我们对数据进行流式计算。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/e3329ed0c7e27980256a5b1f9a0eafbc.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;就像我们的存储Topology读取数据一样，一个独立的Storm Topology实时地从Kafka Topic中读取数据然后进行实时计算，计算的逻辑和MapReduce任务一样。这些实时计算的结果放在另一个独立的Cassandra集群里以供实时查询。&lt;/p&gt;
&lt;p&gt;为了弥补我们在时间以及在资源方面可能的不足，我们没有在批量处理层中而是在实时计算层中使用了一些概率算法，如布隆过滤器、HyperLogLog（也有一些自己开发的算法）。相对于那些蛮力替代品，这些算法在空间和时间复杂度上有数量级的优势，同时只有可忽略的精确度损失。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;合并&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;现在我们拥有两个独立生产出的数据集（批处理和实时处理），我们怎么将二者合并才能得到一个一致的结果？&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/9fe3c8c8276c57184f29d985068c7aeb.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们在API的逻辑中，根据特定的情况分别使用两个数据集然后合并它们。&lt;/p&gt;
&lt;p&gt;因为批量计算是可重现的，且相对于实时计算来说更容错，我们的API总是倾向于使用批量产生的数据。例如，API接到了一个三十天的时间序列的日活跃用户数量数据请求，它首先会到批量数据Cassandra集群里查询全范围的数据。如果这是一个历史数据检索，所有的数据都已经得到。然而，查询的请求更可能会包含当天，批量产生的数据填充了大部分结果，只有近一两天的数据会被实时数据填充。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;错误处理&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;让我们来温习几个失效的场景，看一下这样的架构在处理错误的时候， 是如何避免宕机或者损失数据，取之以优雅地降级。&lt;/p&gt;
&lt;p&gt;我们在上文中已经讨论过设备上的回退重试策略。在设备端网络中断、服务器端短时无服务情况下，重试保证数据最终能够到达服务器。随机回退确保设备不会在某区域网络中断或者后端服务器短时间不可用之后，不会压垮（DDos攻击）服务器。&lt;/p&gt;
&lt;p&gt;当实时处理层失效时，会发生什么？我们待命的工程师会受到通知并去解决问题。因为实时处理层的输入是存储在持久化的Kafka集群里，所以没有数据会丢失；等实时处理恢复之后，它会赶上处理那些停机期间应该处理的数据。&lt;/p&gt;
&lt;p&gt;因为实时处理和批处理是完全解耦的，批处理层完全不会受到影响。因此唯一的影响就是实时处理层失效期间，对数据点实时更新的延迟。&lt;/p&gt;
&lt;p&gt;如果批处理层有问题或者严重延迟的话，会发生什么？我们的API会无缝地多获取实时处理的数据。一个时间序列数据的查询，可能先前只取一天的实时处理结果，现在就需要查询两到三天的实时处理结果。因为实时处理和批处理是完全解耦的，实时处理不受影响继续运行。同时，我们的待命工程师会得到消息并且解决批处理层的问题。一旦批处理层恢复正常，它会执行那些延迟的数据处理任务，API也会无缝切换到使用现在可以得到的批处理的结果。&lt;/p&gt;
&lt;p&gt;我们系统后端架构由四大组件构成：事件接收，事件存储，实时计算和批量计算。各个组件之间的持久化队列确保任意组件的失效不会扩散到其他组件，并且后续可以从中断中恢复。API可以在计算层延迟或者失效时无缝地优雅降级，在服务恢复后重新恢复；这些都是由API内部的检索逻辑来保证的。&lt;/p&gt;
&lt;p&gt;Answer的目标是创建一个仪表盘，这个仪表盘能够把了解你的用户群变得非常简单。因此你可以将时间花费在打造令人惊叹的用户体验上，而不是用来掘穿数据。从现在就开始，&lt;a title=&quot;了解Answers&quot; href=&quot;http://answers.io/?utm_source=twitter_eng_blog&amp;amp;utm_medium=twitter_blog&amp;amp;utm_campaign=answers_5B_sessions_2.17.2015&amp;amp;utm_content=inline_cta&quot; target=&quot;_blank&quot;&gt;点击此处更多了解Answers&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;非常感谢致力于将此架构实现（付诸现实）的Answers团队。还有&lt;a title=&quot;Big Data&quot; href=&quot;http://manning.com/marz/&quot; target=&quot;_blank&quot;&gt;《Big Data》&lt;/a&gt;这本书的作者Nathan Marz。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;贡献者&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://twitter.com/ajorgensen&quot;&gt;Andrew Jorgensen&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/bswift&quot;&gt;Brian Swift&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/brianhatfield&quot;&gt;Brian Hatfield&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/mikefurtak&quot;&gt;Michael Furtak&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/marknic&quot;&gt;Mark Pirri&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/CoryDolphin&quot;&gt;Cory Dolphin&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/rothbutter&quot;&gt;Jamie Rothfeder&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/jeffseibert&quot;&gt;Jeff Seibert&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/sirstarry&quot;&gt;Justin Starry&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/krob&quot;&gt;Kevin Robinson&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/Kris10rht&quot;&gt;Kristen Johnson&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/marcrichards&quot;&gt;Marc Richards&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/patrickwmcgee&quot;&gt;Patrick McGee&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/richparet&quot;&gt;Rich Paret&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/wayne&quot;&gt;Wayne Chang&lt;/a&gt;.&lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87067&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87067votetotal&quot;&gt;2&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87067&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt;  评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;

&lt;div id=&quot;author-bio&quot;&gt;
	
	&lt;h3 class=&quot;widget-title&quot;&gt;
	关于作者：&lt;a target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/mingyuan&quot;&gt;刘志成&lt;/a&gt;
	&lt;/h3&gt;
	&lt;div class=&quot;alignleft&quot;&gt;
		&lt;a target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/mingyuan&quot;&gt;
			&lt;img src=&quot;/images/jobbole.com/4d8ad0b6e65624d1c18aac0963063eaf.jpg&quot;&gt;
		&lt;/a&gt;
	&lt;/div&gt;

    &lt;div class=&quot;author-bio-info&quot;&gt;

        &lt;span class=&quot;author-bio-info-block&quot;&gt;
            新浪微博：@柳鸣渊        &lt;/span&gt;
        &lt;span class=&quot;author-bio-info-block&quot;&gt;
            &lt;a href=&quot;http://www.jobbole.com/members/mingyuan&quot; target=&quot;_blank&quot;&gt;&lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt; 个人主页&lt;/a&gt; ·
            &lt;a href=&quot;http://blog.jobbole.com/author/mingyuan/&quot; target=&quot;_blank&quot;&gt;&lt;i class=&quot;fa fa-file-text-o&quot;&gt;&lt;/i&gt; 我的文章&lt;/a&gt; ·
            &lt;a title=&quot;声望值&quot; target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/mingyuan/reputation/&quot;&gt;&lt;i class=&quot;fa fa-graduation-cap&quot;&gt;&lt;/i&gt; 11&lt;/a&gt;        &lt;/span&gt;
    &lt;/div&gt;
	&lt;div class=&quot;clear&quot;&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Wed, 27 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-27-87067-3e26d261e.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-27-87067-3e26d261e.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>Netflix工程总监眼中的分类算法：深度学习优先级最低</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;p&gt;【编者按】针对Quora上的一个老问题：不同分类算法的优势是什么？Netflix公司工程总监Xavier Amatriain近日给出新的解答，他根据奥卡姆剃刀原理依次推荐了逻辑回归、SVM、决策树集成和深度学习，并谈了他的不同认识。他并不推荐深度学习为通用的方法，这也侧面呼应了我们之前讨论的问题：深度学习能否取代其他机器学习算法。&lt;/p&gt;
&lt;p&gt;不同分类算法的优势是什么？例如有大量的训练数据集，上万的实例，超过10万的特征，我们选择哪种分类算法最好？Netflix公司工程总监Xavier Amatriain认为，应当根据奥卡姆剃刀原理（Occam’s Razor）来选择算法，建议先考虑逻辑回归。&lt;/p&gt;
&lt;p&gt;选择一个合理的算法可以从很多方面来考察，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;训练实例的数量？&lt;/li&gt;
&lt;li&gt;特征空间的维度？&lt;/li&gt;
&lt;li&gt;是否希望该问题线性可分？&lt;/li&gt;
&lt;li&gt;特征是否是独立的？&lt;/li&gt;
&lt;li&gt;是否预期特征能够线性扩展？&lt;/li&gt;
&lt;li&gt;过度拟合是否会成为一个问题？&lt;/li&gt;
&lt;li&gt;系统在速度/性能/内存使用等方面的要求如何？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;逻辑回归&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;作为一般的经验法则，我建议先考虑逻辑回归（LR，Logistic Regression）。逻辑回归是一个漂亮乖巧的分类算法，可以训练你希望的特征大致线性和问题线性可分。你可以很容易地做一些特征引擎把大部分的非线性特征转换为线性。逻辑回归对噪声也相当强劲，能避免过度拟合，甚至使用L2或L1正则化做特征选择。逻辑回归也可以用在大数据场景，因为它是相当有效的，并且可以分布使用，例如ADMM。 逻辑回归的最后一个优点是，输出可以被解释为概率。这是一个好的附加作用，例如，你可以使用它排名而不是分类。&lt;/p&gt;
&lt;p&gt;即使在你不希望逻辑回归100%地工作，你也可以帮自己一个忙，在使用“票友”办法之前，运行一个简单的L2正则化逻辑回归作为基线。&lt;/p&gt;
&lt;p&gt;好了，现在你已经设置逻辑回归基线，下一步你应该做的，我基本上会推荐两个可能的方向：支持向量机（SVM）或者决策树集成。如果我不知道你的具体问题，我肯定会选择后者，但我将开始描述为什么SVM可能是一个值得考虑的方法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;支持向量机&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;支持向量机使用一个与LR不同的损失函数（Hinge）。它们也有不同的解释（maximum-margin）。然而，在实践中，用线性核函数的SVM和逻辑回归是没有很大的不同的（如果你有兴趣，你可以观察Andrew Ng在他的Coursera机器学习课程如何从逻辑回归中驱动SVM）。用SVM代替逻辑回归的一个主要原因可能是因为你的问题线性不可分。在这种情况下，你将不得不使用有非线性内核的SVM（如RBF）。事实上，逻辑回归也可以伴随不同的内核使用，但出于实际原因你更可能选择SVM。另一个使用SVM的相关理由可能是高维空间。例如，SVM已经被报道在工作文本分类方面做得更出色。&lt;/p&gt;
&lt;p&gt;不幸的是，SVM的主要缺点是，它们的训练低效到痛苦。所以，对于有大量训练样本的任何问题，我都不会推荐SVM。更进一步地说，我不会为大多数“工业规模”的应用程序推荐SVM。任何超出玩具/实验室的问题可能会使用其他的算法来更好地解决。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;决策树集成&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;第三个算法家族：决策树集成（Tree Ensembles）。这基本上涵盖了两个不同的算法：随机森林（RF）和梯度提升决策树（GBDT）。它们之间的差异随后再谈，现在先把它们当做一个整体和逻辑回归比较。&lt;/p&gt;
&lt;p&gt;决策树集成有超过LR的不同优势。一个主要优势是，它们并不指望线性特征，甚至是交互线性特性。在LR里我没有提到的是，它几乎不能处理分类（二进制）特性。而决策树集成因为仅仅是一堆决策树的结合，可以非常好地处理这个问题。另一主要优点是，因为它们构造了（使用bagging或boosting）的算法，能很好地处理高维空间以及大量的训练实例。&lt;/p&gt;
&lt;p&gt;至于RF和GBDT之间的差别，可以简单理解为GBDT的性能通常会更好，但它们更难保证正确。更具体而言，GBDT有更多的超参数需要调整，并且也更容易出现过度拟合。RF几乎可以“开箱即用”，这是它们非常受欢迎的一个原因。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;深度学习&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;最后但并非最不重要，没有深度学习的次要参考，这个答案将是不完整的。我绝对不会推荐这种方法作为通用的分类技术。但是，你可能会听说这些方法在某些情况下（如图像分类）表现如何。如果你已经通过了前面的步骤并且感觉你的解决方案还有优化的空间，你可能尝试使用深度学习方法。事实是，如果你使用一个开源工具（如Theano）实现，你会知道如何使这些方法在你的数据集中非常快地执行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;综上所述，先用如逻辑回归一样简单的方法设定一个基准，如果你需要，再使问题变得更加复杂。这一点上，决策树集成可能正是要走的正确道路，特别是随机森林，它们很容易调整。如果你觉得还有改进的余地，尝试GBDT，或者更炫一些，选择深度学习。&lt;/p&gt;
&lt;p&gt;你还可以看看Kaggle比赛。如果你搜索关键字“分类”，选择那些已经完成的，你能找到一些类似的东西，这样你可能会知道选择一个什么样的方法来赢得比赛。在这一点上，你可能会意识到，使用集成方法总容易把事情做好。当然集成的唯一问题，是需要保持所有独立的方法并行地工作。这可能是你的最后一步，花哨的一步。&lt;/p&gt;
&lt;p&gt;编辑点评：Xavier Amatriain不推荐深度学习为通用算法的理由，并不能说是因为深度学习不好，而是因为深度学习会增加复杂性及成本，却无法保证在所有的场景表现出比逻辑回归、SVM及决策树集成更优的结果。事实上，Xavier Amatriain的Netflix团队早已开始研究人工神经网络和深度学习技术，希望借助AWS云服务和GPU加速的分布式神经网络，分析网民最爱看的电影电视剧，实现节目的个性化推荐。&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt; &lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/8152c51793bfd7edcbb064a10c985d69.jpg&quot; width=&quot;581&quot; height=&quot;640&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center&quot;&gt;Netflix推荐系统架构（图片来自Xavier Amatrain参与撰写的Netflix官方博客）&lt;/p&gt;
&lt;p&gt;此后，Xavier Amatriain还分享了Netflix机器学习实践的十大经验教训，大致包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;更多的数据需要与更好的模型之匹配&lt;/li&gt;
&lt;li&gt;你可能不需要所有的大数据&lt;/li&gt;
&lt;li&gt;更复杂的模型未必意味着更好的结果，可能是你的样本集太简单&lt;/li&gt;
&lt;li&gt;要充分考虑你的训练数据&lt;/li&gt;
&lt;li&gt;学会处理偏差&lt;/li&gt;
&lt;li&gt;UI是联系算法和最重要的用户之间唯一通道&lt;/li&gt;
&lt;li&gt;正确的演进方式比数据和模型更重要&lt;/li&gt;
&lt;li&gt;分布式算法重要，知道在哪个层级使用它更重要&lt;/li&gt;
&lt;li&gt;选择合适的度量自动超参数优化&lt;/li&gt;
&lt;li&gt;并非所有的事都能离线完成，近线处理也是一种选择&lt;/li&gt;
&lt;/ul&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87148&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87148votetotal&quot;&gt;&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87148&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt;  评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Tue, 26 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-26-87148-0ee3711f9.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-26-87148-0ee3711f9.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>理解 MySQL（4）：并行数据库与分区(Partition)</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;h3&gt;&lt;strong&gt;1、并行数据库 &lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1.1、并行数据库的体系结构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;并行机的出现，催生了并行数据库的出现，不对，应该是关系运算本来就是高度可并行的。对数据库系统性能的度量主要有两种方式：(1)吞吐量(Throughput)，在给定的时间段里所能完成的任务数量；(2)响应时间(Response time)，单个任务从提交到完成所需要的时间。对于处理大量小事务的系统，通过并行地处理许多事务可以提高它的吞吐量。对于处理大事务的系统，通过并行的执行事务的子任务，可以缩短系统晌应时间。&lt;/p&gt;
&lt;p&gt;并行机有三种基本的体系结构，相应的，并行数据库的体系结构也可以大概分为三类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;共享内存(share memeory)：所有处理器共享一个公共的存储器；&lt;/li&gt;
&lt;li&gt;共享磁盘(share disk)：所有处理器共享公共的磁盘；这种结构有时又叫做集群(cluster)；&lt;/li&gt;
&lt;li&gt;无共享(share nothing)：所有处理器既不共享内存，也不共享磁盘。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/edc230f4efffff66335ecd644f9c42f7.jpg&quot; width=&quot;690&quot; height=&quot;269&quot;&gt;&lt;/p&gt;
&lt;p&gt;1.1.1、 共享内存&lt;br&gt;
该结构包括多个处理器、一个全局共享的内存（主存储器）和多个磁盘存储，各个处理器通过高速通讯网络（Interconnection Network）与共享内存连接，并均可直接访问系统中的一个、多个或全部的磁盘存储，在系统中，所有的内存和磁盘存储均由多个处理器共享。&lt;br&gt;
这种结构的优点在于，处理器之间的通信效率极高，访问内存的速度要比消息通信机制要快很多。这种结构的缺点在于，处理器的规模不能超过32个或者64个，因为总线或互边网络是由所有的处理器共享，它会变成瓶颈。当处理器数量到达某一个点时，再增加处理器已经没有什么好处。&lt;/p&gt;
&lt;p&gt;共享内存结构通常在每个处理器上有很大的高速缓存，从而减少对内存的访问。但是，这些高速缓存必须保持一致，也就是缓存一致性(cache-coherency)的问题。&lt;/p&gt;
&lt;p&gt;1.1.2、 共享磁盘&lt;br&gt;
该结构由多个具有独立内存（主存储器）的处理器和多个磁盘存储构成，各个处理器相互之间没有任何直接的信息和数据的交换，多个处理器和磁盘存储由高速通信网络连接，每个处理器都可以读写全部的磁盘存储。&lt;/p&gt;
&lt;p&gt;共享磁盘与共享内存结构相比，有以下一些优点：(1)每个处理器都有自己的存储器，存储总线不再是瓶颈；(2)以一种较经济的方式提供了容错性(fault tolerence)，如果一个处器发生故障，其它处理器可以代替工作。&lt;/p&gt;
&lt;p&gt;该结构的主要问题不是在于可扩展性问题，虽然存储总线不是瓶颈，但是，与磁盘之间的连接又成了瓶颈。&lt;/p&gt;
&lt;p&gt;运行Rdb的DEC集群是共享磁盘的体系结构的早期商用化产品之一(DEC后来被Compaq公司收购，再后来，Oracle又从Compaq手中取得Rdb，发展成现在的Oracle RAC)。&lt;/p&gt;
&lt;p&gt;1.1.3、 无共享&lt;/p&gt;
&lt;p&gt;该结构由多个完全独立的处理节点构成，每个处理节点具有自己独立的处理器、独立的内存（主存储器）和独立的磁盘存储，多个处理节点在处理器级由高速通信网络连接，系统中的各个处理器使用自己的内存独立地处理自己的数据。&lt;/p&gt;
&lt;p&gt;这 种结构中，每一个处理节点就是一个小型的数据库系统，多个节点一起构成整个的分布式的并行数据库系统。由于每个处理器使用自己的资源处理自己的数据，不存 在内存和磁盘的争用，提高的整体性能。另外这种结构具有优良的可扩展性——只需增加额外的处理节点，就可以以接近线性的比例增加系统的处理能力。&lt;/p&gt;
&lt;p&gt;这种结构中，由于数据是各个处理器私有的，因此系统中数据的分布就需要特殊的处理，以尽量保证系统中各个节点的负载基本平衡，但在目前的数据库领域，这个数据分布问题已经有比较合理的解决方案。&lt;/p&gt;
&lt;p&gt;由于数据是分布在各个处理节点上的，因此，使用这种结构的并行数据库系统，在扩展时不可避免地会导致数据在整个系统范围内的重分布（Re-Distribution）问题。&lt;/p&gt;
&lt;p&gt;Shared-Nothing结构的典型代表是Teradata(并行数据库的先驱)，值得一提的是，MySQL NDB Cluster也使用了这种结构。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.2、I/O并行(I/O Parallelism)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I/O并行的最简单形式是通过对关系划分，放置到多个磁盘上来缩减从磁盘读取关系的时间。并行数据库中数据划分最通用的形式是水平划分(horizontal portioning)，一个关系中的元组被划分到多个磁盘。&lt;/p&gt;
&lt;p&gt;1.2.1、常用划分技术&lt;/p&gt;
&lt;p&gt;假定将数据划分到n个磁盘D0，D1，…，Dn中。&lt;/p&gt;
&lt;p&gt;(1) 轮转法(round-bin)。对关系顺序扫描，将第i个元组存储到标号为Di%n的磁盘上；该方式保证了元组在多个磁盘上均匀分布。&lt;br&gt;
(2) 散列划分(hash partion)。选定一个值域为{0, 1, …,n-1}的散列函数，对关系中的元组基于划分属性进行散列。如果散列函数返回i，则将其存储到第i个磁盘。&lt;br&gt;
(3) 范围划分(range partion)。&lt;/p&gt;
&lt;p&gt;由于将关系存储到多个磁盘，读写时能同时进行，划分(partion)能大大提高系统的读写性能。数据的存取可以分为以下几类：&lt;/p&gt;
&lt;p&gt;(1) 扫描整个关系；&lt;br&gt;
(2) 点查询(point query)，如name = “hustcat”；&lt;br&gt;
(3) 范围查询(range query)，如 20 &amp;lt; age &amp;lt; 30。&lt;/p&gt;
&lt;p&gt;不同的划分技术，对这些存取类型的效率是不同的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;轮转法适合顺序扫描关系，对点查询和范围查询的处理较复杂。&lt;/li&gt;
&lt;li&gt;散列划分特别适合点查询，速度最快。&lt;/li&gt;
&lt;li&gt;范围划分对点查询、范围查询以及顺序扫描都支持较好，所以适用性很广。但是，这种方式存在一个问题——执行偏斜(execution skew)，也就是说某些范围的元组较多，使得大量的I/O出现在某几个磁盘。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1.3、查询间并行(interquery parallism)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;查询间并行指的是不同的查询或事务间并行的执行。这种形式的并行可以提高事务的吞吐量，然而，单个事务并不能执行得更快(即响应时间不能减少)。查询间的并行主要用于扩展事务处理系统，在单位时间内能够处理更多的事务。&lt;/p&gt;
&lt;p&gt;查询间并行是数据库系统最易实现的一种并行，在共享内存的并行系统(如SMP)中尤其这样。为单处理器设计的数据库系统可以不用修改，或者很少修改就能用到共享内存的体系结构。&lt;/p&gt;
&lt;p&gt;在共享磁盘和无共享的体系结构中，实现查询间并行要更复杂一些。各个处理需要协调来进行封锁、日志操作等等，这就需要处理器之间的传递消息。并行数据库系统必须保证两个处理器不会同时更新同一数据。而且，处理器访问数据时，系统必须保证处理器缓存的数据是最新的数据，即缓存一致性问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.4、查询内并行(intraquery parallism)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;查询内并行是指单个查询要在多个处理器和磁盘上同时进行。为了理解，来考虑一个对某关系进行排序的查询。假设关系已经基于某个属性进行了范围划分，存储于多个磁盘上，并且划分是基于划分属性的。则排序操作可以如下进行：对每个分区并行的排序，然后将各个已经有序的分区合并到一起。&lt;/p&gt;
&lt;p&gt;单个查询的执行可以有两种并行方式：&lt;br&gt;
(1) 操作内并行(Intraoperation parallism)：通过并行的执行每一个运算，如排序、选择、连接等，来加快一个查询的处理速度。&lt;br&gt;
(2) 操作间并行(Interoperation parallism)：通过并行的执行一个查询中的多个不同的运算，来加速度一个查询的处理速度。&lt;/p&gt;
&lt;p&gt;注意两者间的区别，前者可以认为多个处理器同时执行一个运算，而后者是多个处理器同时执行不同的运算。&lt;/p&gt;
&lt;p&gt;这两种形式之间的并行是互相补充的，并且可以同时存在于一个查询中。通常由于一个查询中的运算数目相对于元组数目是较小的，所以当并行度增加时，第一种方式取得的效果更显著。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;2、MySQL的分区(partion)&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;2.1、MySQL分区概述&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在MySQL中，InnoDB存储引擎长期支持表空间的概念，并且MySQL服务器甚至在分区引入之前，就能配置为存储不同的数据库使用不同的物理路径。分区(partion)更进一步，它允许你通过设置各种规则将一个表的各个分区跨文件系统存储。实际上，不同位置的不同表分区是作为一个单独的表来存储的。用户所选择的、实现数据分割的规则被称为分区函数(partioning function)，这在MySQL中它可以是模数，或者是简单的匹配一个连续的数值区间或数值列表，或者是一个内部HASH函数，或一个线性HASH函数。&lt;/p&gt;
&lt;p&gt;最常见是的水平分区(horizontal partitioning)，也就是将表的不同的元组分配到不同的物理分区上。目前，MySQL 5.1还不支持垂直分区(vertical partitioning)，即将表的不同列分配到不同的物理分区。你可以使用MySQL支持的大多数存储引擎来创建表的分区，在MySQL 5.1中，同一个表的各个分区必须使用相同的存储引擎，比如，你不能对一个分区使用MyISAM，而对另一个分区使用InnoDB。但是，你可以对同一个数据库的不同的表使用不同的存储引擎。&lt;/p&gt;
&lt;p&gt;要为某个分区表配置一个专门的存储引擎，必须且只能使用[STORAGE] ENGINE 选项，这如同为非分区表配置存储引擎一样。但是，必须记住[STORAGE] ENGINE（和其他的表选项）必须列在用在CREATE TABLE语句中的其他任何分区选项之前。下面的例子给出了怎样创建一个通过HASH分成6个分区、使用InnoDB存储引擎的表：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/cfa3b328a0e403b028502a15ee87e303.jpg&quot; width=&quot;436&quot; height=&quot;108&quot;&gt;&lt;/p&gt;
&lt;p&gt;注：分区必须对一个表的所有数据和索引；不能只对数据分区而不对索引分区，反之亦然，同时也不能只对表的一部分进行分区。&lt;br&gt;
分区对数据库管理系统实现并行处理有着重要的影响，如果对数据进行分区，则很容易进行并行处理，但是，MySQL还没有充分利用分区的这种并行优势，而这也是它改进的方向 (这种分治思想深深的影响着并行计算，而且在并行计算方面具有天然优势)。MySQL的分区，会给系统带来以下一些优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;与单个磁盘或文件系统分区相比，单个表可以存储更多的数据。&lt;/li&gt;
&lt;li&gt;对于那些已经失去保存意义的数据，通常可以通过删除与那些数据有关的分区，很容易地删除那些数据。相反地，在某些情况下，添加新数据的过程又可以通过为那些新数据专门增加一个新的分区，来很方便地实现。&lt;/li&gt;
&lt;li&gt;对于带Where的条件查询语句，可以得到更大的优化；只需要查询某些分区，而不用扫描全部分区。&lt;/li&gt;
&lt;li&gt;还有其它一些优点，不过MySQL 5.1还不支持：&lt;/li&gt;
&lt;li&gt;一些聚合函数，比如SUM() 和COUNT()，能够很容易的并行执行；&lt;/li&gt;
&lt;li&gt;通过并行I/O，可以大大提高查询的吞吐量。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注：实际上，分区不论是对I/O并行，还是查询内并行，都有着重要的影响。只不过MySQL在这方面做得还不够多(不过，正在改进)，而Oracle对于查询内并行，做了很多工作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.2、分区类型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MySQL 5.1中可用的分区类型包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;RANGE分区(portioning)：根据列值所属的范围区间，将元组分配到各个分区。&lt;/li&gt;
&lt;li&gt;LIST分区：类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择。&lt;/li&gt;
&lt;li&gt;HASH分区：根据用户定义的函数的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL 中有效的、产生非负整数值的任何表达式。&lt;/li&gt;
&lt;li&gt;KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL 服务器提供其自身的哈希函数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2.2.1、范围分区&lt;/p&gt;
&lt;p&gt;范围分区是通过计算表达式的值所属的范围区间，对元组进行分区。这些区间要求连续且不能相互重叠，使用VALUES LESS THAN操作符来进行定义。在下面的几个例子中，假定你创建了一个如下的一个表，该表保存有20家音像店的职员记录，这20家音像店的编号从1到20。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/99bc1c2295c9f7639c4e992838f420ed.jpg&quot; width=&quot;434&quot; height=&quot;234&quot;&gt;&lt;/p&gt;
&lt;p&gt;你可以根据需要对该表进行各种分区，比如，你可以通过store_id来进行分区：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/e8fcdeb8a506ca908471878efa14fa62.jpg&quot; width=&quot;434&quot; height=&quot;386&quot;&gt;&lt;/p&gt;
&lt;p&gt;很容易确定数据(72, ‘Michael’, ‘Widenius’, ’1998-06-25′, NULL, 13)被插入分区p2；但是，如果一条数据的store_id = 21，会怎么样呢？由于没有规则处理大于20的情况，所以服务器会报错。你可以通过如下方式来处理这种情况：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/2e25b1df1ea95378b367af4e3a6c58b6.jpg&quot; width=&quot;433&quot; height=&quot;385&quot;&gt;&lt;/p&gt;
&lt;p&gt;MAXVALUE 表示最大的可能的整数值。现在，store_id 列值大于或等于16（定义了的最高值）的所有行都将保存在分区p3中。在将来的某个时候，当商店数已经增长到25, 30, 或更多 ，可以使用ALTER TABLE语句为商店21-25, 26-30,等等增加新的分区&lt;br&gt;
RANGE分区在如下场合特别有用：&lt;/p&gt;
&lt;p&gt;(1) 当需要删除“旧的”数据时。 在上面的例子中，你只需简单地使用 “ALTER TABLE employees DROP PARTITION p0；”来删除所有在1991年前就已经停止工作的雇员相对应的所有行。对于有大量行的表，这比运行一个如“DELETE FROM employees WHERE YEAR(separated) &amp;lt;= 1990；”这样的一个DELETE查询要有效得多。&lt;br&gt;
(2) 经常依赖于分区属性进行查询。例如，当执行一个如“SELECT COUNT(*) FROM employees WHERE YEAR(separated) = 2000 GROUP BY store_id；”这样的查询时，MySQL可以很迅速地确定只有分区p2需要扫描，这是因为余下的分区不可能包含有符合该WHERE子句的任何记录。注：这种优化还没有在MySQL 5.1源程序中启用，但是，有关工作正在进行中。&lt;br&gt;
范围分区的缺点就是容易出现执行偏斜，这会影响系统性能。&lt;/p&gt;
&lt;p&gt;2.2.2、HASH分区&lt;/p&gt;
&lt;p&gt;HASH分区主要用来确保数据在预先确定数目的分区中平均分布。在RANGE和LIST分区中，必须明确指定一个给定的列值或列值集合应该保存在哪个分区中；而在HASH分区中，MySQL 自动完成这些工作，你所要做的只是基于将要被哈希的列值指定一个列值或表达式，以及指定被分区的表将要被分割成的分区数量。&lt;/p&gt;
&lt;p&gt;你可以通过要在CREATE TABLE 语句上添加一个“PARTITION BY HASH (expr)”子句，其中“expr”是一个返回一个整数的表达式。它可以仅仅是字段类型为MySQL 整型的一列的名字。此外，你很可能需要在后面再添加一个“PARTITIONS num”子句，其中num 是一个非负的整数，它表示表将要被分割成分区的数量。比如：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/3dfcaf5a98f8c76a918ca5fd9e34e6af.jpg&quot; width=&quot;431&quot; height=&quot;283&quot;&gt;&lt;/p&gt;
&lt;p&gt;如果没有PARTITIONS语句，默认分区数为1。但是，PARTITIONS后面没有数字，系统会报错。&lt;br&gt;
相对于范围分区，HASH分区更可能保证数据均衡分布。&lt;/p&gt;
&lt;p&gt;2.2.3、子分区(Subpartitioning)&lt;/p&gt;
&lt;p&gt;子分区，也叫做复合分区(composite partitioning)，是对分区表的每个分区的进一步分割。例如，&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/365e7c5244c2bd521028cbb0bc5e5122.jpg&quot; width=&quot;434&quot; height=&quot;208&quot;&gt;&lt;/p&gt;
&lt;p&gt;表ts 有3个RANGE分区。这3个分区中的每一个分区——p0, p1, 和 p2 ——又被进一步分成了2个子分区。实际上，整个表被分成了3 * 2 = 6个分区。但是，由于PARTITION BY RANGE子句的作用，这些分区的头2个只保存“purchased”列中值小于1990的那些记录。&lt;/p&gt;
&lt;p&gt;在MySQL 5.1中，对于已经通过RANGE或LIST分区了的表再进行分区。子分区既可以使用HASH希分区，也可以使用KEY分区。&lt;/p&gt;
&lt;p&gt;为了对个别的子分区指定选项，使用SUBPARTITION 子句来明确定义子分区也是可能的。例如，创建在前面例子中给出的同一个表的、一个更加详细的方式如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/ed18bc63b1142b74e15632f79d5603ac.jpg&quot; width=&quot;434&quot; height=&quot;412&quot;&gt;&lt;/p&gt;
&lt;p&gt;一些注意点：&lt;/p&gt;
&lt;p&gt;(1) 每个分区的子分区数必须相同；&lt;br&gt;
(2) 如果在一个分区表上的任何分区上使用SUBPARTITION 来明确定义任何子分区，那么就必须定义所有的子分区；&lt;br&gt;
(3) 每个SUBPARTITION子句必须包含一个子分区的名称；&lt;br&gt;
(4) MySQL 5.1.7及之前的版本，每个分区的子分区的名称必须唯一，但是在整个表中，没有必要唯一。从MySQL 5.1.8开始，子分区的名称在整个表中都必须唯一。&lt;/p&gt;
&lt;p&gt;子分区可以用于特别大的表，在多个磁盘间分配数据和索引。假设有6个磁盘，分别为/disk0， /disk1， /disk2等，对于如下例子：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/a87179d72a97265f41568e1a5314ac32.jpg&quot; width=&quot;432&quot; height=&quot;718&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;3、体验分区&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;下面通过例子来体验分区：&lt;/p&gt;
&lt;p&gt;(1)创建如下分区表：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/514c4e42f078c78daf8667863c647838.jpg&quot; width=&quot;431&quot; height=&quot;417&quot;&gt;&lt;/p&gt;
&lt;p&gt;(2)创建一个不分区的表：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/2f2580f0ce3d37356ec290669a0c31b4.jpg&quot; width=&quot;433&quot; height=&quot;128&quot;&gt;&lt;/p&gt;
&lt;p&gt;(3)    创建一个生成8000000行数据的存储过程：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/b75a80d3e37c5aa58d45209bc6be4d5e.jpg&quot; width=&quot;434&quot; height=&quot;328&quot;&gt;&lt;/p&gt;
&lt;p&gt;(4)    调用存储过程，生成数据：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/2006399c4b1a90f70c9e268db0dc6d8f.jpg&quot; width=&quot;433&quot; height=&quot;78&quot;&gt;&lt;/p&gt;
&lt;p&gt;(5)&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/c429c9e28527e73d776fe61f92cc3549.jpg&quot; width=&quot;433&quot; height=&quot;81&quot;&gt;&lt;/p&gt;
&lt;p&gt;数据准备好了，下面开始测试：&lt;/p&gt;
&lt;p&gt;(6)&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/b856f8482d9be16244b0efb918b321b1.jpg&quot; width=&quot;435&quot; height=&quot;437&quot;&gt;&lt;/p&gt;
&lt;p&gt;速度差异很明显；下面看一下查询计划：&lt;/p&gt;
&lt;p&gt;(7)&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/75612b73e4437f3d08a7991d1b3f7ba0.jpg&quot; width=&quot;539&quot; height=&quot;669&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;附SQL语句：&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;代码Code highlighting produced by Actipro CodeHighlighter (freeware)http://www.CodeHighlighter.com/--&amp;gt; 1 CREATE TABLE part_tab
(  c1 int default NULL,
c2 varchar(30) default NULL,
c3 date default NULL
) engine=myisam
PARTITION BY RANGE (year(c3)) 
(
PARTITION p0 VALUES LESS THAN (1995),
PARTITION p1 VALUES LESS THAN (1996) , 
PARTITION p2 VALUES LESS THAN (1997) ,
PARTITION p3 VALUES LESS THAN (1998) ,
PARTITION p4 VALUES LESS THAN (1999),
PARTITION p5 VALUES LESS THAN (2000) , 
PARTITION p6 VALUES LESS THAN (2001) ,
PARTITION p7 VALUES LESS THAN (2002) , 
PARTITION p8 VALUES LESS THAN (2003) ,
PARTITION p9 VALUES LESS THAN (2004) , 
PARTITION p10 VALUES LESS THAN (2010),
PARTITION p11 VALUES LESS THAN MAXVALUE 
);

create table no_part_tab
(c1 int(11) default NULL,
c2 varchar(30) default NULL,
c3 date default NULL
) engine=myisam;

delimiter //
CREATE PROCEDURE load_part_tab()
begin
declare v int default 0;
          while v &amp;lt; 8000000
  do
  insert into part_tab(c1,c2,c3)
  values (v,&#39;testing partitions&#39;,adddate(&#39;1995-01-01&#39;,(rand(v)*36520) mod 3652));
  set v = v + 1;
  end while;
  end
//

delimiter ;
call load_part_tab();
explain select count(*) from no_part_tab where
c3 &amp;gt; date &#39;1995-01-01&#39; and c3 &amp;lt; date &#39;1995-12-31&#39;;

explain select count(*) from part_tab where
c3 &amp;gt; date &#39;1995-01-01&#39; and c3 &amp;lt; date &#39;1995-12-31&#39;;

CREATE TABLE part_tab2
(  
c1 int default NULL
) engine=myisam
PARTITION BY RANGE (c1) 
(
PARTITION p0 VALUES LESS THAN (5),
PARTITION p1 VALUES LESS THAN (10),
PARTITION p2 VALUES LESS THAN MAXVALUE
);

insert into part_tab2 values(2),(3);&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主要参考：《MySQL Manual》&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87137&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87137votetotal&quot;&gt;1&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87137&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt;  评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Mon, 25 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-25-87137-2c52da121.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-25-87137-2c52da121.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>理解 MySQL（3）：复制(Replication)</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;h3&gt;&lt;strong&gt;1、复制概述&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1.1、复制解决的问题&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据复制技术有以下一些特点：&lt;br&gt;
(1) 数据分布&lt;br&gt;
(2) 负载平衡(load balancing)&lt;br&gt;
(3) 备份&lt;br&gt;
(4) 高可用性(high availability)和容错&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.2、复制如何工作&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从高层来看，复制分成三步：&lt;br&gt;
(1) master将改变记录到二进制日志(binary log)中（这些记录叫做二进制日志事件，binary log events）；&lt;br&gt;
(2) slave将master的binary log events拷贝到它的中继日志(relay log)；&lt;br&gt;
(3) slave重做中继日志中的事件，将改变反映它自己的数据。&lt;/p&gt;
&lt;p&gt;下图描述了这一过程：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/b59126917043fecf5124a0b2e5e94712.jpg&quot; width=&quot;506&quot; height=&quot;339&quot;&gt;&lt;/p&gt;
&lt;p&gt;该过程的第一部分就是master记录二进制日志。在每个事务更新数据完成之前，master在二日志记录这些改变。MySQL将事务串行的写入二进制日志，即使事务中的语句都是交叉执行的。在事件写入二进制日志完成后，master通知存储引擎提交事务。&lt;/p&gt;
&lt;p&gt;下一步就是slave将master的binary log拷贝到它自己的中继日志。首先，slave开始一个工作线程——I/O线程。I/O线程在master上打开一个普通的连接，然后开始binlog dump process。Binlog dump process从master的二进制日志中读取事件，如果已经跟上master，它会睡眠并等待master产生新的事件。I/O线程将这些事件写入中继日志。&lt;/p&gt;
&lt;p&gt;SQL slave thread处理该过程的最后一步。SQL线程从中继日志读取事件，更新slave的数据，使其与master中的数据一致。只要该线程与I/O线程保持一致，中继日志通常会位于OS的缓存中，所以中继日志的开销很小。&lt;/p&gt;
&lt;p&gt;此外，在master中也有一个工作线程：和其它MySQL的连接一样，slave在master中打开一个连接也会使得master开始一个线程。复制过程有一个很重要的限制——复制在slave上是串行化的，也就是说master上的并行更新操作不能在slave上并行操作。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;2、体验MySQL复制&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;MySQL开始复制是很简单的过程，不过，根据特定的应用场景，都会在基本的步骤上有一些变化。最简单的场景就是一个新安装的master和slave，从高层来看，整个过程如下：&lt;/p&gt;
&lt;p&gt;(1)在每个服务器上创建一个复制帐号；&lt;br&gt;
(2)配置master和slave；&lt;br&gt;
(3)Slave连接master开始复制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.1、创建复制帐号&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;每个slave使用标准的MySQL用户名和密码连接master。进行复制操作的用户会授予REPLICATION SLAVE权限。用户名的密码都会存储在文本文件master.info中。假如，你想创建repl用户，如下：&lt;br&gt;
mysql&amp;gt; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.*&lt;br&gt;
-&amp;gt; TO repl@’192.168.0.%’ IDENTIFIED BY ‘p4ssword’;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.2、配置master&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;接下来对master进行配置，包括打开二进制日志，指定唯一的servr ID。例如，在配置文件加入如下值：&lt;br&gt;
[mysqld]&lt;br&gt;
log-bin=mysql-bin&lt;br&gt;
server-id=10&lt;br&gt;
重启master，运行SHOW MASTER STATUS，输出如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/50f67fedd289e0393860356900bb6628.jpg&quot; width=&quot;519&quot; height=&quot;118&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.3、配置slave&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Slave的配置与master类似，你同样需要重启slave的MySQL。如下：&lt;/p&gt;
&lt;p&gt;log_bin = mysql-bin&lt;br&gt;
server_id = 2&lt;br&gt;
relay_log = mysql-relay-bin&lt;br&gt;
log_slave_updates = 1&lt;br&gt;
read_only = 1&lt;/p&gt;
&lt;p&gt;server_id是必须的，而且唯一。slave没有必要开启二进制日志，但是在一些情况下，必须设置，例如，如果slave为其它slave的master，必须设置bin_log。在这里，我们开启了二进制日志，而且显示的命名(默认名称为hostname，但是，如果hostname改变则会出现问题)。&lt;br&gt;
relay_log配置中继日志，log_slave_updates表示slave将复制事件写进自己的二进制日志(后面会看到它的用处)。&lt;/p&gt;
&lt;p&gt;有些人开启了slave的二进制日志，却没有设置log_slave_updates，然后查看slave的数据是否改变，这是一种错误的配置。所以，尽量使用read_only，它防止改变数据(除了特殊的线程)。但是，read_only并是很实用，特别是那些需要在slave上创建表的应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.4、启动slave&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;接下来就是让slave连接master，并开始重做master二进制日志中的事件。你不应该用配置文件进行该操作，而应该使用CHANGE MASTER TO语句，该语句可以完全取代对配置文件的修改，而且它可以为slave指定不同的master，而不需要停止服务器。如下：&lt;/p&gt;
&lt;p&gt;mysql&amp;gt; CHANGE MASTER TO MASTER_HOST=’server1′,&lt;/p&gt;
&lt;p&gt;-&amp;gt; MASTER_USER=’repl’,&lt;/p&gt;
&lt;p&gt;-&amp;gt; MASTER_PASSWORD=’p4ssword’,&lt;/p&gt;
&lt;p&gt;-&amp;gt; MASTER_LOG_FILE=’mysql-bin.000001′,&lt;/p&gt;
&lt;p&gt;-&amp;gt; MASTER_LOG_POS=0;&lt;/p&gt;
&lt;p&gt;MASTER_LOG_POS的值为0，因为它是日志的开始位置。然后，你可以用SHOW SLAVE STATUS语句查看slave的设置是否正确：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/c6c064b597017836f7f41c2b12b960db.jpg&quot; width=&quot;546&quot; height=&quot;406&quot;&gt;&lt;/p&gt;
&lt;p&gt;Slave_IO_State, Slave_IO_Running, 和Slave_SQL_Running表明slave还没有开始复制过程。日志的位置为4而不是0，这是因为0只是日志文件的开始位置，并不是日志位置。实际上，MySQL知道的第一个事件的位置是4。&lt;/p&gt;
&lt;p&gt;为了开始复制，你可以运行：&lt;/p&gt;
&lt;p&gt;mysql&amp;gt; START SLAVE;&lt;/p&gt;
&lt;p&gt;运行SHOW SLAVE STATUS查看输出结果：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/8ed6916d8f3f6357dfdb00579fffbf33.jpg&quot; width=&quot;552&quot; height=&quot;407&quot;&gt;&lt;/p&gt;
&lt;p&gt;注意，slave的I/O和SQL线程都已经开始运行，而且Seconds_Behind_Master不再是NULL。日志的位置增加了，意味着一些事件被获取并执行了。如果你在master上进行修改，你可以在slave上看到各种日志文件的位置的变化，同样，你也可以看到数据库中数据的变化。&lt;/p&gt;
&lt;p&gt;你可查看master和slave上线程的状态。在master上，你可以看到slave的I/O线程创建的连接：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/33476b877b38f7902e0d90f4f4772754.jpg&quot; width=&quot;590&quot; height=&quot;515&quot;&gt;&lt;/p&gt;
&lt;p&gt;行2为处理slave的I/O线程的连接。&lt;br&gt;
在slave上运行该语句：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/a35142c7ab002dd1950fc5b0bf285bb0.jpg&quot; width=&quot;530&quot; height=&quot;744&quot;&gt;&lt;/p&gt;
&lt;p&gt;行1为I/O线程状态，行2为SQL线程状态。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.5、从另一个master初始化slave&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;前面讨论的假设你是新安装的master和slave，所以，slave与master有相同的数据。但是，大多数情况却不是这样的，例如，你的master可能已经运行很久了，而你想对新安装的slave进行数据同步，甚至它没有master的数据。&lt;/p&gt;
&lt;p&gt;此时，有几种方法可以使slave从另一个服务开始，例如，从master拷贝数据，从另一个slave克隆，从最近的备份开始一个slave。Slave与master同步时，需要三样东西：&lt;/p&gt;
&lt;p&gt;(1)master的某个时刻的数据快照；&lt;br&gt;
(2)master当前的日志文件、以及生成快照时的字节偏移。这两个值可以叫做日志文件坐标(log file coordinate)，因为它们确定了一个二进制日志的位置，你可以用SHOW MASTER STATUS命令找到日志文件的坐标；&lt;br&gt;
(3)master的二进制日志文件。&lt;/p&gt;
&lt;p&gt;可以通过以下几中方法来克隆一个slave：&lt;/p&gt;
&lt;p&gt;(1) 冷拷贝(cold copy)&lt;br&gt;
停止master，将master的文件拷贝到slave；然后重启master。缺点很明显。&lt;br&gt;
(2) 热拷贝(warm copy)&lt;br&gt;
如果你仅使用MyISAM表，你可以使用mysqlhotcopy拷贝，即使服务器正在运行。&lt;br&gt;
(3) 使用mysqldump&lt;/p&gt;
&lt;p&gt;使用mysqldump来得到一个数据快照可分为以下几步：&lt;/p&gt;
&lt;p&gt;&amp;lt;1&amp;gt;锁表：如果你还没有锁表，你应该对表加锁，防止其它连接修改数据库，否则，你得到的数据可以是不一致的。如下：&lt;br&gt;
mysql&amp;gt; FLUSH TABLES WITH READ LOCK;&lt;br&gt;
&amp;lt;2&amp;gt;在另一个连接用mysqldump创建一个你想进行复制的数据库的转储：&lt;br&gt;
shell&amp;gt; mysqldump –all-databases –lock-all-tables &amp;gt;dbdump.db&lt;br&gt;
&amp;lt;3&amp;gt;对表释放锁。&lt;br&gt;
mysql&amp;gt; UNLOCK TABLES;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;3、深入复制&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;已经讨论了关于复制的一些基本东西，下面深入讨论一下复制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.1、基于语句的复制(Statement-Based Replication)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MySQL 5.0及之前的版本仅支持基于语句的复制（也叫做逻辑复制，logical replication），这在数据库并不常见。master记录下改变数据的查询，然后，slave从中继日志中读取事件，并执行它，这些SQL语句与master执行的语句一样。&lt;br&gt;
这种方式的优点就是实现简单。此外，基于语句的复制的二进制日志可以很好的进行压缩，而且日志的数据量也较小，占用带宽少——例如，一个更新GB的数据的查询仅需要几十个字节的二进制日志。而mysqlbinlog对于基于语句的日志处理十分方便。&lt;/p&gt;
&lt;p&gt;但是，基于语句的复制并不是像它看起来那么简单，因为一些查询语句依赖于master的特定条件，例如，master与slave可能有不同的时间。所以，MySQL的二进制日志的格式不仅仅是查询语句，还包括一些元数据信息，例如，当前的时间戳。即使如此，还是有一些语句，比如，CURRENT USER函数，不能正确的进行复制。此外，存储过程和触发器也是一个问题。&lt;br&gt;
另外一个问题就是基于语句的复制必须是串行化的。这要求大量特殊的代码，配置，例如InnoDB的next-key锁等。并不是所有的存储引擎都支持基于语句的复制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.2、基于记录的复制(Row-Based Replication)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MySQL增加基于记录的复制，在二进制日志中记录下实际数据的改变，这与其它一些DBMS的实现方式类似。这种方式有优点，也有缺点。优点就是可以对任何语句都能正确工作，一些语句的效率更高。主要的缺点就是二进制日志可能会很大，而且不直观，所以，你不能使用mysqlbinlog来查看二进制日志。&lt;/p&gt;
&lt;p&gt;对于一些语句，基于记录的复制能够更有效的工作，如：&lt;br&gt;
mysql&amp;gt; INSERT INTO summary_table(col1, col2, sum_col3)&lt;br&gt;
-&amp;gt; SELECT col1, col2, sum(col3)&lt;br&gt;
-&amp;gt; FROM enormous_table&lt;br&gt;
-&amp;gt; GROUP BY col1, col2;&lt;/p&gt;
&lt;p&gt;假设，只有三种唯一的col1和col2的组合，但是，该查询会扫描原表的许多行，却仅返回三条记录。此时，基于记录的复制效率更高。&lt;br&gt;
另一方面，下面的语句，基于语句的复制更有效：&lt;br&gt;
mysql&amp;gt; UPDATE enormous_table SET col1 = 0;&lt;/p&gt;
&lt;p&gt;此时使用基于记录的复制代价会非常高。由于两种方式不能对所有情况都能很好的处理，所以，MySQL 5.1支持在基于语句的复制和基于记录的复制之前动态交换。你可以通过设置session变量binlog_format来进行控制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.3、复制相关的文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;除了二进制日志和中继日志文件外，还有其它一些与复制相关的文件。如下：&lt;/p&gt;
&lt;p&gt;(1)mysql-bin.index&lt;br&gt;
服务器一旦开启二进制日志，会产生一个与二日志文件同名，但是以.index结尾的文件。它用于跟踪磁盘上存在哪些二进制日志文件。MySQL用它来定位二进制日志文件。它的内容如下(我的机器上)：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/4e2faecf5e04ab8482aa913761d2a92c.jpg&quot; width=&quot;231&quot; height=&quot;191&quot;&gt;&lt;/p&gt;
&lt;p&gt;(2)mysql-relay-bin.index&lt;/p&gt;
&lt;p&gt;该文件的功能与mysql-bin.index类似，但是它是针对中继日志，而不是二进制日志。内容如下：&lt;br&gt;
.\mysql-02-relay-bin.000017&lt;br&gt;
.\mysql-02-relay-bin.000018&lt;/p&gt;
&lt;p&gt;(3)master.info&lt;br&gt;
保存master的相关信息。不要删除它，否则，slave重启后不能连接master。内容如下(我的机器上)：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/5ab61c42385f2d61881e393db0310c75.jpg&quot; width=&quot;259&quot; height=&quot;391&quot;&gt;&lt;/p&gt;
&lt;p&gt;I/O线程更新master.info文件，内容如下(我的机器上)：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/e0dadfd1e2bb0e5366ac05fdd6168288.jpg&quot; width=&quot;435&quot; height=&quot;159&quot;&gt;&lt;/p&gt;
&lt;p&gt;(4)relay-log.info&lt;br&gt;
包含slave中当前二进制日志和中继日志的信息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.4、发送复制事件到其它slave&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当设置log_slave_updates时，你可以让slave扮演其它slave的master。此时，slave把SQL线程执行的事件写进行自己的二进制日志(binary log)，然后，它的slave可以获取这些事件并执行它。如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/96f23471a18889f83a895ac624424fa9.jpg&quot; width=&quot;668&quot; height=&quot;319&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.5、复制过滤(Replication Filters)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;复制过滤可以让你只复制服务器中的一部分数据，有两种复制过滤：在master上过滤二进制日志中的事件；在slave上过滤中继日志中的事件。如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/6b7fb272bc32c33fd6accabf53df161f.jpg&quot; width=&quot;634&quot; height=&quot;319&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;4、复制的常用拓扑结构&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;复制的体系结构有以下一些基本原则：&lt;/p&gt;
&lt;p&gt;(1) 每个slave只能有一个master；&lt;br&gt;
(2) 每个slave只能有一个唯一的服务器ID；&lt;br&gt;
(3) 每个master可以有很多slave；&lt;br&gt;
(4) 如果你设置log_slave_updates，slave可以是其它slave的master，从而扩散master的更新。&lt;/p&gt;
&lt;p&gt;MySQL不支持多主服务器复制(Multimaster Replication)——即一个slave可以有多个master。但是，通过一些简单的组合，我们却可以建立灵活而强大的复制体系结构。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.1、单一master和多slave&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由一个master和一个slave组成复制系统是最简单的情况。Slave之间并不相互通信，只能与master进行通信。如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/4aa5875ddf7e5e45471ba940cf36d95a.jpg&quot; width=&quot;283&quot; height=&quot;225&quot;&gt;&lt;/p&gt;
&lt;p&gt;如果写操作较少，而读操作很时，可以采取这种结构。你可以将读操作分布到其它的slave，从而减小master的压力。但是，当slave增加到一定数量时，slave对master的负载以及网络带宽都会成为一个严重的问题。&lt;/p&gt;
&lt;p&gt;这种结构虽然简单，但是，它却非常灵活，足够满足大多数应用需求。一些建议：&lt;br&gt;
(1) 不同的slave扮演不同的作用(例如使用不同的索引，或者不同的存储引擎)；&lt;br&gt;
(2) 用一个slave作为备用master，只进行复制；&lt;br&gt;
(3) 用一个远程的slave，用于灾难恢复；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.2、主动模式的Master-Master(Master-Master in Active-Active Mode)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Master-Master复制的两台服务器，既是master，又是另一台服务器的slave。如图：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/00aaef97b0a0f6ad12016f6c91cfdc19.jpg&quot; width=&quot;212&quot; height=&quot;108&quot;&gt;&lt;/p&gt;
&lt;p&gt;主动的Master-Master复制有一些特殊的用处。例如，地理上分布的两个部分都需要自己的可写的数据副本。这种结构最大的问题就是更新冲突。假设一个表只有一行(一列)的数据，其值为1，如果两个服务器分别同时执行如下语句：&lt;/p&gt;
&lt;p&gt;在第一个服务器上执行：&lt;br&gt;
mysql&amp;gt; UPDATE tbl SET col=col + 1;&lt;br&gt;
在第二个服务器上执行：&lt;br&gt;
mysql&amp;gt; UPDATE tbl SET col=col * 2;&lt;br&gt;
那么结果是多少呢？一台服务器是4，另一个服务器是3，但是，这并不会产生错误。&lt;/p&gt;
&lt;p&gt;实际上，MySQL并不支持其它一些DBMS支持的多主服务器复制(Multimaster Replication)，这是MySQL的复制功能很大的一个限制(多主服务器的难点在于解决更新冲突)，但是，如果你实在有这种需求，你可以采用MySQL Cluster，以及将Cluster和Replication结合起来，可以建立强大的高性能的数据库平台。但是，可以通过其它一些方式来模拟这种多主服务器的复制。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.3、主动-被动模式的Master-Master(Master-Master in Active-Passive Mode)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是master-master结构变化而来的，它避免了M-M的缺点，实际上，这是一种具有容错和高可用性的系统。它的不同点在于其中一个服务只能进行只读操作。如图：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/809b13a2d4c39abf1cca1eb6c1676489.jpg&quot; width=&quot;213&quot; height=&quot;112&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.4、带从服务器的Master-Master结构(Master-Master with Slaves)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这种结构的优点就是提供了冗余。在地理上分布的复制结构，它不存在单一节点故障问题，而且还可以将读密集型的请求放到slave上。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/1f183ba9f0564a1cab22b197442b2e38.jpg&quot; width=&quot;291&quot; height=&quot;218&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主要参考：《High Performance MySQL》 &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87133&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87133votetotal&quot;&gt;&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87133&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt;  评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Mon, 25 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-25-87133-3dfab74e5.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-25-87133-3dfab74e5.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>理解 MySQL（2）：索引与优化</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;p&gt;写在前面：索引对查询的速度有着至关重要的影响，理解索引也是进行数据库性能调优的起点。考虑如下情况，假设数据库中一个表有10^6条记录，DBMS的页面大小为4K，并存储100条记录。如果没有索引，查询将对整个表进行扫描，最坏的情况下，如果所有数据页都不在内存，需要读取10^4个页面，如果这10^4个页面在磁盘上随机分布，需要进行10^4次I/O，假设磁盘每次I/O时间为10ms(忽略数据传输时间)，则总共需要100s(但实际上要好很多很多)。如果对之建立B-Tree索引，则只需要进行log100(10^6)=3次页面读取，最坏情况下耗时30ms。这就是索引带来的效果，很多时候，当你的应用程序进行SQL查询速度很慢时，应该想想是否可以建索引。进入正题：&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;第二章、索引与优化&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1、选择索引的数据类型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MySQL支持很多数据类型，选择合适的数据类型存储数据对性能有很大的影响。通常来说，可以遵循以下一些指导原则：&lt;/p&gt;
&lt;p&gt;(1)越小的数据类型通常更好：越小的数据类型通常在磁盘、内存和CPU缓存中都需要更少的空间，处理起来更快。&lt;/p&gt;
&lt;p&gt;(2)简单的数据类型更好：整型数据比起字符，处理开销更小，因为字符串的比较更复杂。在MySQL中，应该用内置的日期和时间数据类型，而不是用字符串来存储时间；以及用整型数据类型存储IP地址。&lt;/p&gt;
&lt;p&gt;(3)尽量避免NULL：应该指定列为NOT NULL，除非你想存储NULL。在MySQL中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值。&lt;/p&gt;
&lt;p&gt;1.1、选择标识符&lt;/p&gt;
&lt;p&gt;选择合适的标识符是非常重要的。选择时不仅应该考虑存储类型，而且应该考虑MySQL是怎样进行运算和比较的。一旦选定数据类型，应该保证所有相关的表都使用相同的数据类型。&lt;br&gt;
(1) 整型：通常是作为标识符的最好选择，因为可以更快的处理，而且可以设置为AUTO_INCREMENT。&lt;br&gt;
(2) 字符串：尽量避免使用字符串作为标识符，它们消耗更好的空间，处理起来也较慢。而且，通常来说，字符串都是随机的，所以它们在索引中的位置也是随机的，这会导致页面分裂、随机访问磁盘，聚簇索引分裂（对于使用聚簇索引的存储引擎）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、索引入门&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于任何DBMS，索引都是进行优化的最主要的因素。对于少量的数据，没有合适的索引影响不是很大，但是，当随着数据量的增加，性能会急剧下降。&lt;br&gt;
如果对多列进行索引(组合索引)，列的顺序非常重要，MySQL仅能对索引最左边的前缀进行有效的查找。例如：&lt;br&gt;
假设存在组合索引it1c1c2(c1,c2)，查询语句select * from t1 where c1=1 and c2=2能够使用该索引。查询语句select * from t1 where c1=1也能够使用该索引。但是，查询语句select * from t1 where c2=2不能够使用该索引，因为没有组合索引的引导列，即，要想使用c2列进行查找，必需出现c1等于某值。&lt;/p&gt;
&lt;p&gt;2.1、索引的类型&lt;/p&gt;
&lt;p&gt;索引是在存储引擎中实现的，而不是在服务器层中实现的。所以，每种存储引擎的索引都不一定完全相同，并不是所有的存储引擎都支持所有的索引类型。&lt;/p&gt;
&lt;p&gt;2.1.1、B-Tree索引&lt;/p&gt;
&lt;p&gt;假设有如下一个表：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/5074bc5fdd1677ede660cf9d740693a0.jpg&quot; width=&quot;437&quot; height=&quot;159&quot;&gt;&lt;/p&gt;
&lt;p&gt;其索引包含表中每一行的last_name、first_name和dob列。其结构大致如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/7a5eb6c5e34ed1ad43fef584b35da9b0.jpg&quot; width=&quot;671&quot; height=&quot;454&quot;&gt;&lt;/p&gt;
&lt;p&gt;索引存储的值按索引列中的顺序排列。可以利用B-Tree索引进行全关键字、关键字范围和关键字前缀查询，当然，如果想使用索引，你必须保证按索引的最左边前缀(leftmost prefix of the index)来进行查询。&lt;/p&gt;
&lt;p&gt;(1)匹配全值(Match the full value)：对索引中的所有列都指定具体的值。例如，上图中索引可以帮助你查找出生于1960-01-01的Cuba Allen。&lt;br&gt;
(2)匹配最左前缀(Match a leftmost prefix)：你可以利用索引查找last name为Allen的人，仅仅使用索引中的第1列。&lt;br&gt;
(3)匹配列前缀(Match a column prefix)：例如，你可以利用索引查找last name以J开始的人，这仅仅使用索引中的第1列。&lt;br&gt;
(4)匹配值的范围查询(Match a range of values)：可以利用索引查找last name在Allen和Barrymore之间的人，仅仅使用索引中第1列。&lt;br&gt;
(5)匹配部分精确而其它部分进行范围匹配(Match one part exactly and match a range on another part)：可以利用索引查找last name为Allen，而first name以字母K开始的人。&lt;br&gt;
(6)仅对索引进行查询(Index-only queries)：如果查询的列都位于索引中，则不需要读取元组的值。&lt;/p&gt;
&lt;p&gt;由于B-树中的节点都是顺序存储的，所以可以利用索引进行查找(找某些值)，也可以对查询结果进行ORDER BY。当然，使用B-tree索引有以下一些限制：&lt;/p&gt;
&lt;p&gt;(1) 查询必须从索引的最左边的列开始。关于这点已经提了很多遍了。例如你不能利用索引查找在某一天出生的人。&lt;br&gt;
(2) 不能跳过某一索引列。例如，你不能利用索引查找last name为Smith且出生于某一天的人。&lt;br&gt;
(3) 存储引擎不能使用索引中范围条件右边的列。例如，如果你的查询语句为WHERE last_name=”Smith” AND first_name LIKE ‘J%’ AND dob=’1976-12-23′，则该查询只会使用索引中的前两列，因为LIKE是范围查询。&lt;br&gt;
2.1.2、Hash索引&lt;/p&gt;
&lt;p&gt;MySQL中，只有Memory存储引擎显示支持hash索引，是Memory表的默认索引类型，尽管Memory表也可以使用B-Tree索引。Memory存储引擎支持非唯一hash索引，这在数据库领域是罕见的，如果多个值有相同的hash code，索引把它们的行指针用链表保存到同一个hash表项中。&lt;/p&gt;
&lt;p&gt;假设创建如下一个表：&lt;/p&gt;
&lt;p&gt;CREATE TABLE testhash (&lt;br&gt;
fname VARCHAR(50) NOT NULL,&lt;br&gt;
lname VARCHAR(50) NOT NULL,&lt;br&gt;
KEY USING HASH(fname)&lt;br&gt;
) ENGINE=MEMORY;&lt;/p&gt;
&lt;p&gt;包含的数据如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/45057441280555a0e0f5526307251b56.jpg&quot; width=&quot;236&quot; height=&quot;171&quot;&gt;&lt;/p&gt;
&lt;p&gt;假设索引使用hash函数f( )，如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/88369a7dc1356b4c63f767947ff91ea5.jpg&quot; width=&quot;436&quot; height=&quot;108&quot;&gt;&lt;/p&gt;
&lt;p&gt;此时，索引的结构大概如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/548b001039e5a596e76b39c3221bbb22.jpg&quot; width=&quot;500&quot; height=&quot;137&quot;&gt;&lt;/p&gt;
&lt;p&gt;Slots是有序的，但是记录不是有序的。当你执行&lt;br&gt;
mysql&amp;gt; SELECT lname FROM testhash WHERE fname=’Peter’;&lt;br&gt;
MySQL会计算’Peter’的hash值，然后通过它来查询索引的行指针。因为f(‘Peter’) = 8784，MySQL会在索引中查找8784，得到指向记录3的指针。&lt;br&gt;
因为索引自己仅仅存储很短的值，所以，索引非常紧凑。Hash值不取决于列的数据类型，一个TINYINT列的索引与一个长字符串列的索引一样大。&lt;/p&gt;
&lt;p&gt;Hash索引有以下一些限制：&lt;/p&gt;
&lt;p&gt;(1)由于索引仅包含hash code和记录指针，所以，MySQL不能通过使用索引避免读取记录。但是访问内存中的记录是非常迅速的，不会对性造成太大的影响。&lt;br&gt;
(2)不能使用hash索引排序。&lt;br&gt;
(3)Hash索引不支持键的部分匹配，因为是通过整个索引值来计算hash值的。&lt;br&gt;
(4)Hash索引只支持等值比较，例如使用=，IN( )和&amp;lt;=&amp;gt;。对于WHERE price&amp;gt;100并不能加速查询。&lt;/p&gt;
&lt;p&gt;2.1.3、空间(R-Tree)索引&lt;br&gt;
MyISAM支持空间索引，主要用于地理空间数据类型，例如GEOMETRY。&lt;/p&gt;
&lt;p&gt;2.1.4、全文(Full-text)索引&lt;br&gt;
全文索引是MyISAM的一个特殊索引类型，主要用于全文检索。&lt;br&gt;
&lt;strong&gt;3、高性能的索引策略&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;3.1、聚簇索引(Clustered Indexes)&lt;/p&gt;
&lt;p&gt;聚簇索引保证关键字的值相近的元组存储的物理位置也相同（所以字符串类型不宜建立聚簇索引，特别是随机字符串，会使得系统进行大量的移动操作），且一个表只能有一个聚簇索引。因为由存储引擎实现索引，所以，并不是所有的引擎都支持聚簇索引。目前，只有solidDB和InnoDB支持。&lt;/p&gt;
&lt;p&gt;聚簇索引的结构大致如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/e0ac4b23c58d234870940bedfe77644a.jpg&quot; width=&quot;659&quot; height=&quot;490&quot;&gt;&lt;/p&gt;
&lt;p&gt;注：叶子页面包含完整的元组，而内节点页面仅包含索引的列(索引的列为整型)。一些DBMS允许用户指定聚簇索引，但是MySQL的存储引擎到目前为止都不支持。InnoDB对主键建立聚簇索引。如果你不指定主键，InnoDB会用一个具有唯一且非空值的索引来代替。如果不存在这样的索引，InnoDB会定义一个隐藏的主键，然后对其建立聚簇索引。一般来说，DBMS都会以聚簇索引的形式来存储实际的数据，它是其它二级索引的基础。&lt;/p&gt;
&lt;p&gt;3.1.1、InnoDB和MyISAM的数据布局的比较&lt;/p&gt;
&lt;p&gt;为了更加理解聚簇索引和非聚簇索引，或者primary索引和second索引(MyISAM不支持聚簇索引)，来比较一下InnoDB和MyISAM的数据布局，对于如下表：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/5074bc5fdd1677ede660cf9d740693a0.jpg&quot; width=&quot;437&quot; height=&quot;159&quot;&gt;&lt;/p&gt;
&lt;p&gt;假设主键的值位于1—10,000之间，且按随机顺序插入，然后用OPTIMIZE TABLE进行优化。col2随机赋予1—100之间的值，所以会存在许多重复的值。&lt;/p&gt;
&lt;p&gt;(1) MyISAM的数据布局&lt;/p&gt;
&lt;p&gt;其布局十分简单，MyISAM按照插入的顺序在磁盘上存储数据，如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/e141d3bca2f7de9417c1f2fe35120679.jpg&quot; width=&quot;180&quot; height=&quot;209&quot;&gt;&lt;/p&gt;
&lt;p&gt;注：左边为行号(row number)，从0开始。因为元组的大小固定，所以MyISAM可以很容易的从表的开始位置找到某一字节的位置。&lt;br&gt;
据些建立的primary key的索引结构大致如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/1d7c5f5632a21cf72e3934f366404f17.jpg&quot; width=&quot;583&quot; height=&quot;246&quot;&gt;&lt;/p&gt;
&lt;p&gt;注：MyISAM不支持聚簇索引，索引中每一个叶子节点仅仅包含行号(row number)，且叶子节点按照col1的顺序存储。&lt;br&gt;
来看看col2的索引结构：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/fe8835b69c5f0ccfbc3d0ef98d526352.jpg&quot; width=&quot;470&quot; height=&quot;247&quot;&gt;&lt;/p&gt;
&lt;p&gt;实际上，在MyISAM中，primary key和其它索引没有什么区别。Primary key仅仅只是一个叫做PRIMARY的唯一，非空的索引而已。&lt;/p&gt;
&lt;p&gt;(2) InnoDB的数据布局&lt;/p&gt;
&lt;p&gt;InnoDB按聚簇索引的形式存储数据，所以它的数据布局有着很大的不同。它存储表的结构大致如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/d5082d3305d2ee43ee479d6599a08077.jpg&quot; width=&quot;658&quot; height=&quot;304&quot;&gt;&lt;/p&gt;
&lt;p&gt;注：聚簇索引中的每个叶子节点包含primary key的值，事务ID和回滚指针(rollback pointer)——用于事务和MVCC，和余下的列(如col2)。&lt;/p&gt;
&lt;p&gt;相对于MyISAM，二级索引与聚簇索引有很大的不同。InnoDB的二级索引的叶子包含primary key的值，而不是行指针(row pointers)，这减小了移动数据或者数据页面分裂时维护二级索引的开销，因为InnoDB不需要更新索引的行指针。其结构大致如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/091f4c0f4e5a1c8c4d25eb8e1e36c94b.jpg&quot; width=&quot;657&quot; height=&quot;248&quot;&gt;&lt;/p&gt;
&lt;p&gt;聚簇索引和非聚簇索引表的对比：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/8f1ec9dcebb405ec50ecb7b7dfadcc8c.jpg&quot; width=&quot;665&quot; height=&quot;579&quot;&gt;&lt;/p&gt;
&lt;p&gt;3.1.2、按primary key的顺序插入行(InnoDB)&lt;/p&gt;
&lt;p&gt;如果你用InnoDB，而且不需要特殊的聚簇索引，一个好的做法就是使用代理主键(surrogate key)——独立于你的应用中的数据。最简单的做法就是使用一个AUTO_INCREMENT的列，这会保证记录按照顺序插入，而且能提高使用primary key进行连接的查询的性能。应该尽量避免随机的聚簇主键，例如，字符串主键就是一个不好的选择，它使得插入操作变得随机。&lt;/p&gt;
&lt;p&gt;3.2、覆盖索引(Covering Indexes)&lt;/p&gt;
&lt;p&gt;如果索引包含满足查询的所有数据，就称为覆盖索引。覆盖索引是一种非常强大的工具，能大大提高查询性能。只需要读取索引而不用读取数据有以下一些优点：&lt;/p&gt;
&lt;p&gt;(1)索引项通常比记录要小，所以MySQL访问更少的数据；&lt;br&gt;
(2)索引都按值的大小顺序存储，相对于随机访问记录，需要更少的I/O；&lt;br&gt;
(3)大多数据引擎能更好的缓存索引。比如MyISAM只缓存索引。&lt;br&gt;
(4)覆盖索引对于InnoDB表尤其有用，因为InnoDB使用聚集索引组织数据，如果二级索引中包含查询所需的数据，就不再需要在聚集索引中查找了。&lt;/p&gt;
&lt;p&gt;覆盖索引不能是任何索引，只有B-TREE索引存储相应的值。而且不同的存储引擎实现覆盖索引的方式都不同，并不是所有存储引擎都支持覆盖索引(Memory和Falcon就不支持)。&lt;/p&gt;
&lt;p&gt;对于索引覆盖查询(index-covered query)，使用EXPLAIN时，可以在Extra一列中看到“Using index”。例如，在sakila的inventory表中，有一个组合索引(store_id,film_id)，对于只需要访问这两列的查询，MySQL就可以使用索引，如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/e2d455071994988edab8e464dbafb670.jpg&quot; width=&quot;437&quot; height=&quot;356&quot;&gt;&lt;/p&gt;
&lt;p&gt;在大多数引擎中，只有当查询语句所访问的列是索引的一部分时，索引才会覆盖。但是，InnoDB不限于此，InnoDB的二级索引在叶子节点中存储了primary key的值。因此，sakila.actor表使用InnoDB，而且对于是last_name上有索引，所以，索引能覆盖那些访问actor_id的查询，如：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/5a1764aaf27210f3a2f8a55285baf422.jpg&quot; width=&quot;437&quot; height=&quot;356&quot;&gt;&lt;/p&gt;
&lt;p&gt;3.3、利用索引进行排序&lt;/p&gt;
&lt;p&gt;MySQL中，有两种方式生成有序结果集：一是使用filesort，二是按索引顺序扫描。利用索引进行排序操作是非常快的，而且可以利用同一索引同时进行查找和排序操作。当索引的顺序与ORDER BY中的列顺序相同且所有的列是同一方向(全部升序或者全部降序)时，可以使用索引来排序。如果查询是连接多个表，仅当ORDER BY中的所有列都是第一个表的列时才会使用索引。其它情况都会使用filesort。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/cabf2c49dfbf35505f73a6cf426759a4.jpg&quot; width=&quot;438&quot; height=&quot;289&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/2be64445f4b4a8c3afc46de2322054f3.jpg&quot; width=&quot;425&quot; height=&quot;347&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/54ae9cf43f28bd378390e1996bf0e563.jpg&quot; width=&quot;416&quot; height=&quot;353&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/9854470399c6bc12108cd680a2447505.jpg&quot; width=&quot;432&quot; height=&quot;351&quot;&gt;&lt;/p&gt;
&lt;p&gt;当MySQL不能使用索引进行排序时，就会利用自己的排序算法(快速排序算法)在内存(sort buffer)中对数据进行排序，如果内存装载不下，它会将磁盘上的数据进行分块，再对各个数据块进行排序，然后将各个块合并成有序的结果集（实际上就是外排序）。对于filesort，MySQL有两种排序算法。&lt;/p&gt;
&lt;p&gt;(1)两遍扫描算法(Two passes)&lt;/p&gt;
&lt;p&gt;实现方式是先将须要排序的字段和可以直接定位到相关行数据的指针信息取出，然后在设定的内存（通过参数sort_buffer_size设定）中进行排序，完成排序之后再次通过行指针信息取出所需的Columns。&lt;br&gt;
注：该算法是4.1之前采用的算法，它需要两次访问数据，尤其是第二次读取操作会导致大量的随机I/O操作。另一方面，内存开销较小。&lt;/p&gt;
&lt;p&gt;(2) 一次扫描算法(single pass)&lt;/p&gt;
&lt;p&gt;该算法一次性将所需的Columns全部取出，在内存中排序后直接将结果输出。&lt;br&gt;
注：从 MySQL 4.1 版本开始使用该算法。它减少了I/O的次数，效率较高，但是内存开销也较大。如果我们将并不需要的Columns也取出来，就会极大地浪费排序过程所需要的内存。在 MySQL 4.1 之后的版本中，可以通过设置 max_length_for_sort_data 参数来控制 MySQL 选择第一种排序算法还是第二种。当取出的所有大字段总大小大于 max_length_for_sort_data 的设置时，MySQL 就会选择使用第一种排序算法，反之，则会选择第二种。为了尽可能地提高排序性能，我们自然更希望使用第二种排序算法，所以在 Query 中仅仅取出需要的 Columns 是非常有必要的。&lt;/p&gt;
&lt;p&gt;当对连接操作进行排序时，如果ORDER BY仅仅引用第一个表的列，MySQL对该表进行filesort操作，然后进行连接处理，此时，EXPLAIN输出“Using filesort”；否则，MySQL必须将查询的结果集生成一个临时表，在连接完成之后进行filesort操作，此时，EXPLAIN输出“Using temporary;Using filesort”。&lt;/p&gt;
&lt;p&gt;3.4、索引与加锁&lt;br&gt;
索引对于InnoDB非常重要，因为它可以让查询锁更少的元组。这点十分重要，因为MySQL 5.0中，InnoDB直到事务提交时才会解锁。有两个方面的原因：首先，即使InnoDB行级锁的开销非常高效，内存开销也较小，但不管怎么样，还是存在开销。其次，对不需要的元组的加锁，会增加锁的开销，降低并发性。&lt;/p&gt;
&lt;p&gt;InnoDB仅对需要访问的元组加锁，而索引能够减少InnoDB访问的元组数。但是，只有在存储引擎层过滤掉那些不需要的数据才能达到这种目的。一旦索引不允许InnoDB那样做（即达不到过滤的目的），MySQL服务器只能对InnoDB返回的数据进行WHERE操作，此时，已经无法避免对那些元组加锁了：InnoDB已经锁住那些元组，服务器无法解锁了。&lt;br&gt;
来看个例子：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/c673a56d4ed89ea5c72950b95c2cff45.jpg&quot; width=&quot;437&quot; height=&quot;402&quot;&gt;&lt;/p&gt;
&lt;p&gt;该查询仅仅返回2—3的数据，实际已经对1—3的数据加上排它锁了。InnoDB锁住元组1是因为MySQL的查询计划仅使用索引进行范围查询（而没有进行过滤操作，WHERE中第二个条件已经无法使用索引了）：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/f4ff8205864c1bf5c28a50a0a07e8a95.jpg&quot; width=&quot;438&quot; height=&quot;433&quot;&gt;&lt;/p&gt;
&lt;p&gt;表明存储引擎从索引的起始处开始，获取所有的行，直到actor_id&amp;lt;4为假，服务器无法告诉InnoDB去掉元组1。&lt;br&gt;
为了证明row 1已经被锁住，我们另外建一个连接，执行如下操作：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/1e9aaedcea8e8c83c3d3b683499bdbca.jpg&quot; width=&quot;436&quot; height=&quot;84&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87127&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87127votetotal&quot;&gt;&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87127&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt;  评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Mon, 25 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-25-87127-2d5108505.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-25-87127-2d5108505.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>理解 MySQL（1）：架构和概念</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;p&gt;写在前面：最早接触的MySQL是在2006年前，那时候MySQL还是4.x版本，很多功能都不支持，比如，存储过程，视图，触发器，更别说分布式事务等复杂特性了。但从5.0(2005年10月)开始，MySQL渐渐步入企业级数据库的行列了；复制、集群、分区、分布式事务，这些企业级的特性，使得现在的MySQL，完全可以应用于企业级应用环境(很多互联网公司都用其作为数据库服务器，尽管节约成本是一个因素，但是没有强大功能作后盾，则是不可想象的)。虽然，MySQL还有很多不足，比如，复制、分区的支持都十分有限、查询优化仍需要改进，但是MySQL已经是一个足够好的DBMS了，更何况它是opensource的。这段时间没有事，出于好奇，略微的研究了一下MySQL，积累了一些资料，欲总结出来。这些资料打算分为两部分，上部主要讨论MySQL的优化，其中主要参考了《MySQL Manual》和《High Performance MySQL》，如果有时间，以后在下部分析一下MySQL的源码。如果你是MySQL高手，希望你不吝赐教；如果你是新手，希望对你有用。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;第一章、MySQL架构与概念&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1、MySQL的逻辑架构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/aee367182eeb4901f457628d1e067150.jpg&quot; width=&quot;232&quot; height=&quot;325&quot;&gt;&lt;/p&gt;
&lt;p&gt;最上面不是MySQL特有的，所有基于网络的C/S的网络应用程序都应该包括连接处理、认证、安全管理等。&lt;br&gt;
中间层是MySQL的核心，包括查询解析、分析、优化和缓存等。同时它还提供跨存储引擎的功能，包括存储过程、触发器和视图等。&lt;br&gt;
最下面是存储引擎，它负责存取数据。服务器通过storage engine API可以和各种存储引擎进行交互。&lt;/p&gt;
&lt;p&gt;1.1、查询优化和执行(Optimization and Execution)&lt;/p&gt;
&lt;p&gt;MySQL将用户的查询语句进行解析，并创建一个内部的数据结构——分析树，然后进行各种优化，例如重写查询、选择读取表的顺序，以及使用哪个索引等。查询优化器不关心一个表所使用的存储引擎，但是存储引擎会影响服务器如何优化查询。优化器通过存储引擎获取一些参数、某个操作的执行代价、以及统计信息等。在解析查询之前，服务器会先访问查询缓存(query cache)——它存储SELECT语句以及相应的查询结果集。如果某个查询结果已经位于缓存中，服务器就不会再对查询进行解析、优化、以及执行。它仅仅将缓存中的结果返回给用户即可，这将大大提高系统的性能。&lt;/p&gt;
&lt;p&gt;1.2、并发控制&lt;/p&gt;
&lt;p&gt;MySQL提供两个级别的并发控制：服务器级(the server level)和存储引擎级(the storage engine level)。加锁是实现并发控制的基本方法，MySQL中锁的粒度：&lt;/p&gt;
&lt;p&gt;(1) 表级锁：MySQL独立于存储引擎提供表锁，例如，对于ALTER TABLE语句，服务器提供表锁(table-level lock)。&lt;br&gt;
(2) 行级锁：InnoDB和Falcon存储引擎提供行级锁，此外，BDB支持页级锁。InnoDB的并发控制机制，下节详细讨论。&lt;/p&gt;
&lt;p&gt;另外，值得一提的是，MySQL的一些存储引擎（如InnoDB、BDB）除了使用封锁机制外，还同时结合MVCC机制，即多版本两阶段封锁协议(Multiversion two-phrase locking protocal)，来实现事务的并发控制，从而使得只读事务不用等待锁，提高了事务的并发性。&lt;/p&gt;
&lt;p&gt;注：并发控制是DBMS的核心技术之一(实际上，对于OS也一样)，它对系统性能有着至关重要的影响，以后再详细讨论。&lt;br&gt;
1.3、事务处理&lt;/p&gt;
&lt;p&gt;MySQL中，InnoDB和BDB都支持事务处理。这里主要讨论InnoDB的事务处理(关于BDB的事务处理，也十分复杂，以前曾较为详细看过其源码，以后有机会再讨论)。&lt;/p&gt;
&lt;p&gt;1.3.1、事务的ACID特性&lt;/p&gt;
&lt;p&gt;事务是由一组SQL语句组成的逻辑处理单元，事务具有以下4个属性，通常简称为事务的ACID属性(Jim Gray在《事务处理：概念与技术》中对事务进行了详尽的讨论)。&lt;/p&gt;
&lt;p&gt;(1)原子性（Atomicity）：事务是一个原子操作单元，其对数据的修改，要么全都执行，要么全都不执行。&lt;br&gt;
(2)一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态。这意味着所有相关的数据规则都必须应用于事务的修改，以保持数据的完整性；事务结束时，所有的内部数据结构（如B树索引或双向链表）也都必须是正确的。&lt;br&gt;
(3)隔离性（Isolation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的“独立”环境执行。这意味着事务处理过程中的中间状态对外部是不可见的，反之亦然。&lt;br&gt;
(4)持久性（Durable）：事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。&lt;/p&gt;
&lt;p&gt;1.3.2、事务处理带来的相关问题&lt;/p&gt;
&lt;p&gt;由于事务的并发执行，带来以下一些著名的问题：&lt;/p&gt;
&lt;p&gt;(1)更新丢失（Lost Update）：当两个或多个事务选择同一行，然后基于最初选定的值更新该行时，由于每个事务都不知道其他事务的存在，就会发生丢失更新问题－－最后的更新覆盖了由其他事务所做的更新。&lt;br&gt;
(2)脏读（Dirty Reads）：一个事务正在对一条记录做修改，在这个事务完成并提交前，这条记录的数据就处于不一致状态；这时，另一个事务也来读取同一条记录，如果不加控制，第二个事务读取了这些“脏”数据，并据此做进一步的处理，就会产生未提交的数据依赖关系。这种现象被形象地叫做”脏读”。&lt;br&gt;
(3)不可重复读（Non-Repeatable Reads）：一个事务在读取某些数据后的某个时间，再次读取以前读过的数据，却发现其读出的数据已经发生了改变、或某些记录已经被删除了！这种现象就叫做“不可重复读”。&lt;br&gt;
(4)幻读（Phantom Reads）：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为“幻读”。&lt;/p&gt;
&lt;p&gt;1.3.3、事务的隔离性&lt;/p&gt;
&lt;p&gt;SQL2标准定义了四个隔离级别。定义语句如下：&lt;/p&gt;
&lt;p&gt;SET TRANSACTION ISOLATION LEVEL&lt;br&gt;
[READ UNCOMMITTED |&lt;br&gt;
READ COMMITTED |&lt;br&gt;
REPEATABLE READ |&lt;br&gt;
SERIALIZABLE ]&lt;/p&gt;
&lt;p&gt;这与Jim Gray所提出的隔离级别有点差异。其中READ UNCOMMITTED即Jim的10（浏览）；READ COMMITTED即20，游标稳定性；REPEATABLE READ为2.99990隔离(没有幻像保护)；SERIALIZABLE隔离级别为30，完全隔离。SQL2标准默认为完全隔离(30)。各个级别存在问题如下：&lt;/p&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;144&quot;&gt;&lt;strong&gt;隔离级&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;104&quot;&gt;&lt;strong&gt;脏读&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;144&quot;&gt;&lt;strong&gt;不可重复读&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;120&quot;&gt;&lt;strong&gt;幻象读&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;144&quot;&gt;读未提交(Read uncommitted)&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;104&quot;&gt;可能&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;144&quot;&gt;可能&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;120&quot;&gt;可能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;144&quot;&gt;读提交(Read committed)&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;104&quot;&gt;不可能&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;144&quot;&gt;可能&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;120&quot;&gt;可能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;144&quot;&gt;可重复读(Repeatable read)&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;104&quot;&gt;不可能&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;144&quot;&gt;不可能&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;120&quot;&gt;可能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;144&quot;&gt;可串行化(Serializable)&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;104&quot;&gt;不可能&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;144&quot;&gt;不可能&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;120&quot;&gt;不可能&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;各个具体数据库并不一定完全实现了上述4个隔离级别，例如，Oracle只提供READ COMMITTED和Serializable两个标准隔离级别，另外还提供自己定义的Read only隔离级别；SQL Server除支持上述ISO/ANSI SQL92定义的4个隔离级别外，还支持一个叫做“快照”的隔离级别，但严格来说它是一个用MVCC实现的Serializable隔离级别。MySQL 支持全部4个隔离级别，其默认级别为Repeatable read，但在具体实现时，有一些特点，比如在一些隔离级别下是采用MVCC一致性读。国产数据库DM也支持所有级别，其默认级别为READ COMMITTED。&lt;/p&gt;
&lt;p&gt;1.3.4、InnoDB的锁模型&lt;/p&gt;
&lt;p&gt;InnoDB的行级锁有两种类型：&lt;/p&gt;
&lt;p&gt;(1)共享锁(shared lock，S)：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。&lt;br&gt;
(2)排它锁(exclusive lock，X)：允许获得排它锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。&lt;/p&gt;
&lt;p&gt;此外，InnoDB支持多粒度加锁(multiple granularity locking)，从而允许对记录和表同时加锁。为此，InnoDB引入意向锁(intention locks)，意向锁是针对表的：&lt;/p&gt;
&lt;p&gt;(1)意向共享锁（IS）：事务打算给数据行加行共享锁，事务在给一个数据行加共享锁前必须先取得该表的IS锁。&lt;br&gt;
(2)意向排他锁（IX）：事务打算给数据行加行排他锁，事务在给一个数据行加排他锁前必须先取得该表的IX锁。&lt;/p&gt;
&lt;p&gt;例如，SELECT … LOCK IN SHARE MODE加IS锁，SELECT … FOR UPDATE加IX锁，意向锁的规则如下：&lt;/p&gt;
&lt;p&gt;(1)事务在对表T中的记录获取S锁前，先要获取表T的IS锁或者更强的锁；&lt;br&gt;
(2)事务在获取表T中记录的X锁前，先要获取表T的IX锁。&lt;/p&gt;
&lt;p&gt;InnoDB的锁相容性矩阵：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/a2f8aa76118113a48535d489c37d71cd.jpg&quot; width=&quot;690&quot; height=&quot;108&quot;&gt;&lt;/p&gt;
&lt;p&gt;如果一个事务请求的锁模式与当前的锁兼容，InnoDB就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。意向锁只会阻塞其它事务对表的请求，例如，LOCK TABLES …WRITE，意向锁的主要目的是表明该事务将要或者正在对表中的记录加锁。使用封锁机制来进行并发控制，一个比较重要的问题就是死锁。&lt;br&gt;
来看一个死锁的例子：&lt;/p&gt;
&lt;p&gt;例1-1&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;Session 1&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;Session 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; CREATE TABLE t (i INT) ENGINE = InnoDB;Query OK, 0 rows affected (0.22 sec)mysql&amp;gt; INSERT INTO t (i) VALUES(1);Query OK, 1 row affected (0.08 sec)
&lt;p&gt;mysql&amp;gt; START TRANSACTION;&lt;/p&gt;
&lt;p&gt;Query OK, 0 rows affected (0.00 sec)&lt;/p&gt;
&lt;p&gt;mysql&amp;gt; SELECT * FROM t WHERE i = 1 LOCK IN SHARE MODE;&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;| i    |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;|    1 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;1 row in set (0.01 sec)&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; START TRANSACTION;Query OK, 0 rows affected (0.00 sec)mysql&amp;gt; DELETE FROM t WHERE i = 1;等待…&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; DELETE FROM t WHERE i = 1;等待…&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;Query OK, 1 row affected (0.00 sec)&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;1.3.5、一致性非阻塞读&lt;br&gt;
一致性读是MySQL的重要特点之一，InnoDB通过MVCC机制表示数据库某一时刻的查询快照，查询可以看该时刻之前提交的事务所做的改变，但是不能看到该时刻之后或者未提交事务所做的改变。但是，查询可以看到同一事务中之前语句所做的改变，例如：&lt;/p&gt;
&lt;p&gt;例1-2&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;Session 1&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;Session 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; select * from t;Empty set (0.00 sec)mysql&amp;gt; INSERT INTO t (i) VALUES(1);Query OK, 1 row affected (0.00 sec)
&lt;p&gt;mysql&amp;gt; select * from t;&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;| i    |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;|    1 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;1 row in set (0.00 sec)&lt;/p&gt;
&lt;p&gt;mysql&amp;gt; set autocommit = 0;&lt;/p&gt;
&lt;p&gt;Query OK, 0 rows affected (0.01 sec)&lt;/p&gt;
&lt;p&gt;mysql&amp;gt; update t set i=3;&lt;/p&gt;
&lt;p&gt;Query OK, 1 row affected (0.00 sec)&lt;/p&gt;
&lt;p&gt;Rows matched: 1 Changed: 1 Warnings: 0&lt;/p&gt;
&lt;p&gt;mysql&amp;gt; select * from t;&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;| i    |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;|    3 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; set autocommit = 0;Query OK, 0 rows affected (0.00 sec)mysql&amp;gt; select * from t;+——+
&lt;p&gt;| i    |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;|    1 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; commit;Query OK, 0 rows affected (0.06 sec)&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; select * from t;+——+| i    |+——+
&lt;p&gt;|    1 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; commit;Query OK, 0 rows affected (0.00 sec)mysql&amp;gt; select * from t;+——+
&lt;p&gt;| i    |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;|    3 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;如果事务的隔离级别为REPEATABLE READ（默认），同一个事务中的所有一致性读都是读的事务的第一次读操作创建的快照。你可以提交当前事务，然后在新的查询中即可看到最新的快照，如上所示。&lt;br&gt;
如果事务的隔离级别为READ COMMITTED，一致性读只是对事务内部的读操作和它自己的快照而言的，结果如下：&lt;/p&gt;
&lt;p&gt;例1-3&lt;/p&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;Session 1&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;Session 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;Query OK, 0 rows affected (0.01 sec)mysql&amp;gt; set autocommit = 0;Query OK, 0 rows affected (0.00 sec)
&lt;p&gt;mysql&amp;gt; select * from t;&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;| i    |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;|    3 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED;Query OK, 0 rows affected (0.01 sec)mysql&amp;gt; set autocommit = 0;Query OK, 0 rows affected (0.00 sec)
&lt;p&gt;mysql&amp;gt; select * from t;&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;| i    |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;|    3 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; update t set i=5;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; select * from t;+——+| i    |+——+
&lt;p&gt;|    3 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; commit;Query OK, 0 rows affected (0.06 sec)&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; select * from t;+——+| i    |+——+
&lt;p&gt;|    5 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;1 row in set (0.00 sec)&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;注意，session 2发生了不可重复读。&lt;/p&gt;
&lt;p&gt;当InnoDB在READ COMMITTED 和REPEATABLE READ隔离级别下处理SELECT语句时，一致性读是默认的模式。一致性读不会对表加任何锁，所以，其它连接可以同时改变表。&lt;br&gt;
假设事务处于REPEATABLE READ级别，当你正在进行一致性读时，InnoDB根据查询看到的数据给你一个时间点。如果其它的事务在该时间点之后删除一行，且提交事务，你不会看到行已经被删除，插入和更新操作一样。但是，InnoDB与其它DBMS的不同是，在REPEATABLE READ隔离级别下并不会造成幻像。&lt;br&gt;
一致性读不与DROP TABLE 或者 ALTER TABLE一起工作。&lt;br&gt;
在nodb_locks_unsafe_for_binlog变量被设置或者事务的隔离级别不是SERIALIZABLE的情况下，InnoDB对于没有指定FOR UPDATE 或 LOCK IN SHARE MODE的INSERT INTO … SELECT, UPDATE … (SELECT), 和CREATE TABLE … SELECT语句使用一致性读，在这种情况下，查询语句不会对表中的元组加锁。否则，InnoDB将使用锁。&lt;br&gt;
1.3.6、SELECT … FOR UPDATE和SELECT … LOCK IN SHARE MODE的加锁读(locking read)&lt;/p&gt;
&lt;p&gt;在一些场合，一致性读并不是很方便，此时，可以用加锁读。InnoDB支持两种加锁读：&lt;/p&gt;
&lt;p&gt;(1) SELECT … LOCK IN SHARE MODE：对读取的元组加S锁。&lt;br&gt;
(2) SELECT … FOR UPDATE：在扫描索引记录的过程中，会阻塞其它连接的SELECT …LOCK IN SHARE MODE和一定事务隔离级别下的读操作。&lt;/p&gt;
&lt;p&gt;InnoDB使用两阶段封锁协议，事务直到提交或回滚时才会释放所有的锁，这都是系统自动执行的。此外，MySQL支持LOCK TABLES和UNLOCK TABLES，但这些都是在服务器层实现的，而不是在存储引擎。它们有用处，但是不能取代存储引擎完成事务处理，如果你需要事务功能，请使用事务型存储引擎。&lt;br&gt;
来考虑locking read的应用，假设你要在表child插入一个新的元组，并保证child中的记录在表parent有一条父记录。如果你用一致性读来读parent表，确实可以将要插入的child row的parent row，但是可以安全的插入吗？不，因为在你读parent表时，其它连接可能已经删除该记录。（一致性读是针对事务内而言的，对于数据库的状态，它应该叫做“不一致性读”）&lt;br&gt;
此时，就可以使用SELECT LOCK IN SHARE MODE，它会对读取的元组加S锁，从而防止其它连接删除或更新元组。另外，如果你想在查询的同时，进行更新操作，可以使用SELECT … FOR UPDATE，它读取最新的数据，然后对读到的元组加X锁。此时，使用SELECT … LOCK IN SHARE MODE不是一个好主意，因为此时如果有两个事务进行这样的操作，就会造成死锁。&lt;/p&gt;
&lt;p&gt;注：SELECT … FOR UPDATE仅在自动提交关闭(即手动提交)时才会对元组加锁，而在自动提交时，符合条件的元组不会被加锁。&lt;/p&gt;
&lt;p&gt;1.3.7、记录锁(record lok)、间隙锁(gap lock)和后码锁(next-key lock)&lt;/p&gt;
&lt;p&gt;InnoDB有以下几种行级锁：&lt;/p&gt;
&lt;p&gt;(1)记录锁：对索引记录(index records)加锁，InnoDB行级锁是通过给索引的索引项加锁来实现的，而不是对记录实例本身加锁。如果表没有定义索引，InnoDB创建一个隐藏的聚簇索引，然后用它来实现记录加锁（关于索引与加锁之间的关系的详细介绍请看下一章）。&lt;br&gt;
(2)间隙锁：对索引记录之间的区间，或者第一个索引记录之前的区间和最后一个索引之后的区间加锁。&lt;br&gt;
(3)后码锁：对索引记录加记录锁，且对索引记录之前的区间加锁。&lt;/p&gt;
&lt;p&gt;默认情况下，InnoDB的事务工作在REPEATABLE READ的隔离级别，而且系统变量innodb_locks_unsafe_for_binlog为关闭状态。此时，InnoDB使用next-key锁进行查找和索引扫描，从而达到防止“幻像”的目的。&lt;br&gt;
Next-key锁是记录锁和间隙的结合体。当InnoDB查找或扫描表的索引时，对它遇到的索引记录加S锁或者X锁，所以，行级锁(row-level lock)实际上就是索引记录锁(index-record lock)；此外，它还对索引记录之前的区间加锁。也就是说，next-key锁是索引记录锁，外加索引记录之前的区间的间隙锁。如果一个连接对索引中的记录R持有S或X锁，其它的连接不能按照索引的顺序在R之前的区间插入一个索引记录。&lt;br&gt;
假设索引包含以下值：10, 11,13和20，则索引的next-key锁会覆盖以下区间(“(”表示不包含，“[”表示包含)：&lt;br&gt;
(negative infinity, 10]&lt;br&gt;
(10, 11]&lt;br&gt;
(11, 13]&lt;br&gt;
(13, 20]&lt;br&gt;
(20, positive infinity)&lt;br&gt;
对于最后一个区间，next-key锁将锁住索引最大值以上的区间，上界虚记录(“supremum” pseudo-record)的值比索引中的任何值都大，其实，上界不是一个真实的索引记录，所以，next-lock将对索引的最大值之后的区间加锁。&lt;/p&gt;
&lt;p&gt;间隙锁对查询唯一索引中的唯一值是没有必要的，例如，id列有唯一索引，则下面的查询仅对id=100的元组加索引记录锁(index-record lock)，而不管其它连接是否在之前的区间插入元组。&lt;br&gt;
SELECT * FROM child WHERE id = 100;&lt;br&gt;
如果id没有索引，或者非唯一索引，则语句会锁住之前的空间。&lt;br&gt;
例1-4&lt;/p&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;
&lt;pre&gt;Session 1&lt;/pre&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;
&lt;pre&gt;Session 2&lt;/pre&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;
&lt;pre&gt;mysql&amp;gt; create unique index i_index on t(i);&lt;/pre&gt;
&lt;pre&gt;Query OK, 0 rows affected (0.19 sec)&lt;/pre&gt;
&lt;pre&gt;Records: 0 Duplicates: 0 Warnings: 0&lt;/pre&gt;
&lt;pre&gt;mysql&amp;gt; select * from t;&lt;/pre&gt;
&lt;pre&gt;+------+&lt;/pre&gt;
&lt;pre&gt;| i    |&lt;/pre&gt;
&lt;pre&gt;+------+&lt;/pre&gt;
&lt;pre&gt;|    4 |&lt;/pre&gt;
&lt;pre&gt;|   10 |&lt;/pre&gt;
&lt;pre&gt;+------+&lt;/pre&gt;
&lt;pre&gt;2 rows in set (0.00 sec)&lt;/pre&gt;
&lt;pre&gt;&lt;/pre&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;
&lt;pre&gt;mysql&amp;gt; set autocommit=0;&lt;/pre&gt;
&lt;pre&gt;Query OK, 0 rows affected (0.00 sec)&lt;/pre&gt;
&lt;pre&gt;mysql&amp;gt; select i from t where i =10 lock in share mode;&lt;/pre&gt;
&lt;pre&gt;+------+&lt;/pre&gt;
&lt;pre&gt;| i    |&lt;/pre&gt;
&lt;pre&gt;+------+&lt;/pre&gt;
&lt;pre&gt;|   10 |&lt;/pre&gt;
&lt;pre&gt;+------+&lt;/pre&gt;
&lt;pre&gt;1 row in set (0.00 sec)&lt;/pre&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;
&lt;pre&gt;mysql&amp;gt; insert into t(i) values(9);&lt;/pre&gt;
&lt;pre&gt;Query OK, 1 row affected (0.03 sec)&lt;/pre&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;
&lt;pre&gt;mysql&amp;gt; select * from t;&lt;/pre&gt;
&lt;pre&gt;+------+&lt;/pre&gt;
&lt;pre&gt;| i    |&lt;/pre&gt;
&lt;pre&gt;+------+&lt;/pre&gt;
&lt;pre&gt;|    4 |&lt;/pre&gt;
&lt;pre&gt;|    9 |&lt;/pre&gt;
&lt;pre&gt;|   10 |&lt;/pre&gt;
&lt;pre&gt;+------+&lt;/pre&gt;
&lt;pre&gt;3 rows in set (0.00 sec)&lt;/pre&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;上例中，产生了幻像问题。如果将唯一查询变成范围查询，结果如下(接上例的索引)：&lt;/p&gt;
&lt;p&gt;例1-5&lt;/p&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;Session 1&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;Session 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; select * from t;+——+| i    |+——+
&lt;p&gt;|    4 |&lt;/p&gt;
&lt;p&gt;|    9 |&lt;/p&gt;
&lt;p&gt;|   10 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; set autocommit=0;Query OK, 0 rows affected (0.00 sec)mysql&amp;gt; select i from t where i&amp;gt;4 lock in share mode;+——+
&lt;p&gt;| i    |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;|    9 |&lt;/p&gt;
&lt;p&gt;|   10 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; insert into t(i) values(1);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&amp;gt; insert into t(i) values(8);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;可以看到，session 2 的next-key使得在i=4之前的区间和之后的插入都被阻塞。&lt;br&gt;
另外，如果删除索引i_index，则结果如下：&lt;/p&gt;
&lt;p&gt;例1-6&lt;/p&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;Session 1&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;Session 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; drop index i_index on t;Query OK, 3 rows affected (0.25 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&amp;gt; select * from t;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;| i    |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;|    4 |&lt;/p&gt;
&lt;p&gt;|   10 |&lt;/p&gt;
&lt;p&gt;|    9 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; set autocommit=0;Query OK, 0 rows affected (0.00 sec)mysql&amp;gt; select i from t lock in share mode;+——+
&lt;p&gt;| i    |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;|    4 |&lt;/p&gt;
&lt;p&gt;|   10 |&lt;/p&gt;
&lt;p&gt;|    9 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; insert into t(i) values(8);等待。。。&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;另外，针对插入(INSERT)操作，只要多个事务不会在同一索引区间的同一个位置插入记录，它们就不用互相等待，这种情况可以称为插入意向间隙锁(insertion intention gap lock)。例如，索引记录的值为4和7，两个独立的事务分别插入5和6，仅管它们都持有4—7之间的间隙锁，但是它们不会相互阻塞。这可以提高事务的并发性。&lt;/p&gt;
&lt;p&gt;例1-7&lt;/p&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;Session 1&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;Session 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; select * from t;+——+| i    |+——+
&lt;p&gt;|    4 |&lt;/p&gt;
&lt;p&gt;|   10 |&lt;/p&gt;
&lt;p&gt;|    9 |&lt;/p&gt;
&lt;p&gt;|    8 |&lt;/p&gt;
&lt;p&gt;+——+&lt;/p&gt;
&lt;p&gt;4 rows in set (0.00 sec)&lt;/p&gt;
&lt;p&gt;mysql&amp;gt; create unique index i_index on t(i);&lt;/p&gt;
&lt;p&gt;Query OK, 4 rows affected (0.34 sec)&lt;/p&gt;
&lt;p&gt;Records: 4 Duplicates: 0 Warnings: 0&lt;/p&gt;
&lt;p&gt;mysql&amp;gt; set autocommit=0;&lt;/p&gt;
&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; set autocommit=0;Query OK, 0 rows affected (0.00 sec)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; insert into t(i) values(5);Query OK, 1 row affected (0.00 sec)&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;284&quot;&gt;mysql&amp;gt; insert into t(i) values(5);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionmysql&amp;gt; insert into t(i) values(6);Query OK, 1 row affected (0.00 sec)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;间隙锁是可以显示关闭的，如果你将事务的隔离级别设为READ COMMITTED，或者打开innodb_locks_unsafe_for_binlog系统变量，间隙锁就会关闭。在这种情况下，查找或扫描索引仅会进行外键约束检查和重复键值检查。&lt;/p&gt;
&lt;p&gt;此外，READ COMMITTED隔离级别和关闭nodb_locks_unsafe_for_binlog还有另外一个负作用：MySQL会释放掉不匹配Where条件的记录锁。例如，对于UPDATE语句，InnoDB只能进行“半一致性(semi_consistent)读”，所以，它会返回最新提交事务所做改变，从而产生不可重复读和幻像问题。&lt;/p&gt;
&lt;p&gt;1.3.8、使用next-key lock防止幻像问题&lt;br&gt;
例1-4展示了一个幻像问题。使用next-key锁的select语句可以解决幻像问题，但例1-4的之所以会产生总是在于唯一索引，使得select语句没有使用gap lock，而只使用了index-record lock。&lt;br&gt;
1.4、存储引擎&lt;/p&gt;
&lt;p&gt;插件式存储引擎是MySQL最重要特性之一，也是最不同于其它DBMS的地方。MySQL支持很多存储引擎，以适用于不同的应用需求，常用的包括MyISAM、InnoDB、BDB、MEMORY、MERGE、NDB Cluster等。其中，BDB和NDB Cluster提供事务支持。&lt;br&gt;
MySQL默认的存储引擎为MyISAM，当然，创建表的时候可以指定其它的存储引擎，你可以在同一个数据库中对不同的表使用不同的存储引擎(这是非常强大而独特的特性)。可以通过SHOW TABLE STATUS命令查询表所使用的存储引擎，例如，查看mysql数据库的user表：&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;568&quot;&gt;mysql&amp;gt; SHOW TABLE STATUS LIKE ‘user’ \G*************************** 1. row ***************************Name: userEngine: MyISAM
&lt;p&gt;Version: 10&lt;/p&gt;
&lt;p&gt;Row_format: Dynamic&lt;/p&gt;
&lt;p&gt;Rows: 4&lt;/p&gt;
&lt;p&gt;Avg_row_length: 61&lt;/p&gt;
&lt;p&gt;Data_length: 244&lt;/p&gt;
&lt;p&gt;Max_data_length: 281474976710655&lt;/p&gt;
&lt;p&gt;Index_length: 2048&lt;/p&gt;
&lt;p&gt;Data_free: 0&lt;/p&gt;
&lt;p&gt;Auto_increment: NULL&lt;/p&gt;
&lt;p&gt;Create_time: 2009-06-16 21:50:34&lt;/p&gt;
&lt;p&gt;Update_time: 2009-09-30 14:59:08&lt;/p&gt;
&lt;p&gt;Check_time: NULL&lt;/p&gt;
&lt;p&gt;Collation: utf8_bin&lt;/p&gt;
&lt;p&gt;Checksum: NULL&lt;/p&gt;
&lt;p&gt;Create_options:&lt;/p&gt;
&lt;p&gt;Comment: Users and global privileges&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;Name：表的名称；&lt;/li&gt;
&lt;li&gt;Engine：表使用的存储引擎；&lt;/li&gt;
&lt;li&gt;Row_format：记录的格式。MyISAM支持三种不同的存储格式：静态(固定长度)表(默认格式)、动态表及压缩表。静态表的字段都是固定长度的，例如CHAR和INTEGER；动态表的字段可以是变长的，例如，VARCHAR或者BLOB。&lt;/li&gt;
&lt;li&gt;Rows：表中记录的数量。&lt;/li&gt;
&lt;li&gt;Avg_row_length：记录的平均长度(字节数)；&lt;/li&gt;
&lt;li&gt;Data_length：表中数据的全部字节数；&lt;/li&gt;
&lt;li&gt;Max_data_length：表中数据最大的字节数；&lt;/li&gt;
&lt;li&gt;Index_length：索引消耗的磁盘空间；&lt;/li&gt;
&lt;li&gt;Data_free：对于MyISAM表，表示已经分配但还没有使用的空间；该空间包含以前删除的记录留下的空间，可以被INSERT操作重用。&lt;/li&gt;
&lt;li&gt;Auto_increment：下一个自增的值。&lt;/li&gt;
&lt;li&gt;Check_time：上次使用CHECK TABLE或myisamchk检查表的时间。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1.4.1、MyISAM&lt;/p&gt;
&lt;p&gt;1.4.1.1、存储&lt;/p&gt;
&lt;p&gt;MySQL的默认存储引擎，性能与功能的折中，包括全文索引(full-text index)、数据压缩，支持空间(GIS)数据，但是，不支持事务和行级锁。一般来说，MyISAM更适用于大量查询操作。如果你有大量的插入、删除操作，你应该选择InnoDB。&lt;br&gt;
每个表包含3个文件：&lt;/p&gt;
&lt;p&gt;(1).frm：表定义文件，对于其它存储引擎也一样。&lt;br&gt;
(2).MYD文件：数据文件。&lt;br&gt;
(3).MYI文件：索引文件。&lt;/p&gt;
&lt;p&gt;可以在创建表时通过DATA DIRECTORY和INDEX DIRECTORY为数据文件和索引文件指定路径，它们可以位于不同目录。另外，MyISAM的存储格式是跨平台的，你可以将数据文件和索引文件从Intel平台拷贝到PPC或者SPARC平台。&lt;/p&gt;
&lt;p&gt;5.0中，MyISAM的变长记录表默认处理256TB数据，使用6字节的指针来指向数据记录；而之前的版本使用默认的4字节指针，所以只能处理4GB数据。所有的版本都可以将指针增加到8字节指针，如果你想改变MyISAM表的指针的大小，可以通过设置MAX_ROWS和AVG_ROW_LENGTH来实现：&lt;/p&gt;
&lt;p&gt;CREATE TABLE mytable (&lt;br&gt;
a INTEGER NOT NULL PRIMARY KEY,&lt;br&gt;
b CHAR(18) NOT NULL&lt;br&gt;
) MAX_ROWS = 1000000000 AVG_ROW_LENGTH = 32;&lt;/p&gt;
&lt;p&gt;上面的例子中，MySQL将至少可以存储32GB的数据。可以查看一下表的信息：&lt;/p&gt;
&lt;p&gt;：&lt;/p&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;568&quot;&gt;mysql&amp;gt; SHOW TABLE STATUS LIKE ‘mytable’ \G*************************** 1. row ***************************Name: mytableEngine: MyISAM
&lt;p&gt;Row_format: Fixed&lt;/p&gt;
&lt;p&gt;Rows: 0&lt;/p&gt;
&lt;p&gt;Avg_row_length: 0&lt;/p&gt;
&lt;p&gt;Data_length: 0&lt;/p&gt;
&lt;p&gt;Max_data_length: 98784247807&lt;/p&gt;
&lt;p&gt;Index_length: 1024&lt;/p&gt;
&lt;p&gt;Data_free: 0&lt;/p&gt;
&lt;p&gt;Auto_increment: NULL&lt;/p&gt;
&lt;p&gt;Create_time: 2002-02-24 17:36:57&lt;/p&gt;
&lt;p&gt;Update_time: 2002-02-24 17:36:57&lt;/p&gt;
&lt;p&gt;Check_time: NULL&lt;/p&gt;
&lt;p&gt;Create_options: max_rows=1000000000 avg_row_length=32&lt;/p&gt;
&lt;p&gt;Comment:&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;可以看到，Create_options列出了创建时的选项，而且该表的最大的数据量为91GB。你可以用ALTER TABLE来改变指针的大小，但是那会导致表和索引的重建，这会花费很长的时间。&lt;/p&gt;
&lt;p&gt;1.4.1.2、MyISAM的特性&lt;/p&gt;
&lt;p&gt;(1)锁与并发性：MyISAM只有表级锁，不支持行级锁。所以不适合于大量的写操作，但是它支持并发插入(concurrent inserts)，这是一个非常重要且有用的特性。&lt;br&gt;
(2)自动修复：MySQL支持自动检查和修复MyISAM表。&lt;br&gt;
(3)手动修复：你可以使用CHECK TABLE检查表的状态，并用REPAIR TABLE修复表。&lt;br&gt;
(4)索引：你可以为BLOB和TEXT的前500个字符创建索引。而且，MyISAM还支持全文索引，但仅限于CHAR、VARCHAR、和TEXT列。&lt;br&gt;
(5)延迟键写(Delayed key writes)：如果创建MyISAM表时指定DELAY_KEY_WRITE，MySQL在查询结束时，不会将改变的索引数据写入磁盘，而将修改保存在key buffer中。只有要改变缓存或者关闭表时，才会把索引数据刷入磁盘。&lt;/p&gt;
&lt;p&gt;1.4.2、InnoDB&lt;/p&gt;
&lt;p&gt;InnoDB是一个高性能的事务存储引擎，此外，BDB也支持事务处理(关于BDB，以前曾较为详细的阅读过其源码，以后有时间再讨论)，它有以下一些特点：&lt;/p&gt;
&lt;p&gt;1.4.2.1、表空间&lt;br&gt;
InnoDB存储表和索引有两种方式：&lt;/p&gt;
&lt;p&gt;(1)共享表空间存储：这种方式下，表的定义位于.frm文件中，数据和索引保存在innodb_data_home_dir和innodb_data_file_path指定的表空间中。&lt;br&gt;
(2)多表空间存储：表的定义仍位于.frm文件，但是，每个InnoDB表和它的索引在它自己的文件(.idb)中，每个表有它自己的表空间。&lt;br&gt;
对那些想把特定表格移到分离物理磁盘的用户，或者那些希望快速恢复单个表的备份而无须打断其余InnoDB表的使用的用户，使用多表空间会是有益的。你可以往my.cnf的[mysqld]节添加下面行来允许多表空间：&lt;/p&gt;
&lt;p&gt;[mysqld]&lt;br&gt;
innodb_file_per_table&lt;/p&gt;
&lt;p&gt;重启服务器之后，InnoDB存储每个新创建的表到表格所属于的数据库目录下它自己的文件tbl_name.ibd里。这类似于MyISAM存储引擎所做的，但MyISAM 把表分成数据文件tbl_name.MYD和索引文件tbl_name.MYI。对于InnoDB，数据和所以被一起存到.ibd文件。tbl_name.frm文件照旧依然被创建。&lt;/p&gt;
&lt;p&gt;如果你从my.cnf文件删除innodb_file_per_table行，并重启服务器，InnoDB在共享的表空间文件里再次创建表。&lt;br&gt;
innodb_file_per_table只影响表的创建。如果你用这个选项启动服务器，新表被用.ibd文件来创建，但是你仍旧能访问在共享表空间里的表。如果你删掉这个选项，新表在共享表空间内创建，但你仍旧可以访问任何用多表空间创建的表。&lt;/p&gt;
&lt;p&gt;InnoDB总是需要共享表空间，.ibd文件对InnoDB不足以去运行，共享表空间包含熟悉的ibdata文件，InnoDB把内部数据词典和undo日志放在这个文件中。&lt;/p&gt;
&lt;p&gt;1.4.2.2、外键约束&lt;br&gt;
MySQL中，支持外键的存储引擎只有InnoDB，在创建外键时，要求被参照表必须有对应的索引，参照表在创建外键时也会自动创建对应的索引。&lt;/p&gt;
&lt;p&gt;1.4.2.3、MVCC与后码锁(next-key locking)&lt;br&gt;
InnoDB将MVCC机制与next-key lock结合起来，实现事务的各个隔离级别，这是非常用意思的。在nodb_locks_unsafe_for_binlog变量被设置或者事务的隔离级别不是SERIALIZABLE的情况下，InnoDB对于没有指定FOR UPDATE 或 LOCK IN SHARE MODE的INSERT INTO … SELECT, UPDATE … (SELECT), 和CREATE TABLE … SELECT语句使用一致性读(参照前面)，在这种情况下，查询语句不会对表中的元组加锁。否则，InnoDB将使用锁。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主要参考：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;《MySQL Manual》&lt;/p&gt;
&lt;p&gt;《High Performance MySQL》&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87121&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87121votetotal&quot;&gt;1&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87121&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt;  评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Mon, 25 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-25-87121-32418e1ba.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-25-87121-32418e1ba.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>由浅入深探究 MySQL索引结构原理、性能分析与优化</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;p&gt;&lt;strong&gt;第一部分：基础知识：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;索引&lt;/p&gt;
&lt;p&gt;官方介绍索引是帮助MySQL高效获取数据的数据结构。笔者理解索引相当于一本书的目录，通过目录就知道要的资料在哪里，不用一页一页查阅找出需要的资料。关键字index&lt;/p&gt;
&lt;p&gt;————————————————————-&lt;/p&gt;
&lt;p&gt;唯一索引&lt;/p&gt;
&lt;p&gt;强调唯一，就是索引值必须唯一，关键字unique index&lt;/p&gt;
&lt;p&gt;创建索引：&lt;/p&gt;
&lt;p&gt;1、create unique index 索引名 on 表名(列名);&lt;/p&gt;
&lt;p&gt;2、alter table 表名 add unique index 索引名 (列名);&lt;/p&gt;
&lt;p&gt;删除索引：&lt;/p&gt;
&lt;p&gt;1、 drop index 索引名 on 表名;&lt;/p&gt;
&lt;p&gt;2、 alter table 表名 drop index 索引名;&lt;/p&gt;
&lt;p&gt;————————————————————-&lt;/p&gt;
&lt;p&gt;主键&lt;/p&gt;
&lt;p&gt;主键就是唯一索引的一种，主键要求建表时指定，一般用auto_increatment列，关键字是primary key&lt;/p&gt;
&lt;p&gt;主键创建：&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;creat table test2 (id int not null primary key auto_increment);&lt;/pre&gt;
&lt;p&gt;————————————————————-&lt;/p&gt;
&lt;p&gt;全文索引&lt;/p&gt;
&lt;p&gt;InnoDB不支持，Myisam支持性能比较好，一般在 CHAR、VARCHAR 或 TEXT 列上创建。&lt;/p&gt;
&lt;p&gt;Create table 表名( id int not null primary anto_increment,title&lt;/p&gt;
&lt;p&gt;varchar(100),FULLTEXT(title))type=myisam&lt;/p&gt;
&lt;p&gt;——————————&lt;/p&gt;
&lt;p&gt;单列索引与多列索引&lt;/p&gt;
&lt;p&gt;索引可以是单列索引也可以是多列索引(也叫复合索引)。按照上面形式创建出来的索引是单列索引，现在先看看创建多列索引：&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;create table test3 (id int not null primary key auto_increment,uname char
(8) not null default &#39;&#39;,password char(12) not null,INDEX(uname,password))type
=myisam;&lt;/pre&gt;
&lt;p&gt;注意：INDEX(a, b, c)可以当做a或(a, b)的索引来使用，但和b、c或(b,c)的索引来使用这是一个最左前缀的优化方法，在后面会有详细的介绍，你只要知道有这样两个概念&lt;/p&gt;
&lt;p&gt;————————————————————-&lt;/p&gt;
&lt;p&gt;聚集索引&lt;/p&gt;
&lt;p&gt;一种索引，该索引中键值的逻辑顺序决定了表中相应行的物理顺序。聚集索引确定表中数据的物理顺序。Mysql中myisam表是没有聚集索引的，innodb有(主键就是聚集索引)，聚集索引在下面介绍innodb结构的时有详细介绍。&lt;/p&gt;
&lt;p&gt;————————————————————-&lt;/p&gt;
&lt;p&gt;查看表的索引&lt;/p&gt;
&lt;p&gt;通过命令：Show index from 表名&lt;/p&gt;
&lt;p&gt;如：&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; show index from test3;
+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+----+
| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part |
Packed | Null | Index_type | Comment |
+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+----+
| test3 | 0 | PRIMARY | 1 | id | A | 0 | NULL |
NULL | | BTREE | |
+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+&lt;/pre&gt;
&lt;p&gt;Table：表名&lt;/p&gt;
&lt;p&gt;Key_name：什么类型索引(这了是主键)&lt;/p&gt;
&lt;p&gt;Column_name：索引列的字段名&lt;/p&gt;
&lt;p&gt;Cardinality：索引基数，很关键的一个参数，平均数值组=索引基数/表总数据行，平均数值组越接近1就越有可能利用索引&lt;/p&gt;
&lt;p&gt;Index_type：如果索引是全文索引，则是fulltext,这里是b+tree索引，b+tre也是这篇文章研究的重点之一&lt;/p&gt;
&lt;p&gt;其他的就不详细介绍，更多：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二部分：MYISAM和INNODB索引结构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1、 简单介绍B-tree B+ tree树&lt;/p&gt;
&lt;p&gt;B-tree结构视图&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/166d622e9c2fb7e5de13647356cfa551.jpg&quot; width=&quot;549&quot; height=&quot;236&quot;&gt;&lt;/p&gt;
&lt;p&gt;一棵m阶的B-tree树，则有以下性质&lt;/p&gt;
&lt;p&gt;(1)Ki表示关键字值，上图中，k1&amp;lt;k2&amp;lt;…&amp;lt;ki&amp;lt;k0&amp;lt;Kn(可以看出，一个节点的左子节点关键字值&amp;lt;该关键字值&amp;lt;右子节点关键字值)&lt;/p&gt;
&lt;p&gt;(2)Pi表示指向子节点的指针，左指针指向左子节点，右指针指向右子节点。即是：p1[指向值]&amp;lt;k1&amp;lt;p2[指向值]&amp;lt;k2……&lt;/p&gt;
&lt;p&gt;(3)所有关键字必须唯一值(这也是创建myisam 和innodb表必须要主键的原因)，每个节点包含一个说明该节点多少个关键字，如上图第二行的i和n&lt;/p&gt;
&lt;p&gt;(4)节点：&lt;/p&gt;
&lt;p&gt;l 每个节点最可以有m个子节点。&lt;/p&gt;
&lt;p&gt;l 根节点若非叶子节点，至少2个子节点，最多m个子节点&lt;/p&gt;
&lt;p&gt;l 每个非根，非叶子节点至少[m/2]子节点或叫子树([]表示向上取整)，最多m个子节点&lt;/p&gt;
&lt;p&gt;(5)关键字：&lt;/p&gt;
&lt;p&gt;l 根节点的关键字个数1~m-1&lt;/p&gt;
&lt;p&gt;l 非根非叶子节点的关键字个数[m/2]-1~m-1,如m=3，则该类节点关键字个数：2-1~2&lt;/p&gt;
&lt;p&gt;(6)关键字数k和指向子节点个数指针p的关系：&lt;/p&gt;
&lt;p&gt;l k+1=p ，注意根据储存数据的具体需求，左右指针为空时要有标志位表示没有&lt;/p&gt;
&lt;p&gt;B+tree结构示意图如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/f6f063dd532cdde50086697c234cc8f1.jpg&quot; width=&quot;549&quot; height=&quot;236&quot;&gt;&lt;/p&gt;
&lt;p&gt;B+树是B-树的变体，也是一种多路搜索树：&lt;/p&gt;
&lt;p&gt;l 非叶子结点的子树指针与关键字个数相同&lt;/p&gt;
&lt;p&gt;l 为所有叶子结点增加一个链指针(红点标志的箭头)&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;B+树是B-树的变体，也是一种多路搜索树：&lt;/p&gt;
&lt;p&gt;l 非叶子结点的子树指针与关键字个数相同&lt;/p&gt;
&lt;p&gt;l 为所有叶子结点增加一个链指针(红点标志的箭头)&lt;/p&gt;
&lt;p&gt;2、 MyisAM索引结构&lt;/p&gt;
&lt;p&gt;MyisAM索引用的B+tree来储存数据，MyisAM索引的指针指向的是键值的地址，地址存储的是数据，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/3020dd0a64902dd137130d60070e6d1c.jpg&quot; width=&quot;538&quot; height=&quot;450&quot;&gt;&lt;/p&gt;
&lt;p&gt;(1)结构讲解：上图3阶树，主键是Col2，Col值就是改行数据保存的物理地址，其中红色部分是说明标注。&lt;/p&gt;
&lt;p&gt;l 1标注部分也许会迷惑，前面不是说关键字15右指针的指向键值要大于15，怎么下面还有15关键字？因为B+tree的所以叶子节点包含所有关键字且是按照升序排列(主键索引唯一，辅助索引可以不唯一)，所以等于关键字的数据值在右子树&lt;/p&gt;
&lt;p&gt;l 2标注是相应关键字存储对应数据的物理地址，注意这也是之后和InnoDB索引不同的地方之一&lt;/p&gt;
&lt;p&gt;l 2标注也是一个所说MyiAM表的索引和数据是分离的，索引保存在”表名.MYI”文件内，而数据保存在“表名.MYD”文件内，2标注的物理地址就是“表名.MYD”文件内相应数据的物理地址。(InnoDB表的索引文件和数据文件在一起)&lt;/p&gt;
&lt;p&gt;l 辅助索引和主键索引没什么大的区别，辅助索引的索引值是可以重复的(但InnoDB辅助索引和主键索引有很明显的区别，这里先提醒注意一下)&lt;/p&gt;
&lt;p&gt;3、 Annode索引结构&lt;/p&gt;
&lt;p&gt;(1)首先有一个表，内容和主键索引结构如下两图：&lt;/p&gt;
&lt;p&gt;Col1  Col2  Col3&lt;/p&gt;
&lt;p&gt;1  15  phpben&lt;/p&gt;
&lt;p&gt;2  20  mhycoe&lt;/p&gt;
&lt;p&gt;3  23  phpyu&lt;/p&gt;
&lt;p&gt;4  25  bearpa&lt;/p&gt;
&lt;p&gt;5  40  phpgoo&lt;/p&gt;
&lt;p&gt;6  45  phphao&lt;/p&gt;
&lt;p&gt;7  48  phpxue&lt;/p&gt;
&lt;p&gt;……&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/b6a84fb9032a176a91ca80735f0c6a69.jpg&quot; width=&quot;576&quot; height=&quot;346&quot;&gt;&lt;/p&gt;
&lt;p&gt;结构上：由上图可以看出InnoDB的索引结构很MyisAM的有很明显的区别&lt;/p&gt;
&lt;p&gt;l MyisAM表的索引和数据是分开的，用指针指向数据的物理地址，而InnoDB表中索引和数据是储存在一起。看红框1可一看出一行数据都保存了。&lt;/p&gt;
&lt;p&gt;l 还有一个上图多了三行的隐藏数据列(虚线表)，这是因为MyisAM不支持事务，InnoDB处理事务在性能上并发控制上比较好，看图中的红框2中的DB_TRX_ID是事务ID，自动增长；db_roll_ptr是回滚指针，用于事务出错时数据回滚恢复；db_row_id是记录行号，这个值其实在主键索引中就是主键值，这里标出重复是为了容易介绍，还有的是若不是主键索引(辅助索引)，db_row_id会找表中unique的列作为值，若没有unique列则系统自动创建一个。关于InnoDB跟多事务MVCC点此：http://www.phpben.com/?post=72&lt;/p&gt;
&lt;p&gt;(2)加入上表中Col1是主键(下图标错)，而Col2是辅助索引，则相应的辅助索引结构图：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/f04c749384f56dddb89106aedd5e502d.jpg&quot; width=&quot;576&quot; height=&quot;265&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;可以看出InnoDB辅助索引并没有保存相应的所有列数据，而是保存了主键的键值(图中1、2、3….)这样做利弊也是很明显：&lt;/p&gt;
&lt;p&gt;l 在已有主键索引，避免数据冗余，同时在修改数据的时候只需修改辅助索引值。&lt;/p&gt;
&lt;p&gt;l 但辅助索引查找数据事要检索两次，先找到相应的主键索引值然后在去检索主键索引找到对应的数据。这也是网上很多mysql性能优化时提到的“主键尽可能简短”的原因，主键越长辅助索引也就越大，当然主键索引也越大。&lt;/p&gt;
&lt;p&gt;4、 MyisAM索引与InnoDB索引相比较&lt;/p&gt;
&lt;p&gt;l MyisAM支持全文索引(FULLTEXT)、压缩索引，InnoDB不支持&lt;/p&gt;
&lt;p&gt;l AnnoDB支持事务，MyisAM不支持&lt;/p&gt;
&lt;p&gt;l MyisAM顺序储存数据，索引叶子节点保存对应数据行地址，辅助索引很主键索引相差无几；AnnoDB主键节点同时保存数据行，其他辅助索引保存的是主键索引的值&lt;/p&gt;
&lt;p&gt;l MyisAM键值分离，索引载入内存(key_buffer_size),数据缓存依赖操作系统；InnoDB键值一起保存，索引与数据一起载入InnoDB缓冲池&lt;/p&gt;
&lt;p&gt;l MyisAM主键(唯一)索引按升序来存储存储，InnoDB则不一定&lt;/p&gt;
&lt;p&gt;l MyisAM索引的基数值(Cardinality，show index 命令可以看见)是精确的，InnoDB则是估计值。这里涉及到信息统计的知识，MyisAM统计信息是保存磁盘中，在alter表或Analyze table操作更新此信息，而InnoDB则是在表第一次打开的时候估计值保存在缓存区内&lt;/p&gt;
&lt;p&gt;l MyisAM处理字符串索引时用增量保存的方式，如第一个索引是‘preform’，第二个是‘preformence’，则第二个保存是‘7，ance‘，这个明显的好处是缩短索引，但是缺陷就是不支持倒序提取索引，必须顺序遍历获取索引&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第三部分：MYSQL优化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;mysql优化是一个重大课题之一，这里会重点详细的介绍mysql优化，包括表数据类型选择，sql语句优化，系统配置与维护优化三类。&lt;/p&gt;
&lt;p&gt;1、 表数据类型选择&lt;/p&gt;
&lt;p&gt;(1)能小就用小。表数据类型第一个原则是：使用能正确的表示和存储数据的最短类型。这样可以减少对磁盘空间、内存、cpu缓存的使用。&lt;/p&gt;
&lt;p&gt;(2)避免用NULL，这个也是网上优化技术博文传的最多的一个。理由是额外增加字节，还有使索引，索引统计和值更复杂。很多还忽略一&lt;/p&gt;
&lt;p&gt;个count(列)的问题，count(列)是不会统计列值为null的行数。更多关于NULL可参考：http://www.phpben.com/?post=71&lt;/p&gt;
&lt;p&gt;(3)字符串如何选择char和varchar？一般phper能想到就是char是固定大小，varchar能动态储存数据。这里整理一下这两者的区别：&lt;/p&gt;
&lt;p&gt;属性  Char  Varchar&lt;/p&gt;
&lt;p&gt;值域大小  最长字符数是255(不是字节)，不管什么编码，超过此值则自动截取255个字符保存并没有报错。  65535个字节，开始两位存储长度，超过255个字符，用2位储存长度，否则1位，具体字符长度根据编码来确定，如utf8，&lt;span style=&quot;color: #333333;font-style: normal&quot;&gt;则字符最长是21845个&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;如何处理字符串末尾空格  去掉末尾空格，取值出来比较的时候自动加上进行比较  Version&amp;lt;=4.1，字符串末尾空格被删掉，version&amp;gt;5.0则保留&lt;/p&gt;
&lt;p&gt;储存空间  固定空间，比喻char(10)不管字符串是否有10个字符都分配10个字符的空间  Varchar内节约空间，但更新可能发生变化，若varchar(10),开始若储存5个字符，当update成7个时有myisam可能把行拆开，innodb可能分页，这样开销就增大&lt;/p&gt;
&lt;p&gt;适用场合    适用于存储很短或固定或长度相似字符，如MD5加密的密码char(33)、昵称char(8)等    当最大长度远大于平均长度并且发生更新的时候。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;注意当一些英文或数据的时候，最好用每个字符用字节少的类型，如latin1&lt;/p&gt;
&lt;p&gt;(4)整型、整形优先原则&lt;/p&gt;
&lt;p&gt;Tinyint、smallint、mediumint、int、bigint，分别需要8、16、24、32、64。&lt;/p&gt;
&lt;p&gt;值域范围：-2^(n-1)~ 2^(n-1)-1&lt;/p&gt;
&lt;p&gt;很多程序员在设计数据表的时候很习惯的用int，压根不考虑这个问题&lt;/p&gt;
&lt;p&gt;笔者建议：能用tinyint的绝不用smallint&lt;/p&gt;
&lt;p&gt;误区：int(1) 和int(11)是一样的，唯一区别是mysql客户端显示的时候显示多少位。&lt;/p&gt;
&lt;p&gt;整形优先原则：能用整形的不用其他类型替换，如ip可以转换成整形保存，如商品价格‘50.00元’则保存成50&lt;/p&gt;
&lt;p&gt;(5)精确度与空间的转换。在存储相同数值范围的数据时，浮点数类型通常都会比DECIMAL类型使用更少的空间。FLOAT字段使用4字节存储&lt;/p&gt;
&lt;p&gt;数据。DOUBLE类型需要8 个字节并拥有更高的精确度和更大的数值范围，DECIMAL类型的数据将会转换成DOUBLE类型。&lt;/p&gt;
&lt;p&gt;2、 sql语句优化&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; create table one (
id smallint(10) not null auto_increment primary key,
username char(8) not null,
password char(4) not null,
`level` tinyint (1) default 0,
last_login char(15) not null,
index(username,password,last_login))engine=innodb;&lt;/pre&gt;
&lt;p&gt;这是test表，其中id是主键，多列索引(username,password,last_login),里面有10000多条数据.&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null |
Index_type | Comment |
+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+
| one | 0 | PRIMARY | 1 | id | A |20242 | NULL | NULL | |
BTREE | |
+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+
| one | 1 | username | 1 | username | A |10121 | NULL | NULL | |
BTREE | |
+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+
| one | 1 | username | 2 | password | A |10121 | NULL | NULL | YES |
BTREE | |
+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+
| one | 1 | username | 3 | last_login | A |20242 | NULL | NULL | |
BTREE | |
+-------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+&lt;/pre&gt;
&lt;p&gt;(1) 最左前缀原则&lt;/p&gt;
&lt;p&gt;定义：最左前缀原则指的的是在sql where 字句中一些条件或表达式中出现的列的顺序要保持和多索引的一致或以多列索引顺序出现，只要出现非顺序出现、断层都无法利用到多列索引。&lt;/p&gt;
&lt;p&gt;举例说明：上面给出一个多列索引(username,password,last_login)，当三列在where中出现的顺序如(username,password,last_login)、(username,password)、(username)才能用到索引，如下面几个顺序(password,last_login)、(passwrod)、(last_login)—这三者不从username开始，(username,last_login)—断层，少了password，都无法利用到索引。&lt;/p&gt;
&lt;p&gt;因为B+tree多列索引保存的顺序是按照索引创建的顺序，检索索引时按照此顺序检索&lt;/p&gt;
&lt;p&gt;测试：以下测试不精确，这里只是说明如何才能正确按照最左前缀原则使用索引。还有的是以下的测试用的时间0.00sec看不出什么时间区别，因为数据量只有20003条，加上没有在实体机上运行，很多未可预知的影响因素都没考虑进去。当在大数据量，高并发的时候，最左前缀原则对与提高性能方面是不可否认的。&lt;/p&gt;
&lt;p&gt;Ps：最左前缀原则中where字句有or出现还是会遍历全表&lt;/p&gt;
&lt;p&gt;(1.1)能正确的利用索引&lt;/p&gt;
&lt;p&gt;l Where子句表达式顺序是(username)&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; explain select * from one where username=&#39;abgvwfnt&#39;;
+----+-------------+-------+------+---------------+----------+---------+-------+------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref |rows | Extra |
+----+-------------+-------+------+---------------+----------+---------+-------+------+-------------+
| 1 | SIMPLE | one | ref | username | username | 24 | const |5 | Using where |
+----+-------------+-------+------+---------------+----------+---------+-------+------+-------------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;l Where子句表达式顺序是(username,password)&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; explain select * from one where username=&#39;abgvwfnt&#39; and password=&#39;123456&#39;;
+----+-------------+-------+------+---------------+----------+---------+-------------+------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |
+----+-------------+-------+------+---------------+----------+---------+-------------+------+-------------+
| 1 | SIMPLE | one | ref | username | username | 43 | const,const | 1 | Using where |
+----+-------------+-------+------+---------------+----------+---------+-------------+------+-------------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;l Where子句表达式顺序是(username,password, last_login)&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; explain select * from one where username=&#39;abgvwfnt&#39; and password=&#39;123456&#39;and last_login=&#39;1338251170&#39;;
+----+-------------+-------+------+---------------+----------+---------+-------------------+------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref| rows | Extra |
+----+-------------+-------+------+---------------+----------+---------+-------------------+------+-------------+
| 1 | SIMPLE | one | ref | username | username | 83 | const,const,const | 1 | Using where |
+----+-------------+-------+------+---------------+----------+---------+-------------------+------+-------------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;上面可以看出type=ref 是多列索引，key_len分别是24、43、83，这说明用到的索引分别是(username), (username,password), (username,password, last_login );row分别是5、1、1检索的数据行都很少，因为这三个查询都按照索引前缀原则，可以利用到索引。&lt;/p&gt;
&lt;p&gt;(1.2)不能正确的利用索引&lt;/p&gt;
&lt;p&gt;l Where子句表达式顺序是(password, last_login)&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; explain select * from one where password=&#39;123456&#39;and last_login=&#39;1338251170&#39;;
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows| Extra |
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
| 1 | SIMPLE | one | ALL | NULL | NULL | NULL | NULL | 20146 | Using where |
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;l Where 子句表达式顺序是(last_login)&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; explain select * from one where last_login=&#39;1338252525&#39;;
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows| Extra |
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
| 1 | SIMPLE | one | ALL | NULL | NULL | NULL | NULL | 20146 | Using where |
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;以上的两条语句都不是以username开始，这样是用不了索引，通过type=all(全表扫描)，key_len=null，rows都很大20146&lt;/p&gt;
&lt;p&gt;Ps：one表里只有20003条数据，为什么出现20146，这是优化器对表的一个估算值，不精确的。&lt;/p&gt;
&lt;p&gt;l Where 子句表达式虽然顺序是(username,password, last_login)或(username,password)但第一个是有范围’&amp;lt;’、’&amp;gt;’，’&amp;lt;=’，’&amp;gt;=’等出现&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; explain select * from one where username&amp;gt;&#39;abgvwfnt&#39; and password =&#39;123456&#39;and last_login=&#39;1338251170&#39;;
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows| Extra |
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
| 1 | SIMPLE | one | ALL | username | NULL | NULL | NULL | 20146 | Using where |
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;这个查询很明显是遍历所有表，一个索引都没用到，非第一列出现范围(password列或last_login列)，则能利用索引到首先出现范围的一列，也就是“where username=’abgvwfnt’ and password &amp;gt;’123456′and last_login=’1338251170′;”或则“where username=’abgvwfnt’ and password &amp;gt;’123456′and last_login&amp;lt;’1338251170′;”索引长度ref_len=43,索引检索到password列，所以考虑多列索引的时候把那些查询语句用的比较的列放在最后(或非第一位)。&lt;/p&gt;
&lt;p&gt;l 断层，即是where顺序(username, last_login)&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; explain select * from one where username=&#39;abgvwfnt&#39; and last_login=&#39;1338252525&#39;;
+----+-------------+-------+------+---------------+----------+---------+-------+------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |
+----+-------------+-------+------+---------------+----------+---------+-------+------+-------------+
| 1 | SIMPLE | one | ref | username | username | 24 | const |5 | Using where |
+----+-------------+-------+------+---------------+----------+---------+-------+------+-------------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;注意这里的key_len=24=8*3(8是username的长度，3是utf8编码)，rows=5，和下面一条sql语句搜索出来一样&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; select * from one where username=&#39;abgvwfnt&#39;;
+-------+----------+----------+-------+------------+
| id | username | password | level | last_login |
+-------+----------+----------+-------+------------+
| 3597 | abgvwfnt | 234567 | 0 | 1338251420 |
| 7693 | abgvwfnt | 456789 | 0 | 1338251717 |
| 11789 | abgvwfnt | 456789 | 0 | 1338251992 |
| 15885 | abgvwfnt | 456789 | 0 | 1338252258 |
| 19981 | abgvwfnt | 456789 | 0 | 1338252525 |
+-------+----------+----------+-------+------------+
5 rows in set (0.00 sec)

mysql&amp;gt; select * from one where username=&#39;abgvwfnt&#39; and last_login=&#39;1338252525&#39;;
+-------+----------+----------+-------+------------+
| id | username | password | level | last_login |
+-------+----------+----------+-------+------------+
| 19981 | abgvwfnt | 456789 | 0 | 1338252525 |
+-------+----------+----------+-------+------------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;这个就是要的返回结果，所以可以知道断层(username,last_login)，这样只用到username索引，把用到索引的数据再重新检查last_login条件，这个相对全表查询来说还是有性能上优化，这也是很多sql优化文章中提到的where 范围查询要放在最后(这不绝对，但可以利用一部分索引)&lt;/p&gt;
&lt;p&gt;(1.3)如果一个查询where子句中确实不需要password列，那就用“补洞”。&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; select distinct(password) from one;
+----------+
| password |
+----------+
| 234567 |
| 345678 |
| 456789 |
| 123456 |
+----------+
4 rows in set (0.08 sec)&lt;/pre&gt;
&lt;p&gt;可以看出password列中只有这几个值，当然在现实中不可能密码有这么多一样的，再说数据也可能不断更新，这里只是举例说明补洞的方法&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; explain select * from one where username=&#39;abgvwfnt&#39; and password in(&#39;123456&#39;,&#39;234567&#39;,&#39;345678&#39;,&#39;456789&#39;)
and last_login=&#39;1338251170&#39;;
+----+-------------+-------+-------+---------------+----------+---------+------+------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |
+----+-------------+-------+-------+---------------+----------+---------+------+------+-------------+
| 1 | SIMPLE | one | range | username | username| 83 | NULL |4 | Using where |
+----+-------------+-------+-------+---------------+----------+---------+------+------+-------------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;可以看出ref=83 所有的索引都用到了，type=range是因为用了in子句。&lt;/p&gt;
&lt;p&gt;这个被“补洞”列中的值应该是有限的，可预知的，如性别，其值只有男和女(加多一个不男不女也无妨)。&lt;/p&gt;
&lt;p&gt;“补洞”方法也有瓶颈，当很多列，且需要补洞的相应列(可以多列)的值虽有限但很多(如中国城市)的时候，优化器在优化时组合起来的数量是很大，这样的话就要做好基准测试和性能分析，权衡得失，取得一个合理的优化方法。&lt;/p&gt;
&lt;p&gt;(1.4)like&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; explain select * from one where username like &#39;abgvwfnt%&#39;;
+----+-------------+-------+-------+---------------+----------+---------+------+------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref |
rows | Extra |
+----+-------------+-------+-------+---------------+----------+---------+------+------+-------------+
| 1 | SIMPLE | one | range | username | username | 24 | NULL |
5 | Using where |
+----+-------------+-------+-------+---------------+----------+---------+------+------+-------------+
1 row in set (0.00 sec)
mysql&amp;gt; explain select * from one where username like &#39;%abgvwfnt%&#39;;
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows| Extra |
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
| 1 | SIMPLE | one | ALL | NULL | NULL | NULL | NULL | 20259 | Using where |
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
1 row in set (0.01 sec)&lt;/pre&gt;
&lt;p&gt;对比就知道like操作abgvwfnt%能用到索引，%abgvwfnt%用不到&lt;/p&gt;
&lt;p&gt;———————————————————————————————&lt;/p&gt;
&lt;p&gt;(2) Order by 优化&lt;/p&gt;
&lt;p&gt;(2.1)filesort优化算法.&lt;/p&gt;
&lt;p&gt;在mysql version()&amp;lt;4.1之前，优化器采用的是filesort第一种优化算法，先提取键值和指针，排序后再去提取数据，前后要搜索数据两次，第一次若能使用索引则使用，第二次是随机读(当然不同引擎也不同)。mysql version()&amp;gt;=4.1,更新了一个新算法，就是在第一次读的时候也把selcet的列也读出来，然后在sort_buffer_size中排序(不够大则建临时表保存排序顺序)，这算法只需要一次读取数据。所以有这个广为人传的一个优化方法，那就是增大sort_buffer_size。Filesort第二种算法要用到更的空间，sort_buffer_size不够大反而会影响速度，所以mysql开发团队定了个变量max_length_for_sort_data，当算法中读出来的需要列的数据的大小超过该变量的值才使用，所以一般性能分析的时候会尝试把max_length_for_sort_data改小。&lt;/p&gt;
&lt;p&gt;(2.2)单独order by 用不了索引，索引考虑加where 或加limit&lt;/p&gt;
&lt;p&gt;先建一个索引(last_login),建的过程就不给出了&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; explain select * from one order by last_login desc;
+----+-------------+-------+------+---------------+------+---------+------+-------+----------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows
| Extra |
+----+-------------+-------+------+---------------+------+---------+------+-------+----------------+
| 1 | SIMPLE | one | ALL | NULL | NULL | NULL | NULL | 2046
3 | Using filesort |
+----+-------------+-------+------+---------------+------+---------+------+-------+----------------+
1 row in set (0.00 sec)

mysql&amp;gt; explain select * from one order by last_login desc limit 10;
+----+-------------+-------+-------+---------------+------------+---------+------+------+-------+
| id | select_type | table | type | possible_keys | key | key_len | ref
| rows | Extra |
+----+-------------+-------+-------+---------------+------------+---------+------+------+-------+
| 1 | SIMPLE | one | index | NULL | last_login | 4 | NULL
| 10 | |
+----+-------------+-------+-------+---------------+------------+---------+------+------+-------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;开始没limit查询是遍历表的，加了limit后，索引可以使用，看key_len 和key&lt;/p&gt;
&lt;p&gt;(2.3)where + orerby 类型，where满足最左前缀原则，且orderby的列和where子句用到的索引的列的子集。即是(a,b,c)索引，where满足最左前缀原则且order by中列a、b、c的任意组合&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; explain select * from one where username=&#39;abgvwfnt&#39; and password =&#39;123456
&#39; and last_login=&#39;1338251001&#39; order by password desc,last_login desc;

+----+-------------+-------+------+---------------+----------+---------+-------------------+------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref

| rows | Extra |
+----+-------------+-------+------+---------------+----------+---------+-------------------+------+-------------+
| 1 | SIMPLE | one | ref | username | username | 83 | const,c
onst,const | 1 | Using where |
+----+-------------+-------+------+---------------+----------+---------+-------------------+------+-------------+
1 row in set (0.00 sec)

mysql&amp;gt; explain select * from one where username=&#39;abgvwfnt&#39; and password =&#39;123456
&#39; and last_login=&#39;1338251001&#39; order by password desc,level desc;
+----+-------------+-------+------+---------------+----------+---------+-------------------+------+----------------------------+
| id | select_type | table | type | possible_keys | key | key_len | ref| rows | Extra |
+----+-------------+-------+------+---------------+----------+---------+-------------------+------+-----------------------------+
| 1 | SIMPLE | one | ref | username | username | 83 | const,c
onst,const | 1 | Using where; Using filesort |
+----+-------------+-------+------+---------------+----------+---------+-------------------+------+-----------------------------+

1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;上面两条语句明显的区别是多了一个非索引列level的排序，在extra这列对了Using filesort&lt;/p&gt;
&lt;p&gt;笔者测试结果：where满足最左前缀且order by中的列是该多列索引的子集时(也就是说orerby中没最左前缀原则限制)，不管是否有asc ,desc混合出现，都能用索引来满足order by。&lt;/p&gt;
&lt;p&gt;笔者测试过，因为篇幅比较大，这里就不一一列出。&lt;/p&gt;
&lt;p&gt;Ps:很优化博文都说order by中的列要where中出现的列(是索引)的顺序一致，笔者认为不够严谨。&lt;/p&gt;
&lt;p&gt;(2.3) where + orerby+limit&lt;/p&gt;
&lt;p&gt;这个其实也差不多，只要where最左前缀，orderby也正确，limit在此影响不大&lt;/p&gt;
&lt;p&gt;(2.4)如何考虑order by来建索引&lt;/p&gt;
&lt;p&gt;这个回归到创建索引的问题来，在比较常用的oder by的列和where中常用的列建立多列索引，这样优化起来的广度和扩张性都比较好，当然如果要考虑UNION、JOIN、COUNT、IN等进来就复杂很多了&lt;/p&gt;
&lt;p&gt;(3) 隔离列&lt;/p&gt;
&lt;p&gt;隔离列是只查询语句中把索引列隔离出来，也就是说不能在语句中把列包含进表达式中，如id+1=2、inet_aton(’210.38.196.138′)—ip转换成整数、convert(123,char(3))—数字转换成字符串、date函数等mysql内置的大多函数。&lt;/p&gt;
&lt;p&gt;非隔离列影响性能很大甚至是致命的，这也就是赶集网石展的《三十六军规》中的一条，虽然他没说明是隔离列。&lt;/p&gt;
&lt;p&gt;以下就测试一下：&lt;/p&gt;
&lt;p&gt;首先建立一个索引(last_login )，这里就不给出建立的代码了，且把last_login改成整型(这里只是为了方便测试，并不是影响条件)&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; explain select * from one where last_login = 8388605;
+----+-------------+-------+------+---------------+------------+---------+-------+-------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |
+----+-------------+-------+------+---------------+------------+---------+-------+-------+-------------+
| 1 | SIMPLE | one | ref | last_login | last_login | 3 | const
| 1 | Using where |
+----+-------------+-------+------+---------------+------------+---------+-------+-------+-------------+
1 row in set, 1 warning (0.00 sec)
容易看出建的索引已起效
mysql&amp;gt; explain select * from one where last_login +1= 8388606 ;
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows
| Extra |
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
| 1 | SIMPLE | one | ALL | NULL | NULL | NULL | NULL | 2049
7 | Using where |
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;last_login +1=8388608非隔离列的出现导致查找的列20197，说明是遍历整张表且索引不能使用。&lt;/p&gt;
&lt;p&gt;这是因为这条语句要找出所有last_login的数据，然后+1再和20197比较，优化器在这方面比较差，性能很差。&lt;/p&gt;
&lt;p&gt;所以要尽可能的把列隔离出来，如last_login +1=8388606改成login_login=8388607,或者把计算、转换等操作先用php函数处理过再传递给mysql服务器&lt;/p&gt;
&lt;p&gt;(4) OR、IN、UNION ALL，可以尝试用UNION ALL&lt;/p&gt;
&lt;p&gt;(4.1)or会遍历表就算有索引&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; explain select * from one where username = &#39;abgvwfnt&#39; or password=&#39;123456&#39;;
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
| id | select_type | table | type | possible_keys | key | key_len | ref | rows| Extra |
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
| 1 | SIMPLE | one | ALL | username | NULL | NULL | NULL | 20259 | Using where |
+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+
1 row in set (0.00 sec)&lt;/pre&gt;
&lt;p&gt;(4.2)对于in，这个是有争议的，网上很多优化方案中都提到尽量少用in，这不全面，其实在in里面如果是常量的话，可一大胆的用in，这个也是赶集网石展、阿里hellodab的观点(笔者从微博中获知)。应用hellodab一句话“MySQL用IN效率不好，通常是指in中嵌套一个子查询，因为MySQL的查询重写可能会产生一个不好的执行计划，而如果in里面是常量的话，我认为性能没有任何问题，可以放心使用”———当然对于这个比较的话，没有实战数据的话很难辩解，就算有，影响性能的因素也很多，也许会每个dba都有不同的测试结果.这也签名最左前缀中“补洞”一个方法&lt;/p&gt;
&lt;p&gt;(4.3)UNION All 直接返回并集，可以避免去重的开销。之所说“尝试”用UNION All 替代 OR来优化sql语句，因为这不是一直能优化的了，这里只是作为一个方法去尝试。&lt;/p&gt;
&lt;p&gt;(5) 索引选择性&lt;/p&gt;
&lt;p&gt;索引选择性是不重复的索引值也叫基数(cardinality)表中数据行数的比值，索引选择性=基数/数据行，基数可以通过“show index from 表名”查看。&lt;/p&gt;
&lt;p&gt;高索引选择性的好处就是mysql查找匹配的时候可以过滤更多的行，唯一索引的选择性最佳，值为1。&lt;/p&gt;
&lt;p&gt;那么对于非唯一索引或者说要被创建索引的列的数据内容很长，那就要选择索引前缀。这里就简单说明一下：&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql&amp;gt; select count(distinct(username))/count(*) from one;
+------------------------------------+
| count(distinct(username))/count(*) |
+------------------------------------+
| 0.2047 |
+------------------------------------+
1 row in set (0.09 sec)&lt;/pre&gt;
&lt;p&gt;count(distinct(username))/count(*)就是索引选择性的值，这里0.2太小了。&lt;/p&gt;
&lt;p&gt;假如username列数据很长，则可以通过&lt;/p&gt;
&lt;p&gt;select count(distinct(concat(first_name, left(last_name, N))/count(*) from one;测试出接近1的索引选择性，其中N是索引的长度，穷举法去找出N的值，然后再建索引。&lt;/p&gt;
&lt;p&gt;(6) 重复或多余索引&lt;/p&gt;
&lt;p&gt;很多phper开始都以为建索引相对多点性能就好点，压根没考虑到有些索引是重复的，比如建一个(username),(username,password), (username,password,last_login),很明显第一个索引是重复的，因为后两者都能满足其功能。&lt;/p&gt;
&lt;p&gt;要有个意识就是，在满足功能需求的情况下建最少索引。对于INNODB引擎的索引来说，每次修改数据都要把主键索引，辅助索引中相应索引值修改，这可能会出现大量数据迁移，分页，以及碎片的出现。&lt;/p&gt;
&lt;p&gt;3、系统配置与维护优化&lt;/p&gt;
&lt;p&gt;(1) 重要的一些变量&lt;/p&gt;
&lt;p&gt;l key_buffer_size索引块缓存区大小, 针对MyISAM存储引擎,该值越大,性能越好.但是超过操作系统能承受的最大值,反而会使mysql变得不稳定. —-这是很重要的参数&lt;/p&gt;
&lt;p&gt;l sort_buffer_size 这是索引在排序缓冲区大小，若排序数据大小超过该值，则创建临时文件，注意和myisam_sort_buffer_size的区别—-这是很重要的参数&lt;/p&gt;
&lt;p&gt;l read_rnd_buffer_size当排序后按排序后的顺序读取行时，则通过该缓冲区读取行，避免搜索硬盘。将该变量设置为较大的值可以大大改进ORDER BY的性能。但是，这是为每个客户端分配的缓冲区，因此你不应将全局变量设置为较大的值。相反，只为需要运行大查询的客户端更改会话变量&lt;/p&gt;
&lt;p&gt;l join_buffer_size用于表间关联(join)的缓存大小&lt;/p&gt;
&lt;p&gt;l tmp_table_size缓存表的大小&lt;/p&gt;
&lt;p&gt;l table_cache允许 MySQL 打开的表的最大个数，并且这些都cache在内存中&lt;/p&gt;
&lt;p&gt;l delay_key_write针对MyISAM存储引擎,延迟更新索引.意思是说,update记录时,先将数据up到磁盘,但不up索引,将索引存在内存里,当表关闭时,将内存索引,写到磁盘&lt;/p&gt;
&lt;p&gt;更多参数查看http://www.phpben.com/?post=70&lt;/p&gt;
&lt;p&gt;(2) optimize、Analyze、check、repair维护操作&lt;/p&gt;
&lt;p&gt;l optimize 数据在插入，更新，删除的时候难免一些数据迁移，分页，之后就出现一些碎片，久而久之碎片积累起来影响性能，这就需要DBA定期的优化数据库减少碎片，这就通过optimize命令。&lt;/p&gt;
&lt;p&gt;如对MyisAM表操作：optimize table 表名&lt;/p&gt;
&lt;p&gt;对于InnoDB表是不支持optimize操作，否则提示“Table does not support optimize, doing recreate + analyze instead”，当然也可以通过命令：alter table one type=innodb; 来替代。&lt;/p&gt;
&lt;p&gt;l Analyze 用来分析和存储表的关键字的分布，使得系统获得准确的统计信息，影响 SQL 的执行计划的生成。对于数据基本没有发生变化的表，是不需要经常进行表分析的。但是如果表的数据量变化很明显，用户感觉实际的执行计划和预期的执行计划不 同的时候，执行一次表分析可能有助于产生预期的执行计划。&lt;/p&gt;
&lt;p&gt;Analyze table 表名&lt;/p&gt;
&lt;p&gt;l Check检查表或者视图是否存在错误，对 MyISAM 和 InnoDB 存储引擎的表有作用。对于 MyISAM 存储引擎的表进行表检查，也会同时更新关键字统计数据&lt;/p&gt;
&lt;p&gt;l Repair optimize需要有足够的硬盘空间，否则可能会破坏表，导致不能操作，那就要用上repair，注意INNODB不支持repair操作&lt;/p&gt;
&lt;p&gt;以上的操作出现的都是如下这是check&lt;/p&gt;
&lt;p&gt;+———-+——-+————–+————-+&lt;/p&gt;
&lt;p&gt;| Table | Op | Msg_type| Msg_text |&lt;/p&gt;
&lt;p&gt;+———-+——-+————–+————-+&lt;/p&gt;
&lt;p&gt;| test.one | check | status | OK |&lt;/p&gt;
&lt;p&gt;+———-+——-+————–+————-+&lt;/p&gt;
&lt;p&gt;其中op是option 可以是repair check optimize，msg_type 表示信息类型，msg_text 表示信息类型，这里就说明表的状态正常。如在innodb表使用repair就出现note | The storage engine for the table doesn’t support repair&lt;/p&gt;
&lt;p&gt;注意：以上操作最好在数据库访问量最低的时候操作，因为涉及到很多表锁定，扫描，数据迁移等操作，否则可能导致一些功能无法正常使用甚至数据库崩溃。&lt;/p&gt;
&lt;p&gt;(3)表结构的更新与维护&lt;/p&gt;
&lt;p&gt;l 改表结构。当要在数据量千万级的数据表中使用alter更改表结构的时候，这是一个棘手问题。一种方法是在低并发低访问量的时候用平常的alter更改表。另外一种就是建另一个与要修改的表，这个表除了要修改的结构属性外其他的和原表一模一样，这样就能得到一个相应的.frm文件，然后用flush with read lock 锁定读，然后覆盖用新建的.frm文件覆盖原表的.frm，最后unlock table 释放表。&lt;/p&gt;
&lt;p&gt;l 建立新的索引。一般方法这里不说。&lt;/p&gt;
&lt;p&gt;1、 创建没索引的a表，导入数据形成.MYD文件。&lt;/p&gt;
&lt;p&gt;2、 创建包括索引b表，形成.FRM和.MYI文件&lt;/p&gt;
&lt;p&gt;3、 锁定读写&lt;/p&gt;
&lt;p&gt;4、 把b表的.FRM和.MYI文件改成a表名字&lt;/p&gt;
&lt;p&gt;5、 解锁&lt;/p&gt;
&lt;p&gt;6、 用repair创建索引。&lt;/p&gt;
&lt;p&gt;这个方法对于大表也是很有效的。这也是为什么很多dba坚持说“先导数据库在建索引，这样效率更快”&lt;/p&gt;
&lt;p&gt;l 定期检查mysql服务器&lt;/p&gt;
&lt;p&gt;定期使用show status、show processlist等命令检查数据库。这里就不细说，这说起来也篇幅是比较大的，笔者对这个也不是很了解&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第四部分：图说mysql查询执行流程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/102f0110cceb6a5d704ee61175e039e5.jpg&quot; width=&quot;690&quot; height=&quot;616&quot;&gt;&lt;/p&gt;
&lt;p&gt;1、 查询缓存，判断sql语句是否完全匹配，再判断是否有权限，两个判断为假则到解析器解析语句，为真则提取数据结果返回给用户。&lt;/p&gt;
&lt;p&gt;2、 解析器解析。解析器先词法分析，语法分析，检查错误比如引号有没闭合等，然后生成解析树。&lt;/p&gt;
&lt;p&gt;3、 预处理。预处理解决解析器无法决解的语义，如检查表和列是否存在，别名是否有错，生成新的解析树。&lt;/p&gt;
&lt;p&gt;4、 优化器做大量的优化操作。&lt;/p&gt;
&lt;p&gt;5、 生成执行计划。&lt;/p&gt;
&lt;p&gt;6、 查询执行引擎，负责调度引擎获取相应数据&lt;/p&gt;
&lt;p&gt;7、 返回结果。&lt;/p&gt;
&lt;p&gt;参考：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/hustcat/archive/2009/10/28/1591648.html&quot; rel=&quot;nofollow&quot;&gt;http://www.cnblogs.com/hustcat/archive/2009/10/28/1591648.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.cnblogs.com/oldhorse/archive/2009/11/16/1604009.html&quot; rel=&quot;nofollow&quot;&gt;http://www.cnblogs.com/oldhorse/archive/2009/11/16/1604009.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/zuiaituantuan/article/details/5909334&quot; rel=&quot;nofollow&quot;&gt;http://blog.csdn.net/zuiaituantuan/article/details/5909334&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.codinglabs.org/html/theory-of-mysql-index.html&quot; rel=&quot;nofollow&quot;&gt;http://www.codinglabs.org/html/theory-of-mysql-index.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://isky000.com/database/mysql_order_by_implement&quot; rel=&quot;nofollow&quot;&gt;http://isky000.com/database/mysql_order_by_implement&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://dev.mysql.com/doc/refman/5.0/en/server-system-variables.html&quot; rel=&quot;nofollow&quot;&gt;http://dev.mysql.com/doc/refman/5.0/en/server-system-variables.html&lt;/a&gt;&lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87107&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87107votetotal&quot;&gt;1&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87107&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt;  评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Mon, 25 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-25-87107-fe468f89c.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-25-87107-fe468f89c.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>如何安全地存储密码？</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;h3&gt;使用 bcrypt&lt;/h3&gt;
&lt;p&gt;用 &lt;a href=&quot;http://www.usenix.org/events/usenix99/provos.html&quot;&gt;bcrypt&lt;/a&gt;、用 &lt;a href=&quot;http://www.usenix.org/events/usenix99/provos.html&quot;&gt;bcrypt&lt;/a&gt;、用 &lt;a href=&quot;http://www.usenix.org/events/usenix99/provos.html&quot;&gt;bcrypt&lt;/a&gt;、用 &lt;a href=&quot;http://www.usenix.org/events/usenix99/provos.html&quot;&gt;bcrypt&lt;/a&gt;、用&lt;a href=&quot;http://www.usenix.org/events/usenix99/provos.html&quot;&gt; &lt;/a&gt;&lt;a href=&quot;http://www.usenix.org/events/usenix99/provos.html&quot;&gt;bcrypt&lt;/a&gt;、用 &lt;a href=&quot;http://www.usenix.org/events/usenix99/provos.html&quot;&gt;bcrypt&lt;/a&gt;、用 &lt;a href=&quot;http://www.usenix.org/events/usenix99/provos.html&quot;&gt;bcrypt&lt;/a&gt;、用 &lt;a href=&quot;http://www.usenix.org/events/usenix99/provos.html&quot;&gt;bcrypt&lt;/a&gt;、用 &lt;a href=&quot;http://www.usenix.org/events/usenix99/provos.html&quot;&gt;bcrypt&lt;/a&gt; （重要的话就是要多多地重复几次）……&lt;/p&gt;
&lt;h3&gt;为什么不用 {MD5、 SHA1、 SHA256、 SHA512、 SHA-3 等加密算法}?&lt;/h3&gt;
&lt;p&gt;这些都是&lt;em&gt;通用&lt;/em&gt;的hash函数，设计的初衷是为了尽可能快的计算大量数据的摘要。这意味着它们在保证数据完整性方面非常优秀但是对于存储密码则十分糟糕。&lt;/p&gt;
&lt;p&gt;现代的服务器计算 MD5 的哈希值速度大概是&lt;a href=&quot;http://www.cryptopp.com/benchmarks-amd64.html&quot;&gt;每秒330MB&lt;/a&gt;。如果你的用户密码满足小写、数字字母混合、6个字符长这几个条件，你就可以在&lt;strong&gt;40秒内&lt;/strong&gt;&lt;em&gt;穷举&lt;/em&gt;出该密码。&lt;/p&gt;
&lt;p&gt;完全不需要其他的投入。&lt;/p&gt;
&lt;p&gt;如果你愿意花费2000美元和一到两周的时间来挑选一块支持 &lt;a href=&quot;http://www.nvidia.com/object/cuda_home.html&quot;&gt;CUDA&lt;/a&gt; 的显卡，那你可以搭建一个小型的、&lt;a href=&quot;http://www.win.tue.nl/cccc/sha-1-challenge.html&quot;&gt;每秒计算700,000,000个密码&lt;/a&gt;的超级计算机集群。估计你可以以&lt;strong&gt;每秒10%&lt;/strong&gt;的速度来破解那些密码。&lt;/p&gt;
&lt;h3&gt;加盐也救不了你&lt;/h3&gt;
&lt;p&gt;注意了，非常重要的一点：&lt;strong&gt;hash加盐对于字典攻击和暴力破解无效。&lt;/strong&gt;你可以用粗盐，或许多的盐，甚至是人工开采，阴凉的，有机的喜马拉雅粉晶盐。但这都无法影响到攻击者破解你密码的速度。&lt;/p&gt;
&lt;p&gt;加盐与否，只要你用了为速度而设计的通用哈希函数，你就会受到影响。&lt;/p&gt;
&lt;h3&gt;bcrypt 解决了这些问题&lt;/h3&gt;
&lt;p&gt;怎么做呢？从根本上说，是因为它的（计算速度可以）慢到令人发指。它由 Blowfish 加密算法演变而来，并引入了&lt;em&gt;功系数（work factor)&lt;/em&gt;，以便让你能决定该哈希函数的计算强度。基于以上原因，bcrypt 可以紧随摩尔定律的脚步。计算机发展更快，你也可以增加功系数来让哈希更难计算。&lt;/p&gt;
&lt;p&gt;比起 MD5，bcrypt 的计算强度能达到多大呢？这就要看功系数了。把功系数设为12情况下，在我的电脑上用 bcrypt 哈希 yaaa 这个密码大概要0.3秒。另一方面，用MD5 来处理要少于1微秒。&lt;/p&gt;
&lt;p&gt;你的密码可能不需要那么高的安全级别，而需要更快的运算速度。幸好，bcrypt允许你在速度和安全之间进行平衡。&lt;/p&gt;
&lt;h3&gt;长话短说&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;用bcrypt.&lt;/strong&gt;&lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87058&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87058votetotal&quot;&gt;1&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87058&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt; 1 评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;

&lt;div id=&quot;author-bio&quot;&gt;
	
	&lt;h3 class=&quot;widget-title&quot;&gt;
	关于作者：&lt;a target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/lxtalx&quot;&gt;zer0Black&lt;/a&gt;
	&lt;/h3&gt;
	&lt;div class=&quot;alignleft&quot;&gt;
		&lt;a target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/lxtalx&quot;&gt;
			&lt;img src=&quot;/images/jobbole.com/acc7de4f3e21ddea3affb662f132911f.jpg&quot;&gt;
		&lt;/a&gt;
	&lt;/div&gt;

    &lt;div class=&quot;author-bio-info&quot;&gt;

        &lt;span class=&quot;author-bio-info-block&quot;&gt;
            关注信息安全，网络安全，目前为移动开发工程师，android和IOS兼有涉猎。半路出道，基础薄弱，正努力补习计算机基础中。近日习得“遍历”学...        &lt;/span&gt;
        &lt;span class=&quot;author-bio-info-block&quot;&gt;
            &lt;a href=&quot;http://www.jobbole.com/members/lxtalx&quot; target=&quot;_blank&quot;&gt;&lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt; 个人主页&lt;/a&gt; ·
            &lt;a href=&quot;http://blog.jobbole.com/author/lxtalx/&quot; target=&quot;_blank&quot;&gt;&lt;i class=&quot;fa fa-file-text-o&quot;&gt;&lt;/i&gt; 我的文章&lt;/a&gt; ·
            &lt;a title=&quot;声望值&quot; target=&quot;_blank&quot; href=&quot;http://www.jobbole.com/members/lxtalx/reputation/&quot;&gt;&lt;i class=&quot;fa fa-graduation-cap&quot;&gt;&lt;/i&gt; 10&lt;/a&gt;        &lt;/span&gt;
    &lt;/div&gt;
	&lt;div class=&quot;clear&quot;&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Mon, 25 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-25-87058-e4ffd9ea5.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-25-87058-e4ffd9ea5.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>探索C#之微型MapReduce</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;p&gt;MapReduce近几年比较热的分布式计算编程模型，以C#为例简单介绍下MapReduce分布式计算。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;阅读目录&lt;/strong&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;背景&lt;/li&gt;
&lt;li&gt;Map实现&lt;/li&gt;
&lt;li&gt;Reduce实现&lt;/li&gt;
&lt;li&gt;支持分布式&lt;/li&gt;
&lt;li&gt;总结&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;背景&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;某平行世界程序猿小张接到Boss一项任务，统计用户反馈内容中的单词出现次数，以便分析用户主要习惯。文本如下：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;const string hamlet = @&quot;Though yet of Hamlet our dear brother&#39;s death
The memory be green, and that it us befitted
To bear our hearts in grief and our whole kingdom
To be contracted in one brow of woe,
Yet so far hath discretion fought with nature
That we with wisest sorrow think on him,
Together with remembrance of ourselves.
Therefore our sometime sister, now our queen,
The imperial jointress to this warlike state,
Have we, as &#39;twere with a defeated joy,--
With an auspicious and a dropping eye,
With mirth in funeral and with dirge in marriage,
In equal scale weighing delight and dole,--
Taken to wife: nor have we herein barr&#39;d
Your better wisdoms, which have freely gone
With this affair along. For all, our thanks.
Now follows, that you know, young Fortinbras,
Holding a weak supposal of our worth,
Or thinking by our late dear brother&#39;s death
Our state to be disjoint and out of frame,
Colleagued with the dream of his advantage,
He hath not fail&#39;d to pester us with message,
Importing the surrender of those lands
Lost by his father, with all bonds of law,
To our most valiant brother. So much for him.
Now for ourself and for this time of meeting:
Thus much the business is: we have here writ
To Norway, uncle of young Fortinbras,--
Who, impotent and bed-rid, scarcely hears
Of this his nephew&#39;s purpose,--to suppress
His further gait herein; in that the levies,
The lists and full proportions, are all made
Out of his subject: and we here dispatch
You, good Cornelius, and you, Voltimand,
For bearers of this greeting to old Norway;
Giving to you no further personal power
To business with the king, more than the scope
Of these delated articles allow.
Farewell, and let your haste commend your duty.&quot;;&lt;/pre&gt;
&lt;p&gt;小张作为蓝翔高材生，很快就实现了：&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;var content = hamlet.Split(new[] { &quot; &quot;, Environment.NewLine }, StringSplitOptions.RemoveEmptyEntries);
            var wordcount=new Dictionary&amp;lt;string,int&amp;gt;();
            foreach (var item in content)
            {
                if (wordcount.ContainsKey(item))
                    wordcount[item] += 1;
                else
                    wordcount.Add(item, 1);
            }&lt;/pre&gt;
&lt;p&gt;作为有上进心的青年，小张决心对算法进行抽象封装，并支持多节点计算。小张把这个统计次数程序分成两个大步骤：分解和计算。&lt;br&gt;
第一步：先把文本以某维度分解映射成最小独立单元。 (段落、单词、字母维度)。&lt;br&gt;
第二部：把最小单元重复的做合并计算。&lt;br&gt;
小张参考MapReduce论文设计Map、Reduce如下：&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Map实现&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Mapping&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Mapping函数把文本分解映射key，value形式的最小单元，即&amp;lt;单词，出现次数(1)&amp;gt;、&amp;lt;word,1&amp;gt;。&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public IEnumerable&amp;lt;Tuple&amp;lt;T, int&amp;gt;&amp;gt; Mapping(IEnumerable&amp;lt;T&amp;gt; list)
        {
            foreach (T sourceVal in list)
                yield return Tuple.Create(sourceVal, 1);
        }&lt;/pre&gt;
&lt;p&gt;使用，输出为(brow, 1), (brow, 1), (sorrow, 1), (sorrow, 1):&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt; var spit = hamlet.Split(new[] { &quot; &quot;, Environment.NewLine }, StringSplitOptions.RemoveEmptyEntries);
            var mp = new MicroMapReduce&amp;lt;string&amp;gt;(new Master&amp;lt;string&amp;gt;());
            var result= mp.Mapping(spit);&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Combine&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了减少数据通信开销，mapping出的键值对数据在进入真正的reduce前，进行重复键合并。也相对于提前进行预计算一部分，加快总体计算速度。 输出格式为(brow, 2), (sorrow, 2):&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public Dictionary&amp;lt;T, int&amp;gt; Combine(IEnumerable&amp;lt;Tuple&amp;lt;T, int&amp;gt;&amp;gt; list)
        {
            Dictionary&amp;lt;T, int&amp;gt; dt = new Dictionary&amp;lt;T, int&amp;gt;();
            foreach (var val in list)
            {
                if (dt.ContainsKey(val.Item1))
                    dt[val.Item1] += val.Item2;
                else
                    dt.Add(val.Item1, val.Item2);
            }
            return dt;
        }&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Partitioner&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Partitioner主要用来分组划分,把不同节点的统计数据按照key进行分组。&lt;br&gt;
其输出格式为： (brow, {(brow,2)},(brow,3)), (sorrow, {(sorrow,10)},(brow,11)):&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public IEnumerable&amp;lt;Group&amp;lt;T, int&amp;gt;&amp;gt; Partitioner(Dictionary&amp;lt;T, int&amp;gt; list)
        {
            var dict = new Dictionary&amp;lt;T, Group&amp;lt;T, int&amp;gt;&amp;gt;();
            foreach (var val in list)
            {
                if (!dict.ContainsKey(val.Key))
                    dict[val.Key] = new Group&amp;lt;T, int&amp;gt;(val.Key);
                dict[val.Key].Values.Add(val.Value);
            }
            return dict.Values;
        }&lt;/pre&gt;
&lt;p&gt;Group定义:&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public class Group&amp;lt;TKey, TValue&amp;gt; : Tuple&amp;lt;TKey, List&amp;lt;TValue&amp;gt;&amp;gt;
    {
        public Group(TKey key)
            : base(key, new List&amp;lt;TValue&amp;gt;())
        {
        }

        public TKey Key
        {
            get
            {
                return base.Item1;
            }
        }

        public List&amp;lt;TValue&amp;gt; Values
        {
            get
            {
                return base.Item2;
            }
        }
    }&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Reduce实现&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Reducing函数接收，分组后的数据进行最后的统计计算。&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public Dictionary&amp;lt;T, int&amp;gt; Reducing(IEnumerable&amp;lt;Group&amp;lt;T, int&amp;gt;&amp;gt; groups)
        {
            Dictionary&amp;lt;T, int&amp;gt; result=new Dictionary&amp;lt;T, int&amp;gt;();
            foreach (var sourceVal in groups)
            {
                result.Add(sourceVal.Key, sourceVal.Values.Sum());
            }
            return result;
        }&lt;/pre&gt;
&lt;p&gt;封装调用如下：&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public IEnumerable&amp;lt;Group&amp;lt;T, int&amp;gt;&amp;gt; Map(IEnumerable&amp;lt;T&amp;gt; list)
        {
            var step1 = Mapping(list);
            var step2 = Combine(step1);
            var step3 = Partitioner(step2);
            return step3;
        }

  public Dictionary&amp;lt;T, int&amp;gt; Reduce(IEnumerable&amp;lt;Group&amp;lt;T, int&amp;gt;&amp;gt; groups)
        {
            var step1 = Reducing(groups);
            return step1;
        }&lt;/pre&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public  Dictionary&amp;lt;T, int&amp;gt; MapReduce(IEnumerable&amp;lt;T&amp;gt; list)
        {
            var map = Map(list);
            var reduce = Reduce(map);
            return reduce;
        }&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/5db7b9a192ea17c8b61f6aaa233f5604.jpg&quot; width=&quot;195&quot; height=&quot;505&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;支持分布式&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;小张抽象封装后，虽然复杂度上去了。但暴露给使用者是非常清晰的接口，满足MapReduce的数据格式要求，即可使用。&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;var spit = hamlet.Split(new[] { &quot; &quot;, Environment.NewLine }, StringSplitOptions.RemoveEmptyEntries);
            var mp = new MicroMapReduce&amp;lt;string&amp;gt;(new Master&amp;lt;string&amp;gt;());
            var result1= mp.MapReduce(spit);&lt;/pre&gt;
&lt;p&gt;小张完成后脑洞大开，考虑到以后文本数据量超大。 所以fork了个分支，准备支持分布式计算，以后可以在多个服务器节点跑。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;数据分片&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据分片就是把大量数据拆成一块一块的，分散到各个节点上，方便我们的mapReduce程序去计算。 分片主流的有mod、consistent hashing、vitual Buckets、Range Partition等方式。 关于consistent hashing上篇有介绍(探索c#之一致性Hash详解)。在Hadoop中Hdfs和mapreduce是相互关联配合的，一个存储和一个计算。如果自行实现的话还需要个统一的存储。所以这里的数据源可以是数据库也可以是文件。小张只是满足boss需求，通用计算框架的话可以直接用现成的。&lt;/p&gt;
&lt;p&gt;模拟分片&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public List&amp;lt;IEnumerable&amp;lt;T&amp;gt;&amp;gt; Partition(IEnumerable&amp;lt;T&amp;gt; list)
        {
            var temp =new List&amp;lt;IEnumerable&amp;lt;T&amp;gt;&amp;gt;();
            temp.Add(list);
            temp.Add(list);
            return temp;
        }&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Worker节点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;小张定义了Master，worker角色。 master负责汇集输出，即我们的主程序。 每一个worker我们用一个线程来模拟，最后输出到master汇总，master最后可以写到数据库或其他。&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public void WorkerNode(IEnumerable&amp;lt;T&amp;gt; list)
        {
            new Thread(() =&amp;gt;
            {
                var map = Map(list);
                var reduce = Reduce(map);
                master.Merge(reduce);
            }).Start();
        }&lt;/pre&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public class Master&amp;lt;T&amp;gt;
    {
        public Dictionary&amp;lt;T, int&amp;gt; Result = new Dictionary&amp;lt;T, int&amp;gt;();
        public  void Merge(Dictionary&amp;lt;T, int&amp;gt; list)
        {
            foreach (var item in list)
            {
                lock (this)
                {
                    if (Result.ContainsKey(item.Key))
                        Result[item.Key] += item.Value;
                    else
                        Result.Add(item.Key, item.Value);
                }
            }
        }
    }&lt;/pre&gt;
&lt;p&gt;分布式计算步骤图：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/d6d4afb5f02ea24af4ce6304d06a32d1.jpg&quot; width=&quot;563&quot; height=&quot;512&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;MapReduce模型从性能速度来说并不是非常好的，它优势在于隐藏了分布式计算的细节、容灾错误、负载均衡及良好的编程API，包含HDFS、Hive等在内一整套大数据处理的生态框架体系。在数据量级不是很大的话，企业自行实现一套轻量级分布式计算会有很多优点，比如性能更好、可定制化、数据库也不需要导入导出。从成本上也节省不少，因为hadoop开发、运维、服务器都需要不少人力物力。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://files.cnblogs.com/files/mushroom/mapReduce.zip&quot; target=&quot;_blank&quot;&gt;文中例子代码&lt;/a&gt;&lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87088&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87088votetotal&quot;&gt;&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87088&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt;  评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Sun, 24 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-24-87088-03076fa0f.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-24-87088-03076fa0f.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server自动化运维系列：关于数据收集</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;ul&gt;
&lt;li&gt;《&lt;a title=&quot;SQL Server自动化运维系列：监控性能指标脚本&quot; href=&quot;http://blog.jobbole.com/85631/&quot; target=&quot;_blank&quot;&gt;SQL Server自动化运维系列：监控性能指标脚本&lt;/a&gt;》&lt;/li&gt;
&lt;li&gt;《&lt;a title=&quot;SQL Server自动化运维系列：监控磁盘剩余空间及SQL Server错误日志&quot; href=&quot;http://blog.jobbole.com/85637/&quot; target=&quot;_blank&quot;&gt;SQL Server自动化运维系列：监控磁盘剩余空间及SQL Server错误日志&lt;/a&gt;》&lt;/li&gt;
&lt;li&gt;《&lt;a title=&quot;SQL Server自动化运维系列：关于邮件通知那点事&quot; href=&quot;http://blog.jobbole.com/87077/&quot; target=&quot;_blank&quot;&gt;SQL Server自动化运维系列：关于邮件通知那点事&lt;/a&gt;》&lt;/li&gt;
&lt;li&gt;《&lt;a title=&quot;SQL Server自动化运维系列：监控跑批Job运行状态&quot; href=&quot;http://blog.jobbole.com/87080/&quot; target=&quot;_blank&quot;&gt;SQL Server自动化运维系列：监控跑批Job运行状态&lt;/a&gt;》&lt;/li&gt;
&lt;li&gt;《&lt;a title=&quot;SQL Server自动化运维系列：关于数据收集&quot; href=&quot;http://blog.jobbole.com/87084/&quot; target=&quot;_blank&quot;&gt;SQL Server自动化运维系列：关于数据收集&lt;/a&gt;》&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;需求描述&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在生产环境中，很多情况下需要采集数据，用以定位问题或者形成基线。&lt;/p&gt;
&lt;p&gt;关于SQL Server中的数据采集有着很多种的解决思路，可以采用Trace、Profile、SQLdiag、扩展事件等诸多方案。&lt;/p&gt;
&lt;p&gt;几种方案各有利弊，其中从SQL Server2012版本开始，微软的开始各种整合这些采集方案，力推扩展事件。&lt;/p&gt;
&lt;p&gt;对于上述的数据采集只是一种实现手段，对于采集完数据的存储没有统一的规范，并且对于多服务器的数据采集及汇总没形成统一的规范。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本篇实现&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1、通过SQL Server自带的数据采集器实现多服务器的性能采集&lt;/p&gt;
&lt;p&gt;2、利用SQL Server数据采集数据仓库（DW）形成运维报表&lt;/p&gt;
&lt;p&gt;3、通过灵活性的配置方式，实现不同服务器不同采集点的数据收集&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&amp;lt;1&amp;gt;基础配置&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;以前，有个同事说SQL Server的自动化运维太弱了，并且定位问题也比较麻烦，需要记住各种系统的DMV….各种日志查找….你看看人家MySQL强大的图形化界面提示，让你一眼就能发现当前数据库所存在的问题。&lt;/p&gt;
&lt;p&gt;的确，来看看MySQL所提供的图形化的运维界面&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/809ea5d80a232935554818654eeb66eb.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;是他娘的帅气，把整体的平台给划分的很详细：网络、实例状态、存储状态。&lt;/p&gt;
&lt;p&gt;而且还有看上去很优雅的图形化展示界面。&lt;/p&gt;
&lt;p&gt;上述界面所反映的内容，对于问题的查找是相当便利的，在SQL SERVER中就找不到同样的模块。如果有经验的DBA会通过任务管理器、性能监视器、然后配合系统自带个一些个DMV…进行分析….看上去复杂并且很高深的样子。&lt;/p&gt;
&lt;p&gt;其实，在SQL SERVER中，也有类似的功能模块，并且更灵活的实现多台服务器共同采集，下面，我们来看一下详细的使用和配置流程。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5c298df2e694798633813f0d81c386c8.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;在数据收集上，右键选择“配置管理数据仓库”&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/400fdcc5ab996cb46aeb27d40537ce98.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;SQL SERVER为了能够支撑多台服务器的数据采集任务，鉴于数据量的庞大和用于数据分析的重要性，所以自己创建了一个用于数据分析的数据仓库（DW）&lt;/p&gt;
&lt;p&gt;这里选择好实例，创建好数据仓库就可以。&lt;/p&gt;
&lt;p&gt;提示：为了避免影响生产系统的性能，一般这里建议采用另外一台空闲的实例，专门用于数据采集和性能分析。&lt;/p&gt;
&lt;p&gt;我这里演示，就采用本地的实例进行配置，然后下一步：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a8c6571228c7c15c509b597569d77de9.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;到这一步是管理数据仓库的用户权限，可以配置用户权限，三种权限级别：管理员、可读、可写；&lt;/p&gt;
&lt;p&gt;很简单，配置完成直接下一步，然后就完成了该数据采集的数据仓库的搭建。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&amp;lt;2&amp;gt;基础配置&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这一步就是设置数据收集了，简单点讲就是要配置收集的数据项有哪些。&lt;/p&gt;
&lt;p&gt;同样是，数据采集上右键，然后选择“设置数据采集”&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b8a013d77bbe2c29d504f93f259fcb62.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后，下一步就是连接数据仓库，选择缓存目录&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8cf3a720933ac7c67ce73ab6e3243cc0.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后，下一步就可以完成，这里SQL SERVER同样的内置了一套数据搜集的模板，会为你收集全部的基本信息，当然，也可以自定义，文章后面介绍。&lt;/p&gt;
&lt;p&gt;来看默认的数据采集的收集项&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/03f1ccf0221abb9b321d32cb8a472113.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;自带的默认模板中，分为了查询统计信息，其实这个就对应的实例状态、磁盘存储、服务器活动，除了这下还赠送了一个实用工具信息，这个是用来灵活配置其它几个收集项的。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a8c9a21207ac11c080ae7c71adaba176.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以随时的根据个人喜好启动、停止数据收集动作，酌情采用。&lt;/p&gt;
&lt;p&gt;并且，也可以自己配置收集动作的时间间隔或者状态值。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/040a2ee68c5de05ac0ea0c572b287116.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;并且，SQL Server贴心的给内置了一下计划模板，基本涵盖了所有的应用场景。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5a569cf6c9693a6defdd063bd2f7d59c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后，你就放心的让它自己去采集就可以了。不爽的时候随时停止就可以。&lt;/p&gt;
&lt;p&gt;剩下来的事就是查看采集数据了，鉴于MYSQL提供了如此精美的图像化展现方式，SQL SERVER同样也有。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9a89fda630429478279a353090551eb7.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;就是它了&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/7b18a0c8340a109383f6af39cc77ae18.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;看上去是不是也有那么点意思了，包括：CPU、内存、磁盘IO、网络…&lt;/p&gt;
&lt;p&gt;并且顺带着SQL server等待、SQL语句执行情况等&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/2de3321857fae631e91b3c2c2f032743.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后，针对性能调优的一些语句，也给出了排序包括CPU、运行时间、IO总数、物理读取、逻辑读取等&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/604bf2cdefa83f6d2c8e94255c2cabcb.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;当然，我本地的机器本身采集量就很少，并且运行的T-SQL语句就不多，所以图表工具显示的很空旷。&lt;/p&gt;
&lt;p&gt;来看看磁盘存储的&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/231bf79fe23271710338fedc7acf2eb4.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上述内容大体就这些，自己用的时候再行挖掘吧，本篇提供思路。&lt;/p&gt;
&lt;p&gt;如果经验老道的DBA，我估计上述语句通过系统的DMV都可以查看的到，但是那仅限于有经验的，上述方案为小白降低了维护数据库的成本。&lt;/p&gt;
&lt;p&gt;并且可以在多台服务器中进行采集，集中处理问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在本篇介绍利用SQL Server自带的数据收集工具进行数据库运维。关于自定义的数据收集项设置，后一篇介绍吧。&lt;/p&gt;
&lt;p&gt;另外关于数据收集的DW有很多很有用的内容，如果对于大型的平台性能运维，可以借此扩展，形成自己的运维平台。&lt;/p&gt;
&lt;p&gt;关于SQL Server自动化运维和检测的内容很广泛，其中很多都是从日常的经验中出发，一步步的从手动到自动的过程。&lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87084&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87084votetotal&quot;&gt;&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87084&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt;  评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Sun, 24 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-24-87084-2d393ddb0.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-24-87084-2d393ddb0.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server自动化运维系列：监控跑批Job运行状态</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;ul&gt;
&lt;li&gt;《&lt;a title=&quot;SQL Server自动化运维系列：监控性能指标脚本&quot; href=&quot;http://blog.jobbole.com/85631/&quot; target=&quot;_blank&quot;&gt;SQL Server自动化运维系列：监控性能指标脚本&lt;/a&gt;》&lt;/li&gt;
&lt;li&gt;《&lt;a title=&quot;SQL Server自动化运维系列：监控磁盘剩余空间及SQL Server错误日志&quot; href=&quot;http://blog.jobbole.com/85637/&quot; target=&quot;_blank&quot;&gt;SQL Server自动化运维系列：监控磁盘剩余空间及SQL Server错误日志&lt;/a&gt;》&lt;/li&gt;
&lt;li&gt;《&lt;a href=&quot;http://blog.jobbole.com/87077/&quot; target=&quot;_blank&quot;&gt;SQL Server自动化运维系列：关于邮件通知那点事&lt;/a&gt;》&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;需求描述&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在我们的生产环境中，大部分情况下需要有自己的运维体制，包括自己健康状态的检测等。如果发生异常，需要提前预警的，通知形式一般为发邮件告知。&lt;/p&gt;
&lt;p&gt;在上一篇文章中已经分析了SQL SERVER中关于邮件的基础配置，本篇将利用此功能对多台Server的跑批Job进行监控。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本篇实现&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1、每天检查服务器中的SQL Server跑批Job的运行状态，如果跑批失败，则发邮件告诉管理员失败的明细&lt;/p&gt;
&lt;p&gt;2、解决多台服务器同时检查&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;监控脚本&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先我们来解决第二个问题，关于多台服务器的问题：&lt;/p&gt;
&lt;p&gt;&amp;lt;1&amp;gt;一般监控我们需要监控很多台服务器的JOb，所以对于服务器的量控制我们需要生成一个配置文件。&lt;/p&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: xml; gutter: true&quot;&gt;&amp;lt;computernames&amp;gt;
        &amp;lt;computername&amp;gt;
                wuxuelei-pc
        &amp;lt;/computername&amp;gt;
&amp;lt;/computernames&amp;gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;配置文件名字：computername.xml，这样就解决很多服务器的问题，只需要在配置文件中增加就可以，因为我在本地测试，所以就配置了我的本地电脑&lt;/p&gt;
&lt;p&gt;&amp;lt;2&amp;gt;利用Power Shell脚本，抓取出每台服务器的Job的状态，并且将Job的运行时间、运行状态、描述以及错误的步骤等信息整理，形成汇总邮件。&lt;/p&gt;
&lt;p&gt;脚本如下：&lt;/p&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;$server = &quot;(local)&quot;
$uid = &quot;sa&quot;
$db=&quot;master&quot;
$pwd=&quot;password&quot;
$mailprfname = &quot;TestMail&quot;
$recipients = &quot;787449667@qq.com&quot;
$subject = &quot;老大，快去看看这些服务器的Job跑失败了！&quot;
$computernamexml = &quot;F:\PowerShell\发送邮件\computername.xml&quot;

function GetServerName($xmlpath)
{
    $xml = [xml] (Get-Content $xmlpath)
    $return = New-Object Collections.Generic.List[string]
    for($i = 0;$i -lt $xml.computernames.ChildNodes.Count;$i++)
    {
        if ( $xml.computernames.ChildNodes.Count -eq 1)
        {
            $cp = [string]$xml.computernames.computername
        }
        else
        {
            $cp = [string]$xml.computernames.computername[$i]
        }
        $return.Add($cp.Trim())
    }
    $return
}

function GetAlterCounter($xmlpath)
{
    $xml = [xml] (Get-Content $xmlpath)
    $return = New-Object Collections.Generic.List[string]
    $list = $xml.counters.Counter
}

function CreateAlter($message)
{
    $SqlConnection = New-Object System.Data.SqlClient.SqlConnection 
    $CnnString =&quot;Server = $server; Database = $db;User Id = $uid; Password = $pwd&quot; 
    $SqlConnection.ConnectionString = $CnnString 
    $CC = $SqlConnection.CreateCommand(); 
    if (-not ($SqlConnection.State -like &quot;Open&quot;)) { $SqlConnection.Open() } 

    $cc.CommandText=
            &quot; EXEC msdb..sp_send_dbmail 
             @profile_name  = &#39;$mailprfname&#39;
            ,@recipients = &#39;$recipients&#39;
            ,@body = &#39;$message&#39;
            ,@subject = &#39;$subject&#39;
            &quot;
    $cc.ExecuteNonQuery()|out-null 
    $SqlConnection.Close();
}

$report = &quot;&quot;
$item = New-Object Collections.Generic.List[string]
$names = GetServerName($computernamexml)
foreach($cp in $names)
{
$srv=New-Object &quot;Microsoft.SqlServer.Management.Smo.Server&quot; &quot;(local)&quot;
$item=$srv.jobserver.jobs | where-object {$_.lastrunoutcome -eq &quot;Failed&quot; -and $_.isenabled -eq $TRUE} |  select OriginatingServer,name,Description,lastrunoutcome,lastrundate,JobSteps  
#Write-Host $item.JobSteps.name 
$report += &quot; 服务器：&quot;+$item.OriginatingServer+&quot;  Job名称：&quot;+$item.name+&quot;  Job描述：&quot;+$item.Description +&quot;  Job最后运行状态：&quot;+$item.lastrunoutcome  +&quot;  Job最后运行时间：&quot;+$item.lastrundate +&quot;  Job失败的步骤名称：&quot;+$item.JobSteps.name  + &quot;`n&quot;
}
#生产警告
CreateAlter $report&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;通过上述脚本，生成跑批任务，就可以定时监控多台服务器的Job了。&lt;/p&gt;
&lt;p&gt;当然，建议放在所有Job的运行完成之后，进行检测。&lt;/p&gt;
&lt;p&gt;上述代码中，有两个技术点：&lt;/p&gt;
&lt;p&gt;1、需要自己配置SQL Server邮件代理，具体方法参照我上一篇：&lt;a href=&quot;http://blog.jobbole.com/87077/&quot; target=&quot;_blank&quot;&gt;点击此&lt;/a&gt;；&lt;/p&gt;
&lt;p&gt;2、需要自己配置跑批计划，方法自己网上搜，很简单。&lt;/p&gt;
&lt;p&gt;本篇所监控的Job状态，利用的是上一篇我们创建的Job，跑批肯定失败的。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/db555429528e5cf3ec115f721ed1a2aa.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;效果图如下&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/7774a5b98b6664e616d557af7b6271c1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;点击来看一下邮件明细内容：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/67b43b8ef29818a6a852e722eb3b5761.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;给出的失败信息还是挺详细的。&lt;/p&gt;
&lt;p&gt;另外，因为我只建立了一个失败的Job，所以邮件中只是发送一个条。&lt;/p&gt;
&lt;p&gt;其实关于此监控，还有一些状态是可以监控的：&lt;/p&gt;
&lt;p&gt;1、比如：可以指定服务器上的部分Job进行监控&lt;/p&gt;
&lt;p&gt;2、监控Job的状态：失败或者正常等&lt;/p&gt;
&lt;p&gt;以上内容，可以自己根据需要灵活配置。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本篇就列举了一下利用PowerShell实现自动化运维和检测。算作抛砖引玉了吧，自己另有需求可以自己灵活实现。&lt;/p&gt;
&lt;p&gt;另外关于Job，一般除了SQL Server的Agent会存在，还有一部分是操作系统的计划任务也需要检测，我们后面的文章解决此问题。&lt;/p&gt;
&lt;p&gt;关于SQL Server自动化运维和检测的内容很广泛，其中很多都是从日常的经验中出发，一步步的从手动到自动的过程。&lt;/p&gt;
&lt;p&gt;后面的文章，我们将会更深入关于SQL Server的自动化优化运维进行分析。有兴趣的童鞋，可以提前关注。&lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87080&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87080votetotal&quot;&gt;&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87080&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt;  评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Sun, 24 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-24-87080-278f33a82.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-24-87080-278f33a82.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server自动化运维系列：关于邮件通知那点事</title>
        <description>


        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		&lt;ul&gt;
&lt;li&gt;《&lt;a title=&quot;SQL Server自动化运维系列：监控性能指标脚本&quot; href=&quot;http://blog.jobbole.com/85631/&quot; target=&quot;_blank&quot;&gt;SQL Server自动化运维系列：监控性能指标脚本&lt;/a&gt;》&lt;/li&gt;
&lt;li&gt;《&lt;a title=&quot;SQL Server自动化运维系列：监控磁盘剩余空间及SQL Server错误日志&quot; href=&quot;http://blog.jobbole.com/85637/&quot; target=&quot;_blank&quot;&gt;SQL Server自动化运维系列：监控磁盘剩余空间及SQL Server错误日志&lt;/a&gt;》&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;需求描述&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在我们的生产环境中，大部分情况下需要有自己的运维体制，包括自己健康状态的检测等。如果发生异常，需要提前预警的，通知形式一般为发邮件告知。&lt;/p&gt;
&lt;p&gt;邮件作为一种非常便利的预警实现方式，在及时性和易用性方面也有着不可替代的优点。&lt;/p&gt;
&lt;p&gt;所以，在本篇中将详细的分析下在SQL Server中的邮件通知功能及使用方式等。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本篇实现&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1、通过SQL Server自带的邮件功能实现运维的预警及检测&lt;/p&gt;
&lt;p&gt;2、利用数据库邮件组件代替传统的C#发送邮件的弊端&lt;/p&gt;
&lt;p&gt;3、实现Job任务运行状态的检测&lt;/p&gt;
&lt;p&gt;4、利用PowerShell实现Job任务计划的检测&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&amp;lt;1&amp;gt;基础配置&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先，我们来配置下SQL Server中的邮件组件的基础服务项。SQL Server自从05版本起，邮件功能就不需要开启外配配置管理器了，它有着自己的组件，实现邮件发送的功能。&lt;/p&gt;
&lt;p&gt;如果，没使用过，可以按照以下步骤进行配置，步骤很简单。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/efb28ca4c630f5a9b7fd5e16fcae84ba.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;右键，配置数据库邮件&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fef7dc0d55a7bab0c78dab11352c329b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后直接下一步就行，然后新建一个账户&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/e047ab67d6078fe3f1ef645fc1402b39.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后，下一步完成就可以，步骤很简单，这里面有几个概念需要理清楚，对于SQL Server的邮件账户是由权限控制的，目的是实现不同的人使用不同的邮件账户，比如大型数据库的管理一般有好几个DBA负责运维，分职责之后的运行，发送预警邮件也就产生了区分，总不能模块中出现了任何问题都发送给一个人。&lt;/p&gt;
&lt;p&gt;跟你一毛钱关系都没有的异常，天天给你发邮件，是不是很不爽？？….这种管理方式是灰常暴力的！&lt;/p&gt;
&lt;p&gt;为了解决上述问题，SQL Server对邮件的账户进行了分类：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3156c3c64b9bbcee1a00f2924e87bfa7.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;分为公共账户和专用账户。&lt;/p&gt;
&lt;p&gt;一般如果管理人员少，就配置一个公共账户就可以，有问题都发送到该邮箱就可以。&lt;/p&gt;
&lt;p&gt;至此，你已经完成了数据库邮件模块的配置，步骤很简单。这里可以发送一封测试邮件，来测试下邮件的连通性。&lt;/p&gt;
&lt;p&gt;提示：SQL Server邮件组件的运行需呀SQL Server Age运行执行，所以需要确保此服务正在运行。&lt;/p&gt;
&lt;p&gt;在“数据库邮件”上右键，发送测试电子邮件，输入目标邮箱的地址，然后单击发送就可以。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/e37d033a310b5715c64ce8c01833a369.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ddcb5264c5049ac8e9b4c38b73066c41.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;至此，你的SQL Server已经完成邮件组件的基础配置，然后剩下的工作就是如何利用该组件进行部分工作的完成了。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&amp;lt;2&amp;gt;c#调用数据库邮件组件进行邮件的发送&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;还记得当年刚毕业的时候，对于发送邮件这块功能当时是异常的痴迷，各种的研究和各种的调试。&lt;/p&gt;
&lt;p&gt;后来的终归在废了九牛二虎之力之后，终于在一个午夜梦回之时看到了我梦寐以求的测试邮件发送通知，想想一个字描述：草！&lt;/p&gt;
&lt;p&gt;大体我记得需要引用以下几个命名空间：&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f0cd6c7f9e7ae96feae062cb48f670f0.jpg&quot; align=&quot;top&quot;&gt;using System.Net;  using System.Net.Mail;&lt;/p&gt;
&lt;p&gt;然后利用C#提供的SmtpClient类进行组装成邮件实体，而后一个Send()方法，这其中的痛苦点在于各种编码规范等。&lt;/p&gt;
&lt;p&gt;我相信现在也有很多程序猿依然再采用着这种方式。&lt;/p&gt;
&lt;p&gt;今天提供另外一种灵活的实现方式，利用SQL Server数据库的邮件组件进行邮件的发送。&lt;/p&gt;
&lt;p&gt;关于上面第一个步骤提供的邮件组件的调用，其实在SQL Server中是提供系统自带的存储过程进行实现的。方法如下：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/907ac88b5ec4522b097af61216ccf6eb.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;该存储过程提供了发送邮件的的各种参数，完全满足发送邮件的各种需求，比如：主题、内容、附件、CC、秘密CC….等等吧&lt;/p&gt;
&lt;p&gt;调用该存储过程的方法如下：&lt;/p&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;--存储过程调用发邮件
    EXEC msdb.dbo.sp_send_dbmail
    @profile_name = &#39;testMail&#39;,
    @recipients = &#39;787449667@qq.com&#39;,
    @body = &#39;这是测试邮件&#39;,
    @subject = &#39;我发的&#39;, 
    @file_attachments=&#39;C:\temp\3-26-2015-16-20-21.png&#39;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;上面一个简单的方法执行既可以实现，邮件的发送。&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/db111cae12f9d242003d16776fee5724.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后，你需要的就是c#调用该存储过程了。&lt;/p&gt;
&lt;p&gt;关于写C#代码通过Ado.net调用存储过程的过程这里就不赘述了，我相信这是入门级别的小白也能搞定的事情了。&lt;/p&gt;
&lt;p&gt;而后，这里捎带分析一下邮件组件的原理和性能问题。我相信这是很多人关心的，其实SQL Server的邮件发送时通过一个底层的JOB轮询执行的，所以根本不用担心其执行顺序和性能问题。&lt;/p&gt;
&lt;p&gt;并且SQL Server为此还提供了几个系统的视图来查看历史运行状态和当前邮件的队列状态：&lt;/p&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;--邮件内容
SELECT * FROM msdb.dbo.sysmail_allitems&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/32ef60f68b10e88019a33b89835f4943.jpg&quot;&gt;&lt;/p&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;--邮件发送日志
SELECT * FROM msdb.dbo.sysmail_event_log&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/30ebed3a203c0aac3c36a208c569da8c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;并且SQL Server提供了邮件重新发送的功能以及其它默认参数，具体设置参照此画面：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f26c0c6b8fe1d02faf25b40fbe2e142f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;至此，已经完成了利用C#进行发送邮件的功能。&lt;/p&gt;
&lt;p&gt;我相信基本上用C#就会搭配微软自己的SQL Server数据库，而使用它之后就可以少量的代码实现邮件发送的功能。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&amp;lt;3&amp;gt;实现Job任务运行状态的检测&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在我们使用SQL Server的时候，很多情况下都需要自定义Job进行部分功能的实现，而大部分时间是采取凌晨或者非业务期进行工作。&lt;/p&gt;
&lt;p&gt;而此Job的运行结果的检测便形成了一个需要跟踪的问题，比如有时候N个Job的运行，只有几个出现问题，并且不确定的此Job发生在那个机器上，所以自动化运维的重要性就不言而喻了。&lt;/p&gt;
&lt;p&gt;对于上面问题的解决，SQL Server提供了很简单的配置就可以实现。&lt;/p&gt;
&lt;p&gt;（1）首先，需要定义几个操作员，说到底就是几个人值班运维此数据库的&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9cc80fad1fb8345fd926fdf2994a733a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面，我就定义了一个人，其实可以定义多个人，几个运维人员几个…&lt;/p&gt;
&lt;p&gt;（2）其次，需要定义警报，说到底就是将产生的预警发送给上面的几个运维人员。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/99b17f5b02021a5b6015ba12f94cb755.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里面的严重性选项其实是一个很重要的功能，一些简单的问题警告有时候是不需要及时关注的，或者说不需要暂时处理的。&lt;/p&gt;
&lt;p&gt;但是有些问题则需要里面去解决，比如服务器宕机….&lt;/p&gt;
&lt;p&gt;然后，我们来将此预警关联之操作员&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/450ba38deec902337ddd6c22bb0c9949.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;到此，我们已经完成了预警的检测配置，然后需要的就是关联下Job代理的任务属性值。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3fc844ed93e8f7770d5f56c631fdf1ab.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;经过上面的配置，任何我们自定义的Job工作状态都可以进行自动化检测了。&lt;/p&gt;
&lt;p&gt;比如：某个Job跑批成功了，某个Job跑批失败了。我们来新建一个自定义的Job来测试下：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/575a73c8467d0a966224134efc8a2dd0.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后设置警告&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/66fa1fafe2788492342943ec6d858429.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后，在运行此Job出现异常的时候，就可以自动的报告到相应的运维人员了。&lt;/p&gt;
&lt;p&gt;这里我们就设置了一个运维人员，所以这里只发送给一个人。&lt;/p&gt;
&lt;p&gt;我们来手动运行下，来测试一下效果&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fdcfdc725c5d8e0f07af9ae2f095ac65.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;嘿嘿，果然，发出了警报，看起来很贴心的样子&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f0099605873839f87cde76f4418c4a5f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1549c4e62005c38ce60d4ec55fd21163.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;至此，此功能已经配置完成，自己可以灵活的实现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&amp;lt;4&amp;gt;利用PowerShell实现Job任务计划的检测&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;关于Job的明细日志，请参照如下文章：&lt;/p&gt;
&lt;p&gt;&lt;a id=&quot;cb_post_title_url&quot; href=&quot;http://blog.jobbole.com/87080/&quot; target=&quot;_blank&quot;&gt;SQL Server自动化运维系列——监控跑批Job运行状态（Power Shell）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本来打算将利用Power Shell脚本检测的功能实现方式也加上的，但文章已经稍有点篇幅了，后续再完成吧。此篇的关于SQL Server的邮件功能算作抛砖引玉了，自己另有需求可以自己灵活实现。&lt;/p&gt;
&lt;p&gt;其实，在本篇所介绍的Job任务的检测在几台服务器上存在还问题不大，但是如果多台服务器，如果每台服务器上都有几个Job异常的话，每天早上打开邮件多的估计会令你头皮发麻，并且在自带的异常报警中，没有给出详细的错误信息，其实这是一个很不爽弊端。&lt;/p&gt;
&lt;p&gt;所以，为了优雅的进行自动化运维的工作，我们将会每次将我们所有检测的服务器Job运行状态进行扫描，而后将其汇总至一封邮件，然后按照重要性发送至固定的运维人员。&lt;/p&gt;
&lt;p&gt;听起来是不是还有点小激动的样子，下一篇我们来实现此功能。有兴趣的童鞋，可以提前关注。&lt;/p&gt;
&lt;p&gt;关于SQL Server自动化运维和检测的内容很广泛，其中很多都是从日常的经验中出发，一步步的从手动到自动的过程。&lt;/p&gt;

        
        
    &lt;div class=&quot;post-adds&quot;&gt;
        &lt;span data-post-id=&quot;87077&quot; class=&quot;btn-bluet href-style vote-post-up   register-user-only &quot;&gt;&lt;i class=&quot;fa  fa-thumbs-o-up&quot;&gt;&lt;/i&gt; &lt;h10 id=&quot;87077votetotal&quot;&gt;&lt;/h10&gt; 赞&lt;/span&gt;
        &lt;span data-book-type=&quot;1&quot; data-site-id=&quot;2&quot; data-item-id=&quot;87077&quot; data-item-type=&quot;1&quot; class=&quot;btn-bluet href-style bookmark-btn  register-user-only &quot;&gt;&lt;i class=&quot;fa fa-bookmark-o  &quot;&gt;&lt;/i&gt;  收藏&lt;/span&gt;

                &lt;a href=&quot;#article-comment&quot;&gt;&lt;span class=&quot;btn-bluet href-style&quot;&gt;&lt;i class=&quot;fa fa-comments-o&quot;&gt;&lt;/i&gt;  评论&lt;/span&gt;&lt;/a&gt;
        
            &lt;/div&gt;


        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Sun, 24 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-24-87077-779823da9.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-24-87077-779823da9.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>八岁小孩的数学：少儿图论</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;今天早上，我有幸到女儿所在的三年级客串数学老师，和这一群好问的八九岁的小女孩有了一个愉快的互动。接着我去年的时候讲过的话题《&lt;a href=&quot;http://blog.jobbole.com/71701/&quot; target=&quot;_blank&quot;&gt;七岁儿童的数学：图形着色，色彩数，欧拉路径和欧拉环&lt;/a&gt;》，我想和她们一起探索图论里的一些基本概念。这些概念数学内涵丰富，难度对于孩子来说也适宜。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/193b545fa8aa0316ffde1c0b9b7cb3c9.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这次我讲课的目标是让她们体会到独立发现连通平面图的欧拉示性数的惊喜。&lt;/p&gt;
&lt;p&gt;我们从一个简单的例子开始，分别数出图中顶点(V)、边(E)和区域(R)的数量。在数区域的数量的时候，我强调说“图外面”的区域也算一个区域。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/60560ecd676ffd59e51e2e5fb752ade9.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;接着，为了给这堂课添加一些神秘色彩，我提到欧拉在计算V-E+R这个量时，发现它有个独特的性质。她们能够注意到欧拉的发现么？&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/89cf438309650adbd928ef58d8fd1565.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;每个学生都有自己的小册子且计算了各种各样简单的图的欧拉示性数，我也在教室里走动帮助他们。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fbb8019a970dba71e777d3250ecc6e7a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;最后，这些小女孩发现了：她们总是得到同一个结果—2！我听到她们说，“为什么总是得到2呢？”。她们发现了欧拉的惊喜！&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/4fb0d38ffd90b92ab500831f8f551868.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;老师们也对这个结果非常好奇，一个老师惊异地对我说，“我真的很想知道为什么总是2！”&lt;/p&gt;
&lt;p&gt;接着，我建议同学们试试其他的几个不太常见的图，来检验一下这个“始终等于2”的情况有多么稳定。但是在这些图中，我们得到的结果仍然是2。&lt;/p&gt;
&lt;p&gt;女孩们自己画出图形检验了这一假设。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/78bf6ab3c9b648419a45b228293df86d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;最终，我设法提出了非连通图和有交叉边的图的例子，来检验“始终等于2”的现象。（&lt;span style=&quot;color: #808080;&quot;&gt;注：V-E+R=2对这样的图不成立&lt;/span&gt;）&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9bc3d955cae6af2b8219a0be0a6e3037.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/e90351d43d137a88da0300abb4138b3a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;就这样，我们一起把V-E+R=2的假设改进到只适用于连通平面图的情况。&lt;/p&gt;
&lt;p&gt;现在，到了该证明的时候了。我一开始不确定我是否应该给出一个证明，毕竟他们才三年级，证明对他们来说有些太难。但是有些老师向我表达了他们想知道为什么的想法，他们鼓励我让我给出证明，说“即使有的同学不能够理解这个证明，光看到有人能给出这样的证明也会有很大的价值。多好的老师啊！&lt;/p&gt;
&lt;p&gt;证明的过程如下。当一个图只有一个顶点，没有边的时候，V-E+R=2是成立的。而且，当往图里添加一个顶点和一个边的情况下，顶点和边（的贡献）能够互相抵消，这个等式也是成立的。同时，当往图中添加一条边并把一个已有的区域切分成两个的情况下，因为多了一个区域，多了一条边，这两个相互抵消，等式也是成立的。因为任何一个连通平面图都可以用上面描述的两种添加边和顶点的方式构建出来，所以V-E+R=2这个论证对于任何连通平面图都是成立的。这种证明是对图的势（size）的数学归纳法证明。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ec68809030a9aa81df6d7ece925807e6.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/97b9af63b703689c6fcac61c37b41112.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;下一步，我们把研究对象转移到三维立方体和它们的表面上。对于各种各样的多面体，小女孩们依旧能够证实V-E+R=2的拓展例子。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1b5438ecfc1dc0645d6962a4f19d332d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a4c4256ad6c1bb361e3c6b20c2f883bf.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;接着，小女孩们自己画出多面体来计算欧拉示性数，我教她们怎么画立方体和图中所示的立方体；当图形不仅仅是一个简单的立方体时，这对孩子而言是一个挑战，尽管如此，一些小朋友仍然画出了些有趣的立方体。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fa8a648600994aa05be3703a40fd7707.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3eccd08f74a93ffb90452528fb6517fd.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/64217b72026723eaacfad1a235670446.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;最后，每个孩子都有一个可以带回家的精美的小册子。以上图片摘自班里一位同学的小册子。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f0b06e04b618460a912c79aca4bf02a8.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;多棒的一天啊！&lt;/p&gt;
&lt;p&gt;你可以在这儿找到小册子—八岁小孩的数学：&lt;a title=&quot;少儿图论&quot; href=&quot;https://plus.google.com/u/0/+JoelDavidHamkins1/posts/46ZctASr5US&quot; target=&quot;_blank&quot;&gt;少儿图论&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;也可以查看我上一次讲课的报道：&lt;a title=&quot;七岁小孩的数学：图着色和欧拉路径&quot; href=&quot;http://jdh.hamkins.org/math-for-seven-year-olds-graph-coloring-chromatic-numbers-eulerian-paths/&quot; target=&quot;_blank&quot;&gt;七岁小孩的数学：图着色和欧拉路径。&lt;/a&gt;&lt;/p&gt;

        
        &lt;!-- BEGIN #author-bio --&gt;

&lt;div id=&quot;author-bio&quot;&gt;
	
	&lt;h3 class=&quot;widget-title&quot;&gt;
	关于作者： &lt;a href=&quot;http://blog.jobbole.com/author/mingyuan/&quot;&gt;刘志成&lt;/a&gt;
	&lt;/h3&gt;
	&lt;div class=&quot;alignleft&quot;&gt;
		&lt;a href=&quot;http://blog.jobbole.com/author/mingyuan/&quot;&gt;
					&lt;/a&gt;
	&lt;/div&gt;
	&lt;p&gt;新浪微博：&lt;a href=&quot;http://weibo.com/sdwf&quot;&gt;@柳鸣渊&lt;/a&gt;&lt;/p&gt;
	&lt;p&gt;
		&lt;a style=&quot;text-decoration: none;&quot; href=&quot;http://blog.jobbole.com/author/mingyuan/&quot;&gt;查看刘志成的更多文章 »&lt;/a&gt;
	&lt;/p&gt;
	&lt;div class=&quot;clear&quot;&gt;&lt;/div&gt;
	
&lt;/div&gt;

&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Fri, 22 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-22-86960-8358d0dfa.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-22-86960-8358d0dfa.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>Shell（二）：变量、数据重定向和管道</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;在上一篇博客&lt;a href=&quot;http://blog.jobbole.com/86820/&quot; target=&quot;_blank&quot;&gt;Shell（一）：功能、配置和插件&lt;/a&gt;中，介绍了为什么要使用shell，shell有哪些功能，如何使用oh my zsh来提高效率等，本篇重点介绍，shell中的变量的如何设置和读取数据，读取之后如何使用变量？每个程序一般都有输入和输出，让我们看看数据重定向如何处理输入和输出的？还有，Unix/Linux系统提供丰富的工具，我们如何将这些工具通过管道来组合成更加强大的宏工具呢？下面，由我来逐一详细介绍变量、数据重定向和管道。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/23fde73486c88b8ec60e205c3373da96.jpg&quot; width=&quot;690&quot; height=&quot;433&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;变量&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;变量的作用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;变量与其他程序设计语言一样，都是存储数据，然后被程序引用。相比于不使用变量，而是直接使用数据，存在两个问题：&lt;/p&gt;
&lt;p&gt;当数据改变时，直接使用数据的时候却不能灵活地根据数据改变而随着改变，而使用变量却不同，它能够做到这点。&lt;br&gt;
当数据发生变化时，如果想保证数据一致性，必须查找所有引用该数据的所有地方，然后将它修改，当下一次再需要修改时，也是像这种情况一样，是多么繁琐的事，而变量却不用，只需要修改变量值即可。&lt;br&gt;
因此，变量具有可变性和易于修改的两个特点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;变量的分类&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在shell中，大概分为两种变量：环境变量和局部变量，主要区别在于它们的使用范围不同，环境变量可以在父进程与子进程之间共享，而自定义变量只在本进程使用。举一个简单的例子来说明：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/779131174bda78f098c81335331d9195.jpg&quot; width=&quot;690&quot; height=&quot;123&quot;&gt;&lt;/p&gt;
&lt;p&gt;我首先设置一个shell变量devname=sam，然后输入bash打开一个新的shell，而这个shell是子进程，然后echo $devname输出变量值，变量值为空，最后exit退出子进程。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/caa630db46ddeaf5b6c08bcacc241fda.jpg&quot; width=&quot;690&quot; height=&quot;83&quot;&gt;&lt;/p&gt;
&lt;p&gt;但使用export devname设置环境变量后，再次进入输入bash进入子进程之后，echo $devname输出变量值，这次变量值是sam&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;查看环境变量env和set&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果想查看系统中以及自定义有哪些环境变量，可以使用env命令：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/1fa42177ba90ab550862e9b1abacee2e.jpg&quot; width=&quot;690&quot; height=&quot;500&quot;&gt;&lt;/p&gt;
&lt;p&gt;而set命令不仅能查看环境变量，还可以查看与shell接口有关的变量，下面只截取一部分变量：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/b387f8ad5812896873a4269c59ae8e30.jpg&quot; width=&quot;690&quot; height=&quot;353&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;变量有哪些操作&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;显示echo $variable&lt;/p&gt;
&lt;p&gt;如果你想显示某个变量的值，例如PATH，你只需要输入：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;echo $PATH&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/3f2b3bd9138d4012de7e7a1ef8d16a99.jpg&quot; width=&quot;690&quot; height=&quot;146&quot;&gt;&lt;/p&gt;
&lt;p&gt;注意上面一条命令，需要在变量名前加上一个符号$，这样才能访问变量&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;设置variable=value和取消unset&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果你想设置某个变量的值，只需在变量名和变量值之间用符号=连接就行了，例如：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/3a6455d45005433527fc1ddf9571cfe4.jpg&quot; width=&quot;690&quot; height=&quot;231&quot;&gt;&lt;/p&gt;
&lt;p&gt;由上面的输入命令echo $devname，显示结果为空。由此可知，一开始如果没有设置某个变量时，它的是为空。另外，设置变量的规则还需要几点注意：&lt;/p&gt;
&lt;p&gt;1. 在命名变量名时，变量名称只能是英文字母和数字，而且首字母不能是数字。下面演示一个错误的例子：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/25cdbc229733ce96b3833b5a5e62f09d.jpg&quot; width=&quot;690&quot; height=&quot;77&quot;&gt;&lt;/p&gt;
&lt;p&gt;2. 等号=两边不能有空格&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/0808b1c942675bd695b3886bf48631b6.jpg&quot; width=&quot;690&quot; height=&quot;259&quot;&gt;&lt;/p&gt;
&lt;p&gt;3. 如果变量值有空格，可用双引号” “或单引号’ ‘来包围变量值，但两者是有区别：&lt;br&gt;
双引号” “内的一些特殊字符，可以保持原有的特性，例如：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/8ffabfd9a22eecdff7caad20394703f8.jpg&quot; width=&quot;690&quot; height=&quot;190&quot;&gt;&lt;/p&gt;
&lt;p&gt;而单引号’ ‘内的一些特殊字符，仅为一般字符，即纯文本，例如：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/6571f2b0da4d402246fd52d748a3444c.jpg&quot; width=&quot;690&quot; height=&quot;155&quot;&gt;&lt;/p&gt;
&lt;p&gt;4. 如果想显示一些特殊字符（$、空格、!等），在字符前面加上用转义字符\&lt;/p&gt;
&lt;p&gt;5. 有些时候，变量的值可能来源于一些命令，这时你可以使用反单引号`命令`或$(命令)，例如：&lt;/p&gt;
&lt;p&gt;使用反单引号`命令`的方式&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/ccd324509bd446b0e87f2943166831c9.jpg&quot; width=&quot;690&quot; height=&quot;146&quot;&gt;‘&lt;/p&gt;
&lt;p&gt;使用$(命令)的方式&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/8100e6d64cf53da84349526eb9335815.jpg&quot; width=&quot;690&quot; height=&quot;164&quot;&gt;&lt;/p&gt;
&lt;p&gt;6. 如果变量想增加变量的值，可以使用$variable累加&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/930c7e298386a35cff2f2a81b7ea9e24.jpg&quot; width=&quot;690&quot; height=&quot;285&quot;&gt;&lt;/p&gt;
&lt;p&gt;7. 如果变量需要在其他子进程使用，用&lt;code&gt;export&lt;/code&gt;关键字来设置变量为环境变量&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;export VARIABLE&lt;/pre&gt;
&lt;p&gt;8. 系统环境变量一般都是字母全部大写，例如：PATH，HOME，SHELL等&lt;/p&gt;
&lt;p&gt;9. 如果想取消设置变量的值，使用unset variable命令。注意，变量之前是没有符号$&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/ee65dd7bd45f8405c75d605f2e17d2d2.jpg&quot; width=&quot;690&quot; height=&quot;214&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;环境配置文件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;之前那些设置的环境变量，一旦退出系统后，就不能再次使用，如果想再次使用，必须重新再设置才行。如果想就算退出系统，也能重新使用自定义的环境变量，那怎么办呢？&lt;/p&gt;
&lt;p&gt;不用怕，系统提供一些环境配置文件：/etc/profile和~/.bash_profile。/etc/profile是系统整体的设置，每个用户共享，最好不要修改；而~/.bash_profile属于单个用户的设置，每个用户设置后，互不影响和共享。但因为我使用oh my zsh，之前~/.bash_profile设置一些配置都不生效了，但它提供一个环境配置文件.zshrc，所以如果想设置环境变量TEST，只需将export TEST=test添加.zshrc即可。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/ea68fa7a4089f8b86f765403f6e0b76c.jpg&quot; width=&quot;690&quot; height=&quot;223&quot;&gt;&lt;/p&gt;
&lt;p&gt;但在.zshrc文件设置好环境变量TEST后，echo $TEST为空，原因是还没使用source命令来读取环境配置文件。使用source .zshrc命令之后，设置环境变量TEST生效了&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/e00a2a0672aeade7d0bbb0e3d29b1a7f.jpg&quot; width=&quot;690&quot; height=&quot;142&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;数据重定向&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;含义&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当输入命令行时，一般都有输入参数(standard input)，而命令行处理完之后，一般都有输出结果，结果有可能成功(standard output)，也有可能失败(standard error)，而这些结果一般都会输出到屏幕上，如果你想控制结果输出到文件或以文件作为输入的话，你需要了解数据重定向的分类和符号操作。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/b03e3b25d6d6cc9b9d5d1fdcf38be4bf.jpg&quot; width=&quot;690&quot; height=&quot;259&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;分类&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据重定向主要分为三类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;stdin，表示标准输入，代码为0，使用&amp;lt;或&amp;lt;&amp;lt;操作符&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;符号&amp;lt;表示以文件内容作为输入&lt;br&gt;
符号&amp;lt;&amp;lt;表示输入时的结束符号&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;stdout，表示标准输出，代码为1，使用&amp;gt;或&amp;gt;&amp;gt;操作符&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;符号&amp;gt;表示以覆盖的方式将正确的数据输出到指定文件中&lt;br&gt;
符号&amp;gt;&amp;gt;表示以追加的方式将正确的数据输出到指定文件中&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;stderr，表示标准错误输出，代码为2，使用2&amp;gt;或2&amp;gt;&amp;gt;操作符&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;符号2&amp;gt;表示以覆盖的方式将错误的数据输出到指定文件中&lt;br&gt;
符号2&amp;gt;&amp;gt;表示以追加的方式将错误的数据输出到指定文件中&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;stdout&lt;br&gt;
当你输入ls命令，屏幕会显示当前目录有哪些文件和目录；而当你使用符号&amp;gt;时，输出结果将重定向到dir.txt文件，而不显示在屏幕上&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/2146aa56576d3dd6a5a0b45bced80de1.jpg&quot; width=&quot;690&quot; height=&quot;230&quot;&gt;&lt;/p&gt;
&lt;p&gt;而符号&amp;gt;与符号&amp;gt;&amp;gt;有什么区别呢？&amp;gt;表示当文件存在时，将文件内容清空，然后stdout结果存放到文件中。而&amp;gt;&amp;gt;表示当文件存在时，文件内容并没有清空，而是将stdout结果追加到文件尾部。&lt;/p&gt;
&lt;p&gt;当你再次输入命令ls &amp;gt; dir.txt时，文件内容并没有改变，因为之前文件内容被清空，然后stdout结果存放在dir.txt文件&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/0e8da5fd9460376825e200adf87ba101.jpg&quot; width=&quot;690&quot; height=&quot;194&quot;&gt;&lt;/p&gt;
&lt;p&gt;而你这次使用符号ls &amp;gt;&amp;gt; dir.txt的话，文件内容被追加到dir.txt文件&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/07182755db7287ea7f767acd25eb6488.jpg&quot; width=&quot;690&quot; height=&quot;236&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;stderr&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这次我输入命令ls test显示一个不存在的文件，会显示错误信息。然后将错误信息输出到文件error.txt。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/01211958d45d90545ce6108a2c565ae1.jpg&quot; width=&quot;690&quot; height=&quot;138&quot;&gt;&lt;/p&gt;
&lt;p&gt;如果你想追加错误信息，可以使用2&amp;gt;&amp;gt;符号&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/d130de034e3874ccff04dd534edfe3dc.jpg&quot; width=&quot;690&quot; height=&quot;117&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;stdout &amp;amp; stderr&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将stdout和stderr分离：&amp;gt;和2&amp;gt;符号&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;输入ls README.md test，在屏幕显示既有正确信息，也有错误信息，如果想将正确信息和错误信息分离到不同文件，你可以同时使用&amp;gt;和2&amp;gt;符号&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/4938a3e37d9b7d53c45fbdcf664c19de.jpg&quot; width=&quot;690&quot; height=&quot;185&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将stdout和stderr合并：&amp;amp;&amp;gt;符号&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你想将正确信息和错误信息合并，且输出到同一个文件，可以使用&amp;amp;&amp;gt;符号&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/d32578ed30f64d4a03e8a1296d8cafe6.jpg&quot; width=&quot;690&quot; height=&quot;171&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;stdin&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一般输入一些简单的数据的方式都是通过键盘，但是如果要输入大量的数据，最好还是通过文件的方式。举一个简单例子：&lt;br&gt;
首先输入cat &amp;gt; test命令之后，你就可以输入内容，那些内容最终会存放在test文件&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/e22d933ed7692846b61a1822316fbfc7.jpg&quot; width=&quot;690&quot; height=&quot;152&quot;&gt;&lt;/p&gt;
&lt;p&gt;但如果有大量数据从一个文件导入到test文件时，此时需要用到&amp;lt;符号&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/2b8cb1033043b77918f9a8941dd9444d.jpg&quot; width=&quot;690&quot; height=&quot;350&quot;&gt;&lt;/p&gt;
&lt;p&gt;还一个符号&amp;lt;&amp;lt;需要解释，符号&amp;lt;&amp;lt;表示输入时的结束符号。输入cat &amp;gt; test &amp;lt;&amp;lt; “eof”命令之后，你就可以输入内容，那些内容最终会存放在test文件，输入完内容后可以输入eof来结束输入&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/10a52fb8bf0b2ecb32be793ba96367a9.jpg&quot; width=&quot;690&quot; height=&quot;166&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;管道&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;在Unix设计哲学中，有一个重要设计原则–KISS(Keep it Simple, Stupid)，大概意思就是只关注如何做好一件事，并把它做到极致。每个程序都有各自的功能，那么有没有一样东西将不同功能的程序互相连通，自由组合成更为强大的宏工具呢？此时，管道出现了，它能够让程序实现了高内聚，低耦合。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/a9e464ef9cb6e5aeb9fad8eb8b544c22.jpg&quot; width=&quot;690&quot; height=&quot;160&quot;&gt;&lt;/p&gt;
&lt;p&gt;如果我想查看文件是否存在某个关键字，此时我可以使用管道&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/62816c4c13f157c3686fa178d179747c.jpg&quot; width=&quot;690&quot; height=&quot;141&quot;&gt;&lt;/p&gt;
&lt;p&gt;命令cat README.md | grep ‘pod’的处理过程分为两步：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;cat README.md查看文件内容&lt;/li&gt;
&lt;li&gt;然后将cat README.md输出的内容作为grep ‘pod’命令的输入，再进行处理。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上面一个很关键的符号|，就是管道，它能够将前一个命令处理完的stdout作为下一条命令stdin。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;扩展阅读&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://book.douban.com/subject/4889838/&quot; target=&quot;_blank&quot;&gt;鸟哥的Linux私房菜-基础学习篇&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://coolshell.cn/articles/1351.html&quot; target=&quot;_blank&quot;&gt;Unix Pipes 管道原稿&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

        
        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Thu, 21 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-21-87053-498a03022.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-21-87053-498a03022.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>算法题：删除 K 位数字</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;h3&gt;&lt;strong&gt;1.问题描述&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;现有一个 n 位数，你需要删除其中的 k 位，请问如何删除才能使得剩下的数最大？&lt;/p&gt;
&lt;p&gt;比如当数为 2319274， k=1 时，删去 2 变成 319274 后是可能的最大值。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;2.问题分析&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;[1]贪心解法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这题可以使用贪心策略，每次从高位向低位数，删除高位比低位数字小的那位上的数字，直到删除了k位之后，得到的数字肯定是最大值。&lt;/p&gt;
&lt;p&gt;(1)删数问题具有最优子结构：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/4eb1ec5a141234981f4e15990f4bd405.jpg&quot; width=&quot;690&quot; height=&quot;90&quot;&gt;&lt;/p&gt;
&lt;p&gt;(2)删数问题具有贪心选择性质：&lt;/p&gt;
&lt;p&gt;设问题T已按照上面的方法删除，假设 A=(y1,y2,···,yk) 是删数问题的一个最优解。易知，若问题有解，则1≤k≤n。 (1)当k=1时，由前得证，A=(y1,A′)是问题的最优解，其中A′是A中不删除了y1而删除其他位的最优解； (2)当k=q时，由反证法，可得A=(y1,y2···,yq)是最优解； 当k=q+1时，由前得证，A=(y1,y2···,yq+yq+1)是最优解。 所以，删数问题具有贪心选择性质。&lt;/p&gt;
&lt;p&gt;代码很容易实现，AC，1.484s，1.089MB&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;#include &amp;lt;string&amp;gt;
#include &amp;lt;iostream&amp;gt;
using namespace std;
int t,k,len;
string name;
void deletek(){
    int tlen=name.length();
    int tk=k;
    bool flag=true;
    while (k--&amp;gt; 0 &amp;amp;&amp;amp; flag) {
        flag=false;
        len = name.length();
        for (int i=0; i&amp;lt;len; i++) {
            if (i+1&amp;lt;len &amp;amp;&amp;amp; name[i]&amp;lt;name[i+1]) {
                name.erase(i,1);
                len--;
                flag=true;
                break;
            }
        }
    }
    cout &amp;lt;&amp;lt; name.substr(0,tlen-tk) &amp;lt;&amp;lt; endl;
}
int main(int argc, const char * argv[])
{
    cin &amp;gt;&amp;gt; t;
    while (t--&amp;gt;0) {
        cin &amp;gt;&amp;gt; name;
        cin &amp;gt;&amp;gt; k;
        deletek();
    }
    return 0;
}&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[2]动态规划解法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;根据上面的分析可以看出此题还可用动态规划来解决，思路如下：&lt;/p&gt;
&lt;p&gt;假设A(i,j)表示输入数字(字符串)的从第i位到第j位数字组成的字符串，S(i,j)表示前i位中删除j位得到的最优解，它实际上可以看做两个子问题：如果删除第j位，那么S(i,j)等于前i-1位删除j-1位的最优解加上第j位数字；如果不删除第j位，那么S(i,j)等于前i-1位删除j位的最优解。于是便有下面的递推式：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/25d9f951793b5aa11c3f98e18a85bcf2.jpg&quot; width=&quot;519&quot; height=&quot;67&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个递推式非常类似最长公共子序列问题的递推式，所以解法也类似，在空间方面可以只使用一个一维数组，加上一个额外的O(1)的空间，计算过程如下面制作的表格所示，除了第一列，其他中间元素都只依赖于上面一行对应位置S(i−1,j)和上面一行左边位置S(i−1,j−1)两个元素的大小，比较的是字符串，使用字典序进行比较，C++内置的字符串比较函数compare即可。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/1e83f13184510ff68937db00444881b9.jpg&quot; width=&quot;460&quot; height=&quot;331&quot;&gt;&lt;/p&gt;
&lt;p&gt;动态规划实现代码 [这份代码没有AC，只能得到60分就超时了，应该还可以改进]。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;#include &amp;lt;string&amp;gt;
#include &amp;lt;iostream&amp;gt;
using namespace std;
#define MAX_K 1001
int t,k;
string name;string up;string last;string temp;
void deletek(){
    int len=name.length();
    if(k&amp;gt;=len){
        cout &amp;lt;&amp;lt; &quot;&quot; &amp;lt;&amp;lt; endl;
        return;
    }
    string cur[MAX_K]={&quot;&quot;};
    for (int i=1; i &amp;lt;= len; i++) {
        for (int j=0; j &amp;lt; i &amp;amp;&amp;amp; j &amp;lt;= k; j++) {//
            if (j==0) {//sub string
                last=cur[j];
                cur[j]=name.substr(0,i);
            }else{//0 &amp;lt; j &amp;lt;= i
                up=cur[j]+name[i-1];//
                if (up.compare(last)&amp;gt;=0) {//up &amp;gt; left
                    last=cur[j];
                    cur[j]=up;
                }else{//up &amp;lt; left
                    temp=cur[j];
                    cur[j]=last;
                    last=temp;
                }
            }
        }
    }
    cout &amp;lt;&amp;lt; cur[k] &amp;lt;&amp;lt; endl;
}
int main(int argc, const char * argv[])
{
    cin &amp;gt;&amp;gt; t;
    while (t--&amp;gt;0) {
        cin &amp;gt;&amp;gt; name;
        cin &amp;gt;&amp;gt; k;
        deletek();
    }
    return 0;
}&lt;/pre&gt;


        
        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Thu, 21 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-21-87018-3225f88cf.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-21-87018-3225f88cf.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>算法题：最长公共子序列</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;最长公共子序列(LCS)是典型的动态规划问题，如果不理解动态规划请移步先看&lt;a href=&quot;http://python.jobbole.com/81465/&quot; target=&quot;_blank&quot;&gt;这篇动态规划的总结&lt;/a&gt;，否则本篇文章中的代码实现会不理解的哟！&lt;/p&gt;
&lt;p&gt;LCS问题的一个变种就是求最长单调递增子序列，它的一种简易求解方法就是先将原序列A进行排序得到序列B，然后求解序列A和序列B的最长公共子序列。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;1.问题描述&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/3e466bd42e6eac26c6b37f9a8e1e7977.jpg&quot; width=&quot;636&quot; height=&quot;181&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;2.最优子结构和子问题重叠&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/3658414382687496f599f1d277450d10.jpg&quot; width=&quot;629&quot; height=&quot;701&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;3.5种实现方式&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;根据LCS的递推公式&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/dd591d0c1eda24cd1ca024af328f729e.jpg&quot; width=&quot;452&quot; height=&quot;85&quot;&gt;&lt;/p&gt;
&lt;p&gt;(1)从中可以看出计算c[i][j]时只需要2行即可，前一行(i-1)和当前行(i)，每行的长度是min{m,n}，首先初始化前一行都为0，然后计算当前行的值，当要计算下一行之前将当前行的值复制到前一行中即可。&lt;/p&gt;
&lt;p&gt;(2)从递推公式中还可以看出计算当前行i的话，其实只需要一行再加上O(1)的额外空间就行了。因为计算c[i][j]只需要前一行中c[i-1][k] (k&amp;gt;=j-1)的数据，对于k&amp;lt;j-1的数据都是没有用的，而当前行c[i]l的数据都是有用的，要用来计算下一行的值，所以，可以在计算当前行的时候，将当前行的前面计算好的部分复制到前一行中对应位置上，但是c[i][j-1]除外，因为c[i-1][j-1]也是需要的，所以需要额外的O(1)的空间保存c[i][j-1]。&lt;/p&gt;
&lt;p&gt;LCS的五种实现：分别为0：直接递归；1：带备忘录的递归；2：使用二维数组保存结果的迭代；3：使用2个一维数组保存结果的迭代；4：使用1个一维数组和额外的O(1)空间保存结果的迭代。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;def lcs0(i,j):
    #string starts at index 0, not 1
    if i&amp;lt;0 or j&amp;lt;0: return 0 #attention to this!!!
    if x[i]==y[j]:  return lcs0(i-1,j-1)+1
    return max(lcs0(i-1,j),lcs0(i,j-1))

x,y=&#39;abcde&#39;,&#39;oaob&#39;
lenx,leny=len(x),len(y)
print(lcs0(lenx-1,leny-1)) #2

from functools import wraps

def memo(func):
    cache={}
    @wraps(func)
    def wrap(*args):
        if args not in cache:
            cache[args]=func(*args)
        return cache[args]
    return wrap

@memo
def lcs1(i,j):
    #string starts at index 0, not 1
    if i&amp;lt;0 or j&amp;lt;0: return 0 #attention to this!!!
    if x[i]==y[j]:  return lcs1(i-1,j-1)+1
    return max(lcs1(i-1,j),lcs1(i,j-1))

x,y=&#39;abcde&#39;,&#39;oaob&#39;
lenx,leny=len(x),len(y)
print(lcs1(lenx-1,leny-1)) #2

def lcs2(x,y):
    lenx,leny=len(x),len(y)
    minlen,maxlen=0,0
    if lenx&amp;lt;leny: minlen,maxlen=lenx,leny; x,y=y,x
    else: minlen,maxlen=leny,lenx;
    #s is maxlen * minlen
    s=[[0 for j in range(minlen)] for i in range(maxlen)]
    for i in range(maxlen): #so, let x be the longer string!!!
        for j in range(minlen):
            if x[i]==y[j]: s[i][j]=s[i-1][j-1]+1
            else: s[i][j]=max(s[i-1][j],s[i][j-1])
    return s

x,y=&#39;abcde&#39;,&#39;oaob&#39;
s=lcs2(x,y)
print(s) #[[0, 1, 1, 1], [0, 1, 1, 2], [0, 1, 1, 2], [0, 1, 1, 2], [0, 1, 1, 2]]

def lcs3(x,y):
    lenx,leny=len(x),len(y)
    minlen,maxlen=0,0
    if lenx&amp;lt;leny: minlen,maxlen=lenx,leny; x,y=y,x
    else: minlen,maxlen=leny,lenx;
    #s is maxlen * minlen
    pre=[0 for j in range(minlen)]
    cur=[0 for j in range(minlen)]
    for i in range(maxlen): #so, let x be the longer string!!!
        for j in range(minlen):
            if x[i]==y[j]: cur[j]=pre[j-1]+1
            else: cur[j]=max(pre[j],cur[j-1])
        pre[:]=cur[:]
    return cur

x,y=&#39;abcde&#39;,&#39;oaob&#39;
s=lcs3(x,y)
print(s) #[2, 2, 2, 2]

def lcs4(x,y):
    lenx,leny=len(x),len(y)
    minlen,maxlen=0,0
    if lenx&amp;lt;leny: minlen,maxlen=lenx,leny; x,y=y,x
    else: minlen,maxlen=leny,lenx;
    #s is maxlen * minlen
    s=[0 for j in range(minlen)]
    t=0
    for i in range(maxlen): #so, let x be the longer string!!!
        for j in range(minlen):
            if x[i]==y[j]: s[j]=t+1
            else: s[j]=max(s[j],s[j-1])
            t=s[j]
    return s

x,y=&#39;abcde&#39;,&#39;oaobce&#39;
s=lcs4(x,y)
print(s) #[3, 3, 3, 3, 4]&lt;/pre&gt;

        
        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Thu, 21 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-21-87015-293678f7c.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-21-87015-293678f7c.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>算法题：矩阵链乘问题</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;矩阵链乘问题是最典型的动态规划问题，要理解下面的内容请先阅读&lt;a href=&quot;http://python.jobbole.com/81465/&quot; target=&quot;_blank&quot;&gt;这篇动态规划的总结&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;1.问题描述&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;矩阵链乘问题的描述如下，就是说要确定一个完全加括号的形式使得矩阵链乘需要进行的标量计算数目最少，矩阵Ai的维数为pi−1×pi，如果穷举所有可能形式的话，时间复杂度是指数级的！因为该问题满足最优子结构，并且子问题存在重叠，所以我们可以借助动态规划来求解。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/a34199733c6e27f4004e5c5519653cea.jpg&quot; width=&quot;690&quot; height=&quot;581&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;2.问题分析&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;我们需要确定一个递归式来将我们要求解的问题表示出来，下面摘自算法导论，介绍地非常详细&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/cf3e4c85f502681ac9282a4d7eaf50f3.jpg&quot; width=&quot;690&quot; height=&quot;451&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;最后给出的递归式如下，就是说我们要如何确定从第i个矩阵到第j个矩阵组成的矩阵链的最优解。如果i和j相等，那么就是一个矩阵，不需要运算；如果i小于j，那么肯定要从它们中间的某个位置分开来，那从哪里分开来呢? 这个我们可以尝试下所有可能的选择，也就是尝试不同的位置k，k满足条件(i &amp;lt;= k &amp;lt; j)，在位置k将矩阵链进行分开，看看它需要的计算次数，然后我们从这些可能的k中选择使得计算次数最小的那个k进行分开，分开了之后我们的问题就变成了2个小问题，确定矩阵链从i到k 和另一个矩阵链从k+1到j的最优解。如果我们一开始设置i=1(第一个矩阵)，j=n(最后一个矩阵)，那么，经过上面的递归即可得到我们需要的解。这就是递归的思想！&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/3bd99ed2af439196ed7915fa55deb3ef.jpg&quot; width=&quot;471&quot; height=&quot;66&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;3.代码实现&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;根据上面的思想我们很快就可以写出一个递归版本的矩阵链承法的实现代码，输出的结果也没有错，给出的加括号的方式是( ( A1 ( A2 A3 ) ) ( ( A4 A5 ) A6 ) )。[问题的数据是算法导论中的问题的数据，值是30,35,15,5,10,20,25]。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;def matrixchain_rec(p,i,j):
    if i==j:
        return 0
    for k in range(i,j):
        q=matrixchain_rec(p,i,k)+matrixchain_rec(p,k+1,j)+p[i-1]*p[k]*p[j]
        if q&amp;lt;m[i][j]:
            m[i][j]=q
            s[i][j]=k
    return m[i][j]

def showmatrixchain(s,i,j):
    if i==j:
        print &#39;A%d&#39;%(i),
    else:
        print &#39;(&#39;,
        showmatrixchain(s,i,s[i][j])
        showmatrixchain(s,s[i][j]+1,j)
        print &#39;)&#39;,

n=6
p=[30,35,15,5,10,20,25]
m=[[sys.maxint for i in range(n+1)] for j in range(n+1)]
s=[[0 for i in range(n+1)] for j in range(n+1)]
# pprint.pprint(m)
result=matrixchain_rec(p,1,6)
print(result) #15125
showmatrixchain(s,1,6) #( ( A1 ( A2 A3 ) ) ( ( A4 A5 ) A6 ) )&lt;/pre&gt;
&lt;p&gt;上面的代码运行没有问题，但是，它不够完美！为什么呢? 很明显，矩阵链乘问题子问题存在重叠，下面这张图很形象地显示了哪些子问题被重复计算了，所以我们需要改进，改进的方法就是使用带备忘录的递归形式！&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/1519f3c35bc11109b92847db68909758.jpg&quot; width=&quot;690&quot; height=&quot;185&quot;&gt;&lt;/p&gt;
&lt;p&gt;要改成带备忘录的很简单，但是，这次我们不能直接使用原来的装饰器，因为Python中的dict不能对list对象进行hash，所以我们要简单地修改下我们key值的构建，也很简单，看下代码就明白了：&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;from functools import wraps

def memo(func):
    cache={}
    @wraps(func)
    def wrap(*args):
        #build new key!!!
        key=str(args[1])+str(args[2])
        if key not in cache:
            cache[key]=func(*args)
        return cache[key]
    return wrap

@memo
def matrixchain_rec(p,i,j):
    if i==j:
        return 0
    for k in range(i,j):
        q=matrixchain_rec(p,i,k)+matrixchain_rec(p,k+1,j)+p[i-1]*p[k]*p[j]
        if q&amp;lt;m[i][j]:
            m[i][j]=q
            s[i][j]=k
    return m[i][j]

def showmatrixchain(s,i,j):
    if i==j:
        print &#39;A%d&#39;%(i),
    else:
        print &#39;(&#39;,
        showmatrixchain(s,i,s[i][j])
        showmatrixchain(s,s[i][j]+1,j)
        print &#39;)&#39;,

n=6
p=[30,35,15,5,10,20,25]
m=[[sys.maxint for i in range(n+1)] for j in range(n+1)]
s=[[0 for i in range(n+1)] for j in range(n+1)]
# pprint.pprint(m)
result=matrixchain_rec(p,1,6)
print(result) #15125
showmatrixchain(s,1,6) #( ( A1 ( A2 A3 ) ) ( ( A4 A5 ) A6 ) )&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;接下来的一个问题是，我们怎么实现迭代版本呢? 迭代版本关键在于顺序！&lt;/strong&gt;我们怎么保证我们在计算$A{i…j}的最优解时，所有可能的k的选择需要求解的子问题A{i…k}以及A_{(k+1)…j}$是已经求解出来了的呢? 一个简单但是有效的想法就是看矩阵链的长度，我们先计算矩阵链短的最优解，然后再计算矩阵链长的最优解，后者计算时所需要求解的子问题肯定已经求解完了，对不对? 于是就有了迭代版本的实现，需要注意的就是其中的i,j,k的取值范围。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;import sys
def matrixchain_iter(p):
    n=len(p)-1 #total n matrices 6
    #to solve the problem below, so initialize to n+1!!!
    m=[[0 for i in range(n+1)] for j in range(n+1)]
    s=[[0 for i in range(n+1)] for j in range(n+1)]
    # for i in range(n): #for matrix with len=1
        # m[i][i]=0
    # pprint.pprint(m)
    for l in range(2,n+1): #iterate the length, max is n
        for i in range(1,n-l+2): #i max is n-l+1
            j=i+l-1 #j is always l away from i
            m[i][j]=sys.maxint #initial to infinity
            for k in range(i,j):
                #attention to python array when index &amp;lt; 0!!!
                #solution is using more space with useless values
                q=m[i][k]+m[k+1][j]+p[i-1]*p[k]*p[j]
                if q&amp;lt;m[i][j]:
                    m[i][j]=q
                    s[i][j]=k
        # print(&#39;when len is %d &#39; % (l))
        # pprint.pprint(m)
    return m,s

print(&#39;&#39;)
m,s=matrixchain_iter(p)
print(m[1][6]) #15125
showmatrixchain(s,1,6) #( ( A1 ( A2 A3 ) ) ( ( A4 A5 ) A6 ) )&lt;/pre&gt;
&lt;p&gt;实现的时候需要注意一点，在Python中取list中的值时，如果索引是负值的话会从后面往前数返回对应的元素，而以前我们用其他语言的时候肯定是提示越界了，所以代码中用来存储结果的数数组是(n+1)x(n+1)，而不是nxn的，这样的话就能够保证返回的是0，而不是从后往前数得到的结果。&lt;/p&gt;
&lt;p&gt;得到的数组m如下，m[1,6]就是我们需要的解。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;[[0, 0, 0, 0, 0, 0, 0],
 [0, 0, 15750, 7875, 9375, 11875, 15125],
 [0, 0, 0, 2625, 4375, 7125, 10500],
 [0, 0, 0, 0, 750, 2500, 5375],
 [0, 0, 0, 0, 0, 1000, 3500],
 [0, 0, 0, 0, 0, 0, 5000],
 [0, 0, 0, 0, 0, 0, 0]]&lt;/pre&gt;
&lt;p&gt;数组s如下：&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;[[0, 0, 0, 0, 0, 0, 0],
 [0, 0, 1, 1, 3, 3, 3],
 [0, 0, 0, 2, 3, 3, 3],
 [0, 0, 0, 0, 3, 3, 3],
 [0, 0, 0, 0, 0, 4, 5],
 [0, 0, 0, 0, 0, 0, 5],
 [0, 0, 0, 0, 0, 0, 0]]&lt;/pre&gt;
&lt;p&gt;将这个两个数组旋转下，并且只看上三角部分的数字，就可以得到算法导论中给出的那张三角图形了，非常类似杨辉三角&lt;/p&gt;


        
        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Thu, 21 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-21-87012-731b58095.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-21-87012-731b58095.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>算法题：顶点覆盖问题</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;顶点覆盖问题可以用几种不同的算法来实现，本篇文章使用的是分支限界法来实现，或许以后会介绍其他的实现算法，嘿嘿。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;1.问题描述&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;给定一个N个点M条边的无向图G（点的编号从1至N），问是否存在一个不超过K个点的集合S，使得G中的每条边都至少有一个点在集合S中。&lt;/p&gt;
&lt;p&gt;例如，如下图所示的无向图G（报告中算法分析过程中一直使用下面的图G）&lt;/p&gt;
&lt;p&gt;(1)如果选择包含点1,2,6这3个点的集合S不能满足条件，因为边(3,7)两个端点都不在S中。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/b2e7816e9e2fae094cf88a52cc76df0d.jpg&quot; width=&quot;357&quot; height=&quot;181&quot;&gt;&lt;/p&gt;
&lt;p&gt;(2)如果选择包含点1,2,6,7这4个点的集合S虽然满足条件，但是它使用了4个点，其实可以使用更少的点，如下面(3)所示&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/efd35e9d6a6d57ae05058b79301eae8b.jpg&quot; width=&quot;335&quot; height=&quot;172&quot;&gt;&lt;/p&gt;
&lt;p&gt;(3)如果选择包含点1,3,5这3个点的集合S便满足条件，使得G中的每条边都至少有一个点在集合S中。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/cc7cda1362b07dced9667589422c8d95.jpg&quot; width=&quot;356&quot; height=&quot;168&quot;&gt;&lt;/p&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;h3&gt;&lt;strong&gt;2.解题思路&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;我的解题思路基于分支定界和贪心两个策略，用一个优先队列维护当前可行的节点，每个节点维护着该节点情况下还可以选择的顶点数目k、需要覆盖的剩余边数e、顶点的状态state、顶点的边数edge等信息，这些节点的排序遵循下面的贪心策略，节点的扩展遵循下面的分支定界策略。总体思路是：&lt;/p&gt;
&lt;p&gt;①将原图数据构造成一个解空间树的节点，利用定界策略判断是否有解，如果无解直接退出，如果有可能有解则插入到优先队列中；&lt;/p&gt;
&lt;p&gt;②若优先队列不为空，那么便从优先队列中取出第一个可行的节点，进入步骤③，如果优先队列为空则退出；&lt;/p&gt;
&lt;p&gt;③判断当前节点是否满足解的条件，如果满足便输出解退出，如果不满足便进入步骤④；&lt;/p&gt;
&lt;p&gt;④检查当前节点是否可以扩展，不能扩展的话便进入②继续循环，如果能扩展的话则扩展，然后验证扩展到左右节点是否有解，将有解的扩展节点插入到优先队列中，然后进入②继续循环。&lt;/p&gt;
&lt;p&gt;下面分别介绍下分支定界和贪心这两个策略：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(1)分支定界策略&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先，界的选择。在一个确定的无向图G中，每个顶点的边即确定了，那么对于该无向图中k个顶点能够覆盖的最多的边数e也就可以确定了！只要对顶点按照边的数目降序排列，然后选择前k个顶点，将它们的边数相加即能得到一个边数上界！因为这k个顶点相互之间可能有边存在也可能没有，所以这是个上界，而且有可能达到。以图G为例，各个顶点的边数统计，并采用降序排列的结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/e8a29c963ea11fad3a96e38f6e780fb6.jpg&quot; width=&quot;165&quot; height=&quot;421&quot;&gt;&lt;/p&gt;
&lt;p&gt;假设取k=3个点，那么有Up(e)=(3+3+2)=8 &amp;gt; 7 条边（7为图G的总边数），也就是说，如果从图G中取3个点，要覆盖8条边是有可能的。但是，如果取k=2个点，那么有Up(e)=(3+3)=6 &amp;lt; 7 条边，说明从图G中取2个点，是不可能覆盖G中的全部7条边的！基于这个上界，可以在分支树中扩展出来的节点进行验证，已知它还可以选择的顶点数目以及还需要覆盖的边的条数，加上顶点的状态（下面会分析说明）即可判断当前节点是否存在解！如果不存在即可进行剪枝了。&lt;/p&gt;
&lt;p&gt;其次，顶点的状态。该策略中顶点有三种状态，分别为已经选择了的状态S1，不选择的状态S2，可以选择的状态S3。其中，不选择的状态S2对应解空间树中的右节点，不选择该节点，然后设置该节点为不选择状态S2。这点很重要，因为有了这个状态，可以使得上界的判断更为精确，因为只能从剩余顶点集中选择那些状态S3的顶点，状态S1和S2都不行，那么上界便会更小，也就更加精确，从而利于剪枝！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(2)贪心策略&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;贪心的策略是指可行的结点都是按照还需要覆盖的剩余边数的降序排列，即，每次选择的节点都是可行节点中还需要覆盖的边数最小的那个节点，因为它最接近结果了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(3)例子分析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;以图G为例，此时e=7（要覆盖的边数），取k=3，图G用邻接矩阵保存为全局数据，计算每个顶点的边数，然后降序排列。&lt;/p&gt;
&lt;p&gt;步骤①判断是否可能有解，Up(e)=3+3+2=8&amp;gt;7，可能有解，那么将图G构造成一个解空间树的节点，它包含了还能选择的点数k=3，还需要覆盖的边数e=7，每个顶点的边数以及按边数大小的降序排列（上表），每个顶点的状态（初始时都是可选择的状态S3）。然后，将该节点插入到优先队列中，该优先队列是用最小堆实现的，按照前面的贪心策略对队列中的节点进行降序排列。&lt;/p&gt;
&lt;p&gt;步骤②取出了优先队列中的根节点，很显然，还需要覆盖的边数为7，不为0，所以还不满足条件。接下来要检查是否能够进行扩展，从顶点集合中选择状态为可以选择的顶点中边数最多的点，该点存在为顶点2，接着进行扩展，扩展左节点时将还能选择的点数k-1=2，然后计算选择了该点之后删除了几条未覆盖的边，得到还需要覆盖的边数e=4，然后更新所有其他顶点的边数，并重新排序，最后将顶点2的状态设置为已经选择了；扩展右节点时，只要将顶点2的状态设置为不能选择，还能选择的点数k(=3)，还需要覆盖的边数e(=7)保持不变。扩展完了之后，同样判断左右节点是否可能有解，如果有解，将该节点插入到优先队列中。这里左右节点都有解，那么将左右节点都插入到优先队列中，因为左节点还需要覆盖的边数e=4小于右节点的e=7，所以根据贪心策略，左节点在右节点的前面。上面两个步骤的图示如下，其中标明了顶点状态颜色。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/dd91f854277fc97760608d5dc85ca608.jpg&quot; width=&quot;690&quot; height=&quot;609&quot;&gt;&lt;/p&gt;
&lt;p&gt;算法然后继续进入步骤②，此时取出的是节点是刚才插入的左节点，很显然，还需要覆盖的边数为4，不为0，所以还不满足条件。接下来要检查是否能够进行扩展，从顶点集合中选择状态为可以选择的顶点中边数最多的点，该点存在为顶点3，接着进行扩展，扩展左节点时将还能选择的点数k-1=1，然后计算选择了该点之后删除了几条未覆盖的边，得到还需要覆盖的边数e=2，然后更新所有其他顶点的边数，并重新排序，最后将顶点3的状态设置为已经选择了；扩展右节点时，只要将顶点3的状态设置为不能选择，还能选择的点数k(=3)，还需要覆盖的边数e(=7)保持不变。扩展完了之后，同样判断左右节点是否可能有解，如果有解，将该节点插入到优先队列中。这里左右节点都不可能有解，那么直接进入步骤②继续循环。上面这一步的图示如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/2ef9178340deab5b77685890f630c4c2.jpg&quot; width=&quot;690&quot; height=&quot;609&quot;&gt;&lt;/p&gt;
&lt;p&gt;算法按照上面的方式不断进行，最后满足条件的分支的过程是：&lt;/p&gt;
&lt;p&gt;①不选择顶点2；②选择顶点3；③选择顶点1；④选择顶点5。&lt;/p&gt;
&lt;p&gt;最后得到的满足条件的解是选择顶点1,3,5。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;(4)复杂度分析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;该算法优先队列使用的是最小堆实现的(O(nlgn))，对顶点按照边排序使用的是快速排序算法(O(nlgn))，解空间树的深度最多为顶点数目n，每层都要进行分支定界，所以每层的时间复杂度为O(nlgn)，所以算法总的时间复杂度为O(n^2 lgn)。但是，为了实现分支定界，每个节点保存的信息量较多，空间复杂度较大。(有木有分析错了，我不太会分析复杂度)&lt;/p&gt;
&lt;p&gt;青橙OJ系统的结果为：时间 156ms 空间 1.0MB&lt;/p&gt;
&lt;p&gt;本人对指针领悟能力有限，C++也是一知半解，OJ只能用C或者C++，所以下面的C++代码效率不高，仅供参考，:-)&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;#include &amp;lt;iostream&amp;gt;
#include &amp;lt;vector&amp;gt;
using namespace std;
#define MAX_NODE 101
#define INDEBUG 0
int8_t graph[MAX_NODE][MAX_NODE];//int -&amp;gt; int8_t
//int edges[MAX_NODE];//0 is redudent
//int nodes[MAX_NODE];//the order of node
int t,m,n,k,a,b;
class VCNode {//Vertex Cover Node
public:
    int p;//points can be used
    int e;//edges to cover!!
    int index[MAX_NODE];//the index of each node in array [node], index[k]=i!!
    int edge[MAX_NODE];//MAX_NODE the edge number of each node, edge[i]=j!!
    int node[MAX_NODE];//the order of the node
    int state[MAX_NODE];//the state of each node ** 0 can be used / 1 used / -1 can not be used
//    int graph[MAX_NODE][MAX_NODE];//the graph on the node//no need,just use the global graph
    // node k is in index[k]=i position in array [node]
    // node i has number of edge[i]=j edges
};
class Minheap {//Min Heap
public:
    vector&amp;lt;VCNode&amp;gt; nodes;

    void insert(VCNode node);
    VCNode popmin();
//  void print();
};
void Minheap::insert(VCNode node) {
    nodes.push_back(node);
    //  cout &amp;lt;&amp;lt; &quot;size is &quot; &amp;lt;&amp;lt; nodes.size() &amp;lt;&amp;lt; endl;//
    int curpos = (int)nodes.size() - 1; // current position
    int parent = (curpos - 1) / 2; //parent position
    while (curpos != parent &amp;amp;&amp;amp; parent &amp;gt;= 0) { //parent is still in heap
        if (nodes[parent].e &amp;gt; nodes[curpos].e) { //swap parent and child
            VCNode temp = nodes[parent];
            nodes[parent] = nodes[curpos];
            nodes[curpos] = temp;
        } else {
            break; //no longer level up!!!
        }
        curpos = parent; //when curpos=parent=0, exit!!!
        parent = (curpos - 1) / 2; //relocate the parent position
    }
}
VCNode Minheap::popmin() {
    VCNode node;
    if (nodes.size() &amp;gt; 0) { //have nodes left
        node = nodes[0]; //get the first element
        nodes.erase(nodes.begin()); //remove the first element
        if (nodes.size() &amp;gt; 0) { //at least have one element more
            VCNode last = nodes[nodes.size() - 1]; //get the last element
            nodes.pop_back(); //pop the last element
            nodes.insert(nodes.begin(), last); //put it in the first place
            int csize = (int)nodes.size(); //current size
            int curpos = 0; //current position

            // rebuild the minheap
            while (curpos &amp;lt; (csize / 2)) { //reach to the last parent node!!
                int left = 2 * curpos + 1; //left child
                int right = 2 * curpos + 2; //right child
                int min = left; //min store the min child
                if (right &amp;lt; csize) { //have left and right childs
                    if (nodes[right].e &amp;lt; nodes[left].e) {
                        min = right;
                    }
                }
                if (min &amp;lt; csize) { //min child exist!!
                    if (nodes[min].e &amp;lt; nodes[curpos].e) { //need to swap current position with child
                        VCNode temp = nodes[min];
                        nodes[min] = nodes[curpos];
                        nodes[curpos] = temp;
                    }else { //min child no exits!! exit!!
                        break; //can break now!!
                    }
                }
                curpos = min;
            }
        }
    }
    return node;
}
//void Minheap::print() {
//  cout &amp;lt;&amp;lt; &quot;print heap&quot; &amp;lt;&amp;lt; endl;
//  for (int i = 0; i &amp;lt; (int)nodes.size(); i++) {
//      cout &amp;lt;&amp;lt; &quot;edge: &quot; &amp;lt;&amp;lt; nodes[i].e &amp;lt;&amp;lt; &quot; node: &quot; &amp;lt;&amp;lt; nodes[i].p &amp;lt;&amp;lt; endl;
//  }
//  cout &amp;lt;&amp;lt; &quot;heap end&quot; &amp;lt;&amp;lt; endl;
//}
// print array
void printArray(int a[], int start, int end){
    if (INDEBUG) {
        cout &amp;lt;&amp;lt; &quot;print array form &quot; &amp;lt;&amp;lt; start &amp;lt;&amp;lt; &quot; to &quot; &amp;lt;&amp;lt; end &amp;lt;&amp;lt; endl;
        for (int i=start; i&amp;lt;=end; i++) {
            cout &amp;lt;&amp;lt; a[i] &amp;lt;&amp;lt; &quot; &quot;;
        }
        cout &amp;lt;&amp;lt; endl &amp;lt;&amp;lt; &quot;print array end&quot; &amp;lt;&amp;lt; endl;
    }
}
// print the graph
void printGraph(int graph[][MAX_NODE]){
    if (INDEBUG) {
        for(int i=1;i&amp;lt;=n;i++){//0 no need
            for(int j=1;j&amp;lt;=n;j++){
                cout &amp;lt;&amp;lt; graph[i][j] &amp;lt;&amp;lt; &quot; &quot;;
            }
            cout &amp;lt;&amp;lt; endl;
        }
    }
}
// partition function for quick sort
int partition2(int a[], int low, int high, int b[]){
    int key = a[high];
    int i=low-1;
    for (int j=low; j&amp;lt;high; j++) {
        if (a[j]&amp;gt;=key) {
            i++;
            swap(a[i], a[j]);
            swap(b[i], b[j]);
        }
    }
    swap(a[high], a[i+1]);
    swap(b[high], b[i+1]);
    return i+1;
}
// quick sort
void quicksort2(int a[], int low, int high, int b[]) {
    if (low &amp;lt; high) {
        int p = partition2(a,low,high, b);
        quicksort2(a, low, p-1, b);
        quicksort2(a, p+1, high, b);
    }
}
// sum of the first k elements with state==0!!!
int sumofkmax(int edges[], int p, int nodes[], int state[]){
    quicksort2(edges, 1, n, nodes);
    int sum=0,count=0;
    // edges[i] corresponse to nodes[i], its state is state[nodes[i]]
    for(int i=1;i&amp;lt;=n;i++){//attention to i range!!
        if (state[nodes[i]]==0) {
            sum+=edges[i];
            count++;
            if (count == p) {//enough!
                break;
            }
        }
    }
    return sum;
}
// verify the current node can be achievable
bool verify(int edges[], int p, int e, int nodes[], int state[]){
    //caculate the sum of the first p max elements in array edges!!
    int sum = sumofkmax(edges, p, nodes, state);
    // edge of nodes[i] is edges[i]!!!
    if(sum &amp;gt;= e){// may be this can be achieved
        return true;
    }
    return false;
}
// build the index of node in array [index]
void buildIndex(int node[],int index[]){
    for (int i=1; i&amp;lt;=n; i++) {
        index[node[i]] = i;
    }
}
// get the next node: state==0 &amp;amp;&amp;amp; order first!!!
int nextNode(int state[], int nodes[]){
    for (int i=1; i&amp;lt;=n; i++) {
        if (state[nodes[i]]==0) {
            return nodes[i];
        }
    }
    return -1;
}
// generate the left child
VCNode genLeft(VCNode curnode, int label){
    VCNode left;//choose node label!
    left.p = curnode.p - 1;//remove one node
    left.e = curnode.e;
    for (int i=0; i&amp;lt;=n; i++) {//first copy all infos
        left.index[i]=curnode.index[i];
        left.state[i]=curnode.state[i];//init node state
        left.edge[i]=curnode.edge[i];//copy edge info
        left.node[i]=curnode.node[i];//copy node info
//        for (int j=0; j&amp;lt;=n; j++) {
//            left.graph[i][j] = curnode.graph[i][j];
//        }
    }
    // following code will not use curnode anymore!!

    ///
    int sum=0;//removed edge
    for (int j=1; j&amp;lt;=n; j++) {
        //new
        if (label &amp;lt; j &amp;amp;&amp;amp; left.state[j]!=1 &amp;amp;&amp;amp; graph[label][j]==1 ) {//row!
            sum++;
//            left.graph[label][j]=0;
            left.edge[left.index[j]]--;//how to cut it down
        }else if(label &amp;gt; j &amp;amp;&amp;amp; left.state[j]!=1 &amp;amp;&amp;amp; graph[j][label]==1 ){ // col
            sum++;
//            left.graph[j][label]=0;
            left.edge[left.index[j]]--;//how to cut it down
        }
    }
    ///

    left.state[label] = 1;//use label directly!
    left.edge[left.index[label]] = 0;//only use index!!
//    cout &amp;lt;&amp;lt; &quot;remove edge sum is &quot; &amp;lt;&amp;lt; sum &amp;lt;&amp;lt; endl;
    quicksort2(left.edge, 1, n, left.node);
    left.e = left.e - sum;//remove some edges
    buildIndex(left.node, left.index);

    if (INDEBUG) {
        cout &amp;lt;&amp;lt; &quot;======== &quot; &amp;lt;&amp;lt; label &amp;lt;&amp;lt; &quot; gen left begin===========&quot; &amp;lt;&amp;lt; endl;
        cout &amp;lt;&amp;lt; &quot;edge is &quot; &amp;lt;&amp;lt; left.e &amp;lt;&amp;lt; &quot; node is &quot; &amp;lt;&amp;lt; left.p &amp;lt;&amp;lt; endl;
        cout &amp;lt;&amp;lt; &quot;array edge:&quot; &amp;lt;&amp;lt; endl;
        printArray(left.edge,1,n);
        cout &amp;lt;&amp;lt; &quot;array node:&quot; &amp;lt;&amp;lt; endl;
        printArray(left.node, 1, n);
        cout &amp;lt;&amp;lt; &quot;array index:&quot; &amp;lt;&amp;lt; endl;
        printArray(left.index, 1, n);
        cout &amp;lt;&amp;lt; &quot;array state:&quot; &amp;lt;&amp;lt; endl;
        printArray(left.state, 1, n);
//        printGraph(left.graph);
        cout &amp;lt;&amp;lt; &quot;======== &quot; &amp;lt;&amp;lt; label &amp;lt;&amp;lt; &quot; gen left end===========&quot; &amp;lt;&amp;lt; endl;
    }

    return left;
}
// generate the right child
VCNode genRight(VCNode curnode, int label){
    VCNode right;//choose node label!
    right.p = curnode.p;//remain
    right.e = curnode.e;
    for (int i=0; i&amp;lt;=n; i++) {//first copy all infos
        right.index[i]=curnode.index[i];
        right.state[i]=curnode.state[i];//init node state
        right.edge[i]=curnode.edge[i];//copy edge info
        right.node[i]=curnode.node[i];//copy node info
//        for (int j=0; j&amp;lt;=n; j++) {
//            right.graph[i][j] = curnode.graph[i][j];
//        }
    }
    // following code will not use curnode anymore!!
    right.state[label] = -1;//use label directly!

    if (INDEBUG) {
        cout &amp;lt;&amp;lt; &quot;======== &quot; &amp;lt;&amp;lt; label &amp;lt;&amp;lt; &quot; gen right begin===========&quot; &amp;lt;&amp;lt; endl;
        cout &amp;lt;&amp;lt; &quot;edge is &quot; &amp;lt;&amp;lt; right.e &amp;lt;&amp;lt; &quot; node is &quot; &amp;lt;&amp;lt; right.p &amp;lt;&amp;lt; endl;
//        cout &amp;lt;&amp;lt; &quot;array edge:&quot; &amp;lt;&amp;lt; endl;
//        printArray(right.edge,1,n);
//        cout &amp;lt;&amp;lt; &quot;array node:&quot; &amp;lt;&amp;lt; endl;
//        printArray(right.node, 1, n);
//        cout &amp;lt;&amp;lt; &quot;array index:&quot; &amp;lt;&amp;lt; endl;
//        printArray(right.index, 1, n);
//        cout &amp;lt;&amp;lt; &quot;array state:&quot; &amp;lt;&amp;lt; endl;
//        printArray(right.state, 1, n);
//        printGraph(right.graph);
        cout &amp;lt;&amp;lt; &quot;======== &quot; &amp;lt;&amp;lt; label &amp;lt;&amp;lt; &quot; gen right end===========&quot; &amp;lt;&amp;lt; endl;
    }

    return right;
}
// greedy find a way to solve VCP
void greedyFind(int edges[], int nodes[]/*, int graph[][MAX_NODE]*/){
    VCNode node;
    node.e = m;
    node.p = k;

    for (int i=0; i&amp;lt;=n; i++) {
        node.index[i]=0;
        node.state[i]=0;//init node state
        node.edge[i]=edges[i];//copy edge info
        node.node[i]=nodes[i];//copy node info
//        for (int j=0; j&amp;lt;=n; j++) {
//            node.graph[i][j] = graph[i][j];
//        }
    }
    buildIndex(node.node, node.index);

    Minheap minheap;
    minheap.insert(node);

    while (minheap.nodes.size() &amp;gt; 0) {
        // get the heap top node to extend
        VCNode curnode = minheap.popmin();

//        if (INDEBUG) {
//            cout &amp;lt;&amp;lt; &quot;...current graph...&quot; &amp;lt;&amp;lt; endl;
//            printGraph(curnode.graph);
//        }

        // validate the current node
        if (curnode.e == 0) {
            int points = k - curnode.e;
            cout &amp;lt;&amp;lt; points &amp;lt;&amp;lt; endl;
            int count = 1;
            for (int i=1; i&amp;lt;=n; i++) {
                if (curnode.state[i]==1) {
                    if(count == points){
                        cout &amp;lt;&amp;lt; i;
                    }else{
                        cout &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &quot; &quot;;
                    }
                    count++;
                }
            }
            cout &amp;lt;&amp;lt; endl;
            return;
        }

        // generate child nodes
        int label = nextNode(curnode.state, curnode.node);//the label of the node
        if (label != -1) {
            // node i is in index[k] position in array [node]
            // node i has number of edge[i] edges
            VCNode left = genLeft(curnode, label);
            VCNode right = genRight(curnode, label);
            if (verify(left.edge, left.p, left.e, left.node, left.state)) {
//                cout &amp;lt;&amp;lt; &quot;insert &quot; &amp;lt;&amp;lt; label &amp;lt;&amp;lt; &quot; left&quot; &amp;lt;&amp;lt; endl;
                minheap.insert(left);
            }
            if (verify(right.edge, right.p, right.e, right.node, right.state)) {
//                cout &amp;lt;&amp;lt; &quot;insert &quot; &amp;lt;&amp;lt; label &amp;lt;&amp;lt; &quot; right&quot; &amp;lt;&amp;lt; endl;
                minheap.insert(right);
            }
        }

    }

    // if not find, then return -1
    cout &amp;lt;&amp;lt; -1 &amp;lt;&amp;lt; endl;

}
int main() {
//    freopen(&quot;/Volumes/hujiawei/Users/hujiawei/workspace/appleworkspace/algorithmworks/Exp1-2/Exp1-2/in3.txt&quot;, &quot;rt&quot;, stdin);//
    cin &amp;gt;&amp;gt; t;
    while(t--&amp;gt;0){
        cin &amp;gt;&amp;gt; n &amp;gt;&amp;gt; m &amp;gt;&amp;gt; k;
//        int graph[n+1][MAX_NODE];
        for (int i=0; i&amp;lt;= n; i++) {
            for (int j=0; j&amp;lt;= n; j++) {
                graph[i][j]=0;
            }
        }
        int edges[n+1], nodes[n+1], state[n+1];
        for (int i=0; i&amp;lt;= n; i++) {
            edges[i]=0;
            state[i]=0;
            nodes[i]=i;
        }
        int temp = m;
        while(temp--&amp;gt;0){
            cin &amp;gt;&amp;gt; a &amp;gt;&amp;gt; b;
            graph[min(a, b)][max(a,b)]=1;
//          graph[a][b]=1;
//          graph[b][a]=1;//just save half a&amp;lt;=b
            edges[a]++;
            edges[b]++;
        }
        bool flag = verify(edges, k, m, nodes, state);

        if (!flag) {//must not be achieved!!!
            cout &amp;lt;&amp;lt; -1 &amp;lt;&amp;lt; endl;
        }else{
            greedyFind(edges,nodes/*,graph*/);
        }
    }

    return 0;
}&lt;/pre&gt;


        
        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Thu, 21 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-21-87009-b4822702a.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-21-87009-b4822702a.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>选择合适的推荐系统模型</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;&lt;img class=&quot;alignright&quot; id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/9de852c7fc29681d649e4da5cb2281e5.jpg&quot; width=&quot;250&quot; height=&quot;270&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们的机器学习工程师一直忙于构建GraphLab farm。这篇博客针对一个特殊的应用难题：怎样从 &lt;a href=&quot;https://dato.com/products/create/docs/graphlab.toolkits.recommender.html?__hstc=8457130.bb311fd08c8f8aff1469489de1cfa928.1429598917018.1429598917018.1429604555369.2&amp;amp;__hssc=8457130.13.1429604555369&amp;amp;__hsfp=4211374419&quot;&gt;GraphLab Create recommender toolkit&lt;/a&gt; 的众多模型和选项中选择一个合适的推荐模型。&lt;/p&gt;
&lt;p&gt;这完全取决于你现有的数据类型以及你评估结果的方式。&lt;/p&gt;
&lt;p&gt;（注意：这里使用的是GraphLab Create 0.9 的API。GraphLab Create 1.0 支持通过&lt;a href=&quot;https://dato.com/products/create/docs/generated/graphlab.recommender.create.html?__hstc=8457130.bb311fd08c8f8aff1469489de1cfa928.1429598917018.1429598917018.1429604555369.2&amp;amp;__hssc=8457130.1315131713151319.1429604555369&amp;amp;__hsfp=4211374419#graphlab.recommender.create&quot;&gt;recommender.create()&lt;/a&gt; 来智能选择推荐模型。你可以通过 &lt;a href=&quot;https://dato.com/products/create/docs/&quot;&gt;1.0 的API文档&lt;/a&gt;查看recommender toolkit中模型的最新说明。此外，这个论坛列出了&lt;a href=&quot;http://forum.dato.com/discussion/610/api-changes-in-graphlab-create-v1-0-toolkits?__hstc=8457130.bb311fd08c8f8aff1469489de1cfa928.1429598917018.1429604555369.1429606046033.3&amp;amp;__hssc=8457130.2.1429606046033&amp;amp;__hsfp=4211374419&quot;&gt;从版本0.9.1到版本1.0的API变动&lt;/a&gt;。）&lt;/p&gt;
&lt;p&gt;如果你的数据是隐性的，也就是数据中仅有用户和物品间的交互信息（没有用户对物品的打分），那么，你可以选择使用Jaccard相似度的 &lt;a href=&quot;https://dato.com/products/create/docs/generated/graphlab.recommender.item_similarity_recommender.ItemSimilarityRecommender.html?__hstc=8457130.bb311fd08c8f8aff1469489de1cfa928.1429598917018.1429604555369.1429606046033.3&amp;amp;__hssc=8457130.3.1429606046033&amp;amp;__hsfp=4211374419#graphlab.recommender.item_similarity_recommender.ItemSimilarityRecommender&quot;&gt;ItemSimilarityModel&lt;/a&gt;。&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;# 当数据中仅包含&#39;user_id&#39;和&#39;item_id&#39;两个属性的时候
# recommender.create 方法会自动选择
# `method=‘item_similarity’` and `similarity_type=’jaccard’`
&amp;gt;&amp;gt;&amp;gt; itemsim_jaccard_model = graphlab.recommender.create(data)&lt;/pre&gt;
&lt;p&gt;当数据为隐反馈时，你可以通过增加一个均为1的目标列把数据伪装成显性数据。若要构建追求排序性能的模型，请见下文。&lt;/p&gt;
&lt;p&gt;如果数据是显性的，也就是观测数据中包含用户的真实评分，那么你可以从多个模型中选择。使用cosine或Pearson相似度的ItemSimilarityModel可以包含评分信息。此外，&lt;a href=&quot;https://dato.com/products/create/docs/graphlab.toolkits.recommender.html#factorization-recommenders&quot;&gt;MatrixFactorizationModel&lt;/a&gt;（矩阵分解模型）、&lt;a href=&quot;https://dato.com/products/create/docs/graphlab.toolkits.recommender.html#factorization-recommenders&quot;&gt;FactorizationModel&lt;/a&gt;（分解模型） 以及 &lt;a href=&quot;http://products/create/docs/generated/graphlab.recommender.LinearRegressionModel.html&quot;&gt;LinearRegressionModel&lt;/a&gt;（线性回归模型） 都支持评分预测。&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;# 此时数据中包含 3 列，‘user_id’，‘item_id’ 以及 ‘rating’
&amp;gt;&amp;gt;&amp;gt; itemsim_cosine_model = graphlab.recommender.create(data, 
       target=’rating’, 
       method=’item_similarity’, 
       similarity_type=’cosine’)
&amp;gt;&amp;gt;&amp;gt; factorization_machine_model = graphlab.recommender.create(data, 
       target=’rating’, 
       method=’factorization_model’)&lt;/pre&gt;
&lt;p&gt;如果你的目标是提高排序性能，你可以在设置 ranking_regularization 的情况下使用 ItemSimilarityModel（物品相似度模型）、MatrixFactorizationModel（矩阵分解模型） 、 FactorizationModel（分解模型）。排序正则化选项设置后会随机地选取一些未观测数据并把它们的目标评分设成一个偏负面的值。ranking_regularization 值在0到1之间。该值越大，负样本的权重也就越大。如果你想使用 分解模型来处理隐反馈数据，你应该首先给 SFrame 增加一列全为1的值把它变成显性数据，再将 unobserved_rating_value 设为 0 来运行排序正则化。这里明确地设定 unobserved_raint_value 是有必要的，因为模型默认把未知评分设为已知评分的 5% 分位数；当所有已知评分均为 1 时，它们的 5% 分位数也是 1，不能把它作为未知评分的目标值。&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;# 数据中包含一列真实的评分
&amp;gt;&amp;gt;&amp;gt; ranking_regularization_model = graphlab.recommender.create(data, 
       target=’rating’, 
       method=’matrix_factorization’, 
       ranking_regularization=1.0)

# 数据中包含一列“伪造”的评分，全部为 1
&amp;gt;&amp;gt;&amp;gt; rr_model_for_implicit_data = graphlab.recommender.create(data, 
       target=’rating’, 
       method=’matrix_factorization, 
       ranking_regularization=1, 
       unobserved_rating_value=0)&lt;/pre&gt;
&lt;p&gt;如果你想对评分数据进行评分预测，那么选择MatrixFactorizationModel, FactorizationModel, or LinearRegressionModel的任意一个。从统计学的角度看，这三个模型都是明确地对评分建模的回归模型。换句话说，观测评分被建模为一些项的加权组合，其中权重（包括一些项，也被成为因子）通过训练数据得到。这几个模型都可以很方便地引入用户或物品特征。&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;# 当数据包含一列目标值时，默认的方法是 matrix_factorization
&amp;gt;&amp;gt;&amp;gt; matrix_factorization_model = graphlab.recommender.create(data, 
       target=’rating’)
&amp;gt;&amp;gt;&amp;gt; linear_model = graphlab.recommender.create(data, 
       target=’rating’, 
       method=’linear_model’)
&amp;gt;&amp;gt;&amp;gt; factorization_machine_model = graphlab.recommender.create(data, 
       target=’rating’, 
       method=’factorization_model’)&lt;/pre&gt;
&lt;p&gt;LinearRegressionModel 假设评分是用户特征、物品特征、用户偏置、物品流行度偏置的线性组合。MatrixFactorizationModel 和 FactorizationModel 还可以引入两个向量的内积项，其中一个向量表示用户对一组隐性特征的喜好程度，另一个向量表示物品对这组隐性特征的包含程度。这些通常被称为隐性因子并且可以从观测数据中自动学习得到。FactorizationModel （分解模型）较 MatrixFactorizationModel（矩阵分解模型） 更进一步， 考虑到了这些隐性因子与边际特征的交互影响。一般来说，FactorizationModel（分解模型） 最有效，但也最难训练（由于它的威力和灵活性）。LinearRegressionModel（线性回归模型） 最简单，训练速度也最快，但没有考虑用户物品间的交互作用。&lt;/p&gt;
&lt;p&gt;我们建议你从 &lt;a href=&quot;https://dato.com/products/create/docs/graphlab.toolkits.recommender.html#factorization-recommenders&quot;&gt;MatrixFactorizationModel（矩阵分解模型）&lt;/a&gt; 开始，如果这个模型运行时间过长，可以降级使用 &lt;a href=&quot;http://products/create/docs/generated/graphlab.recommender.LinearRegressionModel.html&quot;&gt;LinearRegressionModel&lt;/a&gt;（线性回归模型）。或者，如果你认为需要使用二阶交互项来加强模型，可以升级使用 &lt;a href=&quot;https://dato.com/products/create/docs/graphlab.toolkits.recommender.html#factorization-recommenders&quot;&gt;FactorizationModel（分解模型）&lt;/a&gt;。注意，这些模型都带有几个正则化参数如：n_factors 和 regularization，这些参数会影响测试时的预测精度。这对于 FactorizationModel&lt;a href=&quot;https://dato.com/products/create/docs/graphlab.toolkits.recommender.html#factorization-recommenders&quot;&gt;（分解模型）&lt;/a&gt; 尤为有用。建议你使用超参数搜索函数 &lt;a href=&quot;https://dato.com/products/create/docs/generated/graphlab.toolkits.model_parameter_search.html#graphlab.toolkits.model_parameter_search&quot;&gt;graphlab.toolkits.model_params_search()&lt;/a&gt; 来调整这些参数。&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;# 这里强调了回归模型中一些有用的参数选项
&amp;gt;&amp;gt;&amp;gt; custom_mf_model = graphlab.recommender.create(data, 
       target=’rating’, 
       n_factors=20, 
       regularization=0.2, 
       linear_regularization=0.1)
&amp;gt;&amp;gt;&amp;gt; custom_fm_model = graphlab.recommender.create(data, 
       target=’rating’, 
       method=’factorization_model’, 
       n_factors=50, 
       regularization=0.5, 
       max_iterations=100)
&amp;gt;&amp;gt;&amp;gt; custom_linear_model = graphlab.recommender.create(data, 
       target=’rating’, 
       method=’linear_model’, 
       regularization=0.01)&lt;/pre&gt;
&lt;p&gt;如果目标评分是二值的，也就是它们的值是赞或踩标签，在使用回归模型（LinearRegressionModel, MatrixFactorizationModel, FactorizationModel）时，设置输入参数‘binary_targets = True’。&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;&amp;gt;&amp;gt;&amp;gt; logistic_regression_model = graphlab.recommender.create(data, 
       target=’rating’, 
       method=’linear_model’, 
       binary_targets=True)&lt;/pre&gt;
&lt;p&gt;使用MatrixFactorizationModel（矩阵分解模型） 和 FactorizationModel （分解模型）训练得到的隐性因子可以作为特征用于其他的任务。在这种情形下，使用非负因子有利于提高可解释性。简单地使用‘nmf=True’作为输入参数，分解类型的模型就会学习非负因子。&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;&amp;gt;&amp;gt;&amp;gt; nmf_model = graphlab.recommender.create(data, 
       target=’rating’, 
       method=’matrix_factorization’, 
       nmf=True)&lt;/pre&gt;
&lt;p&gt;已有数据？数据问题？&lt;/p&gt;
&lt;p&gt;最后，有几个影响推荐系统性能的常见数据问题。第一，如果观测数据非常稀疏，也就是仅包含大量用户的一个或两个观测数据，那么任何一个模型都不会比 popularity 或 item_means 这些基准模型效果好。这种情况下，将稀疏用户和物品剔除后重试也许有用。另外，重新检查数据收集和清理过程，看错误是否源于此处。尽可能对每个用户每个物品获取更多的观测数据。&lt;/p&gt;
&lt;p&gt;另一个经常会遇到的问题是把使用数据当做评分。与显性评分位于一个很好的线性区间（例如，[0, 5]）不同，使用数据可能被严重扭曲。例如，在 Million Song 数据集中，一个用户播放一首歌超过 16000 次。所有的模型都很难应对这种严重扭曲的目标。解决的方法是对使用数据进行归类。例如，把播放次数超过 50 次映射成最高评分 5 。你也可以把播放次数转成二进制，例如播放超高两次的为 1，反之为 0。&lt;/p&gt;
&lt;p&gt;好吧，都记住了吗？是的，我们一半都记不住。下面这幅粗略的信息图一目了然地显示了所有的提示。愉快地探索吧，勇敢地推荐系统研究者！&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/80a4b4486df3643cd0434e03edb63893.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;欲了解更多信息，请查看我们最新的 &lt;a href=&quot;https://dato.com/learn/?__hstc=8457130.bb311fd08c8f8aff1469489de1cfa928.1429598917018.1429604555369.1429606046033.3&amp;amp;__hssc=8457130.5053.1429606046033&amp;amp;__hsfp=4211374419&quot;&gt;copious documentation&lt;/a&gt;，让我们知道你的想法。&lt;/p&gt;

        
        &lt;!-- BEGIN #author-bio --&gt;

&lt;div id=&quot;author-bio&quot;&gt;
	
	&lt;h3 class=&quot;widget-title&quot;&gt;
	关于作者： &lt;a href=&quot;http://blog.jobbole.com/author/wuwenmin/&quot;&gt;吴文敏&lt;/a&gt;
	&lt;/h3&gt;
	&lt;div class=&quot;alignleft&quot;&gt;
		&lt;a href=&quot;http://blog.jobbole.com/author/wuwenmin/&quot;&gt;
					&lt;/a&gt;
	&lt;/div&gt;
	&lt;p&gt;&lt;/p&gt;
	&lt;p&gt;
		&lt;a style=&quot;text-decoration: none;&quot; href=&quot;http://blog.jobbole.com/author/wuwenmin/&quot;&gt;查看吴文敏的更多文章 »&lt;/a&gt;
	&lt;/p&gt;
	&lt;div class=&quot;clear&quot;&gt;&lt;/div&gt;
	
&lt;/div&gt;

&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Wed, 20 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-20-86959-580bc7b77.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-20-86959-580bc7b77.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>计算机中的黑魔法：尾递归</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;h1&gt;&lt;span style=&quot;color: #888888&quot;&gt;前言&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;声明：本文是作者在学习SICP有关过程抽象知识的理解，由于书中的语句有些晦涩，所以将作者的理解共享给大家希望帮助一些朋友。原书对尾递归并没有太多介绍，但是这里给出了详细的解释。&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888&quot;&gt;目前是凌晨1点48分。嗯，刚刚写完这篇日志。忍不住想说点什么，或许是当一个不好的书托。可能这些内容对于很多人来说是没有用的，他们甚至会鄙视我写的东西，觉得为这些东西花费时间不值得。对于这些人，我想说，每一个对计算机有着浓厚兴趣的人，都有着一个想够彻头彻尾了解每天超过12小时面对的这台机器是如何工作的愿望。像SICP和CSAPP这种书无疑是枯燥的，你可能一天看下来，仔细品读的话只能看三四页，但是如何你能够真正理解这几页书的内涵的话，那么收获将是巨大的。从去年5月份，陈大师推荐我读CSAPP之后，我才真正找到了那种看上去很枯燥，但是一读起来就欲罢不能的书。这类的书读起来都很困难，如果你带着很强的功利性来读的话，是不可能读下去的。我想了想，能够支撑我一天坐在那琢磨这几页书中说的核心意思的力量，就是来源于我真正想了解计算机是怎么工作的，获取这种信息对于我来说是非常快乐的，这种感觉是奇妙的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ab56a77632a24837eb629fed5f2507df.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（图来自 www.cs.uni.edu）&lt;/p&gt;
&lt;h1&gt;函数和计算过程的区别&lt;/h1&gt;
&lt;p&gt;函数一般是指数学上面的一种计算形式，偏向说明语句，描述如何根据给定的一个或者几个参数去计算出一个值。如SICP中关于求一个数的平方根的函数，我们在该函数的说明中可以推断出关于平方根的一些具体性质和一般性的事实，但是我们无从得知计算一个数的平方根的具体方法。你可能会说，求平方根不就是开根号么。可是你有没有想过，[开根号]也仅仅是一个说明性的语句，具体怎么计算你还是不知道的。延伸到计算机当中的函数，其实和数学上面的函数意义是相同的，我们只不过是换成高级程序设计语言来写我们对于一个函数一般性事实的说明，实际上我们并没有给出一个具体的计算过程。比如求平方根，如果我们是调用math.h中的库函数来求的话：sqrt(x*1.0)，这种形式只是一个说明型的语句，我们利用这个语句来指导计算机去计算，但实际上这个函数并没有提供具体的计算过程。计算机当中的解释器就负责把这种说明性语句转化成真正的计算过程(期待到时候写一个解释器哇)。&lt;/p&gt;
&lt;p&gt;其实感觉这两者的区别就和写作文一样，一个是提纲，另外一个是具体的内容。&lt;/p&gt;
&lt;h1&gt;触摸过程的抽象&lt;/h1&gt;
&lt;p&gt;SICP中关于求一个数平方根的问题，使用的是牛顿的逐步逼近法则，不断的去求新的猜测值，直到结果满足一定的精度结束。求平方根是一个大的功能，想要完成这个大的功能还需要一些小的功能来辅助。&lt;/p&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;我们把整个一个大的计算过程分为几个部分，每一个部分都能单独完成其中的一个小功能，他们组合起来又能够完成最终的功能。所谓过程的抽象和C++中的面向对象思想是和相像的，没准都是一个东西，我不太确定，但是过程的抽象说的都是一个意思，就是对创造者来说重要的是过程的实现，而对于使用者来说，过程的抽象可以屏蔽掉内部实现的细节，从而减轻使用者的负担，只关心这个过程的『黑盒』能够做什么。所以这样一来就增加了程序局部的可替换性，因为对于实现一个功能来说，过程的内部实现可以多种多样。&lt;/p&gt;
&lt;h2&gt;抽象1—局部名字&lt;/h2&gt;
&lt;p&gt;大家都知道调用函数或者过程的时候，有的时候需要传递一些合适的参数，在调用的过程中，函数的形式参数的名字对我们来说其实并不重要，相对于使用者来说确实是这样。但是对于过程的设计者来说，形式参数的名字，或者说是局部变量的名字，对于整个过程能够正常的执行就非常重要了。这也是过程抽象当中的一个细节，计算机把一些复杂的东西封装到了内部。&lt;/p&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;为什么说约束变量的名字对于过程的执行是非常重要的呢。很直接的一个理解就是：局部变量可以在作用域内可以屏蔽同名的全局变量，类比一下，约束变量在相应的作用域内会屏蔽同名的自由变量。&lt;/p&gt;
&lt;pre&gt;    (define (good-enough? guess x)
    ((abs (- (square guess) x)) 0.001))&lt;/pre&gt;
&lt;p&gt;举例来讲，在上面这个过程中，guess 和 x 是good-enough?这个过程的两个约束变量，&amp;lt;, abs, -, square都是自由变量。自由变量是和环境相关的，他们已经有了确定的意义来保持他们正常的执行，但是如果现在guess这个约束变量改名为abs，将会导致abs这个自由变量的意义被约束变量屏蔽，过程中出现的abs为约束变量，不在具有自由变量当中求绝对值的功能。&lt;/p&gt;
&lt;p&gt;所以说，对于过程的设计者而言，过程实现中，自由变量和约束变量的名字都在哪些地方用到是一个非常需要注意的地方，一个过程的顺利执行依赖于约束变量和自由变量的名字不同，并且自由变量的意义正确。&lt;/p&gt;
&lt;h2&gt;抽象2—内部定义和块结构&lt;/h2&gt;
&lt;p&gt;这一点的抽象就更加为我们过程的使用者考虑，它也是一种局部的概念，像局部变量一样，只有内部的作用域可以访问并且识别他，作用域之外是不知道作用域内有这个东西的。只不过我们之前抽象的是变量，这次抽象的是过程。&lt;/p&gt;
&lt;p&gt;sicp中的求平方根的过程，和用户交互的仅仅是一个接口sqrt，其中的子过程的具体实现细节都被抽象一个个的【黑箱】。但是对于用户来说，这些实现计算过程的黑箱是没有用的，只会扰乱他们的思维，并且在用户想自定义一个与这些黑箱中的某一个同名的过程的时候是不被允许的（不能在一个作用域内定义两个同名的过程），这些有着具体功能的【黑箱】污染了全局名字环境。&lt;/p&gt;
&lt;p&gt;对于一个结构局部的东西，我们更好的方式是把他们定义在这个结构的内部，而不应该放在全局环境范围内，因为你需要的并不是其他人也需要的，如果其他人不需要这些东西，那么他们的命名就有可能造成过程调用的命名冲突，造成程序混乱。&lt;/p&gt;
&lt;p&gt;scheme支持在过程的内部再定义新的过程，内部新定义的过程只能在内部作用域可见，外部是不知道有内部这些过程的定义的。&lt;/p&gt;
&lt;pre&gt;(define (sqrt x)
    (define (good-enough? guess x)
        (abs (- (square guess) x)) 0.001)) 

    (define (improve guess x)
        (average guess (/ x guess))) 

    (define (sqrt-iter guess x)
        (if (good-enough? guess x) guess
        (sqrt-iter (improve guess x) x))) 

(sqrt-iter 1.0 x))&lt;/pre&gt;
&lt;p&gt;根据上面的例子来看，我们就把求平方根这计算过程中用到的小黑箱一个一个的都定义在了这个过程的内部 ，过程之外看不到他们，这种嵌套的过程定义就叫做块结构。局部化使程序更清晰,减少全局名字,减少相互干扰。除此之外，由于将一些黑箱进行了内部定义之后，还有一处可以改进的地方，就是参数x的使用。由于局部过程的形参都在x的作用域内，我们就不必在局部过程中再传递x了，直接调用即可。相对于局部过程来说，现在的X由原来的约束变量，变为现在的自由变量了。&lt;/p&gt;
&lt;h1&gt;计算过程的多重形态&lt;/h1&gt;
&lt;p&gt;我们可以用不同种类的过程来完成同一件任务，那么在真正的程序设计的时候，我们应该选用哪种方式呢？按照之前数据结构的角度来看，我们有两个指标：时间复杂度和空间复杂度。不同的过程自然有这不同的计算过程，我们应该通过衡量两个不同计算过程的上述的两个指标来确定最终选择哪一个作为最终版本。这就要求我们能够准确的观察到任何一个过程执行的过程和执行的效果，以及执行过程中所耗费的各种资源。&lt;/p&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;在以实例说明递归和迭代的区别之前，首先要明确这样两个概念的区别：&lt;/p&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;假如现在有一个求n的阶乘的需求：我们有正向和逆向两种思路来求得结果&lt;/p&gt;
&lt;h2&gt;反向（线性递归）&lt;/h2&gt;
&lt;p&gt;算法如下：n! = n &lt;em&gt; (n-1)! = n &lt;/em&gt; (n-1) &lt;em&gt; (n-2)!…..2 &lt;/em&gt; 1 = n * (n-1)!&lt;/p&gt;
&lt;p&gt;有了具体的计算进程，我们可以根据它来写一个过程&lt;/p&gt;
&lt;pre&gt;(define (factorial n)
     (if (= n 1)
        1
    (* n (factorial (- n 1)))))&lt;/pre&gt;
&lt;p&gt;PS:可以看出这个过程在定义的时候调用了自身&lt;/p&gt;
&lt;p&gt;假设现在我们想计算（factorial 6），根据shceme的代换模型推导，可以得出如下计算进程图示：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/25da0b10dcd44f2b21b9b4f55ce481c5.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;从图示中我们可以看出，当我们计算（factorial 6）的时候，根据计算过程的定义，要执行(* 6 (factorial (- 6 1)))。通过这一个复合的表达式我们就可以看出来，（factorial 6）这一步的计算结果并没有计算出来，它需要计算下一个状态来辅助它得出（factorial 6）这一步的计算结果。因为本次的计算没有完成要进行其他的运算来辅助完成，那么本次的运算就算是中断了，既然中断了，我们就需要保存现场，保存此次计算过程目前的状态（变量等等一些资源）以便当下一状态的计算结果出来之后能够顺利的衔接上，从而计算出最终的结果。以后的计算进程仍然是按照这种形式来的，直到遇到边界。&lt;/p&gt;
&lt;p&gt;到此为止，我们就知道，这个计算进程是一个递归计算进程，因为他在计算的进程当中需要耗费资源来保存所需的一些情况和信息。递归的计算过程，想必大家都很熟悉，它是属于一种推迟求值的方式，不能够立即求出最终结果，每一次的计算都依赖于它的子计算状态，直到遇到边界之后，才逐层返回计算结果，最终返回到起点，求出结果。可以说，递归是从后向前推的过程，计算最后一步，也就是最终结果，也许就会需要倒数第一步的结果，那么就计算倒数第一步，以此类推，直到计算到第一步的时候，利用题设条件可以得到第一步的最终结果，然后再把计算结果逐层返回到起点，也就是计算最后一步的位置，得到最终结果。（是深度优先搜索的道理）但是如果计算的次数太多，迭代的层数太深，留给过程的栈空间很有可能会溢出，造成爆栈。&lt;/p&gt;
&lt;p&gt;那么，根据上面的时间和空间复杂度两个指标，我们将评判这个用递归计算阶乘的计算进程的好坏。（其实计算进程就是算法，有木有？！）&lt;/p&gt;
&lt;p&gt;我们可以看到，如果n是6，那么一共要计算12次，如果n是5那么要计算10次，所以相应的时间复杂度大致可以估算为O(N)。从（factorial 6）递归到边界最低端的时候，一共进行了6次迭代，随着n的增加，递归的次数会随n线性增长，所需的内存空间也会线性增长。所以控件复杂度应为O(N)。&lt;/p&gt;
&lt;p&gt;综上所述，整个递归计算进程已经评价完毕，准确的说，这是一个线性递归计算进程。&lt;/p&gt;
&lt;h2&gt;正向（线性迭代）&lt;/h2&gt;
&lt;p&gt;算法：n!就是从1开始一直累乘到n，最终的累乘结果等于n!&lt;/p&gt;
&lt;p&gt;根据这个算法，写出一个过程如下&lt;/p&gt;
&lt;pre&gt;(define (factorial n) 
    (fact-iter 1 1 n))
(define (fact-iter product counter max-count)
    (if ( counter max-count) product
        (fact-iter (* counter product) (+ counter 1)
                max-count)))&lt;/pre&gt;
&lt;p&gt;从上述的过程我们可以看出，它在定义的时候，也是调用了自身。计算（factorial 6）的进算进程图示如下：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ecf75d30b77c4e3917accee286c35c89.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;根据图示可以看出，每一次的计算状态由三个变量来维持，而且每一个状态的计算和其他状态的计算是独立的，各自状态的计算结果不依赖于其他的状态。每一次状态的计算都是干脆利落的执行，下一个状态计算所需要的资源通过参数传递，上一个状态计算完成之后就没有任何用处了，它不必为前一个或者后一个状态来保存什么有用的信息，需要的信息都根据参数传递给新的状态了。而且，在不断计算的过程中，由于把所需要的值的信息一直作为参数传递，一旦得出了最终的结果，不用像递归一样，把计算结果返回给上一个状态，而是直接返回给一开始的调用者。过程的调用都是在栈空间来开辟内存的，根据以上计算特点，上一个状态计算结束之后可以立即销毁之前所用的栈空间，避免了栈溢出。&lt;/p&gt;
&lt;p&gt;这样的计算进程，很容易就可以看出来，时间复杂度O(N)，空间复杂度，因为每次计算只需要保存三个变量，它不随n的变化而变化，则为O（1）,常量级。不仅仅是这个计算过程这样，计算机当中所有的计算的空间复杂度都应该在常数级别下完成，因为内存空间是有限的。&lt;/p&gt;
&lt;p&gt;上述计算进程被称为迭代，如果单就这个实例来说，应该是线性迭代进程。&lt;/p&gt;
&lt;h2&gt;迭代和递归的区别&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;在迭代的进程中，每个状态计算所需的信息都保存在了几个变量中，通过参数传递过去，不需要额外的再开辟栈空间来保存一些隐含的信息。但是递归是需要的，还存在着栈溢出的危险。&lt;/li&gt;
&lt;li&gt;在迭代的进程中，如果我们丢失了一些状态的话，可以从任意一个状态开始继续进行计算，因为计算所需要的信息都保存在几个变量中，即使只剩下中间的一个状态，我们也能够根据计算进程把所有丢失的状态全都算出来。但是如果是递归的话，如果某一个状态的信息丢失了，那么即使它的子状态算出了结果返回给它，因为丢失了一些必要的状态信息，使得计算进程是无法进行下去的。&lt;/li&gt;
&lt;li&gt;虽然两者都在定义过程的时候调用了自身，但是很显然，迭代的定义过程属于用递归的方式定义过程。递归属于递归计算进程。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;黑魔法终极奥义：尾递归&lt;/h2&gt;
&lt;p&gt;一般的编程语言都是通过循环等一些复杂的结构来描述迭代的，但是在scheme中却可以用递归的形式来描述迭代。&lt;/p&gt;
&lt;p&gt;观察上面两个求阶乘的过程，我们可以看到。虽然两者都是调用了自身，用了递归的形式来定义整个过程，表面上都属于递归调用，但是，『递归』版本中，在最后的递归调用之后，还需要进行乘n的操作才算作是完成了此次计算，而在 [迭代]版本中，递归的调用属于最后一个方法，末尾的递归调用执行完，此次的计算也就执行完了，属于该过程的最后一个操作，这就是”尾递归”。尾递归相对于正常的递归来说，它的递归调用处于过程最后，之前过程计算积累的信息对于接下来的这次递归调用的最终结果没有任何影响，那么本次过程调用存储在栈内的信息就可以完全清除。把空间留给之后的递归过程使用。所以说，这意味着如果使用尾递归的方式，是可以实现无限递归的。&lt;/p&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;至于把正常递归转化为尾递归的方法，我觉得比较直接的做法就是，正常递归是从后向前考虑，如果写尾递归，那么就把问题从前向后考虑，并且把所需的信息当做参数传递。&lt;/p&gt;
&lt;p&gt;一般来讲，虽然在过程定义上，看起来是递归的，但是实际的计算进程的原理有可能是迭代的，也有可能是递归的，因为，迭代的计算是可以用尾递归来进行定义的。&lt;/p&gt;

        
        &lt;!-- BEGIN #author-bio --&gt;

&lt;div id=&quot;author-bio&quot;&gt;
	
	&lt;h3 class=&quot;widget-title&quot;&gt;
	关于作者： &lt;a href=&quot;http://blog.jobbole.com/author/fengzixu/&quot;&gt;fengzi&lt;/a&gt;
	&lt;/h3&gt;
	&lt;div class=&quot;alignleft&quot;&gt;
		&lt;a href=&quot;http://blog.jobbole.com/author/fengzixu/&quot;&gt;
			&lt;img src=&quot;/images/jobbole.com/e1037e4e1ba3ce135548c7795f9c150c.jpg&quot; alt=&quot;fengzi&quot; width=&quot;45&quot; height=&quot;80&quot; class=&quot;photo&quot;&gt;		&lt;/a&gt;
	&lt;/div&gt;
	&lt;p&gt;一个普通大学的CS本科生，伪ACmer，喜欢操作系统，喜欢linux,讨厌复制粘贴，喜欢看书，喜欢一切经过思考和积累才能够获得成果的知识。欢迎大家来我的博客逛逛(新浪微博&lt;a href=&quot;http://weibo.com/3626507773&quot;&gt;@徐疯子&lt;/a&gt;)(Blog&lt;a href=&quot;http://fengzixu.net&quot;&gt;疯子徐&#39;s blog&lt;/a&gt;)&lt;/p&gt;
	&lt;p&gt;
		&lt;a style=&quot;text-decoration: none;&quot; href=&quot;http://blog.jobbole.com/author/fengzixu/&quot;&gt;查看fengzi的更多文章 »&lt;/a&gt;
	&lt;/p&gt;
	&lt;div class=&quot;clear&quot;&gt;&lt;/div&gt;
	
&lt;/div&gt;

&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Tue, 19 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-19-86996-7a00a97f3.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-19-86996-7a00a97f3.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>老鸟向新手讲解各种编程比赛</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;过去十年间我一直在参加各种编程比赛。我参加了很多比赛，更重要的是，我参加了很多不同类型的比赛。我的冒险起始于经典算法，之后我转到了优化问题。目前我主要参加机器学习竞赛（作为兼职），我也参加一些只是为了好玩的比赛。&lt;/p&gt;
&lt;p&gt;考虑到有像我这样广泛经历的人并不多，我想我应该写一个编程（算法?）竞赛流行类型的（相对）简短的总结。这不是一个完整的列表，我只关注了那些最流行的，并且在我看来最有用的竞赛。&lt;/p&gt;
&lt;p&gt;这篇文章的结构是以竞赛类型，而不是竞赛网站为导向的。也就是说，我把有相似特征的网站/竞赛归类，而不是呈现给你们仅仅加了我个人描述的随机网站。由于有些网站提供了几种类型的竞赛，我不得不多次列出它们。&lt;/p&gt;
&lt;p&gt;如果你对编程竞赛的世界感到困惑或者好奇，这篇文章能给你关于这个主题的详尽综述。&lt;/p&gt;
&lt;h2&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;经典算法&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;有时又被称为二元问题或（带贬义地）消遣算法。提供给你问题陈述，你的目标是写一个通常很短的程序：读入输入，处理它并输出计算结果。任何东西都是按给定的问题陈述来的。大部分情况下， 你要提交程序源代码，源代码在远程服务器上编译并运行一些对你隐藏的数据。下面要提到的所有竞赛的共性是：你的程序要么被认为是完全正确的，要么是完全错误的，没有中间结果。&lt;/p&gt;
&lt;p&gt;经典算法竞赛通常是编程竞赛的入门级别。难度从答案显而易见，到只有问题作者知道怎么解答。对于新手程序员，它们提供了小的挑战，是很棒的实践练习。在更高的级别，它们需要高度的专注，很好的长期记忆，解决问题的技巧以及很深的专业知识。如果能在这些竞赛中做好，你会开发出很多可以轻易迁移到计算机科学其他领域的技能。前提是你专注于开发纯粹的技能，而不是把时间花在解决成百上千的问题上以期望今后能遇到类似的问题。（&lt;span style=&quot;color: #808080;&quot;&gt;译者注：即不要用题海战术&lt;/span&gt;）&lt;/p&gt;
&lt;h4&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 20px; font-style: normal; font-weight: bold; line-height: 30px;&quot;&gt;竞赛联盟&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;有两个主要的网站定期举办比赛。第一个是 &lt;a href=&quot;https://www.topcoder.com/community/data-science/&quot;&gt;TopCoder&lt;/a&gt;（以下简称 TC），举办Single Round Matches (SRMs)。第二个是 &lt;a href=&quot;http://codeforces.com/&quot;&gt;CodeForces&lt;/a&gt;（以下简称 CF）。&lt;/p&gt;
&lt;p&gt;这两个网站很相似。一周会举办几次比赛（即将到来的比赛链接：&lt;a href=&quot;http://www.topcoder.com/community/events/&quot;&gt;TC&lt;/a&gt;，&lt;a href=&quot;http://codeforces.com/contests&quot;&gt;CF&lt;/a&gt;）。比赛持续大约2小时。每种比赛都会用几个（TC 是 3 个，CF 是 5 个）为这轮特别准备的原创经典问题（通常，对于所有的比赛都是这样的，但我想澄清这一点）。你只需提交程序源代码，程序会在服务器上远程执行。你的程序如果想要被认定为正确，需要在指定的时间和内存限制下运行，产生正确的输出。美中不足的是，只有在比赛结束后你才知道你的解答是否正确。当这轮结束后，你的排名会得到更新（类似于 ELO 等级系统），这很准确地代表了你目前的水平。赛前参赛者（根据他们当前的排名）会被分到两个不同的赛区，每个赛区使用根据参赛者水平量身定做的题目。另外，赛后你可以看其他人的提交，也会发布题解（解释了问题的正确解答）。所有的题目会添加到练习区，这样你之后就可以去解答那些你在比赛中未能解答的题目。这使得这两个网站成为完美的训练场。&lt;/p&gt;
&lt;p&gt;这些是它们的相似之处，那么不同之处是什么呢？TC 最大的缺点是（除了糟糕的管理，不过那又是另一回事了）它使用一个陈旧的 Java applet 来用于竞赛。尽管这使得参加第一次比赛比它应有的过程更复杂（TC 那设计糟糕的网站对此也没什么帮助），但从长远看来比“HTML5”界面也差不了多少。另一个差别是两个网站的题目的关注点稍有不同。TC 上的任务通常向解决问题倾斜，有时候甚至像谜题，然而 CF 就包含很多基于数据结构的“filler”（缺乏想象力的代名词）问题，但这主要取决于问题作者。基于我的经历，TC问题（平均来说）稍微有趣些，但CF的题目更为多样—主要是因为CF每轮有更多的题目。两种竞赛都有一个特性是提供寻找他人代码中bug的机会（如果你成功找到了会获得额外的分数），但是CF对此的设计很可怕&lt;span style=&quot;color: #008000;&quot;&gt;（译者注：表示对此没什么感受）&lt;/span&gt;，最好就是完全忽略它。&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 20px; font-style: normal; font-weight: bold; line-height: 30px;&quot;&gt;年度现场比赛&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;有四个大的比赛：&lt;a href=&quot;https://code.google.com/codejam&quot;&gt;Google Code Jam&lt;/a&gt;、&lt;a href=&quot;https://www.facebook.com/hackercup&quot;&gt;Facebook Hacker Cup&lt;/a&gt;、&lt;a href=&quot;https://contest.yandex.com/?lang=en&quot;&gt;Yandex.Algorithm&lt;/a&gt; 和 &lt;a href=&quot;http://tco15.topcoder.com/algorithm/&quot;&gt;TopCoder Open&lt;/a&gt;（算法组）。它们都很相似。为了取得现场比赛资格，你要参加一系列在线资格赛。通常都是采用淘汰赛的形式，在随后的每一轮减少参赛者的数量。通常对参赛者的身份没有限制（除非你的国家不幸在美国的禁止入境名单上）。每一轮时间都很短，在 90 分钟和 3 个小时之间，只考经典的二元问题（&lt;span style=&quot;color: #808080;&quot;&gt;译者注：前面提过了&lt;/span&gt;）。如果你取得了现场赛资格，他们会支付你参加比赛的交通食宿费用。他们也给获胜者奖金，但对于大多数人来说，你能赢得的最重要的东西是旅行本身，或者（通过比赛）在顶级 IT 公司找到工作。&lt;/p&gt;
&lt;p&gt;这些比赛之间有一些小的差别（题目质量、晋级结构、提交系统），但是它们有两个共性：晋级其中任何一个都非常难（如果你没有两年经验，想要取得资格是极不可能的，即使你聪明且专注于此）。另一个是&lt;a href=&quot;http://en.wikipedia.org/wiki/Gennady_Korotkevich&quot;&gt;有个人&lt;/a&gt;（Gennady Korotkevich）在2014年赢了个大满贯。考虑到所有这些竞赛要想赢都有很高不确定性，这是一个难以置信的壮举。&lt;/p&gt;
&lt;p style=&quot;padding-left: 30px;&quot;&gt;&lt;span style=&quot;color: #008000;&quot;&gt;&lt;b&gt;伯乐在线补充：&lt;/b&gt;Gennady Korotkevich&lt;b&gt;，&lt;/b&gt;年仅11岁时便参加国际信息学奥林比克竞赛，创造了最年轻选手的记录。在2007-2012年间，总共取得6枚奥赛金牌；2013年美国计算机协会编程比赛冠军队成员；2014年Facebook黑客杯冠军得主。截止目前，稳居俄编程网站Codeforces声望第一的宝座，在TopCoder算法竞赛中暂列榜眼位置。&lt;/span&gt;&lt;/p&gt;
&lt;h4&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 20px; font-style: normal; font-weight: bold; line-height: 30px;&quot;&gt;在线判题系统&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;这些有很多了，仅列举一些：&lt;a href=&quot;http://www.spoj.com/&quot;&gt;SPOJ&lt;/a&gt;、&lt;a href=&quot;http://uva.onlinejudge.org/&quot;&gt;UVA&lt;/a&gt;、&lt;a href=&quot;http://acm.timus.ru/&quot;&gt;Timus&lt;/a&gt;。通常，它们主要作为过去的ICPC（&lt;span style=&quot;color: #808080;&quot;&gt;译者注：即 International Collegiate Programming Contest， 国际大学生程序设计竞赛&lt;/span&gt;）竞赛题的存档。&lt;/p&gt;
&lt;p&gt;你在这些网站上花时间原因不外乎那么几个：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一：你觉得你很不擅长某些类型的题目，因此你在寻找一些很难的特定题目（如果你以成为世界前100为目标，这甚至都不应该发生），而你在其他地方又找不到这些题目。&lt;/li&gt;
&lt;li&gt;二：你参加了一场比赛，那些题目被上传到判题网站，你想继续尝试那些你没有解决的问题或者尝试其他的解题方案。&lt;/li&gt;
&lt;li&gt;三：你的算法课老师很懒，他讨厌他的工作。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;优化问题&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;这种问题的标准例子是&lt;a href=&quot;http://en.wikipedia.org/wiki/Travelling_salesman_problem&quot;&gt;旅行商问题&lt;/a&gt;。这些问题以这样的事实来刻画：根据你的解答质量，你得到不同的分数。它们被（或者至少应该被）设计为不可能获得完美的分数。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;有优化问题的比赛通常持续时间更长，因此相对于经典算法比赛关注于不同的技能集，比如心理耐力、时间管理或开箱即用的问题解决技能。通常，优化问题要求你是个多面手，但是你不必擅长于任何特定领域。它们也更接近于做实际研究，因此如果你想把你的职业生涯与软件开发以外的事绑在一起，尝试下它们是个不错的主意。&lt;/p&gt;
&lt;h4&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 20px; font-style: normal; font-weight: bold; line-height: 30px;&quot;&gt;马拉松比赛&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;不幸的是，没有太多地方可以让你磨练在这个领域的技能。Topcoder有&lt;a href=&quot;http://community.topcoder.com/longcontest/?module=ViewActiveContests&quot;&gt;马拉松比赛&lt;/a&gt;，但是他们不再定期举办比赛，几年前他们还这么做。在马拉松比赛旗下举办的大多数比赛都属于机器学习类（在下面描述），例外是年度Top Coder Open比赛中的马拉松类，现场决赛和资格赛都使用优化问题。有传闻他们想重新举办定期比赛，但到目前为止什么都还没改变。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;幸运的是，尽管没有太多比赛，TopCCoder有过去比赛题目的&lt;a href=&quot;http://community.topcoder.com/longcontest/?module=ViewPractice&quot;&gt;存档&lt;/a&gt;。因此如果你的目标只是更擅长优化题目，你可以练习这些旧题。好处是你可以获得所有的优胜解答，另外在这些过去的比赛对应的论坛通常有个“发布你的方法”的帖子。&lt;/p&gt;
&lt;p&gt;在一些其他的比赛中你也可以遇到优化问题。但不幸的是，我不认为有可以与马拉松比赛相提并论的。这个类别下最流行的比赛大概是 &lt;a href=&quot;http://azspcs.com/&quot;&gt;Al Zimmermann 的编程比赛&lt;/a&gt;，但是那的题目都很浅，不太有趣。&lt;/p&gt;
&lt;h2&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;机器学习&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;有时被错误地称为数据科学。这是个有大把钱的地方，因为对专长于机器学习的人才有很大需求，至少相比对经典和优化问题人才的需求来说是很大的。&lt;/p&gt;
&lt;p&gt;相比其他类型的比赛，机器学习需要的知识要多得多，通常来说也不那么有趣。尽管如此，这些比赛仍然是目前在这个领域获得一些亲身实践经历的最容易的方式。如果你需要一些动力，记住需要机器学习技能的工作的报酬在整个IT界是最高的那部分。&lt;/p&gt;
&lt;h4&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 20px; font-style: normal; font-weight: bold; line-height: 30px;&quot;&gt;马拉松比赛（再次）&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;我可能提到上面提过的网站/比赛。Topcoder把优化和机器学习问题结合到一个类别。说得更准确些，在某些时候马拉松比赛类别扩张为包括机器学习比赛。&lt;/p&gt;
&lt;p&gt;Topcoder的机器学习比赛通常只以一种方式呈现。由于整个Topcoder是个众包平台（再加上围绕它构建的社区），客户有时候会有用“简单的”软件竞赛不能解决的问题。在有些情况下，他们处理的问题可以包装成一个机器学习比赛，给表现最好的方案大笔钱。由于机器学习比赛仍然是马拉松比赛，整个提交系统的运行方式是和优化问题完全一样的。唯一的差别是机器学习比赛通常不加入到练习区。&lt;/p&gt;
&lt;h4&gt;Kaggle&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;http://www.kaggle.com/&quot;&gt;Kaggle&lt;/a&gt;是个很大程度围绕机器学习比赛而建的网站。我将关注于TC和Kaggle的差别。最大的差别是在Kaggle你只提交你的解答的输出，而不是整个程序，这有很多后果。首先，你获得整个数据集，对你可以使用的语言/库没有限制。没有任何时间限制，如果你想（并且支付得起）的话，甚至可以用整个集群来计算结果。由于大家不用提交源代码，在比赛结束后你不能查看解答。另一方面，社区要活跃得多。当比赛还在进行中时，会有很多“练习赛”，在此人们分享他们的解答。Kaggle的比赛时间也长得多（对于有奖金的比赛通常是两个月）。&lt;/p&gt;
&lt;p&gt;总体来说，两个网站各自为稍有不同的目的服务，各有利弊。对于那些对高层知识，而不是各种机器学习技术如何工作的低层内部机制更感兴趣的人来说，Kaggle应该更为友好，然而TC对于有很强算法背景的人来说可能更好。另一种看待这个的方式是，在Kaggle你（通常）使用工具，而在马拉松比赛你（通常）写你自己的工具。&lt;/p&gt;
&lt;h2&gt;欢乐24小时&lt;/h2&gt;
&lt;p&gt;15年前，第一届 &lt;a href=&quot;http://ch24.org/&quot;&gt;Challenge24&lt;/a&gt; 组织起来了。我不会细说它的历史，因为实际上我也所知甚少。但我会把这个比赛描述为“24小时的疯狂”。它是在布达佩斯举办的年度团队比赛。你有大概15道题。题目的范围很广：经典、优化、TCP/IP之上的游戏、计算机视觉、声音分析、谜题，以及难以用语言描述的东西。你把你自己的硬件带到比赛现场，整个比赛是离线完成的。老实说，这是我参加过的最有趣的比赛。即使我上次参加时发烧了，我还是要这么说。&lt;/p&gt;
&lt;p&gt;Challenge24启发了&lt;a href=&quot;https://deadline24.pl/home-en/&quot;&gt;Deadline24&lt;/a&gt;，这反过来又启发了&lt;a href=&quot;http://marathon24.com/&quot;&gt;Marathon24&lt;/a&gt;（两个都是在波兰举行）。它们是Challenge24的简化版，但仍然很有趣。它们没有大量题目，通常只有三个游戏，每轮游戏和比赛同时开始。例如，过去的一个游戏是30个选手同时玩经典的行星游戏。&lt;/p&gt;
&lt;p&gt;由于只有有限数量的队伍会被邀请到决赛，这些比赛都举办在线资格赛。由于这些比赛并没有其他年度比赛那么流行，实际上即使没有任何显著的算法（甚至编程）背景，也很可能获得其中之一的资格。&lt;/p&gt;
&lt;p&gt;还有一个额外的年度比赛值得一提，它和这些24小时比赛有些类似：&lt;a href=&quot;http://ipsc.ksp.sk/&quot;&gt;互联网问题解决比赛&lt;/a&gt;。这个比赛也有很多任务，尽管它们更类似于经典算法。&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;其他&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;还有两个大的网站被遗漏了。第一个是&lt;a href=&quot;http://www.codechef.com/&quot;&gt;CodeChef&lt;/a&gt;，有两种不同的月度比赛。两种都是经典算法比赛。另一个是&lt;a href=&quot;https://www.hackerrank.com/domains&quot;&gt;HackerRank&lt;/a&gt;，混合了在线判题系统和举办各种类型一次性比赛的功能。我遗漏它们的原因是，它们都因问题陈述的质量低而闻名（&lt;span style=&quot;color: #808080;&quot;&gt;译者注：译者使用过这两个网站，对此没什么感受&lt;/span&gt;）。考虑到有大量的其他比赛，通常你应该避开它们（尽管有很少的例外）。&lt;/p&gt;
&lt;p&gt;如果你还在读高中，对你来说最重要的比赛是&lt;a href=&quot;http://www.ioinformatics.org/index.shtml&quot;&gt;国际信息学奥林匹克竞赛&lt;/a&gt;。每个国家都有其国家级奥林匹克竞赛和自己的规则。在很多国家，在国家级奥林匹克竞赛中表现优异是进入理想大学最简单和安全的方式。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://icpc.baylor.edu/&quot;&gt;国际大学生程序设计竞赛&lt;/a&gt;（ACM/ICPC）是“经典算法”比赛，在这里所有的比赛/网站中历史最为悠久。它是面向学生的团队比赛。每支队由同一大学的3个人组成。ICPC的主要目标是编程在世界范围的普及。这是用复杂的多层获得资格制度和（同样复杂）的合格标准来达成的。这保证了世界总决赛中队伍的多样性。作为取舍，根据你所在的地方，要想晋级世界总决赛，要么是令人吃惊地容易，要么是近乎不可能。专门针对ICPC来练习可能是把你的时间投资在编程竞赛中最坏的方式，因为它提升的技能集是最窄的，唯一的例外是你生活在那些“幸运的”（&lt;span style=&quot;color: #808080;&quot;&gt;译者注：即容易晋级的&lt;/span&gt;）地区。&lt;/p&gt;
&lt;p&gt;鼓励奖要颁给&lt;a href=&quot;https://helloworldopen.com/&quot;&gt;Hello World Open&lt;/a&gt;，因为它创造了年度最大的扯淡比赛，有着很成功的销售计划。如果你仔细看，你会看到在比赛发起后，他们甚至在&lt;a href=&quot;http://en.wikipedia.org/wiki/Competitive_programming#Long-term&quot;&gt;维基&lt;/a&gt;页面加入了他们的链接。我猜如果你制作收入最高的手机app，你会很熟悉这个。说真的，Topcoder应该向他们学习。&lt;/p&gt;
&lt;p&gt;另一个鼓励奖要颁给 &lt;a href=&quot;https://www.imaginecup.com/&quot;&gt;Imagine Cup&lt;/a&gt;。我参加了四次Imagine Cup。两次作为参赛者，一次作为裁判，最后一次作为助手。这些年我看着它从一个聚集多个不同领域（初创，数字艺术，算法/人工智能）的学生的创新年度比赛，到微软产品的傻逼公关。裁判经常是因政治原因被挑选的，绝对不能胜任他们的工作。并且所有没有直接&lt;strong&gt;&lt;/strong&gt;&lt;label&gt;促进&lt;/label&gt;微软产品的类别都停掉了。事实是，Imagine Cup是我参加过的最好的现场赛事。同时，现在我不会推荐任何人参加它们。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://projecteuler.net/&quot;&gt;Project Euler&lt;/a&gt;是一种特别的在线判题系统（偏重数学），这在于你以编程为工具来解决问题，而不在于它本身。如果你真的想在没有时间压力的情况下做一些编程题，我建议你做Project Euler，而不是我提到的其他判题系统。另外，由于它很流行，如果你在某个问题卡住了，在网上找到一些帮助要容易得多。&lt;/p&gt;
&lt;h3&gt;编注：推荐几篇相关文章&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/18653/&quot;&gt;编程竞赛题和逻辑题网站大集合&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/78575/&quot;&gt;搞定编程竞赛必知哪10个算法？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/33834/&quot;&gt;参加编程竞赛对实际工作的用处&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

        
        &lt;!-- BEGIN #author-bio --&gt;

&lt;div id=&quot;author-bio&quot;&gt;
	
	&lt;h3 class=&quot;widget-title&quot;&gt;
	关于作者： &lt;a href=&quot;http://blog.jobbole.com/author/demolpc/&quot;&gt;demo&lt;/a&gt;
	&lt;/h3&gt;
	&lt;div class=&quot;alignleft&quot;&gt;
		&lt;a href=&quot;http://blog.jobbole.com/author/demolpc/&quot;&gt;
					&lt;/a&gt;
	&lt;/div&gt;
	&lt;p&gt;新浪微博：&lt;a href=&quot;http://weibo.com/u/1802379047&quot;&gt;@shuyechengying&lt;/a&gt;&lt;/p&gt;
	&lt;p&gt;
		&lt;a style=&quot;text-decoration: none;&quot; href=&quot;http://blog.jobbole.com/author/demolpc/&quot;&gt;查看demo的更多文章 »&lt;/a&gt;
	&lt;/p&gt;
	&lt;div class=&quot;clear&quot;&gt;&lt;/div&gt;
	
&lt;/div&gt;

&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Mon, 18 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-18-86799-7596a32e0.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-18-86799-7596a32e0.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>一大波你可能不知道的 Linux 网络工具</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;如果要在你的系统上监控网络，那么使用命令行工具是非常实用的，并且对于 Linux 用户来说，有着许许多多现成的工具可以使用，如： nethogs, ntopng, nload, iftop, iptraf, bmon, slurm, tcptrack, cbm, netwatch, collectl, trafshow, cacti, etherape, ipband, jnettop, netspeed 以及 speedometer。&lt;/p&gt;
&lt;p&gt;鉴于世上有着许多的 Linux 专家和开发者，显然还存在其他的网络监控工具，但在这篇教程中，我不打算将它们所有包括在内。&lt;/p&gt;
&lt;p&gt;上面列出的工具都有着自己的独特之处，但归根结底，它们都做着监控网络流量的工作，只是通过各种不同的方法。例如 nethogs 可以被用来展示每个进程的带宽使用情况，以防你想知道究竟是哪个应用在消耗了你的整个网络资源； iftop 可以被用来展示每个套接字连接的带宽使用情况，而像 nload 这类的工具可以帮助你得到有关整个带宽的信息。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1) nethogs&lt;/strong&gt;&lt;br&gt;
nethogs 是一个免费的工具，当要查找哪个 PID (注：即 process identifier，进程 ID) 给你的网络流量带来了麻烦时，它是非常方便的。它按每个进程来分组带宽，而不是像大多数的工具那样按照每个协议或每个子网来划分流量。它功能丰富，同时支持 IPv4 和 IPv6，并且我认为，若你想在你的 Linux 主机上确定哪个程序正消耗着你的全部带宽，它是来做这件事的最佳的程序。&lt;/p&gt;
&lt;p&gt;一个 Linux 用户可以使用 nethogs 来显示每个进程的 TCP 下载和上传速率，可以使用命令 nethogs eth0 来监控一个指定的设备，上面的 eth0 是那个你想获取信息的设备的名称，你还可以得到有关正在传输的数据的传输速率信息。&lt;/p&gt;
&lt;p&gt;对我而言， nethogs 是非常容易使用的，或许是因为我非常喜欢它，以至于我总是在我的 Ubuntu 12.04 LTS 机器中使用它来监控我的网络带宽。&lt;/p&gt;
&lt;p&gt;例如要想使用混杂模式来嗅探，可以像下面展示的命令那样使用选项 -p：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;nethogs -p wlan0&lt;/pre&gt;
&lt;p&gt;假如你想更多地了解 nethogs 并深入探索它，那么请毫不犹豫地阅读我们做的关于这个网络带宽监控工具的整个教程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2) nload&lt;/strong&gt;&lt;br&gt;
nload 是一个控制台应用，可以被用来实时地监控网络流量和带宽使用情况，它还通过提供两个简单易懂的图表来对流量进行可视化。这个绝妙的网络监控工具还可以在监控过程中切换被监控的设备，而这可以通过按左右箭头来完成。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/c2f1c78f607470e83a0f313f946a2f71.jpg&quot; width=&quot;690&quot; height=&quot;441&quot;&gt;&lt;/p&gt;
&lt;p&gt;正如你在上面的截图中所看到的那样，由 nload 提供的图表是非常容易理解的。nload 提供了有用的信息，也展示了诸如被传输数据的总量和最小/最大网络速率等信息。&lt;/p&gt;
&lt;p&gt;而更酷的是你只需要直接运行 nload 这个工具就行，这个命令是非常的短小且易记的：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;nload&lt;/pre&gt;
&lt;p&gt;我很确信的是：我们关于如何使用 nload 的详细教程将帮助到新的 Linux 用户，甚至可以帮助那些正寻找关于 nload 信息的老手。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3) slurm&lt;/strong&gt;&lt;br&gt;
slurm 是另一个 Linux 网络负载监控工具，它以一个不错的 ASCII 图来显示结果，它还支持许多按键用以交互，例如 c 用来切换到经典模式， s 切换到分图模式， r 用来重绘屏幕， L 用来启用 TX/RX 灯（注：TX，发送流量；RX，接收流量） ，m 用来在经典分图模式和大图模式之间进行切换， q 退出 slurm。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/e7b3b0c277dac16ce10dde70a0f22bb6.jpg&quot; width=&quot;690&quot; height=&quot;430&quot;&gt;&lt;/p&gt;
&lt;p&gt;在网络负载监控工具 slurm 中，还有许多其它的按键可用，你可以很容易地使用下面的命令在 man 手册中学习它们。&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;man slurm&lt;/pre&gt;
&lt;p&gt;slurm 在 Ubuntu 和 Debian 的官方软件仓库中可以找到，所以使用这些发行版本的用户可以像下面展示的那样，使用 apt-get 安装命令来轻松地下载它：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;sudo apt-get install slurm&lt;/pre&gt;
&lt;p&gt;我们已经在一个教程中对 slurm 的使用做了介绍，不要忘记和其它使用 Linux 的朋友分享这些知识。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4) iftop&lt;/strong&gt;&lt;br&gt;
当你想显示连接到网卡上的各个主机的带宽使用情况时，iftop 是一个非常有用的工具。根据 man 手册，iftop 在一个指定的接口或在它可以找到的第一个接口（假如没有任何特殊情况，它应该是一个对外的接口）上监听网络流量，并且展示出一个表格来显示当前的一对主机间的带宽使用情况。&lt;/p&gt;
&lt;p&gt;通过在虚拟终端中使用下面的命令，Ubuntu 和 Debian 用户可以在他们的机器中轻易地安装 iftop：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;sudo apt-get install iftop&lt;/pre&gt;
&lt;p&gt;在你的机器上，可以使用下面的命令通过 yum 来安装 iftop：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;yum -y install iftop&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5) collectl&lt;/strong&gt;&lt;br&gt;
collectl 可以被用来收集描述当前系统状态的数据，并且它支持如下两种模式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;记录模式&lt;/li&gt;
&lt;li&gt;回放模式&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;记录模式 允许从一个正在运行的系统中读取数据，然后将这些数据要么显示在终端中，要么写入一个或多个文件或一个套接字中。&lt;/p&gt;
&lt;p&gt;回放模式&lt;/p&gt;
&lt;p&gt;根据 man 手册，在这种模式下，数据从一个或多个由记录模式生成的数据文件中读取。&lt;/p&gt;
&lt;p&gt;Ubuntu 和 Debian 用户可以在他们的机器上使用他们默认的包管理器来安装 colletcl。下面的命令将为他们做这个工作：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;sudo apt-get install collectl&lt;/pre&gt;
&lt;p&gt;还可以使用下面的命令来安装 collectl， 因为对于这些发行版本（注：这里指的是用 yum 作为包管理器的发行版本），在它们官方的软件仓库中也含有 collectl：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;yum install collectl&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;6) Netstat&lt;/strong&gt;&lt;br&gt;
Netstat 是一个用来监控传入和传出的网络数据包统计数据的接口统计数据命令行工具。它会显示 TCP 连接 (包括上传和下行)，路由表，及一系列的网络接口（网卡或者SDN接口）和网络协议统计数据。&lt;/p&gt;
&lt;p&gt;Ubuntu 和 Debian 用户可以在他们的机器上使用默认的包管理器来安装 netstat。Netsta 软件被包括在 net-tools 软件包中，并可以在 shell 或虚拟终端中运行下面的命令来安装它：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;sudo apt-get install net-tools&lt;/pre&gt;
&lt;p&gt;CentOS, Fedora, RHEL 用户可以在他们的机器上使用默认的包管理器来安装 netstat。Netstat 软件被包括在 net-tools 软件包中，并可以在 shell 或虚拟终端中运行下面的命令来安装它：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;yum install net-tools&lt;/pre&gt;
&lt;p&gt;运行下面的命令使用 Netstat 来轻松地监控网络数据包统计数据：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;netstat&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/6f56487e9f940fe3420c82d984610744.jpg&quot; width=&quot;690&quot; height=&quot;522&quot;&gt;&lt;/p&gt;
&lt;p&gt;更多的关于 netstat 的信息，我们可以简单地在 shell 或终端中键入 man netstat 来了解：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;man netstat&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/e1c065436f7f13a9c64a0933ba84b104.jpg&quot; width=&quot;690&quot; height=&quot;522&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7) Netload&lt;/strong&gt;&lt;br&gt;
netload 命令只展示一个关于当前网络荷载和自从程序运行之后传输数据总的字节数目的简要报告，它没有更多的功能。它是 netdiag 软件的一部分。&lt;/p&gt;
&lt;p&gt;我们可以在 fedora 中使用 yum 来安装 Netload，因为它在 fedora 的默认软件仓库中。但假如你运行的是 CentOS 或 RHEL，则我们需要安装 rpmforge 软件仓库。&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;# yum install netdiag&lt;/pre&gt;
&lt;p&gt;Netload 是默认仓库中 netdiag 的一部分，我们可以轻易地使用下面的命令来利用 apt 包管理器安装 netdiag：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;$ sudo apt-get install netdiag&lt;/pre&gt;
&lt;p&gt;为了运行 netload，我们需要确保选择了一个正在工作的网络接口的名称，如 eth0, eh1, wlan0, mon0等，然后在 shell 或虚拟终端中运行下面的命令：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;$ netload wlan2&lt;/pre&gt;
&lt;p&gt;注意： 请将上面的 wlan2 替换为你想使用的网络接口名称，假如你想通过扫描了解你的网络接口名称，可以在一个虚拟终端或 shell 中运行 ip link show 命令。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8) Nagios&lt;/strong&gt;&lt;br&gt;
Nagios 是一个领先且功能强大的开源监控系统，它使得网络或系统管理员可以在服务器的各种问题影响到服务器的主要事务之前，发现并解决这些问题。 有了 Nagios 系统，管理员便可以在一个单一的窗口中监控远程的 Linux 、Windows 系统、交换机、路由器和打印机等。它会显示出重要的警告并指出在你的网络或服务器中是否出现某些故障，这可以间接地帮助你在问题发生前就着手执行补救行动。&lt;/p&gt;
&lt;p&gt;Nagios 有一个 web 界面，其中有一个图形化的活动监视器。通过浏览网页 http://localhost/nagios/ 或 http://localhost/nagios3/ 便可以登录到这个 web 界面。假如你在远程的机器上进行操作，请使用你的 IP 地址来替换 localhost，然后键入用户名和密码，我们便会看到如下图所展示的信息：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/5c2fe408aae364c18167f19e1fc15a4f.jpg&quot; width=&quot;690&quot; height=&quot;378&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9) EtherApe&lt;/strong&gt;&lt;br&gt;
EtherApe 是一个针对 Unix 的图形化网络监控工具，它仿照了 etherman 软件。它支持链路层、IP 和 TCP 等模式，并支持以太网, FDDI, 令牌环, ISDN, PPP, SLIP 及 WLAN 设备等接口，以及一些封装格式。主机和连接随着流量和协议而改变其尺寸和颜色。它可以过滤要展示的流量，并可从一个文件或运行的网络中读取数据包。&lt;/p&gt;
&lt;p&gt;在 CentOS、Fedora、RHEL 等 Linux 发行版本中安装 etherape 是一件容易的事，因为在它们的官方软件仓库中就可以找到 etherape。我们可以像下面展示的命令那样使用 yum 包管理器来安装它：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;yum install etherape&lt;/pre&gt;
&lt;p&gt;我们也可以使用下面的命令在 Ubuntu、Debian 及它们的衍生发行版本中使用 apt 包管理器来安装 EtherApe ：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;sudo apt-get install etherape&lt;/pre&gt;
&lt;p&gt;在 EtherApe 安装到你的系统之后，我们需要像下面那样以 root 权限来运行 etherape：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;sudo etherape&lt;/pre&gt;
&lt;p&gt;然后， etherape 的 图形用户界面 便会被执行。接着，在菜单上面的 捕捉 选项下，我们可以选择 模式(IP，链路层，TCP) 和 接口。一切设定完毕后，我们需要点击 开始 按钮。接着我们便会看到类似下面截图的东西：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/3cb9becaf5111f8dd81ee92853e7a2aa.jpg&quot; width=&quot;636&quot; height=&quot;503&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10) tcpflow&lt;/strong&gt;&lt;br&gt;
tcpflow 是一个命令行工具，它可以捕捉 TCP 连接(流)的部分传输数据，并以一种方便协议分析或除错的方式来存储数据。它重构了实际的数据流并将每个流存储在不同的文件中，以备日后的分析。它能识别 TCP 序列号并可以正确地重构数据流，不管是在重发还是乱序发送状态下。&lt;/p&gt;
&lt;p&gt;通过 apt 包管理器在 Ubuntu 、Debian 系统中安装 tcpflow 是很容易的，因为默认情况下在官方软件仓库中可以找到它。&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;$ sudo apt-get install tcpflow&lt;/pre&gt;
&lt;p&gt;我们可以使用下面的命令通过 yum 包管理器在 Fedora 、CentOS 、RHEL 及它们的衍生发行版本中安装 tcpflow：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;# yum install tcpflow&lt;/pre&gt;
&lt;p&gt;假如在软件仓库中没有找到它或不能通过 yum 包管理器来安装它，则我们需要像下面展示的那样从 http://pkgs.repoforge.org/tcpflow/ 上手动安装它：&lt;/p&gt;
&lt;p&gt;假如你运行 64 位的 PC：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;# yum install --nogpgcheck http://pkgs.repoforge.org/tcpflow/tcpflow-0.21-1.2.el6.rf.x86_64.rpm&lt;/pre&gt;
&lt;p&gt;假如你运行 32 位的 PC：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;# yum install --nogpgcheck http://pkgs.repoforge.org/tcpflow/tcpflow-0.21-1.2.el6.rf.i686.rpm&lt;/pre&gt;
&lt;p&gt;我们可以使用 tcpflow 来捕捉全部或部分 tcp 流量，并以一种简单的方式把它们写到一个可读的文件中。下面的命令就可以完成这个事情，但我们需要在一个空目录中运行下面的命令，因为它将创建诸如 x.x.x.x.y-a.a.a.a.z 格式的文件，运行之后，只需按 Ctrl-C 便可停止这个命令。&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;$ sudo tcpflow -i eth0 port 8000&lt;/pre&gt;
&lt;p&gt;注意：请将上面的 eth0 替换为你想捕捉的网卡接口名称。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;11) IPTraf&lt;/strong&gt;&lt;br&gt;
IPTraf 是一个针对 Linux 平台的基于控制台的网络统计应用。它生成一系列的图形，如 TCP 连接的包/字节计数、接口信息和活动指示器、 TCP/UDP 流量故障以及局域网内设备的包/字节计数。&lt;/p&gt;
&lt;p&gt;在默认的软件仓库中可以找到 IPTraf，所以我们可以使用下面的命令通过 apt 包管理器轻松地安装 IPTraf：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo apt-get install iptraf&lt;/pre&gt;
&lt;p&gt;我们可以使用下面的命令通过 yum 包管理器轻松地安装 IPTraf：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;# yum install iptraf&lt;/pre&gt;
&lt;p&gt;我们需要以管理员权限来运行 IPTraf，并带有一个有效的网络接口名。这里，我们的网络接口名为 wlan2，所以我们使用 wlan2 来作为参数：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo iptraf wlan2&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/04da36ada415da6f1be2e08492baf0ce.jpg&quot; width=&quot;679&quot; height=&quot;487&quot;&gt;&lt;/p&gt;
&lt;p&gt;开始通常的网络接口统计，键入：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;# iptraf -g&lt;/pre&gt;
&lt;p&gt;查看接口 eth0 的详细统计信息，使用：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;# iptraf -d eth0&lt;/pre&gt;
&lt;p&gt;查看接口 eth0 的 TCP 和 UDP 监控信息，使用：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;# iptraf -z eth0&lt;/pre&gt;
&lt;p&gt;查看接口 eth0 的包的大小和数目，使用：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;# iptraf -z eth0&lt;/pre&gt;
&lt;p&gt;注意:请将上面的 eth0 替换为你的接口名称。你可以通过运行ip link show命令来检查你的接口。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;12) Speedometer&lt;/strong&gt;&lt;br&gt;
Speedometer 是一个小巧且简单的工具，它只用来绘出一幅包含有通过某个给定端口的上行、下行流量的好看的图。&lt;/p&gt;
&lt;p&gt;在默认的软件仓库中可以找到 Speedometer ，所以我们可以使用下面的命令通过 yum 包管理器轻松地安装 Speedometer：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;# yum install speedometer&lt;/pre&gt;
&lt;p&gt;我们可以使用下面的命令通过 apt 包管理器轻松地安装 Speedometer：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo apt-get install speedometer&lt;/pre&gt;
&lt;p&gt;Speedometer 可以简单地通过在 shell 或虚拟终端中执行下面的命令来运行：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ speedometer -r wlan2 -t wlan2&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/9c5541c4d9c7ee198f1fc6b99ad998a1.jpg&quot; width=&quot;690&quot; height=&quot;381&quot;&gt;&lt;/p&gt;
&lt;p&gt;注：请将上面的 wlan2 替换为你想要使用的网络接口名称。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;13) Netwatch&lt;/strong&gt;&lt;br&gt;
Netwatch 是 netdiag 工具集里的一部分，它也显示当前主机和其他远程主机的连接情况，以及在每个连接中数据传输的速率。&lt;/p&gt;
&lt;p&gt;我们可以使用 yum 在 fedora 中安装 Netwatch，因为它在 fedora 的默认软件仓库中。但若你运行着 CentOS 或 RHEL ， 我们需要安装 rpmforge 软件仓库。&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;# yum install netwatch&lt;/pre&gt;
&lt;p&gt;Netwatch 是 netdiag 的一部分，可以在默认的软件仓库中找到，所以我们可以轻松地使用下面的命令来利用 apt 包管理器安装 netdiag：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo apt-get install netdiag&lt;/pre&gt;
&lt;p&gt;为了运行 netwatch， 我们需要在虚拟终端或 shell 中执行下面的命令：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo netwatch -e wlan2 -nt&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/0648d8336641c10b4e85edf40eae907d.jpg&quot; width=&quot;690&quot; height=&quot;381&quot;&gt;&lt;/p&gt;
&lt;p&gt;注意： 请将上面的 wlan2 替换为你想使用的网络接口名称，假如你想通过扫描了解你的网络接口名称，可以在一个虚拟终端或 shell 中运行 ip link show 命令。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;14) Trafshow&lt;/strong&gt;&lt;br&gt;
Trafshow 同 netwatch 和 pktstat 一样，可以报告当前活动的连接里使用的协议和每个连接中数据传输的速率。它可以使用 pcap 类型的过滤器来筛选出特定的连接。&lt;/p&gt;
&lt;p&gt;我们可以使用 yum 在 fedora 中安装 trafshow ，因为它在 fedora 的默认软件仓库中。但若你正运行着 CentOS 或 RHEL ， 我们需要安装 rpmforge 软件仓库。&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;# yum install trafshow&lt;/pre&gt;
&lt;p&gt;Trafshow 在默认仓库中可以找到，所以我们可以轻松地使用下面的命令来利用 apt 包管理器安装它：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo apt-get install trafshow&lt;/pre&gt;
&lt;p&gt;为了使用 trafshow 来执行监控任务，我们需要在虚拟终端或 shell 中执行下面的命令：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo trafshow -i wlan2&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/a552705a37b039a2b7284f0653834b57.jpg&quot; width=&quot;671&quot; height=&quot;470&quot;&gt;&lt;/p&gt;
&lt;p&gt;为了专门监控 tcp 连接，如下面一样添加上 tcp 参数：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo trafshow -i wlan2 tcp&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/f314d7ea6920bbc8b3f3cfee521d3712.jpg&quot; width=&quot;671&quot; height=&quot;470&quot;&gt;&lt;/p&gt;
&lt;p&gt;注意： 请将上面的 wlan2 替换为你想使用的网络接口名称，假如你想通过扫描了解你的网络接口名称，可以在一个虚拟终端或 shell 中运行 ip link show 命令。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;15) Vnstat&lt;/strong&gt;&lt;br&gt;
与大多数的其他工具相比，Vnstat 有一点不同。实际上它运行着一个后台服务或守护进程，并时刻记录着传输数据的大小。另外，它可以被用来生成一个网络使用历史记录的报告。&lt;/p&gt;
&lt;p&gt;我们需要开启 EPEL 软件仓库，然后运行 yum 包管理器来安装 vnstat。&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;# yum install vnstat&lt;/pre&gt;
&lt;p&gt;Vnstat 在默认软件仓库中可以找到，所以我们可以使用下面的命令运行 apt 包管理器来安装它：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo apt-get install vnstat&lt;/pre&gt;
&lt;p&gt;不带有任何选项运行 vnstat 将简单地展示出从该守护进程运行后数据传输的总量。&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ vnstat&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/57746c2cd3ec5f712d0eea99160cba22.jpg&quot; width=&quot;606&quot; height=&quot;131&quot;&gt;&lt;/p&gt;
&lt;p&gt;为了实时地监控带宽使用情况，使用 ‘-l’ 选项(live 模式)。然后它将以一种非常精确的方式来展示上行和下行数据所使用的带宽总量，但不会显示任何有关主机连接或进程的内部细节。&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ vnstat -l&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/4582b462f5f802171eb01fee0c8fdede.jpg&quot; width=&quot;644&quot; height=&quot;72&quot;&gt;&lt;/p&gt;
&lt;p&gt;完成了上面的步骤后，按 Ctrl-C 来停止，这将会得到如下类型的输出：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/c8e6c68cf2f534a44f227232b05a69c0.jpg&quot; width=&quot;671&quot; height=&quot;487&quot;&gt;&lt;br&gt;
&lt;strong&gt;16) tcptrack&lt;/strong&gt;&lt;br&gt;
tcptrack 可以展示 TCP 连接的状态，它在一个给定的网络端口上进行监听。tcptrack 监控它们的状态并展示出排序且不断更新的列表，包括来源/目标地址、带宽使用情况等信息，这与 top 命令的输出非常类似 。&lt;/p&gt;
&lt;p&gt;鉴于 tcptrack 在软件仓库中，我们可以轻松地在 Debian、Ubuntu 系统中从软件仓库使用 apt 包管理器来安装 tcptrack。为此，我们需要在 shell 或虚拟终端中执行下面的命令：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo apt-get install tcptrack&lt;/pre&gt;
&lt;p&gt;我们可以通过 yum 在 fedora 中安装它，因为它在 fedora 的默认软件仓库中。但若你运行着 CentOS 或 RHEL 系统，我们需要安装 rpmforge 软件仓库。为此，我们需要运行下面的命令：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;# wget http://apt.sw.be/redhat/el6/en/x86_64/rpmforge/RPMS/rpmforge-release-0.5.3-1.el6.rf.x86_64.rpm
# rpm -Uvh rpmforge-release*rpm
# yum install tcptrack&lt;/pre&gt;
&lt;p&gt;注：这里我们下载了 rpmforge-release 的当前最新版本，即 0.5.3-1，你总是可以从 rpmforge 软件仓库中下载其最新版本，并请在上面的命令中替换为你下载的版本。&lt;/p&gt;
&lt;p&gt;tcptrack 需要以 root 权限或超级用户身份来运行。执行 tcptrack 时，我们需要带上要监视的网络接口 TCP 连接状况的接口名称。这里我们的接口名称为 wlan2，所以如下面这样使用：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;sudo tcptrack -i wlan2&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/c1f91f7fcb32e32ddfbe523ce4e1513c.jpg&quot; width=&quot;671&quot; height=&quot;470&quot;&gt;&lt;/p&gt;
&lt;p&gt;假如你想监控特定的端口，则使用：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;# tcptrack -i wlan2 port 80&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/555d99b9d9706e35be4f0aef4e53264a.jpg&quot; width=&quot;671&quot; height=&quot;470&quot;&gt;&lt;/p&gt;
&lt;p&gt;请替换上面的 80 为你想要监控的端口号。注意： 请将上面的 wlan2 替换为你想使用的网络接口名称，假如你想通过扫描了解你的网络接口名称，可以在一个虚拟终端或 shell 中运行 ip link show 命令。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;17) CBM&lt;/strong&gt;&lt;br&gt;
CBM （ Color Bandwidth Meter） 可以展示出当前所有网络设备的流量使用情况。这个程序是如此的简单，以至于都可以从它的名称中看出其功能。CBM 的源代码和新版本可以在 http://www.isotton.com/utils/cbm/ 上找到。&lt;/p&gt;
&lt;p&gt;鉴于 CBM 已经包含在软件仓库中，我们可以简单地使用 apt 包管理器从 Debian、Ubuntu 的软件仓库中安装 CBM。为此，我们需要在一个 shell 窗口或虚拟终端中运行下面的命令：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo apt-get install cbm&lt;/pre&gt;
&lt;p&gt;我们只需使用下面展示的命令来在 shell 窗口或虚拟终端中运行 cbm：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ cbm&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/d6ddcd9d9570c8561139a8e75557d58b.jpg&quot; width=&quot;671&quot; height=&quot;453&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;18) bmon&lt;/strong&gt;&lt;br&gt;
Bmon （ Bandwidth Monitoring） ，是一个用于调试和实时监控带宽的工具。这个工具能够检索各种输入模块的统计数据。它提供了多种输出方式，包括一个基于 curses 库的界面，轻量级的HTML输出，以及 ASCII 输出格式。&lt;/p&gt;
&lt;p&gt;bmon 可以在软件仓库中找到，所以我们可以通过使用 apt 包管理器来在 Debian、Ubuntu 中安装它。为此，我们需要在一个 shell 窗口或虚拟终端中运行下面的命令：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo apt-get install bmon&lt;/pre&gt;
&lt;p&gt;我们可以使用下面的命令来运行 bmon 以监视我们的网络状态：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ bmon&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/9c4ffee24597330f8a38972be62b827d.jpg&quot; width=&quot;671&quot; height=&quot;589&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;19) tcpdump&lt;/strong&gt;&lt;br&gt;
TCPDump 是一个用于网络监控和数据获取的工具。它可以为我们节省很多的时间，并可用来调试网络或服务器的相关问题。它可以打印出在某个网络接口上与布尔表达式相匹配的数据包所包含的内容的一个描述。&lt;/p&gt;
&lt;p&gt;tcpdump 可以在 Debian、Ubuntu 的默认软件仓库中找到，我们可以简单地以 sudo 权限使用 apt 包管理器来安装它。为此，我们需要在一个 shell 窗口或虚拟终端中运行下面的命令：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo apt -get install tcpdump&lt;/pre&gt;
&lt;p&gt;tcpdump 也可以在 Fedora、CentOS、RHEL 的软件仓库中找到。我们可以像下面一样通过 yum 包管理器来安装它：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;# yum install tcpdump&lt;/pre&gt;
&lt;p&gt;tcpdump 需要以 root 权限或超级用户来运行，我们需要带上我们想要监控的 TCP 连接的网络接口名称来执行 tcpdump 。在这里，我们有 wlan2 这个网络接口，所以可以像下面这样使用：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo tcpdump -i wlan2&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/53d264ac456414fb07d0bb9dbeece31b.jpg&quot; width=&quot;690&quot; height=&quot;500&quot;&gt;&lt;/p&gt;
&lt;p&gt;假如你只想监视一个特定的端口，则可以运行下面的命令。下面是一个针对 80 端口(网络服务器)的例子：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo tcpdump -i wlan2 &#39;port 80&#39;&lt;/pre&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/0b136b946916009ef37401770de84bea.jpg&quot; width=&quot;690&quot; height=&quot;467&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;20) ntopng&lt;/strong&gt;&lt;br&gt;
[ntopng][20] 是 ntop 的下一代版本。它是一个用于展示网络使用情况的网络探头，在一定程度上它与 top 针对进程所做的工作类似。ntopng 基于 libpcap 并且它以可移植的方式被重写，以达到可以在每一个 Unix 平台 、 MacOSX 以及 Win32 上运行的目的。&lt;/p&gt;
&lt;p&gt;为了在 Debian，Ubuntu 系统上安装 ntopng，首先我们需要安装 编译 ntopng 所需的依赖软件包。你可以通过在一个 shell 窗口或一个虚拟终端中运行下面的命令来安装它们：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo apt-get install libpcap-dev libglib2.0-dev libgeoip-dev redis-server wget libxml2-dev build-essential checkinstall&lt;/pre&gt;
&lt;p&gt;现在，我们需要像下面一样针对我们的系统手动编译 ntopng ：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;$ sudo wget http://sourceforge.net/projects/ntop/files/ntopng/ntopng-1.1_6932.tgz/download
$ sudo tar zxfv ntopng-1.1_6932.tgz
$ sudo cd ntopng-1.1_6932
$ sudo ./configure
$ sudo make
$ sudo make install&lt;/pre&gt;
&lt;p&gt;这样，在你的 Debian 或 Ubuntu 系统上应该已经安装上了你编译的 ntopng 。&lt;/p&gt;
&lt;p&gt;我们已经有了有关 ntopng 的使用方法的教程，它既可以在命令行也可以在 Web 界面中使用，我们可以前往这些教程来获得有关 ntopng 的知识。&lt;/p&gt;


        
        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Sun, 17 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-17-86954-b52f8b3e4.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-17-86954-b52f8b3e4.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>11个让你吃惊的 Linux 终端命令</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;我已经用了十年的Linux了，通过今天这篇文章我将向大家展示一系列的命令、工具和技巧，我希望一开始就有人告诉我这些，而不是曾在我成长道路上绊住我。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. 命令行日常系快捷键&lt;/strong&gt;&lt;br&gt;
如下的快捷方式非常有用，能够极大的提升你的工作效率：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CTRL + U – 剪切光标前的内容&lt;/li&gt;
&lt;li&gt;CTRL + K – 剪切光标至行末的内容&lt;/li&gt;
&lt;li&gt;CTRL + Y – 粘贴&lt;/li&gt;
&lt;li&gt;CTRL + E – 移动光标到行末&lt;/li&gt;
&lt;li&gt;CTRL + A – 移动光标到行首&lt;/li&gt;
&lt;li&gt;ALT + F – 跳向下一个空格&lt;/li&gt;
&lt;li&gt;ALT + B – 跳回上一个空格&lt;/li&gt;
&lt;li&gt;ALT + Backspace – 删除前一个单词&lt;/li&gt;
&lt;li&gt;CTRL + W – 剪切光标前一个单词&lt;/li&gt;
&lt;li&gt;Shift + Insert – 向终端内粘贴文本&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;那么为了让上述内容更易理解来看下面的这行命令。&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;sudo apt-get intall programname&lt;/pre&gt;
&lt;p&gt;如你所见，命令中存在拼写错误，为了正常执行需要把“intall”替换成“install”。&lt;/p&gt;
&lt;p&gt;想象现在光标正在行末，我们有很多的方法将她退回单词install并替换它。&lt;/p&gt;
&lt;p&gt;我可以按两次ALT+B这样光标就会在如下的位置（这里用指代光标的位置）。&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;sudo apt-get^intall programname&lt;/pre&gt;
&lt;p&gt;现在你可以按两下方向键并将“s”插入到install中去了。&lt;/p&gt;
&lt;p&gt;如果你想将浏览器中的文本复制到终端，可以使用快捷键”shift + insert”。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. SUDO !!&lt;/strong&gt;&lt;br&gt;
如果你还不知道这个命令，我觉得你应该好好感谢我，因为如果你不知道的话，那每次你在输入长串命令后看到“permission denied”后一定会痛苦不堪。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sudo !!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如何使用sudo !!？很简单。试想你刚输入了如下命令：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;apt-get install ranger&lt;/pre&gt;
&lt;p&gt;一定会出现“Permission denied”，除非你已经登录了足够高权限的账户。&lt;/p&gt;
&lt;p&gt;sudo !! 就会用 sudo 的形式运行上一条命令。所以上一条命令就变成了这样：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;sudo apt-get install ranger&lt;/pre&gt;
&lt;p&gt;如果你不知道什么是sudo，戳这里。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. 暂停并在后台运行命令&lt;/strong&gt;&lt;br&gt;
我曾经写过一篇如何在终端后台运行命令的指南。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CTRL + Z – 暂停应用程序&lt;/li&gt;
&lt;li&gt;fg – 重新将程序唤到前台&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如何使用这个技巧呢?&lt;/p&gt;
&lt;p&gt;试想你正用nano编辑一个文件：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;sudo nano abc.txt&lt;/pre&gt;
&lt;p&gt;文件编辑到一半你意识到你需要马上在终端输入些命令，但是nano在前台运行让你不能输入。&lt;/p&gt;
&lt;p&gt;你可能觉得唯一的方法就是保存文件，退出 nano，运行命令以后在重新打开nano。&lt;/p&gt;
&lt;p&gt;其实你只要按CTRL + Z，前台的命令就会暂停，画面就切回到命令行了。然后你就能运行你想要运行命令，等命令运行完后在终端窗口输入“fg”就可以回到先前暂停的任务。&lt;/p&gt;
&lt;p&gt;有一个尝试非常有趣就是用nano打开文件，输入一些东西然后暂停会话。再用nano打开另一个文件，输入一些什么后再暂停会话。如果你输入“fg”你将回到第二个用nano打开的文件。只有退出nano再输入“fg”，你才会回到第一个用nano打开的文件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. 使用nohup在登出SSH会话后仍运行命令&lt;/strong&gt;&lt;br&gt;
如果你用ssh登录别的机器时，nohup命令真的非常有用。&lt;/p&gt;
&lt;p&gt;那么怎么使用nohup呢？&lt;/p&gt;
&lt;p&gt;想象一下你使用ssh远程登录到另一台电脑上，你运行了一条非常耗时的命令然后退出了ssh会话，不过命令仍在执行。而nohup可以将这一场景变成现实。&lt;/p&gt;
&lt;p&gt;举个例子，因为测试的需要，我用我的树莓派来下载发行版。我绝对不会给我的树莓派外接显示器、键盘或鼠标。&lt;/p&gt;
&lt;p&gt;一般我总是用SSH从笔记本电脑连接到树莓派。如果我在不用nohup的情况下使用树莓派下载大型文件，那我就必须等待到下载完成后，才能登出ssh会话关掉笔记本。可如果是这样，那我为什么要使用树莓派下文件呢？&lt;/p&gt;
&lt;p&gt;使用nohup的方法也很简单，只需如下例中在nohup后输入要执行的命令即可：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;nohup wget http://mirror.is.co.za/mirrors/linuxmint.com/iso//stable/17.1/linuxmint-17.1-cinnamon-64bit.iso &amp;amp;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;5. ‘在’特定的时间运行Linux命令&lt;/strong&gt;&lt;br&gt;
‘nohup’命令在你用SSH连接到服务器，并在上面保持执行SSH登出前任务的时候十分有用。&lt;/p&gt;
&lt;p&gt;想一下如果你需要在特定的时间执行相同的命令，这种情况该怎么办呢？&lt;/p&gt;
&lt;p&gt;命令‘at’就能妥善解决这一情况。以下是‘at’使用示例。&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;at 10:38 PM Fri
at&amp;gt; cowsay &#39;hello&#39;
at&amp;gt; CTRL + D&lt;/pre&gt;
&lt;p&gt;上面的命令能在周五下午10时38分运行程序cowsay。&lt;/p&gt;
&lt;p&gt;使用的语法就是‘at’后追加日期时间。当at&amp;gt;提示符出现后就可以输入你想在那个时间运行的命令了。&lt;/p&gt;
&lt;p&gt;CTRL + D 返回终端。&lt;/p&gt;
&lt;p&gt;还有许多日期和时间的格式，都需要你好好翻一翻‘at’的man手册来找到更多的使用方式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6. Man手册&lt;/strong&gt;&lt;br&gt;
Man手册会为你列出命令和参数的使用大纲，教你如何使用她们。Man手册看起来沉闷呆板。（我思忖她们也不是被设计来娱乐我们的）。&lt;/p&gt;
&lt;p&gt;不过这不代表你不能做些什么来使她们变得漂亮些。&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;export PAGER=most&lt;/pre&gt;
&lt;p&gt;你需要安装 ‘most’；她会使你的你的man手册的色彩更加绚丽。&lt;/p&gt;
&lt;p&gt;你可以用以下命令给man手册设定指定的行长：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;export MANWIDTH=80&lt;/pre&gt;
&lt;p&gt;最后，如果你有一个可用的浏览器，你可以使用-H在默认浏览器中打开任意的man页。&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;man -H &amp;lt;command&amp;gt;&lt;/pre&gt;
&lt;p&gt;注意啦，以上的命令只有在你将默认的浏览器设置到环境变量$BROWSER中了之后才效果哟。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7. 使用htop查看和管理进程&lt;/strong&gt;&lt;br&gt;
你用哪个命令找出电脑上正在运行的进程的呢？我敢打赌是‘ps’并在其后加不同的参数来得到你所想要的不同输出。&lt;/p&gt;
&lt;p&gt;安装‘htop’吧！绝对让你相见恨晚。&lt;/p&gt;
&lt;p&gt;htop在终端中将进程以列表的方式呈现，有点类似于Windows中的任务管理器。你可以使用功能键的组合来切换排列的方式和展示出来的项。你也可以在htop中直接杀死进程。&lt;/p&gt;
&lt;p&gt;在终端中简单的输入htop即可运行。&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;htop&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;8. 使用ranger浏览文件系统&lt;/strong&gt;&lt;br&gt;
如果说htop是命令行进程控制的好帮手，那么ranger就是命令行浏览文件系统的好帮手。&lt;/p&gt;
&lt;p&gt;你在用之前可能需要先安装，不过一旦安装了以后就可以在命令行输入以下命令启动她：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;ranger&lt;/pre&gt;
&lt;p&gt;在命令行窗口中ranger和一些别的文件管理器很像，但是相比上下结构布局，她是左右结构的，这意味着你按左方向键你将前进到上一个文件夹，而右方向键则会切换到下一个。&lt;/p&gt;
&lt;p&gt;在使用前ranger的man手册还是值得一读的，这样你就可以用快捷键操作ranger了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9. 取消关机&lt;/strong&gt;&lt;br&gt;
无论是在命令行还是图形用户界面关机后，才发现自己不是真的想要关机。&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;shutdown -c&lt;/pre&gt;
&lt;p&gt;需要注意的是，如果关机已经开始则有可能来不及停止关机。&lt;/p&gt;
&lt;p&gt;以下是另一个可以尝试命令：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pkill shutdown&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;10. 杀死挂起进程的简单方法&lt;/strong&gt;&lt;br&gt;
想象一下，你正在运行的应用程序不明原因的僵死了。&lt;/p&gt;
&lt;p&gt;你可以使用‘ps -ef’来找到该进程后杀掉或者使用‘htop’。&lt;/p&gt;
&lt;p&gt;有一个更快、更容易的命令叫做xkill。&lt;/p&gt;
&lt;p&gt;简单的在终端中输入以下命令并在窗口中点击你想杀死的应用程序。&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;xkill&lt;/pre&gt;
&lt;p&gt;那如果整个系统挂掉了怎么办呢？&lt;/p&gt;
&lt;p&gt;按住键盘上的‘alt’和‘sysrq’不放，然后慢慢输入以下键：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;REISUB&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样不按电源键你的计算机也能重启了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;11. 下载Youtube视频&lt;/strong&gt;&lt;br&gt;
一般来说我们大多数人都喜欢看Youtube的视频，也会通过钟爱的播放器播放Youtube的流媒体。&lt;/p&gt;
&lt;p&gt;如果你需要离线一段时间（比如：从苏格兰南部坐飞机到英格兰南部旅游的这段时间）那么你可能希望下载一些视频到存储设备中，到闲暇时观看。&lt;/p&gt;
&lt;p&gt;你所要做的就是从包管理器中安装youtube-dl。&lt;/p&gt;
&lt;p&gt;你可以用以下命令使用youtube-dl：&lt;/p&gt;
&lt;pre class=&quot;brush: shell; gutter: true&quot;&gt;youtube-dl url-to-video&lt;/pre&gt;
&lt;p&gt;你可以在Youtubu视频页面点击分享链接得到视频的url。只要简单的复制链接在粘帖到命令行就行了（要用shift + insert快捷键哟）。&lt;/p&gt;


        
        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Fri, 15 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-15-86948-2f47ad907.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-15-86948-2f47ad907.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>How-old.net 网站是如何运作的？</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;【伯乐在线导读】：最近微软的 How-old.net 网站非常火热，用户在该站上传照片后，它可以测算出照片中人物的性别和年龄。&lt;/p&gt;
&lt;p&gt;有国外网友在 Quora 上问了 How-old.net 的工作原理。下面是参与了该项目的微软项目经理 Eason Wang 的回复。&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/06fe2deada1715c47ffc1c6891cb1088.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（Eason Wang 是 Bing 的资深项目经理，此回答获得了三千三百个点赞）&lt;/p&gt;
&lt;p&gt;我本人就直接参与了这个项目。说实话，这个小网站的走红大大出乎了我的意料。我事后进行了一些为什么会走红的分析并且在 Medium 写了一篇&lt;a href=&quot;https://medium.com/@yushunwang/10-reasons-why-howoldrobot-gets-viral-1a0eb5cb0d96&quot; target=&quot;_blank&quot;&gt;文章&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;回到主题吧，我的回答分成两个部分。第一个部分会讲讲如何快速地在任意的软件中实现一模一样的功能，第二个部分我会深入一些描述这项技术本身。&lt;/p&gt;
&lt;p&gt;在过去的几年和微软研发部门的合作中，就 Bing 的图像搜索技术而言，我们达到了最好的工业图像理解能力，这项技术迅速延伸到微软的其他产品。目前在 &lt;a href=&quot;https://www.projectoxford.ai/&quot; target=&quot;_blank&quot;&gt;微软牛津项目主页&lt;/a&gt; 上，这项技术对所有的开发者开放。想要在自己的软件中实现一样的功能，你只需要简单地调用一下我们的 web API，就可以以 JSON 格式获取所需的一切信息。你可以尝试着在 &lt;a href=&quot;http://www.projectoxford.ai&quot; target=&quot;_blank&quot;&gt;www.projectoxford.ai&lt;/a&gt; 的这个页面上传一幅图像，它将在数秒内给你结果，脸部坐标、性别和年龄信息都在里面。Face API 只是我们在牛津项目上做的特性的其中一项。还有很多其他的核心功能来帮助打造创新性的应用。微软内部的 API 向大众开放让我感到很兴奋，我知道这会对开发社区起到深远的影响。这让之前看起来不可能的事情变得只用简单地调用一下 web API 就能做到了。#HowOldRobot 只是这些能力的小小展示，Azure 机器学习团队的一个开发人员只用了一天就把它开发出来了。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/fc0c9674e425846390635ecc96f9394c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（译者注：以下是 API 示例，为 JSON 格式）&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;JSON:
[
  {
    &quot;faceId&quot;: &quot;5af35e84-ec20-4897-9795-8b3d4512a1f9&quot;,
    &quot;faceRectangle&quot;: {
      &quot;width&quot;: 60,
      &quot;height&quot;: 60,
      &quot;left&quot;: 276,
      &quot;top&quot;: 43
    },
    &quot;faceLandmarks&quot;: {
      &quot;pupilLeft&quot;: {
        &quot;x&quot;: &quot;295.1&quot;,
        &quot;y&quot;: &quot;56.8&quot;
      },
      &quot;pupilRight&quot;: {
        &quot;x&quot;: &quot;317.9&quot;,
        &quot;y&quot;: &quot;59.6&quot;
      },
      &quot;noseTip&quot;: {
        &quot;x&quot;: &quot;311.6&quot;,
        &quot;y&quot;: &quot;74.7&quot;
      },
      &quot;mouthLeft&quot;: {
        &quot;x&quot;: &quot;291.0&quot;,
        &quot;y&quot;: &quot;86.3&quot;
      },
      &quot;mouthRight&quot;: {
        &quot;x&quot;: &quot;311.6&quot;,
        &quot;y&quot;: &quot;88.6&quot;
      },
      &quot;eyebrowLeftOuter&quot;: {
        &quot;x&quot;: &quot;281.6&quot;,
        &quot;y&quot;: &quot;50.1&quot;
      },
      &quot;eyebrowLeftInner&quot;: {
        &quot;x&quot;: &quot;304.2&quot;,
        &quot;y&quot;: &quot;51.6&quot;
      },
      &quot;eyeLeftOuter&quot;: {
        &quot;x&quot;: &quot;289.1&quot;,
        &quot;y&quot;: &quot;57.1&quot;
      },
      &quot;eyeLeftTop&quot;: {
        &quot;x&quot;: &quot;294.0&quot;,
        &quot;y&quot;: &quot;54.5&quot;
      },
      &quot;eyeLeftBottom&quot;: {
        &quot;x&quot;: &quot;293.0&quot;,
        &quot;y&quot;: &quot;61.0&quot;
      },
      &quot;eyeLeftInner&quot;: {
        &quot;x&quot;: &quot;297.8&quot;,
        &quot;y&quot;: &quot;58.7&quot;
      },
      &quot;eyebrowRightInner&quot;: {
        &quot;x&quot;: &quot;316.0&quot;,
        &quot;y&quot;: &quot;54.2&quot;
      },
      &quot;eyebrowRightOuter&quot;: {
        &quot;x&quot;: &quot;324.7&quot;,
        &quot;y&quot;: &quot;54.2&quot;
      },
      &quot;eyeRightInner&quot;: {
        &quot;x&quot;: &quot;312.9&quot;,
        &quot;y&quot;: &quot;60.9&quot;
      },
      &quot;eyeRightTop&quot;: {
        &quot;x&quot;: &quot;317.8&quot;,
        &quot;y&quot;: &quot;57.7&quot;
      },
      &quot;eyeRightBottom&quot;: {
        &quot;x&quot;: &quot;317.9&quot;,
        &quot;y&quot;: &quot;63.7&quot;
      },
      &quot;eyeRightOuter&quot;: {
        &quot;x&quot;: &quot;322.8&quot;,
        &quot;y&quot;: &quot;60.8&quot;
      },
      &quot;noseRootLeft&quot;: {
        &quot;x&quot;: &quot;304.0&quot;,
        &quot;y&quot;: &quot;60.2&quot;
      },
      &quot;noseRootRight&quot;: {
        &quot;x&quot;: &quot;312.2&quot;,
        &quot;y&quot;: &quot;61.2&quot;
      },
      &quot;noseLeftAlarTop&quot;: {
        &quot;x&quot;: &quot;302.6&quot;,
        &quot;y&quot;: &quot;70.2&quot;
      },
      &quot;noseRightAlarTop&quot;: {
        &quot;x&quot;: &quot;313.0&quot;,
        &quot;y&quot;: &quot;70.0&quot;
      },
      &quot;noseLeftAlarOutTip&quot;: {
        &quot;x&quot;: &quot;298.8&quot;,
        &quot;y&quot;: &quot;76.2&quot;
      },
      &quot;noseRightAlarOutTip&quot;: {
        &quot;x&quot;: &quot;315.2&quot;,
        &quot;y&quot;: &quot;76.6&quot;
      },
      &quot;upperLipTop&quot;: {
        &quot;x&quot;: &quot;307.3&quot;,
        &quot;y&quot;: &quot;84.0&quot;
      },
      &quot;upperLipBottom&quot;: {
        &quot;x&quot;: &quot;306.6&quot;,
        &quot;y&quot;: &quot;86.4&quot;
      },
      &quot;underLipTop&quot;: {
        &quot;x&quot;: &quot;305.5&quot;,
        &quot;y&quot;: &quot;89.6&quot;
      },
      &quot;underLipBottom&quot;: {
        &quot;x&quot;: &quot;304.1&quot;,
        &quot;y&quot;: &quot;94.0&quot;
      }
    },
    &quot;attributes&quot;: {
      &quot;age&quot;: 24,
      &quot;gender&quot;: &quot;female&quot;,
      &quot;headPose&quot;: {
        &quot;roll&quot;: &quot;4.0&quot;,
        &quot;yaw&quot;: &quot;31.3&quot;,
        &quot;pitch&quot;: &quot;0.0&quot;
      }
    }
  }
]&lt;/pre&gt;
&lt;p&gt;How-old.net  这个网站主要依赖于三个关键的技术：&lt;strong&gt;面部检测、性别分类和年龄检测&lt;/strong&gt;。面部检测是另外两个的基础。对于年龄检测和性别检测来说，只是机器学习中很典型的回归和分类问题，涉及到了面部特征的表示、训练数据的采集、回归和分类模型的构建以及模型的优化。这方面有很多的已经发表的论文。如果你有兴趣想进一步了解就告诉我。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/4d29a5ce351c42267029f553e2efa737.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;另一方面，深度学习和对大规模数据的理解推动了图像理解的突破，为更加智能的系统和程序端口打开了一扇门。你可以看看我最新的关于图像图表如何应用于更进阶场景的博客：&lt;a href=&quot;http://blogs.bing.com/search-quality-insights/2015/04/22/the-image-graph-powering-the-next-generation-of-bing-image-search/&quot; target=&quot;_blank&quot;&gt;http://blogs.bing.com/search-qua…&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;留下你的评论让我改进这个回答，谢谢！&lt;/p&gt;

        
        &lt;!-- BEGIN #author-bio --&gt;

&lt;div id=&quot;author-bio&quot;&gt;
	
	&lt;h3 class=&quot;widget-title&quot;&gt;
	关于作者： &lt;a href=&quot;http://blog.jobbole.com/author/aahung/&quot;&gt;aahung&lt;/a&gt;
	&lt;/h3&gt;
	&lt;div class=&quot;alignleft&quot;&gt;
		&lt;a href=&quot;http://blog.jobbole.com/author/aahung/&quot;&gt;
					&lt;/a&gt;
	&lt;/div&gt;
	&lt;p&gt;&lt;/p&gt;
	&lt;p&gt;
		&lt;a style=&quot;text-decoration: none;&quot; href=&quot;http://blog.jobbole.com/author/aahung/&quot;&gt;查看aahung的更多文章 »&lt;/a&gt;
	&lt;/p&gt;
	&lt;div class=&quot;clear&quot;&gt;&lt;/div&gt;
	
&lt;/div&gt;

&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Fri, 15 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-15-86939-260384a33.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-15-86939-260384a33.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>修改Hosts为何不生效，是DNS缓存？</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果浏览器使用了代理工具，修改 Hosts 也不会生效。这里是因为，浏览器会优先考虑代理工具（如添加 pac 文件、SwitchySharp等）的代理，建议调试的时候先关闭这些代理。&lt;/li&gt;
&lt;li&gt;使用 pac 文件代理有的时候部分文件的代理不生效，应该是 pac 对应的代理服务器上，做了部分处理。&lt;/li&gt;
&lt;li&gt;部分浏览器也有 DNS 缓存，如 chrome(chrome://dns)，这是为什么重启浏览器也不生效的原因，一般设定时间为 60s (如 Firefox)。&lt;/li&gt;
&lt;li&gt;浏览器有DNS缓存，系统也会存在 DNS 缓存，有的时候即便在 chrome://dns 清空了浏览器 DNS 缓存，依然不生效，是因为系统 DNS 缓存还未刷新，刷新方式可以看这篇文章。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;相信很多同学都在使用 SwitchHosts/iHosts/Gas Mask 等 Hosts 管理工具，当然也有人直接修改 /etc/hosts 或者 system32/drivers/etc/hosts 文件，而经常遇到的疑问是：咿，刚才不是修改并且保存了么，为何 Chrome 浏览器还不生效呢？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;有人说重启下浏览器就好了，&lt;/li&gt;
&lt;li&gt;有人说清空下缓存 DNS（chrome://net-internals/#DNS）就好了，&lt;/li&gt;
&lt;li&gt;有人说隐私模式下打开就好了，&lt;/li&gt;
&lt;li&gt;有人说等一分钟吧…&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;结果就是，进入隐私模式的都好了，重启、清空缓存DNS和等一分钟的同学还在继续纠结中。。。&lt;/p&gt;
&lt;p&gt;上面提到的三个工具，SwitchHosts/iHosts/Gas Mask，其实也只有 iHosts 生效了(Mac下)。&lt;/p&gt;
&lt;p&gt;开发过程中我们会无数次的切换 Hosts，如果不知道原理，我们在测试的时候还是很心惊胆战的=_=||&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;修改Hosts不生效的根本原因&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;因为服务器设置了 keep-alive ！次要原因是存在浏览器 DNS 缓存和系统 DNS 缓存。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&amp;gt; Keep-alive 相关文档&lt;/p&gt;
&lt;p&gt;服务器在响应头设置了 Connection: keep-alive （一般的网页都会设置 keep-alive，保持长连接，避免多次连接产生网络消耗）之后，客户端会跟服务器保持长连接，只要长连接不断开，页面在请求的时候就不会重新解析域名！&lt;/p&gt;
&lt;p&gt;我们可以这样来测试：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;打开一个你至少两分钟没有打开的浏览器（你也可以关闭掉你的浏览器，然后重新打开，记得把所有的 tab 都关了，除了当前 tab ^_^）&lt;/li&gt;
&lt;li&gt;在 hosts 添加 127.0.0.1 www.taobao.com&lt;/li&gt;
&lt;li&gt;新开 tab，打开 www.taobao.com，是不是进不去了 &amp;lt;这里说明 hosts 修改生效了&amp;gt;&lt;/li&gt;
&lt;li&gt;注释掉刚才hosts修改，# 127.0.0.1 www.taobao.com ，再打开 www.taobao.com，很好，正常打开了 &amp;lt;这里说明 hosts 修改也生效了&amp;gt;&lt;/li&gt;
&lt;li&gt;去掉注释符，127.0.0.1 www.taobao.com ，再打开 www.taobao.com，依然可以访问！！！&lt;/li&gt;
&lt;li&gt;Chrome 中进入 chrome://net-internals/#sockets，&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/65f6e1ecce406013f121898b640030de.jpg&quot; width=&quot;690&quot; height=&quot;704&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看到淘宝首页中很多域名都是与服务器保持着长连接，点击上方的 close idle sockets 按钮，可以关闭所有的长连接。此时，再去访问 &lt;a href=&quot;http://www.taobao.com/&quot;&gt;www.taobao.com&lt;/a&gt;，是不是进不去了！&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;为何一些修改可以让 “Hosts 生效”&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1. 重启浏览器&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;重启浏览器之后，所有的连接（包括长连接）都会断开，自然就生效了&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. 隐私模式打开&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因为隐私模式下不会复用 TCP 连接，新开连接的时候，会重新解析 DNS 域名，自然也生效了&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. iHosts 管理器在 Mac 下生效&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因为我在 Windows 下测试过，貌似没有立即生效。问了 iHosts 的作者@必隆，他告诉我，在修改 hosts 文件的时候，会重启网络服务，这个时候必然会断开所有的 TCP 连接（重启网络服务，差不多相当于先断网再联网…)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. 修改之后，等一会儿…&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;“等一会儿”，要稍微等久一点，keep-alive 的默认设置是 120s，开发者也有可能增大或者减小这个配置，所以“等一会儿”也是很伤神的=。 =&lt;/p&gt;


        
        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Thu, 14 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-14-86935-643480ab5.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-14-86935-643480ab5.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>防范 DDoS 攻击的 15 个方法</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;为了对抗 DDoS(分布式拒绝服务)攻击，你需要对攻击时发生了什么有一个清楚的理解. 简单来讲，DDoS 攻击可以通过利用服务器上的漏洞，或者消耗服务器上的资源(例如 内存、硬盘等等)来达到目的。&lt;a href=&quot;http://securitywing.com/10-major-types-of-ddos-attacks-and-prevention/&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;DDoS 攻击主要要两大类: 带宽耗尽攻击和资源耗尽攻击&lt;/a&gt;. 为了有效遏制这两种类型的攻击，你可以按照下面列出的步骤来做：&lt;/p&gt;
&lt;p&gt;1. 如果只有几台计算机是攻击的来源，并且你已经确定了这些来源的 IP 地址, 你就在防火墙服务器上放置一份 &lt;a href=&quot;http://securitywing.com/access-control-list/&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;ACL（访问控制列表)&lt;/a&gt; 来阻断这些来自这些 IP 的访问。如果可能的话 将 web 服务器的 IP 地址变更一段时间，但是如果攻击者通过查询你的 DNS 服务器解析到你新设定的 IP，那这一措施及不再有效了。&lt;/p&gt;
&lt;p&gt;2. 如果你确定攻击来自一个特定的国家，可以考虑将来自那个国家的 IP 阻断，至少要阻断一段时间.&lt;/p&gt;
&lt;p&gt;3、监控进入的网络流量。通过这种方式可以知道谁在访问你的网络，可以监控到异常的访问者，可以在事后分析日志和来源IP。在进行大规模的攻击之前，攻击者可能会使用少量的攻击来测试你网络的健壮性。&lt;/p&gt;
&lt;p&gt;4、对付带宽消耗型的攻击来说，最有效（也很昂贵）的解决方案是购买更多的带宽。&lt;/p&gt;
&lt;p&gt;5、也可以使用高性能的负载均衡软件，使用多台服务器，并部署在不同的数据中心。&lt;/p&gt;
&lt;p&gt;6、对web和其他资源使用负载均衡的同时，也使用相同的策略来保护DNS。&lt;/p&gt;
&lt;p&gt;7、优化资源使用提高 web server 的负载能力。例如，使用 apache 可以安装 apachebooster 插件，该插件与 varnish 和 nginx 集成，可以应对突增的流量和内存占用。&lt;/p&gt;
&lt;p&gt;8、使用高可扩展性的 DNS 设备来保护针对 DNS 的 DDOS 攻击。可以考虑购买 Cloudfair 的商业解决方案，它可以提供针对 DNS 或 TCP/IP3 到7层的 DDOS 攻击保护。&lt;/p&gt;
&lt;p&gt;9、启用路由器或防火墙的反IP欺骗功能。在 CISCO 的 ASA 防火墙中配置该功能要比在路由器中更方便。在 ASDM（Cisco Adaptive Security Device Manager）中启用该功能只要点击“配置”中的“防火墙”，找到“anti-spoofing”然后点击启用即可。也可以在路由器中使用 ACL（access control list）来防止 IP 欺骗，先针对内网创建 ACL，然后应用到互联网的接口上。&lt;/p&gt;
&lt;p&gt;10、使用第三方的服务来保护你的网站。有不少公司有这样的服务，提供高性能的基础网络设施帮你抵御拒绝服务攻击。你只需要按月支付几百美元费用就行。&lt;/p&gt;
&lt;p&gt;11、注意服务器的安全配置，避免资源耗尽型的 DDOS 攻击。&lt;/p&gt;
&lt;p&gt;12、听从专家的意见，针对攻击事先做好应对的应急方案。&lt;/p&gt;
&lt;p&gt;13、监控网络和 web 的流量。如果有可能可以配置多个分析工具，例如：Statcounter 和 Google analytics，这样可以更直观了解到流量变化的模式，从中获取更多的信息。&lt;/p&gt;
&lt;p&gt;14、保护好 DNS 避免 DNS 放大攻击。&lt;/p&gt;
&lt;p&gt;15、在路由器上禁用 ICMP。仅在需要测试时开放 ICMP。在配置路由器时也考虑下面的策略：流控，包过滤，半连接超时，垃圾包丢弃，来源伪造的数据包丢弃，SYN 阀值，禁用 ICMP 和 UDP 广播。&lt;/p&gt;


        
        &lt;!-- BEGIN #author-bio --&gt;


&lt;!-- END #author-bio --&gt;
	

</description>
        <pubDate>Thu, 14 May 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-05-14-86932-6ab912462.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-05-14-86932-6ab912462.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
  </channel>
</rss>
