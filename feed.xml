<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>IT技术干货</title>
    <description>[IT技术干货iftti.com] @KernelHacks</description>
    <link>http://iftti.com/</link>
    <atom:link href="http://iftti.com/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Fri, 09 Jan 2015 11:00:48 +0800</pubDate>
    <lastBuildDate>Fri, 09 Jan 2015 11:00:48 +0800</lastBuildDate>
    <generator>Jekyll v2.2.0</generator>
    
      <item>
        <title>给 Kibana3 添加脚本化字段支持</title>
        <description>

  
  &lt;div style=&quot;background-color: #FFF;&quot;&gt;
    &lt;p&gt;Kibana4 中确实有不少让人眼前一亮的新特性，但是整体框架和使用思路上的重构实在让人较难上手。所以，把一些有需要的特性，port 回目前更稳定的 Kibana3 就有必要了。好在去年在自己 fork 中已经做了很多铺垫，包括一些基础库的版本更新。这些特性基本都只需要几行代码的变动就可以实现。&lt;/p&gt;
&lt;p&gt;从上次写博客介绍的 uniq histogram 去重统计功能后，这段时间又添加了两个功能。&lt;/p&gt;
&lt;h2 id=&quot;table-&quot;&gt;table 的数据导出&lt;/h2&gt;
&lt;p&gt;kibana3 已经带有 &lt;a href=&quot;https://github.com/eligrey/FileSaver.js&quot;&gt;filesaver.js&lt;/a&gt;，所以加一个 &lt;code&gt;exportAsCsv&lt;/code&gt; 函数即可。要点在于怎么给 table panel 右上角那排小按钮加上一个新图标。&lt;/p&gt;
&lt;p&gt;我之前说过，kibana3 代码划分的很细致，每个 panel 都固定只需要提供 editor.html，module.html，module.js 三个文件即可。panel 本身的框架，是不用关心的。因为这部分代码，在 &lt;code&gt;app/directives/kibanaPanel.js&lt;/code&gt; 中。这次我们想修改 panel 外围的样式，就需要来看这个的代码了。最关键的部分在这里：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;s1&quot;&gt;&#39;&amp;lt;span ng-repeat=&quot;task in panelMeta.modals&quot; class=&quot;row-button extra&quot; ng-show=&quot;task.show&quot;&amp;gt;&#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
              &lt;span class=&quot;s1&quot;&gt;&#39;&amp;lt;span bs-modal=&quot;task.partial&quot; class=&quot;pointer&quot;&amp;gt;&amp;lt;i &#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
                &lt;span class=&quot;s1&quot;&gt;&#39;bs-tooltip=&quot;task.description&quot; ng-class=&quot;task.icon&quot; class=&quot;pointer&quot;&amp;gt;&amp;lt;/i&amp;gt;&amp;lt;/span&amp;gt;&#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
            &lt;span class=&quot;s1&quot;&gt;&#39;&amp;lt;/span&amp;gt;&#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;也就是说，它会读取你在 module.js 里定义的 &lt;code&gt;$scope.panelMeta.modals&lt;/code&gt; 数组，然后依次显示。那么就好办了，在我们 table/module.js 里定义下就好了：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;nx&quot;&gt;$scope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;panelMeta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
       &lt;span class=&quot;nx&quot;&gt;modals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
         &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;nx&quot;&gt;description&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Export&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;nx&quot;&gt;icon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;icon-download-alt&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;nx&quot;&gt;partial&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;app/panels/table/export.html&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;nx&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;$scope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;panel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;exportable&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;为了跟其他的比如 inspector, editor 图标行为一致，这里又新增了一个 &lt;code&gt;$scope.panel.exportable&lt;/code&gt; 变量。而这也带来一个问题：之前已经存在的 dashboard，他们的 schema 里是没有这个变量的，所以即便使用带有这个特性的 kibana 打开老 dashboard，依然看不到导出按钮。这时候，可以手动修改一下 schema 的 JSON 内容，添加上一行 &lt;a href=&quot;https://github.com/chenryn/kibana-authorization/blob/master/src/app/dashboards/logstash.json#L138&quot;&gt;&lt;code&gt;&quot;exportable&quot;: true&lt;/code&gt;&lt;/a&gt;，也可以点击 panel 上的 dup 复制按钮，复制出来的 panel 会读取默认变量设置，就会出现导出按钮了。然后删掉原 panel ，保存 dashboard 即可。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：导出的数据只是 table 里的内容，这只是一个 js 功能。不要把它理解成调用 scroll API 获取 Elasticsearch 集群里的全部数据。&lt;/p&gt;
&lt;h2 id=&quot;scriptfield-&quot;&gt;scriptField 聚合&lt;/h2&gt;
&lt;p&gt;Kibana4beta3 的另一个重要特性，是可以预定义一段 script 为 scriptedField，然后在搜索、聚合的时候可以当做普通 field 一样使用这个 scriptedField。示例见官方博客说明(可以直接看&lt;a href=&quot;http://chenlinux.com/2014/12/19/kibana-4-beta-3-now-more-filtery/&quot;&gt;我的翻译&lt;/a&gt;)。至于 script 本身能在 Elasticsearch 里做些什么，之前博客里也写过&lt;a href=&quot;http://chenlinux.com/2014/11/27/elasticsearch-scripts-aggregations/&quot;&gt;两个小示例&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;动态 script 功能在 ES 1.4 之前是因为安全问题被建议关闭的。1.4 开始加入了沙箱功能，才这么大胆的使用。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;我印象中 script field 应该是不能保存在 mapping 里的，于是稍微看了一下 kibana4 的代码，疑似是另外用一个索引来存储这个信息。&lt;em&gt;不确保是这样，kibana4 的代码比 kibana3 难懂多了。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;kibana3 整个界面结构跟 kibana4 不一样，没有单独的字段管理页面，而是通过 &lt;code&gt;app/services/fields.js&lt;/code&gt; 提供了 &lt;code&gt;fields.list&lt;/code&gt; 在各个 panel 的 editor.html 里做 &lt;code&gt;bs-typeahead&lt;/code&gt;。所以，如果完整的思路 port 回来，应该是写一个 &lt;em&gt;app/services/scriptFields.js&lt;/em&gt; 来提供 scriptedField 的增删改查，然后还要自己写个页面来提供操作界面。&lt;/p&gt;
&lt;p&gt;作为页面手残党，我迅速决定放弃这个思路，选择一个更简单的方式来完成类似目的：直接在最常用的 terms panel 里提供输入 script 字符串的功能，反正每个 dashboard 最后会固化成 JSON 的。而且其他 panel 应该不太会用到这个功能(如果要在 table 里也实现，改动又稍大了。Kibana4 里我猜测应该是直接返回勾选的 fields，这个接口是支持 script 的；Kibana3 里则是返回全部字段，然后在 js 里完成的表格字段选择性展示)。&lt;/p&gt;
&lt;p&gt;terms panel 中对类似情况就有示例在。这里本是有个 &lt;code&gt;tmode&lt;/code&gt; 参数，用来选择是用 termsFacet 还是 termstatsFacet API。照葫芦画瓢，我新加了一个 &lt;code&gt;fmode&lt;/code&gt; 参数，用来选择是普通字段(“normal”)还是脚本字段(“script”)：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-html&quot; data-lang=&quot;html&quot;&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;editor-option&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;ng-show=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;panel.fmode == &#39;script&#39;&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;label&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;small&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;ScriptField&lt;span class=&quot;nt&quot;&gt;&amp;lt;/label&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;input&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;input-large&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;ng-model=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;panel.script&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;ng-change=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;set_refresh(true)&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后在生成 request 的时候，做一下判断：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;$scope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;panel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fmode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;script&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
          &lt;span class=&quot;nx&quot;&gt;terms_facet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;scriptField&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;$scope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;panel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这就 OK 了~&lt;/p&gt;
&lt;p&gt;接下来另一个难点：&lt;strong&gt;terms panel 是支持点击生成 filtering 过滤条件的。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;显然 filtering 里没有 script 的支持。filtering 的功能都出自 &lt;code&gt;app/services/filterSrv.js&lt;/code&gt; 服务。其中 &lt;code&gt;toEjsObj&lt;/code&gt; 方法调用不同的 Elastic.js 的 Filter 方法。在这里面可以看到原本 terms 的是怎么生成的：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;terms&#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ejs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;TermsFilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;那么我就添加一个：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;script&#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ejs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;ScriptFilter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;filter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;filterSrv 支持搞定。最后一步，就是返回 terms panel 的 module.js 里完成调用。过一遍 click 关键字很容易找到 &lt;code&gt;build_search&lt;/code&gt; 方法。其中原先是这么生成过滤的：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;isUndefined&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;term&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;meta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
         &lt;span class=&quot;nx&quot;&gt;filterSrv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;terms&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;field&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;$scope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;term&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
           &lt;span class=&quot;nx&quot;&gt;mandate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;negate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;mustNot&#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;must&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)});&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;那么在这个前面判断一下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;$scope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;panel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;fmode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;===&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;script&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;filterSrv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;script&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;script&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;$scope&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;panel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;script&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39; == \&quot;&#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;term&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;\&quot;&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
          &lt;span class=&quot;nx&quot;&gt;mandate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;negate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;mustNot&#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;must&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)});&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;isUndefined&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;term&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;meta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;大功告成！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/chenlinux.com/2335ac5d2a4c0f757b6d3fa1f3d6b87c.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    &lt;hr&gt;
    
    &lt;hr&gt;
  &lt;!-- JiaThis Button BEGIN --&gt;
&lt;div class=&quot;jiathis_style&quot;&gt;
&lt;span class=&quot;jiathis_txt&quot;&gt;分享到：&lt;/span&gt;
&lt;a class=&quot;jiathis_button_tsina&quot;&gt;新浪微博&lt;/a&gt;
&lt;a class=&quot;jiathis_button_weixin&quot;&gt;微信&lt;/a&gt;
&lt;a class=&quot;jiathis_button_renren&quot;&gt;人人网&lt;/a&gt;
&lt;a class=&quot;jiathis_button_ydnote&quot;&gt;有道云笔记&lt;/a&gt;
&lt;a class=&quot;jiathis_button_gmail&quot;&gt;Gmail邮箱&lt;/a&gt;
&lt;a class=&quot;jiathis_button_twitter&quot;&gt;Twitter&lt;/a&gt;
&lt;a class=&quot;jiathis_button_googleplus&quot;&gt;Google+&lt;/a&gt;
&lt;a class=&quot;jiathis_button_hi&quot;&gt;百度空间&lt;/a&gt;
&lt;a class=&quot;jiathis_button_fb&quot;&gt;Facebook&lt;/a&gt;
&lt;a class=&quot;jiathis_button_douban&quot;&gt;豆瓣&lt;/a&gt;
&lt;a href=&quot;http://www.jiathis.com/share?uid=1589850&quot; class=&quot;jiathis jiathis_txt jiathis_separator jtico jtico_jiathis&quot; target=&quot;_blank&quot;&gt;更多&lt;/a&gt;
&lt;a class=&quot;jiathis_counter_style&quot;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var jiathis_config={
	data_track_clickback:true,
	summary:&quot;&quot;,
	ralateuid:{
		&quot;tsina&quot;:&quot;1035836154&quot;
	},
	shortUrl:false,
	hideMore:false
}
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://v3.jiathis.com/code/jia.js?uid=1589850&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;!-- JiaThis Button END --&gt;
&lt;!-- UY BEGIN --&gt;


&lt;!-- UY END --&gt;
  &lt;/div&gt;

</description>
        <pubDate>Tue, 06 Jan 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-01-06-implement-script-field-for-kibana3-633adc088.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-01-06-implement-script-field-for-kibana3-633adc088.html</guid>
        
        
        <category>chenlinux</category>
        
      </item>
    
      <item>
        <title>2014年个人总结</title>
        <description>
&lt;p&gt;2014年对于我来说是重要的一年，因为一方面我刚好年满30岁了，另一方面我的家庭生活和工作都经历了很大的变化。值得总结的包括：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;通过分享，进一步提高了自己的技术影响力&lt;/li&gt;
&lt;li&gt;创业进一步取得成绩&lt;/li&gt;
&lt;/ol&gt;


&lt;h2&gt;技术分享&lt;/h2&gt;

&lt;p&gt;2014年，我的技术分享包括：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;在自己的博客上发布了58篇技术文章。&lt;/li&gt;
&lt;li&gt;在InfoQ网站发表了35期“iOS开发周报”。&lt;/li&gt;
&lt;li&gt;在《程序员》杂志和CSDN网站上发表文章4篇，分别是《从Facebook看移动开发的发展》、《iOS应用安全开发概述》、《WWDC2014，苹果的“软件”发布会》、《那些好用的iOS开发工具》。&lt;/li&gt;
&lt;li&gt;在InfoQ网站和《架构师》迷你书上发表文章4篇，分别是 《作为码农，我们为什么要写作》、《ReactiveCocoa – iOS开发的新框架》、《深入理解Tagged Pointer》、《专访《iOS测试指南》作者羋峮》。&lt;/li&gt;
&lt;li&gt;受朋友邀请，在深圳微信、人人网和豆瓣做了三场技术分享，分享的主题都是：《深入Objective-C对象模型》。&lt;/li&gt;
&lt;li&gt;11月2日在CSDN主办的MDCC移动开发者大会上做了一次分享，主题是：“猿题库的流量优化之路”。&lt;/li&gt;
&lt;li&gt;12月20日在InfoQ主办的ArchSummit北京上做了一次分享，主题是：“猿题库客户端的技术细节”。&lt;/li&gt;
&lt;li&gt;完成了图书&lt;a href=&quot;https://github.com/tangqiaoboy/iOS-Pro&quot;&gt;《iOS开发进阶》&lt;/a&gt;的写作，100本签售版很快卖光，不过正式出版得到2015年1月中旬。&lt;/li&gt;
&lt;li&gt;开源了两个猿题库客户端的iOS基础库：&lt;a href=&quot;https://github.com/yuantiku/YTKKeyValueStore&quot;&gt;YTKKeyValueStore&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/yuantiku/YTKNetwork&quot;&gt;YTKNetwork&lt;/a&gt;，分别得到了400多和700多的star。&lt;/li&gt;
&lt;li&gt;微信公共帐号：iOSDevTips 发表了将近100篇推送，得到了10000多的粉丝。我的微博 &lt;a href=&quot;http://www.weibo.com/tangqiaoboy&quot;&gt;@唐巧_boy&lt;/a&gt; 分享了上百条技术内容，得到了13000多的粉丝。&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;年初的时候我还会怀疑自己的影响力，但现在已经习惯了成为iOS界的“大V”了。微博上分享技术类信息转发常常超过50次，也会常常被人@提醒来请教问题。&lt;/p&gt;

&lt;p&gt;那我是如何树立起自己的技术影响力的呢？这其实主要是通过写博客的方式。我没有想到，从我2010年底开始学iOS开发，到现在短短4年时间，通过博客我能够获得这么大的影响力。现在我也看到越来越多的人加入到技术分享的行列中，用原创的技术博客给整个社区带来知识的分享，同时收获自己的成长和影响力。&lt;/p&gt;

&lt;h2&gt;关于创业&lt;/h2&gt;

&lt;p&gt;我们今年顺利拿到了&lt;a href=&quot;http://tech.sina.com.cn/i/2014-07-22/11209510273.shtml&quot;&gt;C轮1500万美元的融资&lt;/a&gt;，估值达到1.25亿美元。我自己的创业感悟就是觉得决策团队非常牛逼，另外大家的执行力都非常强。我今年除了做日常的iOS开发外，还承担了一些别的事情，包括：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;指导了一位iOS开发零基础的实习生，现在他能够独立的进行开发，非常高兴看着他取得这么大的进步。&lt;/li&gt;
&lt;li&gt;指导了一位实习生完成了Latex渲染引擎在移动端的移植（但其实主要是他的工作出色），这个工作使得我们的客户端在显示公式上和市面上所有同类应用相比具有决定性优势。&lt;/li&gt;
&lt;li&gt;承担了校园招聘的组织工作，大家都被出面试题搞得焦头烂额的，不过最终我们还是搞定了，也收获了不少很有潜力的应届生。&lt;/li&gt;
&lt;li&gt;开始负责小猿搜题这个项目，开始更多地思考产品方面的东西，更多的沟通工作，也开始为更多事情焦虑。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;负责小猿搜题项目对我是一个新的挑战，之前我作为一个iOS程序员，基本上都只需要专注于技术层面上的实现。而现在我不但需要参与产品的讨论，也需要做更多的组织沟通工作。我们团队仍然保持着强大的执行力，小猿搜题从7月底立项到9月底上线只经历了短短2个月时间。而我们的评测数据显示，我们在搜索质量上毫不逊于竞争对手。但我们需要改进的事情还有很多，希望小猿搜题的用户量和活跃度能够超过猿题库，成为又一个拥有海量初高中生用户的产品。&lt;/p&gt;

&lt;h2&gt;读书&lt;/h2&gt;

&lt;p&gt;今年为了更加深入的掌握Swift的函数式编程特性，学习了Scala语言以及coursea上的Funtional Programming相关的课程，不过仍然没有找到感觉。我感觉可能后面多写一些Swift程序才能有深入的理解。&lt;/p&gt;

&lt;p&gt;今年也读了不少产品的书，包括《我的互联网方法论》、《思考的技术》、《失控》、《定位》等。&lt;/p&gt;

&lt;h2&gt;个人Milestone&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;完成 《iOS开发进阶》的写作&lt;/li&gt;
&lt;li&gt;创业完成C轮融资，开始负责小猿搜题项目&lt;/li&gt;
&lt;li&gt;有了宝宝&lt;/li&gt;
&lt;/ul&gt;


</description>
        <pubDate>Thu, 01 Jan 2015 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2015/2015-01-01-2014-summary-2d5e03e4c.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2015/2015-01-01-2014-summary-2d5e03e4c.html</guid>
        
        
        <category>devtang</category>
        
      </item>
    
      <item>
        <title>Linux Page Cache Hit Ratio</title>
        <description>

&lt;p&gt;A recent Linux performance regression turned out to be caused by a difference in the page cache hit ratio: what was caching very well on the older system was caching poorly on the newer one. So how do you measure the page cache hit ratio directly?&lt;/p&gt;

&lt;p&gt;How about a tool like this?:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;./cachestat 1&lt;/b&gt;
Counting cache functions... Output every 1 seconds.
    HITS   MISSES  DIRTIES    RATIO   BUFFERS_MB   CACHE_MB
     210      869        0    19.5%            2        209
     444     1413        0    23.9%            8        210
     471     1399        0    25.2%           12        211
     403     1507        3    21.1%           18        211
     967     1853        3    34.3%           24        212
     422     1397        0    23.2%           30        212
[...]
&lt;/pre&gt;

&lt;p&gt;This not only shows the size of the buffer and page cache, but also activity statistics. I&#39;ve added cachestat to my &lt;a href=&quot;https://github.com/brendangregg/perf-tools&quot;&gt;perf-tools&lt;/a&gt; collection on github.&lt;/p&gt;

&lt;h2&gt;Longer Example&lt;/h2&gt;

&lt;p&gt;Here is some sample output followed by the workload that caused it:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;./cachestat -t&lt;/b&gt;
Counting cache functions... Output every 1 seconds.
TIME         HITS   MISSES  DIRTIES    RATIO   BUFFERS_MB   CACHE_MB
08:28:57      415        0        0   100.0%            1        191
08:28:58      411        0        0   100.0%            1        191
08:28:59      362       97        0    78.9%            0          8
08:29:00      411        0        0   100.0%            0          9
08:29:01      775    20489        0     3.6%            0         89
08:29:02      411        0        0   100.0%            0         89
08:29:03     6069        0        0   100.0%            0         89
08:29:04    15249        0        0   100.0%            0         89
08:29:05      411        0        0   100.0%            0         89
08:29:06      411        0        0   100.0%            0         89
08:29:07      411        0        3   100.0%            0         89
[...]
&lt;/pre&gt;

&lt;p&gt;I used the -t option to include the TIME column, to make describing the output easier.&lt;/p&gt;

&lt;p&gt;The workload was:&lt;/p&gt;

&lt;pre&gt;
# echo 1 &amp;gt; /proc/sys/vm/drop_caches; sleep 2; cksum 80m; sleep 2; cksum 80m
&lt;/pre&gt;

&lt;p&gt;At 8:28:58, the page cache was dropped by the first command, which can be seen by the drop in size for &quot;CACHE_MB&quot; (page cache size) from 191 Mbytes to 8.&lt;/p&gt;

&lt;p&gt;After a 2 second sleep, a cksum command was issued at 8:29:01, for an 80 Mbyte file (called &quot;80m&quot;), which caused a total of ~20,400 misses (&quot;MISSES&quot; column), and the page cache size to grow by 80 Mbytes. Each page is 4 Kbytes, so 20k x 4k == 80 Mbytes. The hit ratio during the uncached read dropped to 3.6%.&lt;/p&gt;

&lt;p&gt;Finally, after another 2 second sleep, at 8:29:03 the cksum command was run a second time, this time hitting entirely from cache (the statistics spanning two output rows).&lt;/p&gt;

&lt;h2&gt;How It Works&lt;/h2&gt;

&lt;p&gt;I was curious to see whether ftrace, which is built into the Linux kernel, could measure cache activity, since ftrace function profiling provides efficient in-kernel counts. Systems can have a very high rate of cache activity, so we need to be careful to consider the overhead of any instrumentation.&lt;/p&gt;

&lt;p&gt;While ftrace function profiling is cheap, its capabilities are also limited. It can count kernel function calls by-CPU, and show average latency, but that&#39;s all. (It is the same facility used by funccount from &lt;a href=&quot;https://github.com/brendangregg/perf-tools&quot;&gt;perf-tools&lt;/a&gt;.) I can&#39;t, for example, use it with an advanced filter to match on function arguments or return values. It will only work if I deduce cache activity from kernel function calls alone.&lt;/p&gt;

&lt;p&gt;For the kernels I&#39;m studying (3.2 and 3.13), here are the four kernel functions I&#39;m profiling to measure cache activity:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;mark_page_accessed() for measuring cache accesses&lt;/li&gt;
&lt;li&gt;mark_buffer_dirty() for measuring cache writes&lt;/li&gt;
&lt;li&gt;add_to_page_cache_lru() for measuring page additions&lt;/li&gt;
&lt;li&gt;account_page_dirtied() for measuring page dirties&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;mark_page_accessed() shows total cache accesses, and add_to_page_cache_lru() shows cache insertions (so does add_to_page_cache_locked(), which even includes a tracepoint, but doesn&#39;t fire on later kernels). I thought for a second that these two were sufficient: assuming insertions are misses, I have misses and total accesses, and can calculate hits.&lt;/p&gt;

&lt;p&gt;The problem is that accesses and insertions also happens for writes, dirtying cache data. So the other two kernel functions help tease this apart (remember, I only have function call rates to work with here). mark_buffer_dirty() is used to see which of the accesses were for writes, and account_page_dirtied() to see which of the insertions were for writes.&lt;/p&gt;

&lt;p&gt;It is possible that the kernel functions I&#39;m using have been renamed (or are different logically) for your kernel version, and this script will not work as-is. I was hoping to use fewer than four functions, to make this more maintainable, but I didn&#39;t find a smaller set that worked for the workloads I tested.&lt;/p&gt;

&lt;p&gt;If cachestat starts breaking too much for my kernel versions, I may rewrite it to use SystemTap or perf_events, which allow filtering.&lt;/p&gt;

&lt;h2&gt;Warnings&lt;/h2&gt;

&lt;p&gt;Instrumenting cache activity does cost some overhead, and this tool might slow your target system by 2% or so. Higher if you stress-test the cache. It also uses dynamic tracing of kernel functions, which could cause kernel freezes or panics, depending on your kernel version. Test before use.&lt;/p&gt;

&lt;p&gt;The statistics should also be treated as best-effort. There may be some error margin depending on the frequency of unusual workload types, not properly matched by these four kernel functions. Test with a known workload to get confidence it will work for the intended target.&lt;/p&gt;

&lt;h2&gt;The Problem&lt;/h2&gt;

&lt;p&gt;When I encountered the earlier Linux performance regression, I didn&#39;t have cachestat. We had spotted a high rate of disk I/O, which led me to investigate the cause and work my way back to cache misses. I did this using custom ftrace and perf_events commands, measuring the rate of kernel functions and their call stacks.&lt;/p&gt;

&lt;p&gt;While I got the job done, I wanted a better way for next time, which led to cachestat.&lt;/p&gt;

&lt;h2&gt;Other Techniques&lt;/h2&gt;

&lt;p&gt;I&#39;ve found a few ways people commonly study the page cache hit ratio on Linux:&lt;/p&gt;

&lt;ul&gt;
&lt;p&gt;A) Study the page cache miss rate by using iostat(1) to monitor disk reads, and assume these are cache misses, and not, for example, O_DIRECT. The miss rate is usually a more important metric than the ratio anyway, since misses are proportional to application pain. Also use free(1) to see the cache sizes.&lt;/p&gt;

&lt;p&gt;B) Drop the page cache (echo 1 &amp;gt; /proc/sys/vm/drop_caches), and measure how much performance gets worse! I love the use of a negative experiment, but this is of course a painful way to shed some light on cache usage.&lt;/p&gt;

&lt;p&gt;C) Use sar(1) and study minor and major faults. I don&#39;t think this works (eg, regular I/O).&lt;/p&gt;

&lt;p&gt;D) Use the &lt;a href=&quot;https://sourceware.org/systemtap/wiki/WSCacheHitRate&quot;&gt;cache-hit-rate.stp&lt;/a&gt; SystemTap script, which is number two in an Internet search for Linux page cache hit ratio.  It instruments cache access high in the stack, in the VFS interface, so that reads to any file system or storage device can be seen. Cache misses are measured via their disk I/O. This also misses some workload types (some are mentioned in &quot;Lessons&quot; on that page), and calls ratios &quot;rates&quot;.&lt;/p&gt;
&lt;/ul&gt;

&lt;p&gt;I would have tried the SystemTap approach myself to begin with, but it can miss types including mmap&#39;d reads and other kernel sources. For example, here&#39;s a call stack for mark_page_accessed() (a cache read), showing that we got here via a write() syscall:&lt;/p&gt;

&lt;pre&gt;
          dd-30425 [000] 6788093.150288: mark_page_accessed: (mark_page_accessed+0x0/0x60)
          dd-30425 [000] 6788093.150291: &lt;stack trace&gt;
 =&amp;gt; __getblk
 =&amp;gt; __bread
 =&amp;gt; ext3_get_branch
 =&amp;gt; ext3_get_blocks_handle
 =&amp;gt; ext3_get_block
 =&amp;gt; __block_write_begin
 =&amp;gt; ext3_write_begin
 =&amp;gt; generic_perform_write
 =&amp;gt; generic_file_buffered_write
 =&amp;gt; __generic_file_aio_write
 =&amp;gt; generic_file_aio_write
 =&amp;gt; do_sync_write
 =&amp;gt; vfs_write
 =&amp;gt; sys_write
 =&amp;gt; system_call_fastpath
&lt;/stack&gt;&lt;/pre&gt;

&lt;p&gt;It&#39;s reading file system metadata. This example uses ftrace, via my kprobe tool (&lt;a href=&quot;https://github.com/brendangregg/perf-tools&quot;&gt;perf-tools&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;My preferred technique would be to modify the kernel to instrument page cache activity. Eg, either:&lt;/p&gt;

&lt;ul&gt;
&lt;p&gt;E) Apply Keiichi&#39;s &lt;a href=&quot;https://lkml.org/lkml/2011/7/18/326&quot;&gt;pagecache monitoring&lt;/a&gt; kernel patch, which provides tracepoints for cache instrumentation, and tools with awesome capabilities: not just system-wide ratios, but also per-process and per-file. I&#39;d like this to be in mainline.&lt;/p&gt;

&lt;p&gt;F) Develop another kernel patch to add cache hit/miss statistics to /proc/meminfo.&lt;/p&gt;
&lt;/ul&gt;

&lt;p&gt;And then, there&#39;s the approach I used myself for the issue: dynamic tracing of file system and disk I/O functions using ftrace and perf_events.&lt;/p&gt;

&lt;h2&gt;pcstat&lt;/h2&gt;

&lt;p&gt;If you&#39;re interested in page cache activity, you should also like &lt;a href=&quot;https://github.com/tobert/pcstat&quot;&gt;pcstat&lt;/a&gt;, by Al Tobey, which uses mincore (or fincore), to see size how much files are present in the page cache. It&#39;s pretty awesome.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Hopefully in the future the kernel will provide an easy way to measure page cache activity, be it from /proc or tracepoints. In the meantime, I have cachestat which works for my kernel versions. Its current implementation is brittle, and may not work well on other versions without modifications, so its greatest value may be &lt;a href=&quot;http://dtrace.org/blogs/brendan/2013/05/27/the-greatest-tool-that-never-worked-har/&quot;&gt;showing what can be done&lt;/a&gt; with a little effort.&lt;/p&gt;


</description>
        <pubDate>Wed, 31 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-31-linux-page-cache-hit-ratio.html-deae9b8e2.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-31-linux-page-cache-hit-ratio.html-deae9b8e2.html</guid>
        
        
        <category>brendangregg</category>
        
      </item>
    
      <item>
        <title>2014 年度个人总结</title>
        <description>

  
  &lt;div style=&quot;background-color: #FFF;&quot;&gt;
    &lt;p&gt;又到一年底，总结个人业绩和得失的时候了。于我个人而言，2014 年真是精彩纷呈。&lt;/p&gt;
&lt;h2 id=&quot;section&quot;&gt;说说写作&lt;/h2&gt;
&lt;p&gt;首先，4 月份我写的《网站运维技术与实践》面市。开卖之前，有好心的朋友叮嘱说，万一碰到在网店评论区捣乱的，千万不要理会。不过半年多过去，似乎最差的评论也只是说章节名字取得太烂。这点真心承认，尤其是第一章，各小节标题直接就是各种 linux 命令，偏巧一般网上目录介绍默认就只显示最前面一点而不是展开全部目录的，第一眼看过去就好像本书是一本命令大全！&lt;/p&gt;
&lt;p&gt;第一次写书，留下几个遗憾。第一，忘了写致谢！第二，章节的安排次序在我心中其实是有一个完整的先后逻辑的，然而我竟然忘记在前言中讲明。直到半年后有人问及为什么没有说说一个产品交付运维的完整流程应该如何，我回答说：看书目录的次序就是了。&lt;/p&gt;
&lt;p&gt;好在销量据说尚可，这应该让我有机会在第二版中弥补。&lt;/p&gt;
&lt;p&gt;为此书写的《西江月》最后是印在了封底内页，或许第二版，我给每章写一句诗做副标题？&lt;/p&gt;
&lt;p&gt;其次，跟刘宇、长元、春生一起翻译的《Puppet Cookbook》应该也快面市了。一本 200 页的小书，编辑也忍耐我们这么多人来打酱油，呼呼~ Puppet 本身是一个到处都有新矿可挖的生态圈。曾经有同事看过刘宇的《Puppet 实战》和我的《网站运维技术与实践》Puppet 章节后说：你写的 puppet 跟刘宇的完全不一样的技术点，完全可以叫《Another Puppet 实战》。那么，现在大家有福了，这本翻译的 cookbook 内容大多又是我们两个之前没覆盖到的，可算是《Yet Another Puppet 实战》。&lt;/p&gt;
&lt;p&gt;在这两个之外，还在 gitbook.com 上写了两本电子书，是关于实时大数据处理 ELKstack 的。稍后再单独说。&lt;/p&gt;
&lt;p&gt;技术写作这件事情，本身在圈内就很有争议。比如左耳朵耗子就多次明嘲暗贬。我还是觉得，抛开赚钱的话题(其实就是根本不赚钱，一本书稿费还不抵作者半个月薪水呢)，认认真真给自己的技术归纳体系，列目录，写总结，完善用例，深挖根源，一般情况下绝对是很难真的动手而且万难坚持下来的事情。一旦你决定要写成“书”而不是散落的“文本”，各方面的压力就从此变成动力。&lt;/p&gt;
&lt;p&gt;突然想起来这段感慨在去年应该就写过了……因为《网站运维技术与实践》其实在去年秋天就完稿的。&lt;/p&gt;
&lt;h2 id=&quot;section-1&quot;&gt;工作和生活&lt;/h2&gt;
&lt;p&gt;5 月去了苏州旅游。作为一个婚假都忘了休的人，这真是一次美好的记忆。原先计划要跑遍长三角，结果看着苏州园林，听着吴侬软语，吃着生煎，就挪不动步子，彻彻底底在苏州呆完了整个假期。现在一边写着这份总结，一边又想起昆曲博物馆里坐我左手边的那个台湾老教授，想起虎丘山门外林立的名家碑文。这是怎样一种奢侈。&lt;/p&gt;
&lt;p&gt;7 月换了份工作到新浪。新浪的面试官是惯来喜欢砸人的，于是我先前在一家公司呆久了，就会先找个新浪的面试，被砸一砸，然后回去就可以安心的继续工作或者研究。不料这次真的进新浪了，开始了我“砸”别人的日子……&lt;/p&gt;
&lt;p&gt;9 月是最紧张的时候，丢掉之前各种规划，接手一个没有测试报告，没有设计文档，没有运行状态，只有“又不行了”的日志系统。老妈正好这个月来北京，于是一边想着不能让老妈觉得我其实一直这么苦逼的拼命啊，一边半夜三点回家……&lt;/p&gt;
&lt;p&gt;这破烂状态虽然现在结束了，但是手头已有和要有的这摊子事情，依然都是没测试没设计没文档的状态，真心要吐槽，一点“大公司”的感觉都没有啊。&lt;/p&gt;
&lt;h2 id=&quot;section-2&quot;&gt;社区活动&lt;/h2&gt;
&lt;p&gt;4 月 CSDN 邀请了 Larry Wall 来中国。对于 Perl 程序员简直是再幸福不过了。好玩的是教主在我的大骆驼书上签名时划破了那页纸，于是他拿起他的大骆驼印章，给那页上一口气按了十多个骆驼==！&lt;/p&gt;
&lt;p&gt;12 月，主动提起应该继续 PerlChina 的 Advent 活动，在 fayland 的帮助下，搭建了 &lt;a href=&quot;http://advent.perl-china.com&quot;&gt;http://advent.perl-china.com&lt;/a&gt; 网站，而且 24 篇 gift 我写了 11 篇。还是那句话，坚持是最大的困难……&lt;/p&gt;
&lt;p&gt;同样在坚持的，还有 @perldaily 这个微博号，一年来每周的 perlweekly、rubyweekly、devopsweekly，都坚持阅读，并且挑选转发到微博上。12 月更是同时阅读着每天的 perladvent、perl6advent、catalystadvent、danceradvent、perladvent.kr、perladvent.jp、rubyadvent、goadvent、sysadvent、performanceadvent，并且转发到微博。&lt;/p&gt;
&lt;h2 id=&quot;section-3&quot;&gt;技术动态&lt;/h2&gt;
&lt;h3 id=&quot;docker&quot;&gt;docker&lt;/h3&gt;
&lt;p&gt;年初的时候跟着去年下半年的惯性，还是很积极的跟踪尝试 docker 来着。包括用 docker 做了一个类似 JSFiddle 的 Perl 在线代码调试工具。唯一的问题就是 fork 炸弹，然后靠 ulimit 启动解决。&lt;/p&gt;
&lt;p&gt;稍后还参加了第一次 docker beijing meetup。差不多时间接赵鹏的邀请试用了一把他的 visualops，转身自己用开源的 diagramo 试了试如何在页面拖动服务器图标生成 fig.yml 配置。不过玩起来好搞，搞成产品，那就难了，visualops 做的是真到位，赞！&lt;/p&gt;
&lt;p&gt;docker 的故事就到这里，之后就没机会再参与了。&lt;/p&gt;
&lt;h3 id=&quot;perl&quot;&gt;perl&lt;/h3&gt;
&lt;p&gt;模仿 serverspec 工具写了 Rex::Test::Spec 模块，结果被 rex 项目作者邀请加入了 RexOps 开发组。不过实话是 Perl 确实现在式微，2013 年，Rex 跟 Saltstack、Ansible 感觉都是差不多的小众产品，到今年，后二者风头正劲，无数人开始问“salt 跟 puppet 哪个好啊”的问题。公司内部也没有 Perl 氛围，我也就保持着自己个人使用，懒得推广了。&lt;/p&gt;
&lt;p&gt;另一个一直在保持跟踪的是 Perl6。测试过用 Perl6 写 Puppet 的 ENC 脚本，还为此去修复了 Perl6 版本的 YAML::Dump 模块。测试过用 Perl6 如何做并发编程，了解了 Promise、Supply 等概念。但愿教主和 jnthn 能在明年解决一定的性能问题，发布 6.0 版吧……&lt;/p&gt;
&lt;p&gt;今年还订阅了 Perl5Porter 的邮件组，看着 Perl5 开发者们是如何维护 Perl5 代码的。跟昨天 Larry Wall 发表在 Perl6 Advent 上的想法真是出奇的一致：Perl 是一个健全的城市，不需要五年计划，有人愿意盖房子，市议会负责别让他影响其他人就够了。就在这个思想的指导下，今年 5 月发的 Perl5 version 20 加上了 sub signature，实现者是今年 2 月份才提出自己要做的；而下半年突然出现的俄罗斯大神则提出要给 Perl5 的 OOP 性能提高一倍，然后看着 P5P 的人一步一步教他怎么用 git，怎么拆分他的大 patch 成一个一个 commit 和 test，让人无比期待明年的 Perl5 version 22 了。&lt;/p&gt;
&lt;h3 id=&quot;elkstack&quot;&gt;ELKstack&lt;/h3&gt;
&lt;p&gt;ELKstack 在今年占据了我大量的精力，从博客中就可以看到。2014 年，一共发了 64 篇博客，标记为 ELK 相关的有 27 篇，接近一半。&lt;/p&gt;
&lt;p&gt;ES 公司从今年 4 月开始停止了 Kibana3 的开发，专门去做 Kibana4 的重构工作，至今还没发布正式版。在这大半年的空档期内，我在自己的 &lt;a href=&quot;https://github.com/chenryn/kibana-authorization&quot;&gt;fork 仓库&lt;/a&gt;里，新增了 11 项功能，替换 Facet 为 Aggr 接口，百分比统计、区间分布统计、去重数据走势、高德地图、请求生成器、阈值通知、数值统计值地图、单图表引用、表单导出等等。还提供了社区最完整的验证授权代理功能。目前收到了 40 个 star。&lt;/p&gt;
&lt;p&gt;去年底建的 QQ 群，到目前有接近 400 人加入。尤其开心的，这让我发现 ELK 的使用者，很多是开发工程师、安全工程师。这种交叉领域的聊天非常舒服，给人启发。当然要感谢携程的几位朋友，wood 童鞋老早在群里公开自己的十亿级用例的 ppt，也是官网文档的活字典，childe 童鞋最早开始写 statisictrend panel，没他吃螃蟹在先，我可能还想不到自己动手做 kibana 去。&lt;/p&gt;
&lt;p&gt;QQ 群里经常出现的重复问题，也触发我最终选择在 gitbook.com 上写电子书。很遗憾 ELK 还不够火，所以单独写纸质书的可能性是微乎其微了，好在 gitbook 的使用感觉还不错，需要吐槽的就是定价只能涨不能降这个设定，此外，不凑够 $50 不能取现，不取现不能删除书籍也让我头疼不已，我真的不是有意给自己电子书设置价格的。&lt;/p&gt;
&lt;p&gt;两本书的 markdown 源码都发在了 github 上托管。分别有 &lt;a href=&quot;https://github.com/chenryn/logstash-best-practice-cn&quot;&gt;82&lt;/a&gt; 和 &lt;a href=&quot;https://github.com/chenryn/kibana-guide-cn&quot;&gt;34&lt;/a&gt; 个 star。此外，还收到了共计 573.87 元支付宝打赏。然后我花了其中两百多去买了一个很有意思的域名：&lt;a href=&quot;http://kibana.logstash.es/&quot;&gt;kibana.logstash.es&lt;/a&gt;。哈哈~&lt;/p&gt;
&lt;p&gt;ELK 本身的讨论和思考，年终总结里就不再啰嗦了，基本都写在电子书里，欢迎大家阅读、点赞和打赏……&lt;/p&gt;
&lt;p&gt;10 月，medcl 主办了 ES 中国的第三次大会，也是第一届正式的大会(突然有第 24 次第一届搞笑诺贝尔奖即视感)。应该有 200 人到会场。我做了 《&lt;a href=&quot;http://pan.baidu.com/s/1i3qsoBF#path=%252FESCC%25233&quot;&gt;{&lt;span&gt;{&lt;/span&gt;More}} Kibana&lt;/a&gt;》的分享。认识了几位演讲嘉宾，一个赛一个的年轻，全都是 85 后。&lt;/p&gt;
&lt;p&gt;11 月，长元离京前的 Puppet 群组 8 人小聚会上，分享 ELK 概念和演示常见配置用法。&lt;/p&gt;
&lt;p&gt;12 月，Beijing.pm 例行月度 7 人小聚会上，分享 ELK 概念和演示常见配置用法。&lt;/p&gt;
&lt;p&gt;加上明年 1 月准备在&lt;a href=&quot;http://www.uml.com.cn/communicate/2015-1-17.asp&quot;&gt;火龙果&lt;/a&gt;上做的 ELK 分享。这会是连续 4 个月在外分享 ELKstack 了。这或许又会是一种坚持？看看明年 2 月以后还有没有机会继续吧……&lt;/p&gt;
    &lt;hr&gt;
    
    &lt;hr&gt;
  &lt;!-- JiaThis Button BEGIN --&gt;
&lt;div class=&quot;jiathis_style&quot;&gt;
&lt;span class=&quot;jiathis_txt&quot;&gt;分享到：&lt;/span&gt;
&lt;a class=&quot;jiathis_button_tsina&quot;&gt;新浪微博&lt;/a&gt;
&lt;a class=&quot;jiathis_button_weixin&quot;&gt;微信&lt;/a&gt;
&lt;a class=&quot;jiathis_button_renren&quot;&gt;人人网&lt;/a&gt;
&lt;a class=&quot;jiathis_button_ydnote&quot;&gt;有道云笔记&lt;/a&gt;
&lt;a class=&quot;jiathis_button_gmail&quot;&gt;Gmail邮箱&lt;/a&gt;
&lt;a class=&quot;jiathis_button_twitter&quot;&gt;Twitter&lt;/a&gt;
&lt;a class=&quot;jiathis_button_googleplus&quot;&gt;Google+&lt;/a&gt;
&lt;a class=&quot;jiathis_button_hi&quot;&gt;百度空间&lt;/a&gt;
&lt;a class=&quot;jiathis_button_fb&quot;&gt;Facebook&lt;/a&gt;
&lt;a class=&quot;jiathis_button_douban&quot;&gt;豆瓣&lt;/a&gt;
&lt;a href=&quot;http://www.jiathis.com/share?uid=1589850&quot; class=&quot;jiathis jiathis_txt jiathis_separator jtico jtico_jiathis&quot; target=&quot;_blank&quot;&gt;更多&lt;/a&gt;
&lt;a class=&quot;jiathis_counter_style&quot;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var jiathis_config={
	data_track_clickback:true,
	summary:&quot;&quot;,
	ralateuid:{
		&quot;tsina&quot;:&quot;1035836154&quot;
	},
	shortUrl:false,
	hideMore:false
}
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://v3.jiathis.com/code/jia.js?uid=1589850&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;!-- JiaThis Button END --&gt;
&lt;!-- UY BEGIN --&gt;


&lt;!-- UY END --&gt;
  &lt;/div&gt;

</description>
        <pubDate>Fri, 26 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-26-report-of-this-year-daa3e3bfa.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-26-report-of-this-year-daa3e3bfa.html</guid>
        
        
        <category>chenlinux</category>
        
      </item>
    
      <item>
        <title>算法：塔防游戏中的路径寻找</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;在塔防游戏中，有许多敌人向着同一目标前进。在很多塔防游戏当中，有一条或几条事先预定好的路径。在一些中，比如经典的《Desktop Tower Defense》，你可以将塔放在任何位置，它们充当障碍影响敌人选择的路径。试一试，点击地图来移动墙壁：&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/05a3c829944d6862efa6cfe5fe8be5bb.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;（原文中的可播放的动画，&lt;a href=&quot;http://www.redblobgames.com/pathfinding/tower-defense/&quot; target=&quot;_blank&quot;&gt;点击跳转查看&lt;/a&gt;）&lt;/p&gt;
&lt;p&gt;我们如何来实现这种效果？&lt;/p&gt;
&lt;p&gt;像A*这样的图搜索算法经常被用来寻找两点之间的最短路径。你可以用这个来为每一个敌人找到前往目标的路径。在这种类型的游戏当中，我们有很多不同的图搜索算法来。这是一些经典方法&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;单源，单目标&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Best_first_search&quot; target=&quot;_blank&quot;&gt;贪心搜索算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;a href=&quot;http://en.wikipedia.org/wiki/A*_search_algorithm&quot; target=&quot;_blank&quot;&gt;A*&lt;/a&gt;算法 – 在游戏当中常用&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;单源多目标或多源单目标&lt;/strong&gt;&lt;/p&gt;
&lt;ul style=&quot;font-weight: inherit;&quot;&gt;
&lt;li&gt;
&lt;a href=&quot;http://en.wikipedia.org/wiki/Breadth_first_search&quot; target=&quot;_blank&quot;&gt;广度优先算法&lt;/a&gt;-无加权边&lt;/li&gt;
&lt;li&gt;
&lt;a href=&quot;http://en.wikipedia.org/wiki/Dijkstra%27s_algorithm&quot; target=&quot;_blank&quot;&gt;Dijkstra算法&lt;/a&gt;-有加权边&lt;/li&gt;
&lt;li&gt;
&lt;a href=&quot;http://en.wikipedia.org/wiki/Bellman%E2%80%93Ford_algorithm&quot; target=&quot;_blank&quot;&gt;Bellman-Ford算法&lt;/a&gt;-支持负权重&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;多源多目标&lt;br&gt;
&lt;/strong&gt;&lt;/p&gt;
&lt;ul style=&quot;font-weight: inherit;&quot;&gt;
&lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm&quot; target=&quot;_blank&quot;&gt;Floyd-Warshall算法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Johnson%27s_algorithm&quot; target=&quot;_blank&quot;&gt;Johnson’s算法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;像《Desktop Tower Defense》这样的游戏会有很多个敌人（源）和一个共同的目的地。这使得它被归为多源单目标一类。我们可以执行一个算法，一次算出所有敌人的路径，而不是为每个敌人执行一次A*算法。更好的是，我们可以计算出每个位置的最短路径，所以当敌人挤在一块或者新敌人被创建时，他们的路径已经被计算好了。&lt;/p&gt;
&lt;p&gt;我们先来看看有时也被称作“洪水填充法”（FIFO变种）的广度优先算法。虽然图搜索算法是适用于任何由节点和边构成的图，但是我还是使用方形网格来表示这些例子。网格是图的一个特例。每个网格瓦片是图节点，网格瓷砖之间的边界是图的边。我会在另一篇文章当中探讨非网格图。&lt;/p&gt;
&lt;p&gt;广度优先搜索始于一个节点，并访问邻居节点。关键的概念是“边界”，在已探索和未开发的区域之间的边界。边界从原始节点向外扩展，直到探索了整张图。&lt;/p&gt;
&lt;p&gt;边界队列是一个图节点(网格瓦片)是否需要被分析的列表/数组。它最开始仅仅包含一个元素，起始节点。每个节点上的访问标志追踪我们是否采访过该节点。开始的时候除了起始节点都标志为FALSE。使用滑块来查看边界是如何扩展的：&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8cb8e61ba7f9898ea9c0202dfe41372c.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;（原文中的可播放的动画，&lt;a href=&quot;http://www.redblobgames.com/pathfinding/tower-defense/&quot; target=&quot;_blank&quot;&gt;点击跳转查看&lt;/a&gt;）&lt;/p&gt;
&lt;p&gt;这个算法是如何工作的？在每一步，获得一个元素的边界并把它命名为current。然后寻找current的每个邻居，next。如果他们还没有被访问过的话，将他们都添加到边界队列里面。下面是一些python代码：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;frontier = Queue()
frontier.put(start)
visited = {}
visited[start] = True

while not frontier.empty():
   current = frontier.get()
   for next in graph.neighbors(current):
      if next not in visited:
         frontier.put(next)
         visited[next] = True&lt;/pre&gt;
&lt;p&gt;现在已经看见代码了，试着步进上面的动画。注意边界队列，关于current的代码，还有next节点的集合。在每一步，有一个边界元素成为current节点，它的邻居节点会被标注，并且未被拜访过的邻居节点会被添加到边界队列。有一些邻居节点可能已经被访问过，他们就不需要被添加到边界队列里面了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这是一个相对简单的算法，并且对于包括AI在内的很多事情都是有用的。我有三种主要使用它的办法：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1.标识所有可达的点。这在你的图不是完全连接的，并且想知道哪些点是可达的时候是很有用的。这就是我再上面用visited这部分所做的。&lt;br&gt;
2.寻找从一个点到所有其他点或者所有点到一个点的路径。我在文章开始部分的动画demo里面使用了它。&lt;br&gt;
3.测量从一个点到所有其他点的距离。这在想知道一个移动中的怪物的距离时是很有用的。&lt;/p&gt;
&lt;p&gt;如果你正在生成路径，你可能会想知道从每个点移动的方向。当你访问一个邻居节点的时候，要记得你是从哪个节点过来的。让我们把visited重命名为came_from并且用它来保存之前位置的轨迹：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;frontier = Queue()
frontier.put(start)
came_from = {}
came_from[start] = None

while not frontier.empty():
   current = frontier.get()
   for next in graph.neighbors(current):
      if next not in came_from:
         frontier.put(next)
         came_from[next] = current&lt;/pre&gt;
&lt;p&gt;我们来看看它看起来是怎样的：&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a5dd354fc60127319e5c6f07ee224104.jpg&quot;&gt;&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;p&gt;（原文中的可播放的动画，&lt;a href=&quot;http://www.redblobgames.com/pathfinding/tower-defense/&quot; target=&quot;_blank&quot;&gt;点击跳转查看&lt;/a&gt;）&lt;/p&gt;
&lt;p style=&quot;text-align: left;&quot;&gt;如果你需要距离，你可以在起始节点讲一个计数器设置为0，并在每次访问邻居节点的时候将它加一。让我们把visitd重命名为distance，并且用它来存储一个计数器：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;frontier = Queue()
frontier.put(start)
distance = {}
distance[start] = 0

while not frontier.empty():
   current = frontier.get()
   for next in graph.neighbors(current):
      if next not in distance:
         frontier.put(next)
         distance[next] = 1 + distance[current]&lt;/pre&gt;
&lt;p style=&quot;text-align: left;&quot;&gt;我们来看看它看起来是怎样的：&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/48b8cfbdf91a65e0f136df23971e3283.jpg&quot;&gt;&lt;/p&gt;
&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;p&gt;（原文中的可播放的动画，&lt;a href=&quot;http://www.redblobgames.com/pathfinding/tower-defense/&quot; target=&quot;_blank&quot;&gt;点击跳转查看&lt;/a&gt;）&lt;/p&gt;
&lt;p style=&quot;text-align: left;&quot;&gt;如果你想同时计算路径和距离，你可以使用两个变量。&lt;/p&gt;
&lt;p style=&quot;text-align: left;&quot;&gt;这就是广度优先检索算法。对于塔防风格的游戏，我用它来计算所有位置到一个指定位置的路径，而不是重复使用A*算法为每个敌人分开计算路径。我用它来寻找一个怪物指定行动距离内所有的位置。我也是用它来进行程序化的地图生成。Minecraft使用它来进行可见性提出。由此可见这是一个不错的算法。&lt;/p&gt;
&lt;p style=&quot;text-align: left;&quot;&gt;下一步&lt;/p&gt;
&lt;ul style=&quot;text-align: left;&quot;&gt;
&lt;li&gt;我有python和c++代码的实现。&lt;/li&gt;
&lt;/ul&gt;
&lt;ul style=&quot;text-align: left;&quot;&gt;
&lt;li&gt;如果你想要找到从一个点出发而不是到达一个点的路径，只需要在检索路径的时候翻转came_from指针。&lt;/li&gt;
&lt;/ul&gt;
&lt;ul style=&quot;text-align: left;&quot;&gt;
&lt;li&gt;如果你想要知道一些点而不是一个点的路径，你可以在图的边缘为你的每个目标点添加一个额外的点。额外的点不会出现在网格中，但是它会表示在图中的目标位置。&lt;/li&gt;
&lt;/ul&gt;
&lt;ul style=&quot;text-align: left;&quot;&gt;
&lt;li&gt;提前退出：如果你是在寻找一个到达某一点或从某一点出发，。我在A*算法的文章当中描述了这种情况。&lt;/li&gt;
&lt;/ul&gt;
&lt;ul style=&quot;text-align: left;&quot;&gt;
&lt;li&gt;加权边：如果你需要不同的移动成本，广度优先搜索可以替换为为Dijkstra算法。我在A*算法的文章当中描述了这种情况。&lt;/li&gt;
&lt;/ul&gt;
&lt;ul style=&quot;text-align: left;&quot;&gt;
&lt;li&gt;启发：如果你需要添加一种指导寻找目标的方法，广度优先算法可以替换为最佳优先算法。我在A*算法的文章当中描述了这种情况。&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li style=&quot;text-align: left;&quot;&gt;如果你从广度优先算法，并且加上了提前退出，加权边和启发，你会得到A*。如你所想，我在A*算法的文章当中描述了这种情况。&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 26 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-26-82629-d0497714c.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-26-82629-d0497714c.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>有哪些实用的计算机相关技能，可以在一天内学会？</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;&lt;a href=&quot;http://www.quora.com/What-are-some-useful-computer-related-technical-skills-I-can-learn-within-a-day&quot; target=&quot;_blank&quot;&gt;这个问题&lt;/a&gt;来自 Quora 网友，题主还补充说：&lt;/p&gt;
&lt;p style=&quot;padding-left: 30px;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;注：这个问题特指和计算机打交道的技能。&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;padding-left: 30px;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;寒假我有一个月的时间，我想学习很多大约一天就能学会的实用技能。我不期望（一天）精通，但有了良好理解后，我能做些基本操作。比如，我想学习如何使用 Eclipse 的调试器，如何创建 makefile，学习一些重要的 Linux 终端命令。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;以下的列表是来自Quora网友回复的归纳总结。译者在有些技能下面添加了简明教程与技巧的文章，另外也推荐了一些相关联的简明课程。&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;技术技能&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1）版本控制：Git、Github 和 SVN&lt;/strong&gt;（链接： &lt;a href=&quot;http://git-scm.com/book/zh&quot; target=&quot;_blank&quot; data-tooltip=&quot;attached&quot;&gt;Git – Getting Started&lt;/a&gt; ）&lt;/p&gt;
&lt;p&gt;译注：推荐这个&lt;a href=&quot;http://hao.jobbole.com/try-git/&quot; target=&quot;_blank&quot;&gt;交互式的 Git 入门资源&lt;/a&gt;，号称 15 分钟就够了。入门课程推荐《&lt;a href=&quot;http://www.imooc.com/learn/208?from=jobboleblog&quot; target=&quot;_blank&quot;&gt;版本管理工具介绍—Git篇&lt;/a&gt;》和《&lt;a href=&quot;http://www.imooc.com/view/109?from=jobboleblog&quot; target=&quot;_blank&quot;&gt;版本管理工具介绍—SVN篇&lt;/a&gt;》。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2）正则表达式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;译注：推荐《&lt;a href=&quot;http://blog.jobbole.com/63398/&quot; target=&quot;_blank&quot;&gt;55分钟学会正则表达式&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3）AWK&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;译注：《&lt;a href=&quot;http://blog.jobbole.com/31817/&quot; target=&quot;_blank&quot;&gt;「sed &amp;amp; awk」读书笔记之 awk &lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4）sed&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;译注：《&lt;a href=&quot;http://blog.jobbole.com/31026/&quot; target=&quot;_blank&quot;&gt;「sed &amp;amp; awk」读书笔记之 sed&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5）&lt;a href=&quot;http://zh.wikipedia.org/zh-cn/Grep&quot; target=&quot;_blank&quot;&gt;Grep&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6）学习如何用 Vim 做你从来不知道可以这样的事情&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;译注：推荐阅读《&lt;a href=&quot;http://blog.jobbole.com/18339/&quot; target=&quot;_blank&quot;&gt;简明Vim练级攻略&lt;/a&gt;》和《&lt;a href=&quot;http://blog.jobbole.com/10250/&quot; target=&quot;_blank&quot;&gt;25个Vim教程、视频和资源&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7）做一个爬虫，可以抓取一些网页并能解析一些基本数据&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;译注：向熟悉Python的朋友推荐这个爬虫框架《&lt;a href=&quot;http://hao.jobbole.com/python-scrapy/&quot; target=&quot;_blank&quot;&gt;Scrapy：Python的爬虫框架&lt;/a&gt;》和一篇入门教程《&lt;a href=&quot;http://blog.jobbole.com/73115/&quot; target=&quot;_blank&quot;&gt;Scrapy 轻松定制网络爬虫&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8）做一个更大的爬虫，必须填写一到两个表单&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9）做一个简单的线性代数库（矩阵、向量、乘法）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10）向上面这个库中增加“奇异值分解” SVD&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;（注：奇异值分解（singular value decomposition)是线性代数中一种重要的矩阵分解）&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;11）向这个库中增加矩阵求逆&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;12）向这个库中增加最小二乘法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;13）确保你的库能高效处理稀疏数据&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;14）学习如何使用 Python 中的列表&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;译注：推荐《&lt;a href=&quot;http://www.imooc.com/learn/177?from=jobboleblog&quot; target=&quot;_blank&quot;&gt;Python入门&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;15）注册一个 &lt;a href=&quot;http://stackoverflow.com/&quot; target=&quot;_blank&quot;&gt;StackOverflow&lt;/a&gt; 帐号，学习如何使用该站点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;16）阅读你最喜欢编程语言的手册&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;17）自己实现一个简单的机器学习算法，包括完整的流水线&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;译注：推荐阅读《&lt;a href=&quot;http://blog.jobbole.com/73806/&quot; target=&quot;_blank&quot;&gt;国外程序员整理的机器学习资源大全&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;18）学习如何在 Excel 中做一个简单的线图&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;19）安装 &lt;a href=&quot;https://eclipse.org/&quot; target=&quot;_blank&quot;&gt;Eclipse&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;20）学习 NoSQL 数据库的基本功能&lt;/strong&gt;&lt;br&gt;
译注：推荐阅读：《&lt;a href=&quot;http://blog.jobbole.com/1344/&quot; target=&quot;_blank&quot;&gt;8种Nosql数据库系统对比&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;21）学习 SQL 的大部分基本功能&lt;/strong&gt;&lt;br&gt;
译注：推荐阅读《&lt;a href=&quot;http://blog.jobbole.com/55086/&quot; target=&quot;_blank&quot;&gt;十步完全理解SQL&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;22）理解 SQL 和 NoSQL 之间的区别（优点、弱点、限制，使用场景，如何使用，为什么，等等）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;23）熟悉 Linux 系统&lt;/strong&gt;&lt;br&gt;
译注：推荐课程《&lt;a href=&quot;http://www.imooc.com/learn/181?from=jobboleblog&quot; target=&quot;_blank&quot;&gt;Linux Guide for Developers&lt;/a&gt;》、《&lt;a href=&quot;http://www.imooc.com/learn/175?from=jobboleblog&quot; target=&quot;_blank&quot;&gt;Linux达人养成计划 I&lt;/a&gt;》和《&lt;a href=&quot;http://www.imooc.com/learn/111?from=jobboleblog&quot; target=&quot;_blank&quot;&gt;Linux达人养成计划 II&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;24）学习一到两个排序算法。（快速排序和合并排序）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;译注：推荐两个资源《&lt;a href=&quot;http://hao.jobbole.com/visualgo/&quot; target=&quot;_blank&quot;&gt;VisuAlgo：通过动画学习算法和数据结构&lt;/a&gt;》、《&lt;a href=&quot;http://hao.jobbole.com/visualizing-algorithms-and-data-structure/&quot; target=&quot;_blank&quot;&gt;旧金山大学数据结构和算法的可视化学习工具&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;25）学习 D3.js 库&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;译注：推荐课程《&lt;a href=&quot;http://www.imooc.com/learn/103?from=jobboleblog&quot; target=&quot;_blank&quot;&gt;使用D3制作图表&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;26）学习给代码做单元测试&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;27）了解一些 AWS 服务，还有其 API（根据你的语言喜欢来选）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;28）基本图论&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;29）一天一个算法&lt;/strong&gt;&lt;br&gt;
译注：推荐关注这个包括&lt;a href=&quot;http://blog.jobbole.com/tag/%E7%AE%97%E6%B3%95/&quot; target=&quot;_blank&quot;&gt;上百篇算法文章的列表&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;30）理解分布式处理和分布式数据存储的需求和挑战（basics of CAP Theorem, MapReduce 算法, MySQL 或 PostgreSQL 数据库的集群）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;31）具体落实到 Python&lt;/strong&gt;&lt;br&gt;
译注：推荐《&lt;a href=&quot;http://www.imooc.com/learn/177?from=jobboleblog&quot; target=&quot;_blank&quot;&gt;Python入门&lt;/a&gt;》&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;仔细阅读 Python 的内置函数，理解如何在命令行玩转这些内置函数&lt;/li&gt;
&lt;li&gt;通过遵循Flask 指南或修改 Tornado 示例，来创建一个网站&lt;/li&gt;
&lt;li&gt;学习 itertools 模块&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;32）玩一玩 &lt;a href=&quot;http://www.checkio.org/&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;CheckIO&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;译注：checkio是一个通过游戏学习编程的站点。另外，同时推荐另外一个寓学于乐的网站&lt;a href=&quot;http://hao.jobbole.com/codecombat/&quot; target=&quot;_blank&quot;&gt;CodeCombat&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;33）学习如何编辑维基百科的文章，修改语法问题，或依照维基媒体的原则（比如观点中立）来修改&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;34）学习用 &lt;a href=&quot;http://zh.wikipedia.org/zh-cn/Markdown&quot; target=&quot;_blank&quot;&gt;Markdown&lt;/a&gt; 写作&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;35）学习 LaTeX、BibTex 和 pgfplots&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;36）学习如何在命令行下工作&lt;/strong&gt;&lt;br&gt;
译注：《&lt;a href=&quot;http://blog.jobbole.com/54425/&quot; target=&quot;_blank&quot;&gt;每个Linux用户都应该了解的命令行省时技巧&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;37）学习 JavaScript (Link: &lt;a href=&quot;http://eloquentjavascript.net/paper.html&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot; data-tooltip=&quot;attached&quot;&gt;Eloquent JavaScript&lt;/a&gt;)&lt;/strong&gt;&lt;br&gt;
译注：推荐两门免费的课程《&lt;a href=&quot;http://www.imooc.com/learn/36?from=jobboleblog&quot; target=&quot;_blank&quot;&gt;JavaScript入门篇&lt;/a&gt;》和《&lt;a href=&quot;http://www.imooc.com/learn/10?from=jobboleblog&quot; target=&quot;_blank&quot;&gt;JavaScript进阶篇&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;38）如果熟悉 OOP，那可以学习设计模式&lt;/strong&gt;&lt;br&gt;
译注：《&lt;a href=&quot;http://blog.jobbole.com/74393/&quot; target=&quot;_blank&quot;&gt;23个设计模式的简明教程&lt;/a&gt;》&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;39）搞个&lt;a href=&quot;http://www.raspberrypi.org/&quot; target=&quot;_blank&quot;&gt;树莓派&lt;/a&gt;板子深入研究&lt;/strong&gt;&lt;/p&gt;
&lt;h2&gt;非技术的技能&lt;/h2&gt;
&lt;p&gt;1）搞搞园林&lt;/p&gt;
&lt;p&gt;2）酿啤酒（译注：没条件的童鞋，推荐试试酿米酒）&lt;/p&gt;
&lt;p&gt;3）体验远离计算机的生活&lt;/p&gt;
&lt;p&gt;4）学电焊&lt;/p&gt;
&lt;p&gt;5）学打字&lt;/p&gt;
&lt;p&gt;6）约会&lt;/p&gt;
&lt;h3&gt;欢迎大家补充。&lt;/h3&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Thu, 25 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-25-82633-cb2017403.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-25-82633-cb2017403.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>MapReduce实战：倒排索引</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;h2&gt;1.倒排索引简介&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;倒排索引&lt;/strong&gt;（Inverted index），也常被称为&lt;strong&gt;反向索引&lt;/strong&gt;、&lt;strong&gt;置入档案&lt;/strong&gt;或&lt;strong&gt;反向档案&lt;/strong&gt;，是一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。它是文档检索系统中最常用的数据结构。&lt;/p&gt;
&lt;p&gt;有两种不同的反向索引形式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一条记录的水平反向索引（或者反向档案索引）包含每个引用单词的文档的列表。&lt;/li&gt;
&lt;li&gt;一个单词的水平反向索引（或者完全反向索引）又包含每个单词在一个文档中的位置。&lt;sup id=&quot;cite_ref-isbn0-201-39829-X-p192_1-0&quot;&gt;&lt;br&gt;
&lt;/sup&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;后者的形式提供了更多的兼容性（比如短语搜索），但是需要更多的时间和空间来创建。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;举例：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;以英文为例，下面是要被索引的文本：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;T&lt;sub&gt;0&lt;/sub&gt; = &quot;it is what it is&quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T&lt;sub&gt;1&lt;/sub&gt; = &quot;what is it&quot;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;T&lt;sub&gt;2&lt;/sub&gt; = &quot;it is a banana&quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们就能得到下面的反向文件索引：&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt; &quot;a&quot;:      {2}
 &quot;banana&quot;: {2}
 &quot;is&quot;:     {0, 1, 2}
 &quot;it&quot;:     {0, 1, 2}
 &quot;what&quot;:   {0, 1}&lt;/pre&gt;
&lt;p&gt;检索的条件&lt;code&gt;&quot;what&quot;&lt;/code&gt;, &lt;code&gt;&quot;is&quot;&lt;/code&gt; 和 &lt;code&gt;&quot;it&quot;&lt;/code&gt; 将对应这个集合：{0,1}∩{0,1,2}∩{0,1,2}={0,1}。&lt;/p&gt;
&lt;p&gt;对相同的文字，我们得到后面这些完全反向索引，有文档数量和当前查询的单词结果组成的的成对数据。 同样，文档数量和当前查询的单词结果都从零开始。&lt;/p&gt;
&lt;p&gt;所以，&lt;code&gt;&quot;banana&quot;: {(2, 3)}&lt;/code&gt; 就是说 “banana”在第三个文档里 (T&lt;sub&gt;2&lt;/sub&gt;)，而且在第三个文档的位置是第四个单词(地址为 3)。&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt;&quot;a&quot;:      {(2, 2)}
&quot;banana&quot;: {(2, 3)}
&quot;is&quot;:     {(0, 1), (0, 4), (1, 1), (2, 1)}
&quot;it&quot;:     {(0, 0), (0, 3), (1, 2), (2, 0)} 
&quot;what&quot;:   {(0, 2), (1, 0)}&lt;/pre&gt;
&lt;p&gt;如果我们执行短语搜索&lt;code&gt;&quot;what is it&quot;&lt;/code&gt; 我们得到这个短语的全部单词各自的结果所在文档为文档0和文档1。但是这个短语检索的连续的条件仅仅在文档1得到。&lt;/p&gt;
&lt;h2&gt;2.分析和设计&lt;/h2&gt;
&lt;p&gt;（1）Map过程&lt;/p&gt;
&lt;p&gt;首先使用默认的TextInputFormat类对输入文件进行处理，得到文本中每行的偏移量及其内容，Map过程首先必须分析输入的&amp;lt;key, value&amp;gt;对，得到倒排索引中需要的三个信息：单词、文档URI和词频，如图所示：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/953fd2d4c32e99e3fb3c9af1c8a89c1d.jpg&quot; rel=&quot;lightbox[82607]&quot; title=&quot;MapReduce实战：倒排索引&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82609&quot; alt=&quot;182227128605743&quot; src=&quot;/images/jobbole.com/38f9bd33a5007579e7d82ca2fbe68bd9.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;存在两个问题，第一：&amp;lt;key, value&amp;gt;对只能有两个值，在不使用Hadoop自定义数据类型的情况下，需要根据情况将其中的两个值合并成一个值，作为value或key值；&lt;/p&gt;
&lt;p&gt;第二，通过一个Reduce过程无法同时完成词频统计和生成文档列表，所以必须增加一个Combine过程完成词频统计&lt;/p&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: java; gutter: true&quot;&gt;public static class InvertedIndexMapper extends Mapper&amp;lt;Object, Text, Text, Text&amp;gt; {
    private Text keyInfo = new Text();  //存储单词和URI的组合
    private Text valueInfo = new Text();//存储词频
    private FileSplit split;            //存储Split对象
    
    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
        //获得&amp;lt;key,value&amp;gt;对所属的FileSplit对象
        split = (FileSplit)context.getInputSplit();
        StringTokenizer itr = new StringTokenizer(value.toString());
        
        while(itr.hasMoreTokens()) {
            //key值由单词和URI组成，如&quot;MapReduce:1.txt&quot;
            keyInfo.set(itr.nextToken() + &quot;:&quot; + split.getPath().toString());
            // 词频初始为1
            valueInfo.set(&quot;1&quot;);
            context.write(keyInfo, valueInfo);
        }
    }
}&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;（2）Combine过程&lt;/p&gt;
&lt;p&gt;将key值相同的value值累加，得到一个单词在文档中的词频，如图&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/fac86f77df394927cdfd2d2288889d0a.jpg&quot; rel=&quot;lightbox[82607]&quot; title=&quot;MapReduce实战：倒排索引&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82610&quot; alt=&quot;221942393901921&quot; src=&quot;/images/jobbole.com/8317f43498fc14260dd06782d29e83c7.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: java; gutter: true&quot;&gt;public static class InvertedIndexCombiner extends Reducer&amp;lt;Text, Text, Text, Text&amp;gt; {
    private Text info = new Text();
    public void reduce(Text key, Iterable&amp;lt;Text&amp;gt;values, Context context) throws IOException, InterruptedException {
        //统计词频
        int sum = 0;
        for(Text value : values) {
            sum += Integer.parseInt(value.toString());
        }
        int splitIndex= key.toString().indexOf(&quot;:&quot;);
        
        //重新设置value值由URI和词频组成
        info.set(key.toString().substring(splitIndex + 1) + &quot;:&quot; + sum);
        //重新设置key值为单词
        key.set(key.toString().substring(0, splitIndex));
        context.write(key, info);
    }
}&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;（3）Reduce过程&lt;/p&gt;
&lt;p&gt;讲过上述两个过程后，Reduce过程只需将相同key值的value值组合成倒排索引文件所需的格式即可，剩下的事情就可以直接交给MapReduce框架进行处理了&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/38026ed22fc1a91d92b5d2ef93540f20.jpg&quot; rel=&quot;lightbox[82607]&quot; title=&quot;MapReduce实战：倒排索引&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82611&quot; alt=&quot;3&quot; src=&quot;/images/jobbole.com/5e5d4ebd2ac4c7767f75437293ec8ee9.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: java; gutter: true&quot;&gt;public static class InvertedIndexReducer extends Reducer&amp;lt;Text, Text, Text, Text&amp;gt; {
    private Text result = new Text();
    public void reducer(Text key, Iterable&amp;lt;Text&amp;gt;values, Context context) throws IOException, InterruptedException {
        //生成文档列表
        String fileList = new String();
        for(Text value : values) {
            fileList += value.toString() + &quot;;&quot;;
        }
        result.set(fileList);
        context.write(key, result);
    }
}&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;完整代码如下：&lt;/p&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: java; gutter: true&quot;&gt;import java.io.IOException;
import java.util.StringTokenizer;
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.FileSplit;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;

public class InvertedIndex {
    public static class InvertedIndexMapper extends Mapper&amp;lt;Object, Text, Text, Text&amp;gt; {
        private Text keyInfo = new Text();
        private Text valueInfo = new Text();
        private FileSplit split;
        
        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
            split = (FileSplit)context.getInputSplit();
            StringTokenizer itr = new StringTokenizer(value.toString());
            
            while(itr.hasMoreTokens()) {
                keyInfo.set(itr.nextToken() + &quot;:&quot; + split.getPath().toString());
                valueInfo.set(&quot;1&quot;);
                context.write(keyInfo, valueInfo);
            }
        }
        
    }
    public static class InvertedIndexCombiner extends Reducer&amp;lt;Text, Text, Text, Text&amp;gt; {
        private Text info = new Text();
        public void reduce(Text key, Iterable&amp;lt;Text&amp;gt;values, Context context) throws IOException, InterruptedException {
            int sum = 0;
            for(Text value : values) {
                sum += Integer.parseInt(value.toString());
            }
            int splitIndex= key.toString().indexOf(&quot;:&quot;);
            info.set(key.toString().substring(splitIndex + 1) + &quot;:&quot; + sum);
            key.set(key.toString().substring(0, splitIndex));
            context.write(key, info);
        }
    }
    public static class InvertedIndexReducer extends Reducer&amp;lt;Text, Text, Text, Text&amp;gt; {
        private Text result = new Text();
        public void reducer(Text key, Iterable&amp;lt;Text&amp;gt;values, Context context) throws IOException, InterruptedException {
            String fileList = new String();
            for(Text value : values) {
                fileList += value.toString() + &quot;;&quot;;
            }
            result.set(fileList);
            context.write(key, result);
        }
    }
    public static void main(String[] args) throws Exception{
        // TODO Auto-generated method stub
        Configuration conf = new Configuration();
        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
        if(otherArgs.length != 2) {
            System.err.println(&quot;Usage: wordcount &amp;lt;in&amp;gt; &amp;lt;out&amp;gt;&quot;);
            System.exit(2);
        }
        Job job = new Job(conf, &quot;InvertedIndex&quot;);
        job.setJarByClass(InvertedIndex.class);
        job.setMapperClass(InvertedIndexMapper.class);
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(Text.class);
        job.setCombinerClass(InvertedIndexCombiner.class);
        job.setReducerClass(InvertedIndexReducer.class);
        
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(Text.class);
        
        FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
        FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));
        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}&lt;/pre&gt;
&lt;/div&gt;
&lt;h2&gt;参考资料&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://zh.wikipedia.org/wiki/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95&quot;&gt;http://zh.wikipedia.org/wiki/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;《实战Hadop：开启通向云计算的捷径.刘鹏》&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Wed, 24 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-24-82607-e1c6c09df.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-24-82607-e1c6c09df.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列进阶篇（查询优化器的运行方式）</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;ul&gt;
&lt;li&gt;&lt;a id=&quot;cb_post_title_url&quot; href=&quot;http://blog.jobbole.com/81176/&quot; target=&quot;_blank&quot;&gt;SQL Server调优系列基础篇&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a id=&quot;homepage1_HomePageDays_DaysList_ctl00_DayList_TitleUrl_0&quot; href=&quot;http://blog.jobbole.com/81182/&quot; target=&quot;_blank&quot;&gt;SQL Server调优系列基础篇（常用运算符总结）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a id=&quot;cb_post_title_url&quot; href=&quot;http://blog.jobbole.com/81184/&quot; target=&quot;_blank&quot;&gt;SQL Server调优系列基础篇（联合运算符总结）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a id=&quot;cb_post_title_url&quot; href=&quot;http://blog.jobbole.com/81186/&quot; target=&quot;_blank&quot;&gt;SQL Server调优系列基础篇（并行运算总结）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a id=&quot;cb_post_title_url&quot; href=&quot;http://blog.jobbole.com/81189/&quot; target=&quot;_blank&quot;&gt;SQL Server调优系列基础篇（并行运算总结篇二）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/81193/&quot; target=&quot;_blank&quot;&gt;SQL Server调优系列基础篇（索引运算总结）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a id=&quot;cb_post_title_url&quot; href=&quot;http://blog.jobbole.com/82459/&quot;&gt;SQL Server调优系列基础篇（子查询运算总结）&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;前面我们的几篇文章介绍了一系列关于运算符的基础介绍，以及各个运算符的优化方式和技巧。其中涵盖：查看执行计划的方式、几种数据集常用的连接方式、联合运算符方式、并行运算符等一系列的我们常见的运算符。有兴趣的童鞋可以点击查看。&lt;/p&gt;
&lt;p&gt;本篇介绍在SQL Server中查询优化器的工作方式，也就是一个好的执行计划的形成，是如何评估出来的，作为该系列的进阶篇。&lt;/p&gt;
&lt;p&gt;废话少说，开始本篇的正题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据库版本为SQL Server2008R2，利用微软的一个更简洁的案例库（Northwind）进行分析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;正文内容&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在我们将写好的一个T-SQL语句抛给SQL Server准备执行的时候，首选要经历的过程就是编译过程，当然如果此语句以前在SQL Server中执行过，那么将检测是否存在已经缓存的编译过的执行计划，用以重用。&lt;/p&gt;
&lt;p&gt;但是，执行编译的过程需要执行一系列的优化过程，关于优化过程大致分为两个阶段：&lt;/p&gt;
&lt;p&gt;1、首先，SQL Server对我们写的T-SQL语句先执行一些简化，通常由查询本身来寻找交互性及重新安排操作的顺序。&lt;/p&gt;
&lt;p&gt;在此过程中，SQL Server侧重于语句写法调整，而不过多的考虑成本或者分析索引可用性的等，最重要的目标就是产生一个有效的查询。&lt;/p&gt;
&lt;p&gt;然后，SQL Server才会加载元数据，包括索引的统计信息，进入第二个阶段。&lt;/p&gt;
&lt;p&gt;2、在这个阶段才是SQL Server一个复杂的优化过程，这个阶段SQL Server会根据上一阶段形成的执行计划运算符进行评估和尝试，甚至于重组执行计划，所以相对这个优化过程是一个耗时的过程。&lt;/p&gt;
&lt;p&gt;通过如下流程图，来理解该过程：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/28c8edde3d61a0411511d3b1866f06362.png&quot; rel=&quot;lightbox[82467]&quot; title=&quot;SQL Server调优系列进阶篇（查询优化器的运行方式）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82468&quot; alt=&quot;1&quot; src=&quot;/images/jobbole.com/f7f32edacdf77f99a6e994c3c738b1f9.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这个图看上去有点复杂，我们来详细分析下，其实就是将这个优化阶段分为3个子阶段&lt;/p&gt;
&lt;p&gt;&amp;lt;1&amp;gt;这个阶段仅考虑串行计划，也就说单处理器运行，如果这个阶段找到了一个好的串行计划，优化器就不会进入下一阶段。所以对于数据量少的情况，或者执行语句简单的情况下，基本采用的都是串行计划。&lt;/p&gt;
&lt;p&gt;当然，如果这个阶段开销比较大，那么会进入到第2个阶段，再进行优化。&lt;/p&gt;
&lt;p&gt;&amp;lt;2&amp;gt;这个阶段首先对第1阶段的串行计划进行优化，然后如果环境支持并行化操作，则进行并行化操作，通过进行比较，然后进行优化后的成本如果比较低则输出执行计划，如果成本还是比较高，则进入第2阶段，再继续优化。&lt;/p&gt;
&lt;p&gt;&amp;lt;3&amp;gt;其实到达这个阶段就是优化的最后一个阶段了，这个阶段会对第2个阶段中采用串行和并行的比较结果进行最后一步优化，如果串行执行好那就进一步优化，当然如果并行执行好的话，则再继续并行优化。&lt;/p&gt;
&lt;p&gt;其实第3阶段是查询优化器的无奈之举，当到达第3阶段了就是一个补救阶段，只能最后做优化了，优化完好不好的就只能按照这个执行计划执行了。&lt;/p&gt;
&lt;p&gt;那么上述过程中，各个阶段的优化的原则有哪些：&lt;/p&gt;
&lt;p&gt;关于这些优化器的最重要原则的就是：&lt;span style=&quot;background-color: #ffff00;&quot;&gt;尽可能的减少扫描范围，不管是表或者索引，当然走索引比表好，索引的量也是越少越好，最理想的情况是只有一条或者几条。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;所以，SQL Server也尊重上述原则，一直围绕着这个原则去优化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、筛选条件分析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所谓的筛选条件，其实就是我们所写的T-SQL语句中的WHERE语句后面的条件，我们会通过这里面的语句进行尽量缩小数据扫描范围，SQL Server通过这些语句来优化。&lt;/p&gt;
&lt;p&gt;一般格式如下：&lt;/p&gt;
&lt;p&gt;column  operator  &amp;lt;constant or variable&amp;gt;&lt;br&gt;
或者&lt;br&gt;
&amp;lt;constant or variable&amp;gt;  operator  column&lt;/p&gt;
&lt;p&gt;而这上面格式中operator包括：=、&amp;gt;、&amp;lt;、=&amp;gt;、&amp;lt;=、BETWEEN、LIKE&lt;/p&gt;
&lt;p&gt;比如：name=’liudehua’、price&amp;gt;4000、4000&amp;lt;price、name like ‘liu%’、name=’liudehua’ AND price &amp;gt;1000&lt;/p&gt;
&lt;p&gt;上面这些语句是我们写的语句中最常用的方式，并且这种方式也将被SQL Server用来减少扫描，并且这些列被索引覆盖，那将尽量采取索引进行获取值，但是SQL Server也不是万能的，有些写法它也是不能识别的，也是我们写语句要避免的：&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;background-color: #ffff00;&quot;&gt;a、where name like ‘%liu’这货就不能被SQL Server优化器识别，所以它只能通过全表扫描或者索引扫描执行。&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;background-color: #ffff00;&quot;&gt;b、name=’liudehua’ OR price &amp;gt;1000，这个同样也是失效的，因为它不能利用两个的筛选条件进行逐步减少扫描。&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;background-color: #ffff00;&quot;&gt;c、price+4&amp;gt;100这个同样不被识别&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;background-color: #ffff00;&quot;&gt;d、name not in (‘liudehua’、‘zhourunfa’)，当然还有类似的：NOT 、NOT LIKE&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;举个例子：&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT CustomerID FROM Orders
WHERE CustomerID=&#39;Vinet&#39;

SELECT CustomerID FROM Orders
WHERE UPPER(CustomerID)=&#39;VINET&#39;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/665f644e43731ff9db3d341da5c827e12.png&quot; rel=&quot;lightbox[82467]&quot; title=&quot;SQL Server调优系列进阶篇（查询优化器的运行方式）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82470&quot; alt=&quot;2&quot; src=&quot;/images/jobbole.com/e9359377ab11e0fff8ff9b7cce4b3e22.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;所以上述的方式写语句的时候需要尽量避免，或者采取变通的方式实现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二、索引优化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;经过上面的筛选范围的确定之后，SQL Server紧接着开始索引的选择，首先要确定的第一件事就是筛选字段是否存在索引项，也就是说是否被索引覆盖。&lt;/p&gt;
&lt;p&gt;当然，如果查询项为索引覆盖最好，如果不被索引覆盖，那么为了充分利用索引的特性，就引入了书签查找（bookmark）部分。&lt;/p&gt;
&lt;p&gt;所以，鉴于此，我们在创建索引的时候，所参考的属性值就为筛选条件的列了。&lt;/p&gt;
&lt;p&gt;关于利用索引优化的选择：&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;CREATE INDEX EmployeesName ON Employees(FirstName,LastName)
INCLUDE(HIREDATE) WITH(ONLINE=ON)
GO

SELECT FirstName,LastName,HireDate,EmployeeID 
FROM Employees
WHERE FirstName=&#39;Anne&#39;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/38026ed22fc1a91d92b5d2ef93540f202.png&quot; rel=&quot;lightbox[82467]&quot; title=&quot;SQL Server调优系列进阶篇（查询优化器的运行方式）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82472&quot; alt=&quot;3&quot; src=&quot;/images/jobbole.com/1a76bfe7ceb756909d7572cef2e2b31f.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;当然也不尽然只要查询列存在索引覆盖就执行索引查找，这取决于扫描的内容的多少，所以对于索引的利用程度还取决获取内容的多少&lt;/p&gt;
&lt;p&gt;来举个例子：&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;CREATE INDEX NameIndex  ON person.contact(FirstName,LastName)
GO

SELECT * FROM Person.Contact
WHERE FirstName LIKE &#39;K%&#39;

SELECT * FROM Person.Contact
WHERE FirstName LIKE &#39;Y%&#39;
GO&lt;/pre&gt;
&lt;p&gt;完全相同的查询语句，来看执行计划：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/011ecee7d295c066ae68d4396215c3d01.png&quot; rel=&quot;lightbox[82467]&quot; title=&quot;SQL Server调优系列进阶篇（查询优化器的运行方式）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82473&quot; alt=&quot;4&quot; src=&quot;/images/jobbole.com/365edb0452eec0aa9211f6471482feeb.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;完全相同的查询语句，产生的查询计划完全不同，一个是索引扫描，一个则是高效的索引查找。&lt;/p&gt;
&lt;p&gt;这里我只告诉你：FirstName like ‘K%’的有1255行；而FirstName like ‘Y%’只有37行，其中&lt;/p&gt;
&lt;p&gt;其实，关于这里的原因就是统计信息在作怪了。&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;所以，特定的T-SQL语句不一定生成特定的查询计划，同样特定的查询计划不一定是最优的方式，影响的它的因素很多：关于索引、关于硬件、关于表内容、关于统计信息等诸多因素影响。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;关于统计信息这块是大篇幅内容，我们放在以后的篇幅中介绍，有兴趣的可以提前关注。&lt;/p&gt;
&lt;p&gt;有问题可以留言或者私信，随时恭候有兴趣的童鞋加入SQL SERVER的深入研究。共同学习，一起进步。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Sun, 21 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-21-82467-53e038f55.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-21-82467-53e038f55.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列基础篇（子查询运算总结）</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;前面我们的几篇文章介绍了一系列关于运算符的介绍，以及各个运算符的优化方式和技巧。其中涵盖：查看执行计划的方式、几种数据集常用的连接方式、联合运算符方式、并行运算符等一系列的我们常见的运算符。有兴趣的童鞋可以点击查看。&lt;/p&gt;
&lt;p&gt;本篇我们介绍关于子查询语句的一系列内容，子查询一般是我们形成复杂查询的一些基础性操作，所以关于子查询的应用方式就非常重要。&lt;/p&gt;
&lt;p&gt;废话少说，开始本篇的正题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据库版本为SQL Server2008R2，利用微软的一个更简洁的案例库（Northwind）进行分析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、独立的子查询方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所谓的独立的子查询方式，就是说子查询和主查询没有相关性，这样带来的好处就是子查询不依赖于外部查询，所以可以独立外部查询而被评估，形成自己的执行计划执行。&lt;/p&gt;
&lt;p&gt;举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT O1.OrderID,O1.Freight
FROM Orders O1
WHERE O1.Freight&amp;gt;
(
   SELECT AVG(O2.Freight)
   FROM Orders O2
)&lt;/pre&gt;
&lt;p&gt;这句SQL执行的目标是查询订单中运费大于平均运费数的订单。&lt;/p&gt;
&lt;p&gt;这里提取平均运费的子句就是一个完全独立的子查询，完全不依赖主查询而独立执行。同时这里我们这里利用利用一个标量计算（AVG），因此正好返回一行。&lt;/p&gt;
&lt;p&gt;查看一下该语句的查询计划：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/b8ea7007df5dbcb7acc84c7ea1d87d35.png&quot; rel=&quot;lightbox[82459]&quot; title=&quot;SQL Server调优系列基础篇（子查询运算总结）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82469&quot; alt=&quot;pic1&quot; src=&quot;/images/jobbole.com/2ef5f6f30fb5d50870f67a8fa220f754.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这个查询计划没啥好介绍的，关于子查询的执行计划形成可以参照我的第二篇：&lt;a href=&quot;http://blog.jobbole.com/81182/&quot; target=&quot;_blank&quot;&gt;SQL Server调优系列基础篇（常用运算符总结）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;不过这里需要提示一下就是，关于流聚合和计算标量形成的结果值（AVG）只包含一个结果值，所以该语句能正常的执行。&lt;/p&gt;
&lt;p&gt;我们再来看另外一种情况&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT O.OrderID
FROM Orders O
WHERE O.CustomerID=
(
   SELECT C.CustomerID
   FROM Customers C
   WHERE C.ContactName=N&#39;Maria Anders&#39;
)&lt;/pre&gt;
&lt;p&gt;该语句的也是获取名字为’Maria Anders’的顾客有多少订单。这句T-SQL语句能否执行的前提是在顾客表里存不存在同名的“’Maria Anders’”顾客，如果存在同名情况，该语句就不能正确执行，而如果恰巧只有一名顾客为’Maria Anders’，则能正常执行。&lt;/p&gt;
&lt;p&gt;我们来分析一下对于这种执行的时候才能判断能否正确执行的SQL Server如何判断的。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/e6492c6a731d44402737bf08032a5cd8.png&quot; rel=&quot;lightbox[82459]&quot; title=&quot;SQL Server调优系列基础篇（子查询运算总结）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82471&quot; alt=&quot;pic2&quot; src=&quot;/images/jobbole.com/c6402bdab7b9069c19c4c33f3224f09b.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;在这里出现了一个新的运算符，名字是：断言。我们用文本执行计划来查看一下，这个运算符的主要功能是什么&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/44359f0078a64fbc57f2485f8af558d1.png&quot; rel=&quot;lightbox[82459]&quot; title=&quot;SQL Server调优系列基础篇（子查询运算总结）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82474&quot; alt=&quot;pic3&quot; src=&quot;/images/jobbole.com/734538939353a6b0c3848754dd6a5c62.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/fb5fabf73a5d46c19fb390901dbdaecb.png&quot; rel=&quot;lightbox[82459]&quot; title=&quot;SQL Server调优系列基础篇（子查询运算总结）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82475&quot; alt=&quot;pic4&quot; src=&quot;/images/jobbole.com/87985cf5f1dfb226990e728e9c0e98a9.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;经过上面的分析，我们已经分析出了上面的“断言”运算符的作用，因为我们的子查询语句不能保证返回的结果为一行，所以，这里引入了一个断言运算符来做判断。&lt;/p&gt;
&lt;p&gt;所以，断言的作用就是根据下文的条件，判断子查询句的查询结果是否满足主语句的查询要求。&lt;/p&gt;
&lt;p&gt;如果，断言发现子语句不满足，就会直接报错，比如上面的Expr1005&amp;gt;1&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/e71e6c1e0311333eaf86c6f90015e0e6.png&quot; rel=&quot;lightbox[82459]&quot; title=&quot;SQL Server调优系列基础篇（子查询运算总结）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82476&quot; alt=&quot;pic5&quot; src=&quot;/images/jobbole.com/ab5cdcbd95b4f8336962f260ab8e1fa3.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;并且，断言运算符还经常用来检测其它条件是否满足，比如：约束条件、参数类型、值长度等。&lt;/p&gt;
&lt;p&gt;其实，这里断言要解决的问题就是判断我们的筛选条件中ContactName中的值是否存在重复值的，对于这种判断相对性能消耗还是比较小的，有时候对于别的复杂的断言操作需要消耗大量资源，所以我们就可以根据适当情况情况避免断言操作。&lt;/p&gt;
&lt;p&gt;比如，上面的语句我们可以明确的告诉SQL Server在表Customers中ContactName列就不存在重复值，它就不需要断言了。我们在上面建立一个：&lt;strong&gt;唯一、非聚集索引&lt;/strong&gt;实现。&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;CREATE UNIQUE INDEX ContactNameIndex ON Customers(ContactName)
GO
SELECT O.OrderID
FROM Orders O
WHERE O.CustomerID=
(
   SELECT C.CustomerID
   FROM Customers C
   WHERE C.ContactName=N&#39;Maria Anders&#39;
)
drop index Customers.ContactNameIndex
GO&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/ea2364f25dbcbb9f760966c0a074055b.png&quot; rel=&quot;lightbox[82459]&quot; title=&quot;SQL Server调优系列基础篇（子查询运算总结）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82477&quot; alt=&quot;pic6&quot; src=&quot;/images/jobbole.com/a0e298f4857de7a50525704978eb9258.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;经过我们唯一非聚集索引的提示，SQL Server已经明确的知道我们的子查询语句不会返回多行的情况，所以就去掉了断言操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二、相关的子查询方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;相比上面的独立子查询方式，这里的相关的子查询方式相对复杂点，就是我们的子查询依赖于主查询的的结果，对于这种子查询就不能单独执行。&lt;/p&gt;
&lt;p&gt;我们来看个这样的子查询例子&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT O1.OrderID
FROM Orders O1
WHERE O1.Freight&amp;gt;
(
   SELECT AVG(O2.Freight)
   FROM Orders O2
   WHERE O2.OrderDate&amp;lt;O1.OrderDate
)&lt;/pre&gt;
&lt;p&gt;这个语句就是返回之前订单中运费量大于平均值的顶点编号。&lt;/p&gt;
&lt;p&gt;语句很简单的逻辑，但是这里面的子查询就依赖于主查询的结果项，筛选条件中 WHERE O2.OrderDate&amp;lt;O1.OrderDate，所以这个子查询就不能独立运行。&lt;/p&gt;
&lt;p&gt;我们来看一下这个语句的执行计划&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/335ca6ae128e1e9ed929fc7172020673.png&quot; rel=&quot;lightbox[82459]&quot; title=&quot;SQL Server调优系列基础篇（子查询运算总结）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82478&quot; alt=&quot;pic7&quot; src=&quot;/images/jobbole.com/be6d65ae1b6833aa278db3063a54568e.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;这里的查询计划有出现了一个新的运算符：索引假脱机。&lt;/p&gt;
&lt;p&gt;其实，关于索引假脱机的作用主要是用于子查询的独立运行，因为我们知道这里的子查询的查询条件是依赖于主查询的，所以，这里想运行的话就的先提前获取出主查询的结果项，而这里获取的主查询的结果项需要一个中间表来暂存，这里暂存的工具就是：(索引池)Index Spool，而对这个索引池的操作，比如：新建、增加等操作就是上面我们所标示的“索引假脱机”了。&lt;/p&gt;
&lt;p&gt;索引假脱机分为两种：Eager Spool和Lazy Spool，其实简单点讲就是需不需要立刻将结果存入Index Spool里面，还是通过延迟操作。&lt;/p&gt;
&lt;p&gt;而这里形成的索引池（Index Spool）是存放于系统的临时库Tempdb中。&lt;/p&gt;
&lt;p&gt;我们通过文本查询计划，来分析下两个索引假脱机里面的值是什么&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/a2bf5f40dd19e648ff84280352a52403.png&quot; rel=&quot;lightbox[82459]&quot; title=&quot;SQL Server调优系列基础篇（子查询运算总结）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82479&quot; alt=&quot;pic8&quot; src=&quot;/images/jobbole.com/10c2faa408bab295a03214bdfdfaa9bd.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;经过上面的分析，我们已经看到了，里面的Eager Spool是和主查询比较形成的结果值，因为这个必须要及时的形成，以便于子查询的进行，所以它的类型为Eager Spool，&lt;/p&gt;
&lt;p&gt;而子查询外面的那个Index Spool为Lazy Spool，这个结果项的保存不需要那么及时了，这个保存的就是子查询的形成的结果项了，就是相对每个订单运费的平均值。&lt;/p&gt;
&lt;p&gt;我上面的分析，希望各位看官能看懂了。&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;其实，关于这个Index Spool的设计的目的，完全为了就是提升性能，因为我们知道上面的查询语句每个子查询的进行，都必须回调主查询的结果，所以为了避免每次都回调，就采用了Index Spool进行暂存，而这个Index Spool存储的位置就是Tempdb，所以Tempdb运行的快慢直接关乎这种查询语句的性能。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;这也是我们为什么强调大并发的数据库搭建，建议将Tempdb库单独存放于高性能的硬件环境中。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Index Spool&lt;/strong&gt; 物理运算符在&lt;strong&gt; Argument&lt;/strong&gt; 列中包含 SEEK:() 谓词。&lt;strong&gt;Index Spool&lt;/strong&gt; 运算符扫描其输入行，将每行的副本放置在隐藏的假脱机文件（存储在&lt;strong&gt; tempdb&lt;/strong&gt; 数据库中且只在查询的生存期内存在）中，并为这些行创建非聚集索引。这样可以使用索引的查找功能来仅输出那些满足 SEEK:() 谓词的行。&lt;/p&gt;
&lt;p&gt;如果重绕该运算符（例如通过 &lt;strong&gt;Nested Loops&lt;/strong&gt; 运算符重绕），但不需要任何重新绑定，则将使用假脱机数据，而不用重新扫描输入。&lt;/p&gt;
&lt;p&gt;跟索引脱机类似的还有一个相似的运算符：表脱机，其功能类似，表脱机存储的应该是键值列，而表脱机则是存储的是多列数据了。&lt;/p&gt;
&lt;p&gt;来看例子&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT O1.OrderID,O1.Freight
FROM Orders O1
WHERE O1.Freight&amp;gt;
(
   SELECT AVG(O2.Freight)
   FROM Orders O2
   WHERE O2.CustomerID=O1.CustomerID
)&lt;/pre&gt;
&lt;p&gt;这个查询和上面的类似，只不过是查询的同一个客户加入的超过所有订单运费平均值的订单。&lt;/p&gt;
&lt;p&gt;此语句同样不是独立的子查询语句，每个子查询的结果的形成都需要依赖主查询的结果项，为了加快速度，提升性能，SQL Server会将主表查询的的结果项暂存到一张临时表中，这个表就被称为&lt;strong&gt;表脱机&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们来看这句话的执行计划：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/0575c5ca0afa3e2b875c1c249b55a70c.png&quot; rel=&quot;lightbox[82459]&quot; title=&quot;SQL Server调优系列基础篇（子查询运算总结）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82483&quot; alt=&quot;pic9&quot; src=&quot;/images/jobbole.com/5cdde8e32f1ecb0d4aef0c75c054745e.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;这里就用到了一个表脱机的运算符，这个运算符的作用就是用来暂存后面扫描获取的结果集合，用于下面的子查询的应用&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/906605f3561557653801a07c547757a4.png&quot; rel=&quot;lightbox[82459]&quot; title=&quot;SQL Server调优系列基础篇（子查询运算总结）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82484&quot; alt=&quot;pic10&quot; src=&quot;/images/jobbole.com/14029c4186bdbf8efcbb4ff70645ec0c.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;这个表脱机形成的结果项也是存储到临时库Tempdb中，所以它的应用和前面提到的索引脱机类似。&lt;/p&gt;
&lt;p&gt;上面的执行计划中，还提到了一个新的运算符：段（Segment）&lt;/p&gt;
&lt;p&gt;这个运算符的解释是：&lt;br&gt;
&lt;strong&gt;Segment&lt;/strong&gt; 既是一个物理运算符，也是一个逻辑运算符。它基于一个或多个列的值将输入集划分成多个段。这些列显示为 Segment 运算符中的参数。然后运算符每次输出一个段。&lt;/p&gt;
&lt;p&gt;其实作用就是将结果进行汇总整理，将相同值汇聚到一起，跟排序一样，只不过这里可以对多列值进行汇聚。&lt;/p&gt;
&lt;p&gt;我们再来看一个例子，加深 一下关于段运算的作用&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT CustomerID,O1.OrderID,O1.Freight
FROM Orders O1
WHERE O1.Freight=
(
   SELECT MAX(O2.Freight)
   FROM Orders O2
   WHERE O2.CustomerID=O1.CustomerID
)&lt;/pre&gt;
&lt;p&gt;这个语句查询的是：&lt;span style=&quot;color: #ff0000;&quot;&gt;每个顾客所产生的最大运费的订单数据。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;以上语句，如果理解起来有难度，我们可以变通以下的相同逻辑的T-SQL语句，相同的逻辑&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT O1.CustomerID,O1.OrderID,O1.Freight 
FROM Orders O1
INNER JOIN
(
    SELECT CustomerID,max(Freight) Freight
    FROM Orders
    GROUP BY CustomerID
) AS O2
ON O1.CustomerID=O2.CustomerID
AND O1.Freight=O2.Freight&lt;/pre&gt;
&lt;p&gt;先根据客户编号分组，然后获取出最大的运费项，再关联主表获取订单信息。&lt;/p&gt;
&lt;p&gt;以上两种语句生成的相同的查询计划：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/45030f060cb9e34f61b6868ecff171a9.png&quot; rel=&quot;lightbox[82459]&quot; title=&quot;SQL Server调优系列基础篇（子查询运算总结）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82486&quot; alt=&quot;pic11&quot; src=&quot;/images/jobbole.com/59333e03d1e5ef246d3107f52f143be4.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;这里我们来解释一下，SQL Server的强大之处，也是段运算符使用的最佳方式。&lt;/p&gt;
&lt;p&gt;本来这句话要实现，按照逻辑需要有一个嵌套循环连接，参照上面的方式，使用表脱机的方式进行数据的获取。&lt;/p&gt;
&lt;p&gt;但是，我们这句话获取的结果项是每个顾客的最大运费的订单明细项，而且CustomerID列作为输出项，所以这里采用了，先按照运费列（Freight）排序，&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/3fccd101141eb64fa36763ecf8f2654f.png&quot; rel=&quot;lightbox[82459]&quot; title=&quot;SQL Server调优系列基础篇（子查询运算总结）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82487&quot; alt=&quot;pic12&quot; src=&quot;/images/jobbole.com/1e08afa099325dcaa29f21e1ad46f902.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;然后采用段运算符进行将每个顾客相同的数据汇聚到一起，然后再输出每个顾客的前一列（TOP 1）获取的就是最每个顾客的运费最大的订单项。&lt;/p&gt;
&lt;p&gt;省去了任何的表假脱机、索引假脱机、关联连接等一系列复杂的操作。&lt;/p&gt;
&lt;p&gt;SQL Server看来这种智能化的操作还是挺强的。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;我们再来分析SQL Server关于子查询这块的智能特性，因为经过上面的分析通过对比，相关的子查询语句在运行时需要更多的消耗：&lt;/p&gt;
&lt;p&gt;1、有时候需要通过索引假脱机（Index Spool）、表脱机（Table Spool）进行中间结果项的暂存，而这一过程的中间项需要创建、增加、删除、销毁等操作都需要消耗大量的内存和CPU&lt;/p&gt;
&lt;p&gt;2、关于相关子查询中以上提到的中间项的形成都是位于Tempdb临时库中，有时候会增大Tempdb的空间，增加Tempdb库的消耗、页争用等问题。&lt;/p&gt;
&lt;p&gt;所以，要避免上面的问题，最好的方式是避免使用相关子查询，尽量使用独立子查询进行操作。&lt;/p&gt;
&lt;p&gt;当然，SQL Server同样提供了自动转换的功能，智能的去分析语句，避免相关的子查询操作进行：&lt;/p&gt;
&lt;p&gt;来看一个稍差的写法：&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT o.OrderID 
FROM Orders O
WHERE EXISTS
(
   SELECT c.CustomerID
   FROM  Customers C
   WHERE C.City=N&#39;Londom&#39; AND C.CustomerID=O.CustomerID
)&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/d87682b10d42449d80fdbc2a183a329d.png&quot; rel=&quot;lightbox[82459]&quot; title=&quot;SQL Server调优系列基础篇（子查询运算总结）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-82488&quot; alt=&quot;pic13&quot; src=&quot;/images/jobbole.com/6e8e6d7717022ea2757acf7dbe11ed8b.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;上面的语句，我们写的是相关的子查询操作，但是在执行计划中形成的确实独立的子查询，这样从而避免相关的子查询所带来的性能消耗。&lt;/p&gt;
&lt;p&gt;其实上面语句，相对好的写法是如下&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT o.OrderID 
FROM Orders O
WHERE O.CustomerID IN
(
   SELECT c.CustomerID
   FROM  Customers C
   WHERE C.City=N&#39;Londom&#39;
)&lt;/pre&gt;
&lt;p&gt;这样所形成的就是完全独立的子查询，这也是SQL Server要执行的意图。所以这个语句形成的查询计划是和上面的查询计划一样。&lt;/p&gt;
&lt;p&gt;这里的优化全部得益于SQL Server的智能化。&lt;/p&gt;
&lt;p&gt;但是我们在写语句的时候，需要自己了解，掌握好，这样才能写出高效的T-SQL语句。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微软联机丛书逻辑运算符和物理运算符引用&lt;/li&gt;
&lt;li&gt;参照书籍《SQL.Server.2005.技术内幕》系列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本篇篇幅有点长，但是介绍的子查询内容也还不是很全，后续慢慢的补充上，我们写的SQL语句中很多都涉及到子查询，所以这块应用还是挺普遍的。到本篇文章关于日常调优的T-SQL中的查询语句经常用到的一些运算符基本介绍全了，当然，还有一些别的增删改一系列的运算符，这些日常生活中我们一般不采用查询计划调优，后续我们的文章会将这些运算符也添加上，以供参考之用。&lt;/p&gt;
&lt;p&gt;在完成本系列关于查询计划相关的调优之后，我打算将数据库有关统计信息这块也做一个详细的分析介绍。因为统计信息是支撑SQL Server评估最优执行计划的最重要的决策点，&lt;/p&gt;
&lt;p&gt;所以统计信息的重要性不言而喻。有兴趣的童鞋可以提前关注。&lt;/p&gt;
&lt;p&gt;关于SQL Server性能调优的内容涉及面很广，后续文章中依次展开分析。&lt;/p&gt;
&lt;p&gt;有问题可以留言或者私信，随时恭候有兴趣的童鞋加入SQL SERVER的深入研究。共同学习，一起进步。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Sun, 21 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-21-82459-896aaf6f8.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-21-82459-896aaf6f8.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>【翻译】Kibana 4 beta 3 发布，重新支持过滤器</title>
        <description>

  
  &lt;div style=&quot;background-color: #FFF;&quot;&gt;
    &lt;p&gt;本文是 Elasticsearch 官方博客内容，原文地址：&lt;a href=&quot;http://www.elasticsearch.org/blog/kibana-4-beta-3-now-more-filtery/&quot;&gt;http://www.elasticsearch.org/blog/kibana-4-beta-3-now-more-filtery/&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Kibana 4 Beta 3 出来啦! 我们依然给你机会直接&lt;a href=&quot;http://www.elasticsearch.org/overview/kibana/installation/&quot;&gt;下载 Kibana 4 Beta 3&lt;/a&gt;。不过还是要建议你阅读本文对主要特性的讲解。嗯，先暂停一下下载，开始阅读吧！&lt;/p&gt;
&lt;h2 id=&quot;section&quot;&gt;交互式图表和仪表盘&lt;/h2&gt;
&lt;p&gt;过滤器回到了仪表盘上，也可以在单个可视化页上使用了！柱状图、点图、饼图都可以通过点击的方式创建可切换的过滤器。我们还添加了一些函数来操作所有的过滤器，这样你可以一键切换整个过滤效果。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/chenlinux.com/cbcf25cdd795f421f30ccfaa341104d9.jpg&quot; alt=&quot;Screen Shot 2014-12-15 at 12.28.30 PM&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;section-1&quot;&gt;脚本化字段&lt;/h2&gt;
&lt;p&gt;Kibana 现在支持 Elasticsearch 脚本了！不单是可以写脚本，还可以给它命名，并且在应用中跟用普通字段一样调用你取的名字。创建一个脚本化字段，这个字段就像本来就存在一样的显示在你的 Kibana 文档里了。唯一需要注意的是，脚本毕竟不是 Elasticsearch 索引的内容，你不能在这个字段里进行搜索。&lt;/p&gt;
&lt;p&gt;你可以用脚本来连接多个字段，或者在数值字段上做运算，然后把结果导入可视化页里。为了帮助你上手，我们在脚本化字段屏下添加了一个标题叫“从时间字段创建的示例”的连接。你可以在设置(Settings)标签页的索引(Index)区域里找到这个连接。选择或者创建一个索引表达式，然后点击“脚本化字段(Scripted Fields)”标签。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/chenlinux.com/0d7bcd941759969d4f8f2bf85803efa4.jpg&quot; alt=&quot;Screen Shot 2014-12-15 at 1.06.51 PM&quot;&gt;&lt;/p&gt;
&lt;p&gt;做完这些以后，你就可以在聚合页里找到一些新的数值字段可用。比如说，我们可以查一天的 24 个小时，然后获取 30 天 来每个小时的 hits 数的总和：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/chenlinux.com/3eb98923a097937b7e395e23c2481b6a.jpg&quot; alt=&quot;unnamed&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;source-&quot;&gt;高亮和 _source 的新格式&lt;/h2&gt;
&lt;p&gt;JSON 很棒，我们都爱 JSON。谁会不爱 JSON 呢？XML，这是谁？完全无关紧要嘛。&lt;/p&gt;
&lt;p&gt;JSON 在查看上可能有点乱，所以我们对格式做了一点优化。原始的 JSON 内容，当然可以在点击 JSON 标签展开事件后查看。Kibana 现在还会自动高亮匹配上的字段，甚至把他们挪到本行开头的位置展示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/chenlinux.com/ab8e2dd4ea11545f1c4134b735b36399.jpg&quot; alt=&quot;Screen Shot 2014-12-16 at 11.16.17 AM&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;hit-&quot;&gt;hit 连接&lt;/h2&gt;
&lt;p&gt;可能你已经注意到前面截屏上的 “Link to..” ? 你可能不需要分享整个可视化结果或者一个搜索结果，你只是想让别人看到一条重要的命中的记录。现在，这事儿简单了！&lt;/p&gt;
&lt;h2 id=&quot;metric-visualization&quot;&gt;metric visualization&lt;/h2&gt;
&lt;p&gt;有时候你不需要图或者文档！你只需要一个数值在仪表盘上就够了。现在可以做到了：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/chenlinux.com/4e1e896f9a611b3ac8b2837029be41ab.jpg&quot; alt=&quot;Screen Shot 2014-12-16 at 11.16.59 AM&quot;&gt;&lt;/p&gt;
&lt;p&gt;好了，就是这些！还是那句话，到 &lt;a href=&quot;https://github.com/elasticsearch/kibana&quot;&gt;GitHub&lt;/a&gt; 上给我们提问题，建议，贡献。或者，如果你跟我们一样喜欢 IRC，加入我们在 Freenode 上的 #kibana 频道。&lt;/p&gt;
    &lt;hr&gt;
    
    &lt;hr&gt;
  &lt;!-- JiaThis Button BEGIN --&gt;
&lt;div class=&quot;jiathis_style&quot;&gt;
&lt;span class=&quot;jiathis_txt&quot;&gt;分享到：&lt;/span&gt;
&lt;a class=&quot;jiathis_button_tsina&quot;&gt;新浪微博&lt;/a&gt;
&lt;a class=&quot;jiathis_button_weixin&quot;&gt;微信&lt;/a&gt;
&lt;a class=&quot;jiathis_button_renren&quot;&gt;人人网&lt;/a&gt;
&lt;a class=&quot;jiathis_button_ydnote&quot;&gt;有道云笔记&lt;/a&gt;
&lt;a class=&quot;jiathis_button_gmail&quot;&gt;Gmail邮箱&lt;/a&gt;
&lt;a class=&quot;jiathis_button_twitter&quot;&gt;Twitter&lt;/a&gt;
&lt;a class=&quot;jiathis_button_googleplus&quot;&gt;Google+&lt;/a&gt;
&lt;a class=&quot;jiathis_button_hi&quot;&gt;百度空间&lt;/a&gt;
&lt;a class=&quot;jiathis_button_fb&quot;&gt;Facebook&lt;/a&gt;
&lt;a class=&quot;jiathis_button_douban&quot;&gt;豆瓣&lt;/a&gt;
&lt;a href=&quot;http://www.jiathis.com/share?uid=1589850&quot; class=&quot;jiathis jiathis_txt jiathis_separator jtico jtico_jiathis&quot; target=&quot;_blank&quot;&gt;更多&lt;/a&gt;
&lt;a class=&quot;jiathis_counter_style&quot;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var jiathis_config={
	data_track_clickback:true,
	summary:&quot;&quot;,
	ralateuid:{
		&quot;tsina&quot;:&quot;1035836154&quot;
	},
	shortUrl:false,
	hideMore:false
}
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://v3.jiathis.com/code/jia.js?uid=1589850&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;!-- JiaThis Button END --&gt;
&lt;!-- UY BEGIN --&gt;


&lt;!-- UY END --&gt;
  &lt;/div&gt;

</description>
        <pubDate>Fri, 19 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-19-kibana-4-beta-3-now-more-filtery-a351cc0d7.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-19-kibana-4-beta-3-now-more-filtery-a351cc0d7.html</guid>
        
        
        <category>chenlinux</category>
        
      </item>
    
      <item>
        <title>MapReduce实例浅析</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;在文章《&lt;a href=&quot;http://blog.jobbole.com/80619/&quot; target=&quot;_blank&quot;&gt;MapReduce原理与设计思想&lt;/a&gt;》中，详细剖析了MapReduce的原理，这篇文章则通过实例重点剖析MapReduce&lt;/p&gt;
&lt;h2&gt;1.MapReduce概述&lt;/h2&gt;
&lt;div&gt;
&lt;p&gt;Hadoop Map/Reduce是一个使用简易的软件框架，基于它写出来的应用程序能够运行在由上千个商用机器组成的大型集群上，并以一种可靠容错的方式并行处理上T级别的数据集。&lt;/p&gt;
&lt;p&gt;一个Map/Reduce 作业（job） 通常会把输入的数据集切分为若干独立的数据块，由 &lt;em&gt;map任务（task）&lt;/em&gt;以完全并行的方式处理它们。框架会对map的输出先进行排序， 然后把结果输入给&lt;em&gt;reduce任务&lt;/em&gt;。通常作业的输入和输出都会被存储在文件系统中。 整个框架负责任务的调度和监控，以及重新执行已经失败的任务。&lt;/p&gt;
&lt;p&gt;通常，Map/Reduce框架和分布式文件系统是运行在一组相同的节点上的，也就是说，计算节点和存储节点通常在一起。这种配置允许框架在那些已经存好数据的节点上高效地调度任务，这可以使整个集群的网络带宽被非常高效地利用。&lt;/p&gt;
&lt;p&gt;Map/Reduce框架由一个单独的master JobTracker 和每个集群节点一个slave TaskTracker共同组成。master负责调度构成一个作业的所有任务，这些任务分布在不同的slave上，master监控它们的执行，重新执行已经失败的任务。而slave仅负责执行由master指派的任务。&lt;/p&gt;
&lt;p&gt;应用程序至少应该指明输入/输出的位置（路径），并通过实现合适的接口或抽象类提供map和reduce函数。再加上其他作业的参数，就构成了&lt;em&gt;作业配置（job configuration）&lt;/em&gt;。然后，Hadoop的 &lt;em&gt;job client&lt;/em&gt;提交作业（jar包/可执行程序等）和配置信息给JobTracker，后者负责分发这些软件和配置信息给slave、调度任务并监控它们的执行，同时提供状态和诊断信息给job-client。&lt;/p&gt;
&lt;p&gt;虽然Hadoop框架是用Java实现的，但Map/Reduce应用程序则不一定要用 Java来写 。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fa0c8daeccec299d6274456b7f95f2e9.jpg&quot;&gt;&lt;/p&gt;
&lt;h2&gt;2.样例分析：单词计数&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1、WordCount源码分析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;单词计数是最简单也是最能体现MapReduce思想的程序之一，该程序完整的代码可以在Hadoop安装包的src/examples目录下找到&lt;/p&gt;
&lt;p&gt;单词计数主要完成的功能是：统计一系列文本文件中每个单词出现的次数，如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f8f1609a69e7e2aeb6be826b172c28a5.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（1）Map过程&lt;/p&gt;
&lt;p&gt;Map过程需要继承org.apache.hadoop.mapreduce包中的Mapper类，并重写map方法&lt;/p&gt;
&lt;p&gt;通过在map方法中添加两句把key值和value值输出到控制台的代码，可以发现map方法中的value值存储的是文本文件中的一行（以回车符作为行结束标记），而key值为该行的首字符相对于文本文件的首地址的偏移量。然后StringTokenizer类将每一行拆分成一个个的单词，并将&amp;lt;word,1&amp;gt;作为map方法的结果输出，其余的工作都交由MapReduce框架处理。其中IntWritable和Text类是Hadoop对int和string类的封装，这些类能够被串行化，以方便在分布式环境中进行数据交换。&lt;/p&gt;
&lt;p&gt;TokenizerMapper的实现代码如下：&lt;/p&gt;
&lt;pre class=&quot;brush: java; gutter: true&quot;&gt;public static class TokenizerMapper extends Mapper&amp;lt;Object, Text, Text, IntWritable&amp;gt;{
    private final static IntWritable one = new IntWritable(1);
    private Text word = new Text();
      
    public void map(Object key, Text value, Context context) throws IOException, InterruptedException {
        System.out.println(&quot;key = &quot; + key.toString());//添加查看key值
        System.out.println(&quot;value = &quot; + value.toString());//添加查看value值
        StringTokenizer itr = new StringTokenizer(value.toString());
        while (itr.hasMoreTokens()) {
            word.set(itr.nextToken());
            context.write(word, one);
        }
    }
}&lt;/pre&gt;
&lt;p&gt;（2）Reduce过程&lt;/p&gt;
&lt;p&gt;Reduce过程需要继承org.apache.hadoop.mapreduce包中的Reducer类，并重写reduce方法&lt;/p&gt;
&lt;p&gt;reduce方法的输入参数key为单个单词，而values是由各Mapper上对应单词的计数值所组成的列表，所以只要遍历values并求和，即可得到某个单词的出现总次数&lt;/p&gt;
&lt;p&gt;IntSumReduce类的实现代码如下：&lt;/p&gt;
&lt;pre class=&quot;brush: java; gutter: true&quot;&gt;public static class IntSumReducer extends Reducer&amp;lt;Text,IntWritable,Text,IntWritable&amp;gt; {
    private IntWritable result = new IntWritable();

    public void reduce(Text key, Iterable&amp;lt;IntWritable&amp;gt; values, Context context) throws IOException, InterruptedException {
      int sum = 0;
      for (IntWritable val : values) {
          sum += val.get();
      }
      result.set(sum);
      context.write(key, result);
   }
}&lt;/pre&gt;
&lt;p&gt;（3）执行MapReduce任务&lt;/p&gt;
&lt;p&gt;在MapReduce中，由Job对象负责管理和运行一个计算任务，并通过Job的一些方法对任务的参数进行相关的设置。此处设置了使用TokenizerMapper完成Map过程和使用的IntSumReduce完成Combine和Reduce过程。还设置了Map过程和Reduce过程的输出类型：key的类型为Text，value的类型为IntWritable。任务的输入和输出路径则由命令行参数指定，并由FileInputFormat和FileOutputFormat分别设定。完成相应任务的参数设定后，即可调用job.waitForCompletion()方法执行任务，主函数实现如下：&lt;/p&gt;
&lt;pre class=&quot;brush: java; gutter: true&quot;&gt;public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
    if (otherArgs.length != 2) {
      System.err.println(&quot;Usage: wordcount &amp;lt;in&amp;gt; &amp;lt;out&amp;gt;&quot;);
      System.exit(2);
    }
    Job job = new Job(conf, &quot;word count&quot;);
    job.setJarByClass(wordCount.class);
    job.setMapperClass(TokenizerMapper.class);
    job.setCombinerClass(IntSumReducer.class);
    job.setReducerClass(IntSumReducer.class);
    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(IntWritable.class);
    FileInputFormat.addInputPath(job, new Path(otherArgs[0]));
    FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));
    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}&lt;/pre&gt;
&lt;p&gt;运行结果如下：&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:26 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:26 INFO input.FileInputFormat: Total input paths to process : 2&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:26 INFO mapred.JobClient: Running job: job_local_0001&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:26 INFO input.FileInputFormat: Total input paths to process : 2&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:26 INFO mapred.MapTask: io.sort.mb = 100&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.MapTask: data buffer = 79691776/99614720&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.MapTask: record buffer = 262144/327680&lt;/span&gt;&lt;br&gt;
key = 0&lt;br&gt;
value = Hello World&lt;br&gt;
key = 12&lt;br&gt;
value = Bye World&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.MapTask: Starting flush of map output&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.MapTask: Finished spill 0&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.TaskRunner: Task:attempt_local_0001_m_000000_0 is done. And is in the process of commiting&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.LocalJobRunner: &lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.TaskRunner: Task ‘attempt_local_0001_m_000000_0′ done.&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.MapTask: io.sort.mb = 100&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.MapTask: data buffer = 79691776/99614720&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.MapTask: record buffer = 262144/327680&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.MapTask: Starting flush of map output&lt;/span&gt;&lt;br&gt;
key = 0&lt;br&gt;
value = Hello Hadoop&lt;br&gt;
key = 13&lt;br&gt;
value = Bye Hadoop&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.MapTask: Finished spill 0&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.TaskRunner: Task:attempt_local_0001_m_000001_0 is done. And is in the process of commiting&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.LocalJobRunner: &lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.TaskRunner: Task ‘attempt_local_0001_m_000001_0′ done.&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.LocalJobRunner: &lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.Merger: Merging 2 sorted segments&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 73 bytes&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.LocalJobRunner: &lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.TaskRunner: Task:attempt_local_0001_r_000000_0 is done. And is in the process of commiting&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.LocalJobRunner: &lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.TaskRunner: Task attempt_local_0001_r_000000_0 is allowed to commit now&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO output.FileOutputCommitter: Saved output of task ‘attempt_local_0001_r_000000_0′ to out&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.LocalJobRunner: reduce &amp;gt; reduce&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.TaskRunner: Task ‘attempt_local_0001_r_000000_0′ done.&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: map 100% reduce 100%&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: Job complete: job_local_0001&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: Counters: 14&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: FileSystemCounters&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: FILE_BYTES_READ=17886&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: HDFS_BYTES_READ=52932&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: FILE_BYTES_WRITTEN=54239&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: HDFS_BYTES_WRITTEN=71431&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: Map-Reduce Framework&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: Reduce input groups=4&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: Combine output records=6&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: Map input records=4&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: Reduce shuffle bytes=0&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: Reduce output records=4&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: Spilled Records=12&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: Map output bytes=78&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: Combine input records=8&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: Map output records=8&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 05:53:27 INFO mapred.JobClient: Reduce input records=6&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;2、WordCount处理过程&lt;/p&gt;
&lt;p&gt;上面给出了WordCount的设计思路和源码，但是没有深入细节，下面对WordCount进行更加详细的分析：&lt;/p&gt;
&lt;p&gt;（1）将文件拆分成splits，由于测试用的文件较小，所以每一个文件为一个split，并将文件按行分割成&amp;lt;key, value&amp;gt;对，如图，这一步由Mapreduce框架自动完成，其中偏移量包括了回车所占的字符&lt;/p&gt;
&lt;p&gt;（2）将分割好的&amp;lt;key, value&amp;gt;对交给用户定义的map方法进行处理，生成新的&amp;lt;key, value&amp;gt;对&lt;/p&gt;
&lt;p&gt;（3）得到map方法输出的&amp;lt;key, value&amp;gt;对后，Mapper会将它们按照key值进行排序，并执行Combine过程，将key值相同的value值累加，得到Mapper的最终输出结果，如图：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/33003804bf2c324f3255fd6bdf4de91d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（4）Reduce先对从Mapper接收的数据进行排序，再交由用户自定义的reduce方法进行处理，得到新的&amp;lt;key, value&amp;gt;对，并作为WordCount的输出结果，如图：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/2b44260ecff000a48f1ab45b123b78f0.jpg&quot;&gt;&lt;/p&gt;
&lt;h2&gt;3.MapReduce，你够了解吗？&lt;/h2&gt;
&lt;p&gt;MapReduce框架在幕后默默地完成了很多的事情，如果不重写map和reduce方法，会出现什么情况呢？&lt;/p&gt;
&lt;p&gt;下面来实现一个简化的MapReduce，新建一个LazyMapReduce，该类只对任务进行必要的初始化及输入/输出路径的设置，其余的参数均保持默认&lt;/p&gt;
&lt;p&gt;代码如下：&lt;/p&gt;
&lt;pre class=&quot;brush: java; gutter: true&quot;&gt;public class LazyMapReduce {
    public static void main(String[] args) throws Exception {
        // TODO Auto-generated method stub
        Configuration conf = new Configuration();
        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
        if(otherArgs.length != 2) {
            System.err.println(&quot;Usage:wordcount&amp;lt;in&amp;gt;&amp;lt;out&amp;gt;&quot;);
            System.exit(2);
        }
        Job job = new Job(conf, &quot;LazyMapReduce&quot;);
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true)? 0:1);
    }
}&lt;/pre&gt;
&lt;p&gt;运行结果为：&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:13 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:14 INFO input.FileInputFormat: Total input paths to process : 2&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:14 INFO mapred.JobClient: Running job: job_local_0001&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:14 INFO input.FileInputFormat: Total input paths to process : 2&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:14 INFO mapred.MapTask: io.sort.mb = 100&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:15 INFO mapred.JobClient: map 0% reduce 0%&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:18 INFO mapred.MapTask: data buffer = 79691776/99614720&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:18 INFO mapred.MapTask: record buffer = 262144/327680&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:18 INFO mapred.MapTask: Starting flush of map output&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:19 INFO mapred.MapTask: Finished spill 0&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:19 INFO mapred.TaskRunner: Task:attempt_local_0001_m_000000_0 is done. And is in the process of commiting&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:19 INFO mapred.LocalJobRunner: &lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:19 INFO mapred.TaskRunner: Task ‘attempt_local_0001_m_000000_0′ done.&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.MapTask: io.sort.mb = 100&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.MapTask: data buffer = 79691776/99614720&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.MapTask: record buffer = 262144/327680&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.MapTask: Starting flush of map output&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.MapTask: Finished spill 0&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.TaskRunner: Task:attempt_local_0001_m_000001_0 is done. And is in the process of commiting&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.LocalJobRunner: &lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.TaskRunner: Task ‘attempt_local_0001_m_000001_0′ done.&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.LocalJobRunner: &lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.Merger: Merging 2 sorted segments&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 90 bytes&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.LocalJobRunner: &lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.TaskRunner: Task:attempt_local_0001_r_000000_0 is done. And is in the process of commiting&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.LocalJobRunner: &lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.TaskRunner: Task attempt_local_0001_r_000000_0 is allowed to commit now&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO output.FileOutputCommitter: Saved output of task ‘attempt_local_0001_r_000000_0′ to out&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.LocalJobRunner: reduce &amp;gt; reduce&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.TaskRunner: Task ‘attempt_local_0001_r_000000_0′ done.&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: map 100% reduce 100%&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: Job complete: job_local_0001&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: Counters: 14&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: FileSystemCounters&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: FILE_BYTES_READ=46040&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: HDFS_BYTES_READ=51471&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: FILE_BYTES_WRITTEN=52808&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: HDFS_BYTES_WRITTEN=98132&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: Map-Reduce Framework&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: Reduce input groups=3&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: Combine output records=0&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: Map input records=4&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: Reduce shuffle bytes=0&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: Reduce output records=4&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: Spilled Records=8&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: Map output bytes=78&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: Combine input records=0&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: Map output records=4&lt;/span&gt;&lt;br&gt;
&lt;span style=&quot;color: #ff0000&quot;&gt;14/12/17 23:04:20 INFO mapred.JobClient: Reduce input records=4&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;可见在默认情况下，MapReduce原封不动地将输入&amp;lt;key, value&amp;gt;写到输出&lt;/p&gt;
&lt;p&gt;下面介绍MapReduce的部分参数及其默认设置：&lt;/p&gt;
&lt;p&gt;（1）InputFormat类&lt;/p&gt;
&lt;p&gt;该类的作用是将输入的数据分割成一个个的split，并将split进一步拆分成&amp;lt;key, value&amp;gt;对作为map函数的输入&lt;/p&gt;
&lt;p&gt;（2）Mapper类&lt;/p&gt;
&lt;p&gt;实现map函数，根据输入的&amp;lt;key, value&amp;gt;对生产中间结果&lt;/p&gt;
&lt;p&gt;（3）Combiner&lt;/p&gt;
&lt;p&gt;实现combine函数，合并中间结果中具有相同key值的键值对。&lt;/p&gt;
&lt;p&gt;（4）Partitioner类&lt;/p&gt;
&lt;p&gt;实现getPartition函数，用于在Shuffle过程按照key值将中间数据分成R份，每一份由一个Reduce负责&lt;/p&gt;
&lt;p&gt;（5）Reducer类&lt;/p&gt;
&lt;p&gt;实现reduce函数，将中间结果合并，得到最终的结果&lt;/p&gt;
&lt;p&gt;（6）OutputFormat类&lt;/p&gt;
&lt;p&gt;该类负责输出最终的结果&lt;/p&gt;
&lt;p&gt;上面的代码可以改写为:&lt;/p&gt;
&lt;pre class=&quot;brush: java; gutter: true&quot;&gt;public class LazyMapReduce {
    public static void main(String[] args) throws Exception {
        // TODO Auto-generated method stub
        Configuration conf = new Configuration();
        String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();
        if(otherArgs.length != 2) {
            System.err.println(&quot;Usage:wordcount&amp;lt;in&amp;gt;&amp;lt;out&amp;gt;&quot;);
            System.exit(2);
        }
        Job job = new Job(conf, &quot;LazyMapReduce&quot;);
        job.setInputFormatClass(TextInputFormat.class);
        job.setMapperClass(Mapper.class);
        
        job.setMapOutputKeyClass(LongWritable.class);
        job.setMapOutputValueClass(Text.class);
        job.setPartitionerClass(HashPartitioner.class);
        job.setReducerClass(Reducer.class);
        
        job.setOutputKeyClass(LongWritable.class);
        job.setOutputValueClass(Text.class);
        job.setOutputFormatClass(FileOutputFormat.class);
        
        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));
        System.exit(job.waitForCompletion(true)? 0:1);
    }
}&lt;/pre&gt;
&lt;p&gt;不过由于版本问题，显示有些类已经过时&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;参考资料&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;《实战Hadop：开启通向云计算的捷径.刘鹏》&lt;/p&gt;

&lt;/div&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 19 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-19-81676-eae58d6ae.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-19-81676-eae58d6ae.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>重构遗留代码（11）：终结篇</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        &lt;span style=&quot;display:block;margin-bottom:10px;&quot;&gt;&lt;/span&gt;
		
&lt;p&gt;旧代码，丑陋的代码，复杂的代码，意大利面条似的代码，鬼话废话……就是四个字：遗留代码。这是一个系列文章，将有助于你处理并解决它。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/78635/&quot; target=&quot;_blank&quot;&gt;重构遗留代码（1）：金牌大师&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/79323/&quot; target=&quot;_blank&quot;&gt;重构遗留代码（2）：魔术字符串和常量&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/80106&quot; target=&quot;_blank&quot;&gt;重构遗留代码（3）：复杂的条件语句&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/80095/&quot; target=&quot;_blank&quot;&gt;重构遗留代码（4）：第一个单元测试&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/80096/&quot; target=&quot;_blank&quot;&gt;重构遗留代码（5）：游戏的可测试方法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/80094/&quot; target=&quot;_blank&quot;&gt;重构遗留代码（6）：进攻复杂的方法&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/80382/&quot; target=&quot;_blank&quot;&gt;重构遗留代码（7）：识别表示层&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/80383/&quot; target=&quot;_blank&quot;&gt;重构遗留代码（8）：一个整洁架构的依赖反转&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/80384/&quot; target=&quot;_blank&quot;&gt;重构遗留代码（9）：分析 Concerns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/80565/&quot; target=&quot;_blank&quot;&gt;重构遗留代码（10）：剖析长方法&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在我们前面的课程中，我们已经学习了一种通过提取直到放弃来理解和做出更好代码的方法。虽然那篇教程是学习这项技术的不错的方式，但它并不是理解这项技术好处的理想例子。在这篇教程中，我们将对所有的问答游戏相关代码使用提取直到放弃的方法，并且我们将分析最后的结果。&lt;/p&gt;
&lt;p&gt;这篇教程也将总结我们关于重构这一系列的文章。如果你认为我们遗漏了什么，以建议的主题来随意评论吧。如果好主意收集了，我将基于你的要求继续写额外的教程。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h1&gt;
&lt;b&gt;进&lt;/b&gt;&lt;b&gt;攻我&lt;/b&gt;&lt;b&gt;们&lt;/b&gt;&lt;b&gt;最&lt;/b&gt;&lt;b&gt;长&lt;/b&gt;&lt;b&gt;的方法&lt;/b&gt;&lt;b&gt;&lt;/b&gt;
&lt;/h1&gt;
&lt;p&gt;拿我们最长的方法并将它提取到小段代码中，有比这更好地开始我们文章的方式吗。像往常一样，测试优先将使得这一过程不仅有效而且也有趣。&lt;/p&gt;
&lt;p&gt;通常，当我开始这篇教程的时候，你已经有了代码，它在php start文件夹里，而最终结果在php文件夹。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;function wasCorrectlyAnswered() {
      if ($this-&amp;gt;inPenaltyBox[$this-&amp;gt;currentPlayer]) {
            if ($this-&amp;gt;isGettingOutOfPenaltyBox) {
                  $this-&amp;gt;display-&amp;gt;correctAnswer();
                  $this-&amp;gt;purses[$this-&amp;gt;currentPlayer]++;

                  $this-&amp;gt;display-&amp;gt;playerCoins($this-&amp;gt;players[$this-&amp;gt;currentPlayer], $this-&amp;gt;purses[$this-&amp;gt;currentPlayer]);

                  $winner = $this-&amp;gt;didPlayerNotWin();
                  $this-&amp;gt;currentPlayer++;
                  if ($this-&amp;gt;shouldResetCurrentPlayer()) {
                        $this-&amp;gt;currentPlayer = 0;
                  }

                  return $winner;
            } else {
                  $this-&amp;gt;currentPlayer++;
                  if ($this-&amp;gt;shouldResetCurrentPlayer()) {
                        $this-&amp;gt;currentPlayer = 0;
                  }
                  return true;
            }

      } else {

            $this-&amp;gt;display-&amp;gt;correctAnswerWithTypo();
            $this-&amp;gt;purses[$this-&amp;gt;currentPlayer]++;
            $this-&amp;gt;display-&amp;gt;playerCoins($this-&amp;gt;players[$this-&amp;gt;currentPlayer], $this-&amp;gt;purses[$this-&amp;gt;currentPlayer]);

            $winner = $this-&amp;gt;didPlayerNotWin();
            $this-&amp;gt;currentPlayer++;
            if ($this-&amp;gt;shouldResetCurrentPlayer()) {
                  $this-&amp;gt;currentPlayer = 0;
            }

            return $winner;
      }
}&lt;/pre&gt;
&lt;p&gt;wasCorrectlyAnswered()这个方法是我们第一个牺牲者。&lt;/p&gt;
&lt;pre&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h1&gt;
&lt;b&gt;测试&lt;/b&gt;&lt;b&gt;wasCorrectlyAnswered()&lt;/b&gt;
&lt;/h1&gt;
&lt;p&gt;正如我们在前一课程学到的，修改遗留代码的第一步是测试它。这是个艰难的过程。对我们来说幸运的是，wasCorrectlyAnswered()方法很简单。它由几个if-else表达式组成。代码的每个分支返回一个值。当我们有返回值时，我们总可以推测测试是可行的。不一定容易，但至少可能。 &lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;function testWasCorrectlyAnsweredAndGettingOutOfPenaltyBoxWhileBeingAWinner() {
      $this-&amp;gt;setAPlayerThatIsInThePenaltyBox();
      $this-&amp;gt;game-&amp;gt;isGettingOutOfPenaltyBox = true;
      $this-&amp;gt;game-&amp;gt;purses[$this-&amp;gt;game-&amp;gt;currentPlayer] = Game::$numberOfCoinsToWin;

      $this-&amp;gt;assertTrue($this-&amp;gt;game-&amp;gt;wasCorrectlyAnswered());
}&lt;/pre&gt;
&lt;p&gt;先写什么测试没有明确的规则。我们只选择这里执行部分的第一分支。实际上我们有个不错的惊喜，我们重用了在之前的教程中提取很多次的私有方法中的一个。但我们还没完成。全部通过，那么是时候重构了。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;function testWasCorrectlyAnsweredAndGettingOutOfPenaltyBoxWhileBeingAWinner() {
      $this-&amp;gt;setAPlayerThatIsInThePenaltyBox();
      $this-&amp;gt;currentPlayerWillLeavePenaltyBox();
      $this-&amp;gt;setCurrentPlayerAWinner();

      $this-&amp;gt;assertTrue($this-&amp;gt;game-&amp;gt;wasCorrectlyAnswered());
}&lt;/pre&gt;
&lt;p&gt;这更容易阅读并且明显更具描述性。你可以在附带的代码中找到提取的方法。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;function testWasCorrectlyAnsweredAndGettingOutOfPenaltyBoxWhileNOTBeingAWinner() {
      $this-&amp;gt;setAPlayerThatIsInThePenaltyBox();
      $this-&amp;gt;currentPlayerWillLeavePenaltyBox();
      $this-&amp;gt;setCurrentPlayerNotAWinner();

      $this-&amp;gt;assertFalse($this-&amp;gt;game-&amp;gt;wasCorrectlyAnswered());
}

private function setCurrentPlayerNotAWinner() {
      $this-&amp;gt;game-&amp;gt;purses[$this-&amp;gt;game-&amp;gt;currentPlayer] = 0;
}&lt;/pre&gt;
&lt;p&gt;我们期望这能通过，但它失败了。原因还不明确。对didPlayerNotWin()解析也许会有帮助。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;function didPlayerNotWin() {
      return !($this-&amp;gt;purses[$this-&amp;gt;currentPlayer] == self::$numberOfCoinsToWin);
}&lt;/pre&gt;
&lt;p&gt;事实上当玩家没有赢的时候方法返回了true。也许我们可以重命名变量，但首先测试必须通过。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;private function setCurrentPlayerAWinner() {
      $this-&amp;gt;game-&amp;gt;purses[$this-&amp;gt;game-&amp;gt;currentPlayer] = Game::$numberOfCoinsToWin;
}

private function setCurrentPlayerNotAWinner() {
      $this-&amp;gt;game-&amp;gt;purses[$this-&amp;gt;game-&amp;gt;currentPlayer] = 0;
}&lt;/pre&gt;
&lt;p&gt;通过仔细观察，我们知道我们在这儿混淆了值。我们的困惑存在于在方法名和变量名之间，使得我们反转了条件。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;private function setCurrentPlayerAWinner() {
      $this-&amp;gt;game-&amp;gt;purses[$this-&amp;gt;game-&amp;gt;currentPlayer] = 0;
}

private function setCurrentPlayerNotAWinner() {
      $this-&amp;gt;game-&amp;gt;purses[$this-&amp;gt;game-&amp;gt;currentPlayer] = Game::$numberOfCoinsToWin - 1;
}&lt;/pre&gt;
&lt;p&gt;这样可以了。当分析didPlayerNotWin()的时候，我们同样注意到它使用等于来决定赢家。我们必须设置值，一个都不能少，因为在我们测试的产品代码中值是增加的。&lt;/p&gt;
&lt;p&gt;剩下的三个测试程序很容易写。它们只是前两个的变体。你可以在附带的代码中找到它们。&lt;/p&gt;
&lt;h1&gt;
&lt;b&gt;提取并重命名&lt;/b&gt;&lt;b&gt;wasCorrectlyAnswered()&lt;/b&gt;&lt;b&gt;方法直到我&lt;/b&gt;&lt;b&gt;们&lt;/b&gt;&lt;b&gt;放弃&lt;/b&gt;&lt;b&gt;&lt;/b&gt;
&lt;/h1&gt;
&lt;p&gt;最困惑的一个问题是具有误导性的$winner变量名。那应该是$notWinner。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;$notAWinner = $this-&amp;gt;didPlayerNotWin();
$this-&amp;gt;currentPlayer++;
if ($this-&amp;gt;shouldResetCurrentPlayer()) {
      $this-&amp;gt;currentPlayer = 0;
}
return $notAWinner;&lt;/pre&gt;
&lt;p&gt;我们看到$notWinner变量是只用来返回值的。我们可以在return语句中直接调用didPlayerNotWin()方法吗？&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;$this-&amp;gt;currentPlayer++;
if ($this-&amp;gt;shouldResetCurrentPlayer()) {
      $this-&amp;gt;currentPlayer = 0;
}
return $this-&amp;gt;didPlayerNotWin();&lt;/pre&gt;
&lt;p&gt;这仍然使得我们的单元测试通过了，但如果我们运行金牌大师测试程序，将会以“没有足够内存”而失败。事实上，修改使得游戏永远结束不了。&lt;/p&gt;
&lt;p&gt;目前的情况是，当前玩家被更新为下一个玩家了。因为我们只有一个单一的玩家，所以我们总是复用相同的玩家。这就是测试发生的。你永远不会知道什么时候在一段很难的代码中你会发现一个隐藏的逻辑。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;function testWasCorrectlyAnsweredAndGettingOutOfPenaltyBoxWhileBeingAWinner() {
      $this-&amp;gt;setAPlayerThatIsInThePenaltyBox();
      $this-&amp;gt;game-&amp;gt;add(&#39;Another Player&#39;);
      $this-&amp;gt;currentPlayerWillLeavePenaltyBox();
      $this-&amp;gt;setCurrentPlayerAWinner();

      $this-&amp;gt;assertTrue($this-&amp;gt;game-&amp;gt;wasCorrectlyAnswered());
}&lt;/pre&gt;
&lt;p&gt;只通过在针对这个方法的每个测试方法中增加另一个玩家，我们可以确保逻辑被覆盖到。测试将使得上述修改后的return语句失败。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;private function selectNextPlayer() {
      $this-&amp;gt;currentPlayer++;
      if ($this-&amp;gt;shouldResetCurrentPlayer()) {
            $this-&amp;gt;currentPlayer = 0;
      }
}&lt;/pre&gt;
&lt;p&gt;我们可以马上发现对于下一个玩家的选择在两个条件下都是相同的。我们可以将其移到一个方法中去。我们给这个方法的名字是selectNextPlayer()。这个名字帮助突出当前玩家的值将被修改这一事实。它同样表明didPlayerNotWin()方法可以被重命名为能反映当前玩家关系的名字。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;function wasCorrectlyAnswered() {
      if ($this-&amp;gt;inPenaltyBox[$this-&amp;gt;currentPlayer]) {
            if ($this-&amp;gt;isGettingOutOfPenaltyBox) {
                  $this-&amp;gt;display-&amp;gt;correctAnswer();
                  $this-&amp;gt;purses[$this-&amp;gt;currentPlayer]++;

                  $this-&amp;gt;display-&amp;gt;playerCoins($this-&amp;gt;players[$this-&amp;gt;currentPlayer], $this-&amp;gt;purses[$this-&amp;gt;currentPlayer]);

                  $notAWinner = $this-&amp;gt;didCurrentPlayerNotWin();
                  $this-&amp;gt;selectNextPlayer();
                  return $notAWinner;
            } else {
                  $this-&amp;gt;selectNextPlayer();
                  return true;
            }

      } else {

            $this-&amp;gt;display-&amp;gt;correctAnswerWithTypo();
            $this-&amp;gt;purses[$this-&amp;gt;currentPlayer]++;
            $this-&amp;gt;display-&amp;gt;playerCoins($this-&amp;gt;players[$this-&amp;gt;currentPlayer], $this-&amp;gt;purses[$this-&amp;gt;currentPlayer]);

            $notAWinner = $this-&amp;gt;didCurrentPlayerNotWin();
            $this-&amp;gt;selectNextPlayer();

            return $notAWinner;
      }
}&lt;/pre&gt;
&lt;p&gt;我们的代码变得更短并更具说明力了。接下来我们能做什么？我们可以修改“not winner”逻辑的奇怪的名字并且将方法从负逻辑改为正逻辑。或者我们可以继续提取并稍后处理混乱的负逻辑。我不认为有一种确定的方式去做这事。所以，我将把负逻辑的问题作为你的一个练习，我们将继续提取。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;function wasCorrectlyAnswered() {
      if ($this-&amp;gt;inPenaltyBox[$this-&amp;gt;currentPlayer]) {
            return $this-&amp;gt;getCorrectlyAnsweredForPlayersInPenaltyBox();
      } else {
            return $this-&amp;gt;getCorrectlyAnsweredForPlayersNotInPenaltyBox();
      }
}&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;作为一个经验法则，试着将一行代码放到决策逻辑的每条分支上。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;我们提取每个if表达式中的整块代码。这是很重要的步骤，是你应该经常思考的。当你的代码中有决策路径或者循环，它其中应该只有单一的表达式。阅读这个方法的人大部分可能是不关心具体的实现的。他或者她会关心决策逻辑，就是if表达式。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;function wasCorrectlyAnswered() {
      if ($this-&amp;gt;inPenaltyBox[$this-&amp;gt;currentPlayer]) {
            return $this-&amp;gt;getCorrectlyAnsweredForPlayersInPenaltyBox();
      }

      return $this-&amp;gt;getCorrectlyAnsweredForPlayersNotInPenaltyBox();
}&lt;/pre&gt;
&lt;p&gt;如果我们摆脱了任何额外的代码，我们应该这么做。移除else并且在我们稍稍做修改的情况下，仍旧保持相同的逻辑。我更喜欢这个解决方案，因为它突出了函数“默认的”行为是什么。该代码是直接在函数的内部(这里的最后一行代码)。if表达式是加到默认函数的特殊的功能。&lt;/p&gt;
&lt;p&gt;我听说推论按照这种方式写条件如果if表达式激活的话，可能会隐藏默认没有执行的事实。我只能赞同这点，如果你更愿意保留else部分以更清晰，请这么做。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;private function getCorrectlyAnsweredForPlayersInPenaltyBox() {
      if ($this-&amp;gt;isGettingOutOfPenaltyBox) {
            return $this-&amp;gt;getCorrectlyAnsweredForPlayerGettingOutOfPenaltyBox();
      } else {
            return $this-&amp;gt;getCorrectlyAnsweredForPlayerStayingInPenaltyBox();
      }
}&lt;/pre&gt;
&lt;p&gt;我们可以继续在新建的私有方法中提取。对下一个条件表达式适用相同的规则将带来上述的代码。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;private function giveCurrentUserACoin() {
      $this-&amp;gt;purses[$this-&amp;gt;currentPlayer]++;
}&lt;/pre&gt;
&lt;p&gt;通过观察私有方法getCorrectlyAnsweredForPlayerNotInPenaltyBox()和getCorrectlyAnsweredForPlayerGettingOutOfPenaltyBox()，我们可以马上注意到简单的任务重复了。那个任务可能对于像我们这样已经知道钱包和钱币的人来说是明显的，但对一个新人来说不是。将那一行提取到方法giveCurrentUserACoin()中是个好主意。&lt;/p&gt;
&lt;p&gt;它也对处理重复有利。如果将来我们修改给予玩家钱币的方式，我们只需要修改这个私有方法的代码。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;private function getCorrectlyAnsweredForPlayersNotInPenaltyBox() {
      $this-&amp;gt;display-&amp;gt;correctAnswerWithTypo();
      return $this-&amp;gt;getCorrectlyAnsweredForAPlayer();
}

private function getCorrectlyAnsweredForPlayerGettingOutOfPenaltyBox() {
      $this-&amp;gt;display-&amp;gt;correctAnswer();
      return $this-&amp;gt;getCorrectlyAnsweredForAPlayer();
}

private function getCorrectlyAnsweredForAPlayer() {
      $this-&amp;gt;giveCurrentUserACoin();
      $this-&amp;gt;display-&amp;gt;playerCoins($this-&amp;gt;players[$this-&amp;gt;currentPlayer], $this-&amp;gt;purses[$this-&amp;gt;currentPlayer]);

      $notAWinner = $this-&amp;gt;didCurrentPlayerNotWin();
      $this-&amp;gt;selectNextPlayer();
      return $notAWinner;
}&lt;/pre&gt;
&lt;p&gt;那么两个正确回答的方法是相同的，除了其中一个输出了带错字的内容。我们提取了重复的代码并且将不同保持在各自方法里。你可能会想我们可以在调用代码处使用提取的带一个参数的方法，并且一次输出正常，一次输出带错字。然而，上述提出的解决方案有个优点：它使两个概念分离，不在禁区和摆脱禁区。&lt;/p&gt;
&lt;p&gt;这就是对wasCorrectlyAnswered()处理的结论。&lt;/p&gt;
&lt;pre&gt;&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h1&gt;
&lt;b&gt;wrongAnswer()&lt;/b&gt;&lt;b&gt;方法怎么&lt;/b&gt;&lt;b&gt;处&lt;/b&gt;&lt;b&gt;理？&lt;/b&gt;&lt;b&gt;&lt;/b&gt;
&lt;/h1&gt;
&lt;p&gt; &lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;function wrongAnswer() {
      $this-&amp;gt;display-&amp;gt;incorrectAnswer();
      $currentPlayer = $this-&amp;gt;players[$this-&amp;gt;currentPlayer];
      $this-&amp;gt;display-&amp;gt;playerSentToPenaltyBox($currentPlayer);
      $this-&amp;gt;inPenaltyBox[$this-&amp;gt;currentPlayer] = true;

      $this-&amp;gt;currentPlayer++;
      if ($this-&amp;gt;shouldResetCurrentPlayer()) {
            $this-&amp;gt;currentPlayer = 0;
      }
      return true;
}&lt;/pre&gt;
&lt;p&gt;这个方法有11行不算巨大，但无疑很大。你还记得魔术数字7加负二的研究吗？它指出，我们的大脑可以同时想7+-2这样的事。也就是说，我们的能力有限。所以为了容易并完全得理解一个方法，我们需要它的内部逻辑适用其范围。总共11行，包括9行内容，这个方法就是这种极限。你可能会说，其实也有一个空行，另外只是一个括号。这使得逻辑行只有7行。&lt;/p&gt;
&lt;p&gt;虽然括号和空格所占空间很短，但对于我们它们是有意义的。它们分离了逻辑部分，并且有意义，所以我们的大脑必须处理它们。是的，相对于全部的比较逻辑，它是容易的但仍需处理。&lt;/p&gt;
&lt;p&gt;这就是为什么方法中我们的目标逻辑行是4行的原因。那是对上述逻辑最低线之下的，这样天才和平庸的程序员都应该能够理解方法。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;$this-&amp;gt;currentPlayer++;
if ($this-&amp;gt;shouldResetCurrentPlayer()) {
      $this-&amp;gt;currentPlayer = 0;
}&lt;/pre&gt;
&lt;p&gt;我们已经有了针对这段代码的一个方法，所以我们应该利用它。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;function wrongAnswer() {
      $this-&amp;gt;display-&amp;gt;incorrectAnswer();
      $currentPlayer = $this-&amp;gt;players[$this-&amp;gt;currentPlayer];
      $this-&amp;gt;display-&amp;gt;playerSentToPenaltyBox($currentPlayer);
      $this-&amp;gt;inPenaltyBox[$this-&amp;gt;currentPlayer] = true;
      $this-&amp;gt;selectNextPlayer();
      return true;
}&lt;/pre&gt;
&lt;p&gt;更好了，但我们应该放弃还是继续？&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;$currentPlayer = $this-&amp;gt;players[$this-&amp;gt;currentPlayer];
$this-&amp;gt;display-&amp;gt;playerSentToPenaltyBox($currentPlayer);&lt;/pre&gt;
&lt;p&gt;我们可以从这两行内联变量。$this-&amp;gt;currentPlayer很明显返回当前玩家，所以没必要重复这个逻辑。通过使用局部变量，我们没学到任何新东西或者抽象任何新东西。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;function wrongAnswer() {
      $this-&amp;gt;display-&amp;gt;incorrectAnswer();
 $this-&amp;gt;display-&amp;gt;playerSentToPenaltyBox($this-&amp;gt;players[$this-&amp;gt;currentPlayer]);
      $this-&amp;gt;inPenaltyBox[$this-&amp;gt;currentPlayer] = true;
      $this-&amp;gt;selectNextPlayer();
      return true;
}&lt;/pre&gt;
&lt;p&gt;降到5行了。还有什么其他内容吗？&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;$this-&amp;gt;inPenaltyBox[$this-&amp;gt;currentPlayer] = true;&lt;/pre&gt;
&lt;p&gt;我们可以把上面这行提取到它自己的方法中。它将帮助解释发什么并且隔离在它自己的方法中的送当前玩家到禁区的逻辑里。&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;function wrongAnswer() {
      $this-&amp;gt;display-&amp;gt;incorrectAnswer();
 $this-&amp;gt;display-&amp;gt;playerSentToPenaltyBox($this-&amp;gt;players[$this-&amp;gt;currentPlayer]);
      $this-&amp;gt;sendCurrentPlayerToPenaltyBox();
      $this-&amp;gt;selectNextPlayer();
      return true;
}&lt;/pre&gt;
&lt;p&gt;还是5行，但所有都是方法调用。最初的两个是显示用的。接下来的两个关系我们的逻辑。最后一行只返回true。不引入复杂的提取物，我看没有办法使这个方法更容易理解，例如通过提取两个显示方法到一个私有方法中的方式。如果我们要这么做，方法应该怎么提取？放入这个Game类，还是放入Display类？我认为这已经是一个太复杂的问题，针对我们方法纯粹的简单性来说，这点不值得考虑。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h1&gt;
&lt;b&gt;最后的思考和一些统计&lt;/b&gt;&lt;b&gt;&lt;/b&gt;
&lt;/h1&gt;
&lt;p&gt;让我们通过从PHPUnit开发者那里检出这个强大的工具&lt;a href=&quot;https://github.com/sebastianbergmann/phploc.git&quot;&gt;https://github.com/sebastianbergmann/phploc.git&lt;/a&gt;来做一些统计。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;b&gt;原始问答游戏代码的统计&lt;/b&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;./phploc ../Refactoring Legacy Code - Part 1: The Golden Master/Source/trivia/php/

phploc 2.1-gca70e70 by Sebastian Bergmann.

Size

  Lines of Code (LOC)                              232

  Comment Lines of Code (CLOC)                       0 (0.00%)

  Non-Comment Lines of Code (NCLOC)                232 (100.00%)

  Logical Lines of Code (LLOC)                      99 (42.67%)

    Classes                                         88 (88.89%)

      Average Class Length                          88

        Minimum Class Length                        88

        Maximum Class Length                        88

      Average Method Length                          7

        Minimum Method Length                        1

        Maximum Method Length                       17

    Functions                                        1 (1.01%)

      Average Function Length                        1

    Not in classes or functions                     10 (10.10%)

Cyclomatic Complexity

  Average Complexity per LLOC                     0.26

  Average Complexity per Class                   25.00

    Minimum Class Complexity                     25.00

    Maximum Class Complexity                     25.00

  Average Complexity per Method                   3.18

    Minimum Method Complexity                     1.00

    Maximum Method Complexity                    10.00

Dependencies

  Global Accesses                                    0

    Global Constants                                 0 (0.00%)

    Global Variables                                 0 (0.00%)

    Super-Global Variables                           0 (0.00%)

  Attribute Accesses                               115

    Non-Static                                     115 (100.00%)

    Static                                           0 (0.00%)

  Method Calls                                      21

    Non-Static                                      21 (100.00%)

    Static                                           0 (0.00%)

Structure

  Namespaces                                         0

  Interfaces                                         0

  Traits                                             0

  Classes                                            1

    Abstract Classes                                 0 (0.00%)

    Concrete Classes                                 1 (100.00%)

  Methods                                           11

    Scope

      Non-Static Methods                            11 (100.00%)

      Static Methods                                 0 (0.00%)

    Visibility

      Public Methods                                11 (100.00%)

      Non-Public Methods                             0 (0.00%)

  Functions                                          1

    Named Functions                                  1 (100.00%)

    Anonymous Functions                              0 (0.00%)

  Constants                                          0

    Global Constants                                 0 (0.00%)

    Class Constants                                  0 (0.00%)&lt;/pre&gt;
&lt;p&gt;&lt;b&gt; &lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;重构后问答游戏代码的统计&lt;/b&gt;&lt;/p&gt;
&lt;pre class=&quot;brush: php; gutter: true&quot;&gt;./phploc ../Refactoring Legacy Code - Part 11: The End?/Source/trivia/php
phploc 2.1-gca70e70 by Sebastian Bergmann.

Size
  Lines of Code (LOC)                              371
  Comment Lines of Code (CLOC)                       0 (0.00%)
  Non-Comment Lines of Code (NCLOC)                371 (100.00%)
  Logical Lines of Code (LLOC)                     151 (40.70%)
    Classes                                        145 (96.03%)
      Average Class Length                          36
        Minimum Class Length                         8
        Maximum Class Length                        89
      Average Method Length                          2
        Minimum Method Length                        1
        Maximum Method Length                       14
    Functions                                        0 (0.00%)
      Average Function Length                        0
    Not in classes or functions                      6 (3.97%)

Cyclomatic Complexity
  Average Complexity per LLOC                     0.15
  Average Complexity per Class                    6.50
    Minimum Class Complexity                      1.00
    Maximum Class Complexity                     17.00
  Average Complexity per Method                   1.46
    Minimum Method Complexity                     1.00
    Maximum Method Complexity                    10.00

Dependencies
  Global Accesses                                    0
    Global Constants                                 0 (0.00%)
    Global Variables                                 0 (0.00%)
    Super-Global Variables                           0 (0.00%)
  Attribute Accesses                                96
    Non-Static                                      94 (97.92%)
    Static                                           2 (2.08%)
  Method Calls                                      74
    Non-Static                                      74 (100.00%)
    Static                                           0 (0.00%)

Structure
  Namespaces                                         0
  Interfaces                                         1
  Traits                                             0
  Classes                                            3
    Abstract Classes                                 0 (0.00%)
    Concrete Classes                                 3 (100.00%)
  Methods                                           59
    Scope
      Non-Static Methods                            59 (100.00%)
      Static Methods                                 0 (0.00%)
    Visibility
      Public Methods                                35 (59.32%)
      Non-Public Methods                            24 (40.68%)
  Functions                                          0
    Named Functions                                  0 (0.00%)
    Anonymous Functions                              0 (0.00%)
  Constants                                          3
    Global Constants                                 0 (0.00%)
    Class Constants                                  3 (100.00%)&lt;/pre&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;h3&gt;分析&lt;/h3&gt;
&lt;p&gt;本身的数据一样好，我们可以理解并分析它。&lt;/p&gt;
&lt;p&gt;逻辑代码行数增加相当显著从99行加到了151行。但这个数字不应该欺骗你让你认为我们的代码变得更复杂了。这是一个良好重构代码的自然趋势，因为增加了方法和对它们的调用代码。&lt;/p&gt;
&lt;p&gt;只要我们看看类的平均长度，我们可以看到代码行数大幅下降，从88行降到36行。&lt;/p&gt;
&lt;p&gt;这是多么得惊人，方法长度从平均7行降到只有2行代码。&lt;/p&gt;
&lt;p&gt;行数是每个计量单位代码量的良好指标，真正获得的是圈复杂度的分析。每次我们对代码做了个决定，我们将增加了圈复杂度。当我们把if表达式放在另一个里面时，该方法的圈复杂度呈指数上升。我们持续得提取导致方法中只有一个单一的决策，从而降低了它们每个方法的平均复杂度从3.18到1.00。你可以将其理解为“我们重构的方法比原始代码简单3.18倍”。在类级别，复杂度的降低甚至更加惊人。它从25.00降到了6.50。&lt;/p&gt;
&lt;h3&gt;&lt;/h3&gt;
&lt;p&gt;&lt;b&gt;结&lt;/b&gt;&lt;b&gt;束了？&lt;/b&gt;&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;好了，就这样了。结束这个系列。如果你认为我们遗漏了任何重构话题，请在下面的评论中自由表述你的意见来询问它们。如果它们很有趣那我将会把它们移到这个系列的额外篇幅中。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;感谢你的全神贯注。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 19 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-19-81330-79e917487.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-19-81330-79e917487.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>超酷算法：用四叉树和希尔伯特曲线做空间索引</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;随着越来越多的数据和应用和地理空间相关，空间索引变得愈加重要。然而，有效地查询地理空间数据是相当大的挑战，因为数据是二维的（有时候更高），不能用标准的索引技术来查询位置。空间索引通过各种各样的技术来解决这个问题。在这篇博文中，我将介绍几种：&lt;a href=&quot;http://en.wikipedia.org/wiki/Quadtree&quot; target=&quot;_blank&quot;&gt;四叉树&lt;/a&gt;，&lt;a href=&quot;http://en.wikipedia.org/wiki/Geohash&quot;&gt;geohash&lt;/a&gt;（不要和&lt;a href=&quot;http://wiki.xkcd.com/geohashing/Main_Page&quot;&gt;geohashing&lt;/a&gt;混淆）以及空间填充曲线，并揭示它们是怎样相互关联的。&lt;/p&gt;
&lt;h2&gt;四叉树&lt;/h2&gt;
&lt;p&gt;四叉树是种很直接的空间索引技术。在四叉树中，每个节点表示覆盖了部分进行索引的空间的边界框，根节点覆盖了整个区域。每个节点要么是叶节点，有包含一个或多个索引点的列表，没有孩子。要么是内部节点，有四个孩子，每个孩子对应将区域沿两根轴对半分得到的四个象限中的一个，四叉树也因此得名。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;aligncenter&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/39fecd468ba069854ffe8d28f44f0068.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图1    展示四叉树是怎样划分索引区域的 来源：&lt;a href=&quot;http://en.wikipedia.org/wiki/File:Point_quadtree.svg&quot;&gt;维基百科&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;将数据插入四叉树很简单：从根节点开始，判断你的数据点属于哪个象限。递归到相应的节点，重复步骤，直到到达叶节点，然后将该点加入节点的索引点列表中。如果列表中的元素个数超出了预设的最大数目，则将节点分裂，将其中的索引点移动到相应的子节点中去。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c1f387ac669a9f6a26ab952da6bb8c27.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图2    四叉树的内部结构&lt;/p&gt;
&lt;p&gt;查询四叉树时从根节点开始，检查每个子节点看是否与查询的区域相交。如果是，则递归进入该子节点。当到达叶节点时，检查点列表中的每一个项看是否与查询区域相交，如果是则返回此项。&lt;/p&gt;
&lt;p&gt;注意四叉树是非常规则的，事实上它是一种&lt;a href=&quot;http://en.wikipedia.org/wiki/Trie&quot;&gt;字典树&lt;/a&gt;，因为树节点的值不依赖于插入的数据。因此我们可以用直接的方式给节点编号：用二进制给每个象限编号（左上是00，右上是10等等 &lt;span style=&quot;color: #808080;&quot;&gt;译者注：第一个比特位为0表示在左半平面，为1在右半平面。第二个比特位为0表示在上半平面，为1在下半平面&lt;/span&gt;），任一节点的编号是由从根开始，它的各祖先的象限号码串接而成的。在这个编号系统中，图2中右下角节点的编号是1101。&lt;/p&gt;
&lt;p&gt;如果我们定义了树的最大深度，不需通过树就可以计算数据点所在节点的编号：只要把节点的坐标标准化到适当的整数区间中（比如32位整数），然后把转化后x, y坐标的比特位交错组合。每对比特指定了假想的四叉树中的一个象限。（&lt;span style=&quot;color: #808080;&quot;&gt;译者注：不了解的读者可看看&lt;/span&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Z-order_curve&quot;&gt;Z-order&lt;/a&gt;，&lt;span style=&quot;color: #808080;&quot;&gt;它和下文的希尔伯特曲线都是将二维的点映射到一维的方法&lt;/span&gt;）&lt;/p&gt;
&lt;h3&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;Geohash&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;上述编号系统可能看起来有些熟悉，没错，就是&lt;a href=&quot;http://en.wikipedia.org/wiki/Geohash&quot;&gt;geohash&lt;/a&gt;！此刻，你可以把四叉树扔掉了。节点编号，或者说geohash，包含了对于节点在树中位置我们需要的全部信息。全高树中的每个叶节点是个完整的geohash，每个内部节点代表从它最小的叶节点到最大的叶节点的区间。因此，通过查询所需的节点覆盖的数值区间中的一切（在geohash上索引），你可以有效地定位任意内部节点下的所有数据点。&lt;/p&gt;
&lt;p&gt;一旦我们丢掉了四叉树，查询就变得复杂一点了。我们需要事先构建搜索集合而不是在树中递归地精炼搜索集合。首先，找到完全覆盖查询区域的最小前缀（或者说四叉树节点  &lt;span style=&quot;color: #808080;&quot;&gt;译者注：注意在我们的编号系统中节点由比特串表示&lt;/span&gt;）。在最坏情况下，这可能远大于实际的查询区域，比如对于在索引区域中心、和四个象限都相交的小块地方，查询将要从根节点开始。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;现在的目标是构建一组完全包含查询区域的前缀，并且尽可能少包含区域外的部分。如果没有其他约束，我们可以简单地选择与查询区域相交的叶节点，但这会造成大量的查询。所以要加一个约束：使得要查询的不同区间最少。&lt;/p&gt;
&lt;p&gt;一种达到这个目的的方法是先设置我们愿意承受的查询区间的最大数目。构建一组区间，最开始都设为我们之前指定的前缀。从中选择可以再分裂而不超出最大区间数并将从查询区域删除最不受欢迎区域的节点。重复这个过程直到集合中再没有区间可以细分。最后，检查得到的集合，如果可能的话合并相邻的区间。下面的图说明了这对于查询一个圆形区域且限制最大5个查询区间是如何工作的。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b1120ce5106afa2e05d2960a503b4e62.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图3    一个对区域的查询是怎样分解成一连串geohash前缀/区间的&lt;/p&gt;
&lt;p&gt;这个方法工作地很好，它使我们避免了递归查找。我们执行的一整套区间查找都可以并行完成。由于每次查找都预期要一次硬盘搜索，将查询并行化大大减少了返回结果需要的时间。&lt;/p&gt;
&lt;p&gt;然而，我们还可以做得更好。你可能注意到上图中我们要查询的所有区域都是相邻的，但我们却只能将其中两个合并（选择区域的右下角的两个）成一个单独的查询，进而只要4次单独查询。&lt;span style=&quot;color: #808080;&quot;&gt;（译者注：这两个区域可以合并是因为它们在geohash以Z字形遍历区域的路径上是相邻的）&lt;/span&gt;这个后果部分是由于geohash访问子区域的顺序，在每个象限中从左到右，从上到下。从右上角象限到左下角象限的不连续性使得我们不得不将本可以使之连续的区间分裂。如果以不同的顺序访问区域，可能我们就可以最小化或者消除这些不连续性，使得更多的区域可以被看做是相邻的，一次查询就可得到结果。通过这样效率上的提升，对于同样的覆盖区域，我们可以做更少的查询，或者相反地，同样的查询次数的情况下包含更少的无关区域。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a8453f1a894f9e8d97f9130bdb1b465c.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图4    geohash访问象限的顺序&lt;/p&gt;
&lt;h3&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;希尔伯特曲线&lt;/span&gt;&lt;/h3&gt;
&lt;p align=&quot;left&quot;&gt;现在假设我们以U字形来访问区域。在每个象限中，我们同样以U字形来访问子象限，但是要调整好U字形的朝向使得和相邻的象限衔接起来。如果我们正确地组织了这些U字形的朝向，我们就能完全消除不连续性，不管我们选择了什么分辨率，都能连续地访问整个区域，可以在完全地探访了一个区域后才移动到下一个。这个方案不仅消除了不连续性，而且提高了总体的局域性。按照这个方案得到的图案看起来有些熟悉，没错，就是希尔伯特曲线。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Hilbert_curve&quot;&gt;希尔伯特曲线&lt;/a&gt;属于一类被称为&lt;a href=&quot;http://en.wikipedia.org/wiki/Space-filling_curve&quot;&gt;空间填充曲线&lt;/a&gt;的一维分形，因为它们虽然是一维的线，却可以填充固定区域的所有空间。它们相当有名，部分是由于&lt;a href=&quot;http://blag.xkcd.com/2006/12/11/the-map-of-the-internet/&quot;&gt;XKCD把它们用于互联网地图&lt;/a&gt;。如你所见，对于空间索引它们也是有用的，因为它们展现的正是我们需要的局域性和连续性。再看看之前用一组查询来覆盖圆的例子，我们发现（应用希尔伯特曲线）还可以减少一次查询：左下方的小区域现在和它右边的区域连起来了（减少一次），虽然底部的两块区域不再连续了（增加一次），右下角的区域现在却和它上方的连续了（减少一次）。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot; align=&quot;left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/4f8a19d0cae6c4f480deab72c6f3cf3c.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot; align=&quot;left&quot;&gt;图5    希尔伯特曲线访问象限的顺序&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;到目前为止，我们优雅的系统还缺一样东西：将(x,y)坐标转换为希尔伯特曲线上相应位置的方法。对于geohash，这是简单而明显的–只需将x, y坐标交错，但没有明显的方法修改这个方案使之对希尔伯特曲线也适用。在网上搜索，你很可能遇到很多关于希尔伯特曲线是怎样画出来的描述，但很少有关于找到任意点（在曲线上）位置的。为了搞定它，我们需要更仔细看看希尔伯特曲线是怎么递归构建的。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;首先要注意到虽然大多数关于希尔伯特曲线的文献都关注曲线是怎么画出来的，却容易让我们忽略曲线的本质属性以及其重要性：曲线规定了平面上点的顺序。如果我们用这顺序来表达希尔伯特曲线，画曲线就不值一提了：仅仅是把点连起来。忘记怎么把子曲线连起来吧，把注意力集中在怎么递归地列举点上。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot; align=&quot;left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/448eac58b45d967edfb3b7f13add636c.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot; align=&quot;left&quot;&gt;图6    希尔伯特曲线规定了二维平面上的点的顺序&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;在根这一层，列举点很简单：选定一个方向和一个起始点，环绕四个象限，用0到3给他们编号。当我们要确定访问子象限的顺序同时维护总体的邻接属性，困难就来了。通过检查我们发现，子象限的曲线是原曲线的简单变换，而且只有四种变换。自然地，这个结论也适用于子子象限，等等。对于一个给定的象限，我们在其中画出的曲线是由象限所在大的方形的曲线以及该象限的位置决定的。只需要费一点力，我们就能构建出如下概况所有情况的表。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot; align=&quot;left&quot;&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/fcce8a2c8572a9bf70d084de7b13e0cc.jpg&quot; width=&quot;668&quot; height=&quot;184&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图7&lt;/p&gt;
&lt;p&gt;假设我们想用这个表来确定某个点在第三层希尔伯特曲线上的位置。在这个例子中，假设点的坐标是(5,2)。&lt;span style=&quot;color: #808080;&quot;&gt;（译者注：请参照图8）&lt;/span&gt;从上图的第一个方形开始，找到你的点所在的象限。在这个例子中，是在右上方的象限。那么点在希尔伯特曲线上的位置的第一部分是3（二进制是11）。接着我们进入象限3里面的方块，在这个例子中，它是（图7中的）第二个方块。重复刚才的过程：我们的点落在哪个子象限？这次是左下角，意味着位置的下一部分是1（二进制01），我们将进入的小方块又是第二个。最后一次重复这个过程，发现点落在右上角的子子象限，因此位置的最后部分是3（二进制11）。把这些位置连接起来，我们得到点在曲线上的位置是二进制的110111，或者十进制的55。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://fanyi.jobbole.com/wp-content/uploads/sites/9/2014/10/hilbert_curve.png&quot; rel=&quot;lightbox[81106]&quot; title=&quot;超酷算法：用四叉树和希尔伯特曲线做空间索引&quot;&gt;&lt;img class=&quot;alignnone size-medium wp-image-1175&quot; alt=&quot;hilbert_curve&quot; src=&quot;/images/jobbole.com/65007f040e43a1e10906ab9ec0263dd8.jpg&quot; width=&quot;300&quot; height=&quot;297&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图8  三阶希尔伯特曲线&lt;/p&gt;
&lt;p&gt;让我们更系统一些，写出从x, y坐标到希尔伯特曲线位置转换的方法。首先，我们要以计算机看得懂的形式表达图7：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;hilbert_map = { 
&#39;a&#39;: {(0, 0): (0, &#39;d&#39;), (0, 1): (1, &#39;a&#39;), (1, 0): (3, &#39;b&#39;), (1, 1): (2, &#39;a&#39;)}, 
&#39;b&#39;: {(0, 0): (2, &#39;b&#39;), (0, 1): (1, &#39;b&#39;), (1, 0): (3, &#39;a&#39;), (1, 1): (0, &#39;c&#39;)}, 
&#39;c&#39;: {(0, 0): (2, &#39;c&#39;), (0, 1): (3, &#39;d&#39;), (1, 0): (1, &#39;c&#39;), (1, 1): (0, &#39;b&#39;)}, 
&#39;d&#39;: {(0, 0): (0, &#39;a&#39;), (0, 1): (3, &#39;c&#39;), (1, 0): (1, &#39;d&#39;), (1, 1): (2, &#39;d&#39;)}}&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;上面的代码中，每个hilbert_map的元素对应图7四个方形中的一个。为了容易区分，我用一个字母来标识每个方块：’a&#39;是第一个方块，’b&#39;是第二个，等等。每个方块的值是个字典，将(子)象限的x, y坐标映射到曲线上的位置（元组值的第一部分）以及下一个用到的方块（元组值的第二部分）。下面的代码展示了怎么用这个来将x, y坐标转换成希尔伯特曲线上的位置：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;def point_to_hilbert(x, y, order=16):
    current_square = &#39;a&#39;
    position = 0
    for i in range(order - 1, -1, -1):
        position &amp;lt;&amp;lt;= 2
        quad_x = 1 if x &amp;amp; (1 &amp;lt;&amp;lt; i) else 0
        quad_y = 1 if y &amp;amp; (1 &amp;lt;&amp;lt; i) else 0
        quad_position, current_square = hilbert_map[current_square][(quad_x, quad_y)]
        position |= quad_position
    return position&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;函数的输入是为整数的x, y坐标和曲线的阶。一阶曲线填充2×2的格子，二阶曲线填充4×4的格子，等等。我们的x, y坐标应该先标准化到0到2&lt;sup&gt;order&lt;/sup&gt;-1的区间。这个函数从最高位开始，逐步处理x, y坐标的每个比特位。在每个阶段中，通过测试对应的比特位，可以确定坐标处于哪个（子）象限，还可以从我们之前定义的hilbert_map中取得在曲线上的位置以及下一个要用的方块。在这阶段取得的位置，加入到目前总的位置的最低两位。在下一次循环的开头，总的位置左移两位以便给下一个位置腾出地方。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;让我们运行一下之前的例子来检验一下函数写对了没有：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;&amp;gt;&amp;gt;&amp;gt; point_to_hilbert(5,2,3)
55&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;对了！为了进一步测试，我们可以用这个函数生成一条希尔伯特曲线的有序点的完整列表，然后用电子制表软件把它们画出来看我们是否真的得到了一条希尔伯特曲线。在Python交互解释器中输入如下代码：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;&amp;gt;&amp;gt;&amp;gt; points = [(x, y) for x in range(8) for y in range(8)]
&amp;gt;&amp;gt;&amp;gt; sorted_points = sorted(points, key=lambda k: point_to_hilbert(k[0], k[1], 3))
&amp;gt;&amp;gt;&amp;gt; print &#39;n&#39;.join(&#39;%s,%s&#39; % x for x in sorted_points)&lt;/pre&gt;
&lt;p&gt;将输出的文本粘贴到文件中，保存为hilbert.csv，用你最喜欢的电子制表软件打开，将数据画成一个散点图。结果当然是一条漂亮的希尔伯特曲线！&lt;/p&gt;
&lt;p&gt;将hilbert_map做简单的反转就能实现point_to_hilbert的逆向功能（将希尔伯特曲线上的位置转换为x, y坐标），把这个留给读者作为练习吧。&lt;/p&gt;
&lt;h2&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;结论&lt;/span&gt;&lt;/h2&gt;
&lt;p align=&quot;left&quot;&gt;空间索引，从四叉树到geohash到希尔伯特曲线，到这就结束了。最后一点说明：如果你将一条希尔伯特曲线上的x, y坐标的有序序列写成二进制形式，对于顺序你注意到什么有趣的东西吗？你想到了什么？&lt;/p&gt;
&lt;p&gt;结束前的一点警告：我在这里描述的全部索引方法都只适用于索引点。如果你想索引线、折线或者多边形，这些方法可能就不管用了。据我所知，已知的唯一能有效索引形体的算法是&lt;a href=&quot;http://en.wikipedia.org/wiki/R-tree&quot;&gt;R-tree&lt;/a&gt;，这是一种完全不同且更复杂的方法。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Thu, 18 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-18-81106-2aba1c5c3.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-18-81106-2aba1c5c3.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>图文说明：Linux监控命令全覆盖</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;h2&gt;1.1 top&lt;/h2&gt;
&lt;h4&gt;1.1.1 命令说明&lt;/h4&gt;
&lt;p&gt;Top 命令能够实时监控系统的运行状态，并且可以按照cpu、内存和执行时间进行排序&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.1.2 参数说明&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;命令行启动参数：&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;用法: top -hv | -bcisSHM -d delay -n iterations [-u user | -U user] -p pid [,pid ...]&lt;/li&gt;
&lt;li&gt;-b : 批次模式运行。通常用作来将top的输出的结果传送给其他程式或储存成文件&lt;/li&gt;
&lt;li&gt;-c : 显示执行任务的命令行&lt;/li&gt;
&lt;li&gt;-d : 设定延迟时间&lt;/li&gt;
&lt;li&gt;-h : 帮助&lt;/li&gt;
&lt;li&gt;-H : 显示线程。当这个设定开启时，将显示所有进程产生的线程&lt;/li&gt;
&lt;li&gt;-i : 显示空闲的进程&lt;/li&gt;
&lt;li&gt;-n : 执行次数。一般与-b搭配使用&lt;/li&gt;
&lt;li&gt;-u : 监控指定用户相关进程&lt;/li&gt;
&lt;li&gt;-U : 监控指定用户相关进程&lt;/li&gt;
&lt;li&gt;-p : 监控指定的进程。当监控多个进程时，进程ID以逗号分隔。这个选项只能在命令行下使用&lt;/li&gt;
&lt;li&gt;-s : 安全模式操作&lt;/li&gt;
&lt;li&gt;-S : 累计时间模式&lt;/li&gt;
&lt;li&gt;-v : 显示top版本，然后退出。&lt;/li&gt;
&lt;li&gt;-M : 自动显示内存单位（k/M/G）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt;&lt;strong&gt;全局命令&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;回车、空格 : 刷新显示信息&lt;/li&gt;
&lt;li&gt;?、h : 帮助&lt;/li&gt;
&lt;li&gt;= : 移除所有任务显示的限制&lt;/li&gt;
&lt;li&gt;A : 交替显示模式切换&lt;/li&gt;
&lt;li&gt;B : 粗体显示切换&lt;/li&gt;
&lt;li&gt;d、s : 更改界面刷新时间间隔&lt;/li&gt;
&lt;li&gt;G : 选择其它窗口/栏位组&lt;/li&gt;
&lt;li&gt;I : Irix或Solaris模式切换&lt;/li&gt;
&lt;li&gt;u、U : 监控指定用户相关进程&lt;/li&gt;
&lt;li&gt;k : 结束进程&lt;/li&gt;
&lt;li&gt;q : 退出top&lt;/li&gt;
&lt;li&gt;r : 重新设定进程的nice值&lt;/li&gt;
&lt;li&gt;W : 存储当前设定&lt;/li&gt;
&lt;li&gt;Z : 改变颜色模板&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt;&lt;strong&gt;摘要区命令&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;l : 平均负载及系统运行时间显示开关&lt;/li&gt;
&lt;li&gt;m : 内存及交换空间使用率显示开关&lt;/li&gt;
&lt;li&gt;t : 当前任务及CPU状态显示开关&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1 : 汇总显示CPU状态或分开显示每个CPU状态&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt;&lt;strong&gt;任务区命令&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;外观样式&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;b : 黑体/反色显示高亮的行/列。控制x和y交互命令的显示样式&lt;/li&gt;
&lt;li&gt;x : 高亮显示排序的列&lt;/li&gt;
&lt;li&gt;y : 高亮显示正在运行的任务&lt;/li&gt;
&lt;li&gt;z : 彩色/黑白显示。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;显示内容&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;c : 任务执行的命令行或进程名称&lt;/li&gt;
&lt;li&gt;f、o : 增加和移除进程信息栏位及调整进程信息栏位显示顺序&lt;/li&gt;
&lt;li&gt;H : 显示线程&lt;/li&gt;
&lt;li&gt;S : 时间累计模式&lt;/li&gt;
&lt;li&gt;u : 监控指定用户相关进程&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;任务显示的数量&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;i : 显示空闲的进程&lt;/li&gt;
&lt;li&gt;n或# : 设置任务显示最大数量&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;任务排序（shift+f&lt;/strong&gt;&lt;strong&gt;）&lt;/strong&gt;
&lt;/li&gt;
&lt;li&gt;M : 按内存使用率排序&lt;/li&gt;
&lt;li&gt;N : 按PID排序&lt;/li&gt;
&lt;li&gt;P : 按CPU使用率排序&lt;/li&gt;
&lt;li&gt;T : 按Time+排序&lt;/li&gt;
&lt;li&gt;&amp;lt; : 按当前排序栏位左边相邻栏位排序&lt;/li&gt;
&lt;li&gt;&amp;gt; : 按当前排序栏位右边相邻栏位排序&lt;/li&gt;
&lt;li&gt;F 或 O : 选择排序栏位&lt;/li&gt;
&lt;li&gt;R : 反向排序&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.1.3  结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fc9a0b3650de3198a8de2b9b1d58d8cd.jpg&quot;&gt;&lt;/p&gt;
&lt;h3&gt;1.2 free&lt;/h3&gt;
&lt;h4&gt;1.2.1  命令说明&lt;/h4&gt;
&lt;p&gt;Free命令是监控系统内存最常用的命令&lt;/p&gt;
&lt;h4&gt;1.2.2.参数说明&lt;/h4&gt;
&lt;p&gt;-m：以M为单位查看内存使用情况（默认为kb）&lt;/p&gt;
&lt;p&gt;-b：以字节为单位查看内存使用情况&lt;/p&gt;
&lt;p&gt;-s：可以在指定时间段内不简单监控内存的使用情况&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.2.3 结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/89fedab6983ba6fac4f3213a706fc780.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;total：总计物理内存的大小。&lt;/li&gt;
&lt;li&gt;Used：已使用多大。&lt;/li&gt;
&lt;li&gt;Free：可用有多少。&lt;/li&gt;
&lt;li&gt;shared：多个进程共享的内存总额。&lt;/li&gt;
&lt;li&gt;buffers/cached:磁盘缓存的大小。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.3 vmstat&lt;/h3&gt;
&lt;h4&gt;1.1.1命令说明&lt;/h4&gt;
&lt;p&gt;可以监控操作系统的进程状态、内存、虚拟内存、磁盘IO、上下文、CPU的信息。&lt;/p&gt;
&lt;h4&gt;1.1.2参数说明&lt;/h4&gt;
&lt;p&gt;vmstat [-a] [-n] [-S unit] [delay [ count]]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-a：显示活跃和非活跃内存&lt;/li&gt;
&lt;li&gt;-m：显示slabinfo&lt;/li&gt;
&lt;li&gt;-n：只在开始时显示一次各字段名称。&lt;/li&gt;
&lt;li&gt;-s：显示内存相关统计信息及多种系统活动数量。&lt;/li&gt;
&lt;li&gt;delay：刷新时间间隔。如果不指定，只显示一条结果。&lt;/li&gt;
&lt;li&gt;count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。&lt;/li&gt;
&lt;li&gt;-d：显示各个磁盘相关统计信息。&lt;/li&gt;
&lt;li&gt;-S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes）&lt;/li&gt;
&lt;li&gt;-V：显示vmstat版本信息。&lt;/li&gt;
&lt;li&gt;-p：显示指定磁盘分区统计信息&lt;/li&gt;
&lt;li&gt;-D：显示磁盘总体信息&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;1.1.3 结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a34977b8ecda13cdccf7d2692d391219.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Procs&lt;/li&gt;
&lt;li&gt;R:等待被执行的进程数，即表示运行和等待CPU时间片的进程数&lt;/li&gt;
&lt;li&gt;B:排队的进程数，即等待资源的进程数&lt;/li&gt;
&lt;li&gt;Memory&lt;/li&gt;
&lt;li&gt;Swap : 虚拟内存，切换到虚拟内存的内存大小&lt;/li&gt;
&lt;li&gt;Free: 空闲的物理内存大小&lt;/li&gt;
&lt;li&gt;Buff: 缓冲区大小&lt;/li&gt;
&lt;li&gt;Cache: 缓存大小&lt;/li&gt;
&lt;li&gt;Swap&lt;/li&gt;
&lt;li&gt;Si:磁盘写入虚拟内存，即由内存进入到虚拟内存的大小。&lt;/li&gt;
&lt;li&gt;So:虚拟内存写入磁盘，即由虚拟内存进入到磁盘的大小。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Io&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bi:由块设备读入的数据总量，读磁盘&lt;/li&gt;
&lt;li&gt;Bo:由块设备写入的数据总量，写磁盘&lt;/li&gt;
&lt;li&gt;System&lt;/li&gt;
&lt;li&gt;In: 每秒设备中断数&lt;/li&gt;
&lt;li&gt;Cs:每秒上下文切换的次数&lt;/li&gt;
&lt;li&gt;Cpu&lt;/li&gt;
&lt;li&gt;Us:用户进程消耗cpu百分比&lt;/li&gt;
&lt;li&gt;Sy:内核进程消耗cpu百分比&lt;/li&gt;
&lt;li&gt;Id:cpu处于空闲状态的时间百分比&lt;/li&gt;
&lt;li&gt;Wa：Io等待cpu所占时间的百分比&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.4 iostat&lt;/h3&gt;
&lt;h4&gt;1.4.1命令说明&lt;/h4&gt;
&lt;p&gt;Iostat是对系统磁盘IO操作进行监控，它的输出主要显示磁盘的读写操作的统计信息。同时给出cpu的使用情况&lt;/p&gt;
&lt;h4&gt;1.4.2参数说明&lt;/h4&gt;
&lt;p&gt;iostat [ -c | -d ] [ -k | -m ] [ -t ] [ -V ] [ -x ] [ device [ ... ] | ALL ] [ -p [ device | ALL ] ] [ interval [ count ] ]&lt;br&gt;
各选项以及参数含义如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-c： 仅显示CPU统计信息.与-d选项互斥.&lt;/li&gt;
&lt;li&gt;-d ：仅显示磁盘统计信息.与-c选项互斥.&lt;/li&gt;
&lt;li&gt;-k ：以K为单位显示每秒的磁盘请求数,默认单位块.&lt;/li&gt;
&lt;li&gt;-p ：device | ALL&lt;br&gt;
与-x选项互斥,用于显示块设备及系统分区的统计信息.也可以在-p后指定一个设备名,如:&lt;br&gt;
# iostat -p had&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;或显示所有设备&lt;br&gt;
# iostat -p ALL&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-t ：在输出数据时,打印搜集数据的时间.&lt;/li&gt;
&lt;li&gt;-V ：打印版本号和帮助信息.&lt;/li&gt;
&lt;li&gt;-x  device  输出指定要统计的磁盘设备名称，默认为所有磁盘设备.&lt;/li&gt;
&lt;li&gt;- interval ：指两次统计间隔时间&lt;/li&gt;
&lt;li&gt;-  count ：按照interval 指定的时间间隔统计的次数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.4.3结果说明&lt;/h4&gt;
&lt;p&gt;Iostat的简单应用&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f577cded44dfba51f23a0ad91cb5e7c8.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;Iostat磁盘监控&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/74b290084e02eb3ca810612b5900d24e.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rrqm/s：每秒进行 merge 的读操作数目，即 delta(rmerge)/s 。&lt;/li&gt;
&lt;li&gt;wrqm/s：每秒进行 merge 的写操作数目，即 delta(wmerge)/s 。&lt;/li&gt;
&lt;li&gt;r/s：每秒完成的读 I/O 设备次数，即 delta(rio)/s 。&lt;/li&gt;
&lt;li&gt;w/s： 每秒完成的写 I/O 设备次数，即 delta(wio)/s 。&lt;/li&gt;
&lt;li&gt;rsec/s：每秒读扇区数，即 delta(rsect)/s。&lt;/li&gt;
&lt;li&gt;wsec/s：每秒写扇区数，即 delta(wsect)/s&lt;/li&gt;
&lt;li&gt;rkB/s：每秒读K字节数，是 rsect/s 的一半，因为每扇区大小为512字节。&lt;/li&gt;
&lt;li&gt;wkB/s：每秒写K字节数，是 wsect/s 的一半&lt;/li&gt;
&lt;li&gt;avgrq-sz：平均每次设备I/O操作的数据大小 (扇区)，即                                                               delta(rsect+wsect)/delta(rio+wio) 。&lt;/li&gt;
&lt;li&gt;avgqu-sz：平均I/O队列长度，即 delta(aveq)/s/1000 (因为aveq的单位为毫秒)。&lt;/li&gt;
&lt;li&gt;Await：平均每次设备I/O操作的等待时间 (毫秒)，即  delta(ruse+wuse)/delta(rio+wio) 。&lt;/li&gt;
&lt;li&gt;Svctm：平均每次设备I/O操作的服务时间 (毫秒)，即 delta(use)/delta(rio+wio) 。&lt;/li&gt;
&lt;li&gt;%util：一秒中有百分之多少的时间用于 I/O 操作，或者说一秒中有多少时间 I/O 队列是非空的，&lt;br&gt;
即 delta(use)/s/1000 (因为use的单位为毫秒) 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Iostat   cpu 监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/065ea149d47af73faf4a211a65ca6e5f.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;%usr：用户进程消耗的CPU时间百分比。&lt;/li&gt;
&lt;li&gt;%nice:  运行正常进程消耗的CPU时间百分比。&lt;/li&gt;
&lt;li&gt;%system：系统进程消耗的CPU时间百分比。&lt;/li&gt;
&lt;li&gt;%iowait：I/O等待所占CPU时间百分比。&lt;/li&gt;
&lt;li&gt;%steal：在内存紧张环境下，pagein强制对不同的页面进行的steal操作。&lt;/li&gt;
&lt;li&gt;%idle：CPU空闲状态的时间百分比。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.5 mpstat&lt;/h3&gt;
&lt;h4&gt;1.5.1命令说明&lt;/h4&gt;
&lt;p&gt;Mpstat可以监控到cpu的一些统计信息，在多核cpu的系统里不但能够查看所有cpu的平均状况信息，而且能够查看特定的cpu的信息&lt;/p&gt;
&lt;h4&gt;1.5.2参数说明&lt;/h4&gt;
&lt;p&gt;mpstat [-P {|ALL}] [internal [count]]&lt;/p&gt;
&lt;p&gt;参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（1）-P {|ALL}：表示监控哪个CPU，在[0,cpu个数-1]中取值；&lt;/li&gt;
&lt;li&gt;（2）internal：相邻的两次采样的间隔时间；&lt;/li&gt;
&lt;li&gt;（3）count：采样的次数，count只能和delay一起使用；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;备注：当没有参数时，mpstat则显示系统启动以后所有信息的平均值。有interval时，第一行的信息自系统启动以来的平均信息。从第二行开始，输出为前一个interval时间段的平均信息。&lt;/p&gt;
&lt;h4&gt;1.5.3结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/25ea44eadc7f3c535b3a5d21d5637049.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; （1）user：在internal时间段里，用户态的CPU时间（%），不包含nice值为负进程，值为 (usr/total)*100；&lt;/li&gt;
&lt;li&gt;（2）nice：在internal时间段里，nice值为负进程的CPU时间（%），值为(nice/total)*100；&lt;/li&gt;
&lt;li&gt;（3）system：在internal时间段里，核心时间（%），值为(system/total)*100；&lt;/li&gt;
&lt;li&gt;（4）iowait：在internal时间段里，硬盘IO等待时间（%），值为(iowait/total)*100；&lt;/li&gt;
&lt;li&gt;（5）irq：在internal时间段里，硬中断时间（%），值为(irq/total)*100；&lt;/li&gt;
&lt;li&gt;（6）soft：在internal时间段里，软中断时间（%），值为(softirq/total)*100；&lt;/li&gt;
&lt;li&gt;（7）idle：在internal时间段里，CPU除去等待磁盘IO操作外的因为任何原因而空闲的时间闲置时间（%），值为(idle/total)*100；&lt;/li&gt;
&lt;li&gt;（8）intr/s：在internal时间段里，每秒CPU接收的中断的次数，值为(intr/total)*100；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.6 sar&lt;/h3&gt;
&lt;h4&gt;1.6.1命令说明&lt;/h4&gt;
&lt;p&gt;Sar命令可以全名的获取到cpu 、运行、磁盘IO、虚拟内存、内存、网络等信息。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.6.2参数说明&lt;/h4&gt;
&lt;p&gt;sar 命令行的常用格式：&lt;br&gt;
sar [options] [-A] [-o file] t [n]&lt;br&gt;
在命令行中，n 和t 两个参数组合起来定义采样间隔和次数，t为采样间隔，是必须有的参数，n为采样次数，是可选的，默认值是1，-o file表示将命令结果以二进制格式存放在文件中，file 在此处不是关键字，是文件名。options 为命令行选项，sar命令的选项很多，下面只列出常用选项：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-A：所有报告的总和。&lt;/li&gt;
&lt;li&gt;-u：CPU利用率&lt;/li&gt;
&lt;li&gt;-v：进程、节点、文件和锁表状态。&lt;/li&gt;
&lt;li&gt;-p：像是当前系统中指定CPU使用信息。&lt;/li&gt;
&lt;li&gt;-d：硬盘使用报告。&lt;/li&gt;
&lt;li&gt;-r：显示系统内存的使用情况。&lt;/li&gt;
&lt;li&gt;-n：显示网络运行状态。参数后面可跟DEV、EDEV、SOCK和FULL。DEV显示网络接口信息，EDEV显示网络错误的统计数据，SOCK显示套接字信息，FULL显示前三参数所有信息。&lt;/li&gt;
&lt;li&gt;-q：显示运行队列的大小，它与系统当时的平均负载相同&lt;/li&gt;
&lt;li&gt;-B：内存分页情况&lt;/li&gt;
&lt;li&gt;-R：显示进程在采样时间内的活动情况。&lt;/li&gt;
&lt;li&gt;-g：串口I/O的情况。&lt;/li&gt;
&lt;li&gt;-b：缓冲区使用情况。&lt;/li&gt;
&lt;li&gt;-a：文件读写情况。&lt;/li&gt;
&lt;li&gt;-c：系统调用情况。&lt;/li&gt;
&lt;li&gt;-R：进程的活动情况。&lt;/li&gt;
&lt;li&gt;-y：终端设备活动情况。&lt;/li&gt;
&lt;li&gt;-W：系统交换活动。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.6.3结果说明&lt;/h4&gt;
&lt;p&gt;Cpu资源监控&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9b59f930a06ed273e49e799fb6144cde.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;CPU：all 表示统计信息为所有 CPU 的平均值。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;%user：显示在用户级别(application)运行使用 CPU 总时间的百分比。&lt;/li&gt;
&lt;li&gt;%nice：显示在用户级别，用于nice操作，所占用 CPU 总时间的百分比。&lt;/li&gt;
&lt;li&gt;%system：在核心级别(kernel)运行所使用 CPU 总时间的百分比。&lt;/li&gt;
&lt;li&gt;%iowait：显示用于等待I/O操作占用 CPU 总时间的百分比。&lt;/li&gt;
&lt;li&gt;%steal：管理程序(hypervisor)为另一个虚拟进程提供服务而等待虚拟 CPU 的百分比。&lt;/li&gt;
&lt;li&gt;%idle：显示 CPU 空闲时间占用 CPU 总时间的百分比。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1. 若 %iowait 的值过高，表示硬盘存在I/O瓶颈&lt;/p&gt;
&lt;p&gt;2. 若 %idle 的值高但系统响应慢时，有可能是 CPU 等待分配内存，此时应加大内存容量&lt;/p&gt;
&lt;p&gt;1. 若 %idle 的值持续低于1，则系统的 CPU 处理能力相对较低，表明系统中最需要解决的资源是 CPU 。&lt;/p&gt;
&lt;p&gt;如果要查看二进制文件test中的内容，需键入如下sar命令：&lt;/p&gt;
&lt;p&gt;sar -u -f test&lt;/p&gt;
&lt;p&gt;Inode、文件和其他内核表监控&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/7618312dd4e19c83dbcbfdbc335dc1ba.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; Dentunued: 目录告诉缓存中未被使用的条目数量&lt;/li&gt;
&lt;li&gt;File-nr: 文件句柄的使用数量&lt;/li&gt;
&lt;li&gt;Inode-nr: 索引节点句柄的使用数量&lt;/li&gt;
&lt;li&gt;Pty-nr :使用的pty的数量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;内存和交换空间监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c8242104dbe01003ae60d7b06e662948.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kbmemfree：这个值和free命令中的free值基本一致,所以它不包括buffer和cache的空间.&lt;/li&gt;
&lt;li&gt;kbmemused：这个值和free命令中的used值基本一致,所以它包括buffer和cache的空间.&lt;/li&gt;
&lt;li&gt;%memused：这个值是kbmemused和内存总量(不包括swap)的一个百分比.&lt;/li&gt;
&lt;li&gt;kbbuffers和kbcached：这两个值就是free命令中的buffer和cache.&lt;/li&gt;
&lt;li&gt;kbcommit：保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap).&lt;/li&gt;
&lt;li&gt;%commit：这个值是kbcommit与内存总量(包括swap)的一个百分比.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt; 内存分页监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/eeec89d54067a726da3f2aea5e2212fe.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pgpgin/s：表示每秒从磁盘或SWAP置换到内存的字节数(KB)&lt;/li&gt;
&lt;li&gt;pgpgout/s：表示每秒从内存置换到磁盘或SWAP的字节数(KB)&lt;/li&gt;
&lt;li&gt;fault/s：每秒钟系统产生的缺页数,即主缺页与次缺页之和(major + minor)&lt;/li&gt;
&lt;li&gt;majflt/s：每秒钟产生的主缺页数.&lt;/li&gt;
&lt;li&gt;pgfree/s：每秒被放入空闲队列中的页个数&lt;/li&gt;
&lt;li&gt;pgscank/s：每秒被kswapd扫描的页个数&lt;/li&gt;
&lt;li&gt;pgscand/s：每秒直接被扫描的页个数&lt;/li&gt;
&lt;li&gt;pgsteal/s：每秒钟从cache中被清除来满足内存需要的页个数&lt;/li&gt;
&lt;li&gt;%vmeff：每秒清除的页(pgsteal)占总扫描页(pgscank+pgscand)的百分比&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt; IO和传送速率监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6d976da42d91d87beb830afc2106db84.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; tps：每秒钟物理设备的 I/O 传输总量&lt;/li&gt;
&lt;li&gt;rtps：每秒钟从物理设备读入的数据总量&lt;/li&gt;
&lt;li&gt;wtps：每秒钟向物理设备写入的数据总量&lt;/li&gt;
&lt;li&gt;bread/s：每秒钟从物理设备读入的数据量，单位为 块/s&lt;/li&gt;
&lt;li&gt;bwrtn/s：每秒钟向物理设备写入的数据量，单位为 块/s&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;进程队列长度和平均负载状态监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/322e27cc538370dfc4e973ef13b1df2a.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;runq-sz：运行队列的长度（等待运行的进程数）&lt;/li&gt;
&lt;li&gt;plist-sz：进程列表中进程（processes）和线程（threads）的数量&lt;/li&gt;
&lt;li&gt;ldavg-1：最后1分钟的系统平均负载（System load average）&lt;/li&gt;
&lt;li&gt;ldavg-5：过去5分钟的系统平均负载&lt;/li&gt;
&lt;li&gt;ldavg-15：过去15分钟的系统平均负载&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;系统交换活动信息监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/11e32ec5dd63016c5728d4d0989009d7.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; pswpin/s：每秒系统换入的交换页面（swap page）数量&lt;/li&gt;
&lt;li&gt;pswpout/s：每秒系统换出的交换页面（swap page）数量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;设备使用情况监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ea9a684b6d475681c1093d973458e10d.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;参数-p可以打印出sda,hdc等磁盘设备名称,如果不用参数-p,设备节点则有可能是dev8-0,dev22-0&lt;/li&gt;
&lt;li&gt; tps:每秒从物理磁盘I/O的次数.多个逻辑请求会被合并为一个I/O磁盘请求,一次传输的大小是不确定的.&lt;/li&gt;
&lt;li&gt;rd_sec/s:每秒读扇区的次数.&lt;/li&gt;
&lt;li&gt;wr_sec/s:每秒写扇区的次数.&lt;/li&gt;
&lt;li&gt;avgrq-sz:平均每次设备I/O操作的数据大小(扇区).&lt;/li&gt;
&lt;li&gt;avgqu-sz:磁盘请求队列的平均长度.&lt;/li&gt;
&lt;li&gt;await:从请求磁盘操作到系统完成处理,每次请求的平均消耗时间,包括请求队列等待时间,单位是毫秒(1秒=1000毫秒).&lt;/li&gt;
&lt;li&gt;svctm:系统处理每次请求的平均时间,不包括在请求队列中消耗的时间.&lt;/li&gt;
&lt;li&gt;%util:I/O请求占CPU的百分比,比率越大,说明越饱和.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1. avgqu-sz 的值较低时，设备的利用率较高。&lt;/p&gt;
&lt;p&gt;2. 当%util的值接近 1% 时，表示设备带宽已经占满。&lt;/p&gt;
&lt;h3&gt;1.7 netstat&lt;/h3&gt;
&lt;h4&gt;1.7.1命令说明&lt;/h4&gt;
&lt;p&gt;Netstat 命令用于显示本机网络链接、运行端口、路由表等信息&lt;/p&gt;
&lt;h4&gt;1.7.2参数说明&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;netstat [&lt;/strong&gt;&lt;strong&gt;选项]&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-a (all)：显示一个所有的有效连接信息列表，包括已建立的连接（ESTABLISHED），也包括监听连接请求（LISTENING）的那些连接，断开连接（CLOSE_WAIT）或者处于联机等待状态的（TIME_WAIT）等&lt;/li&gt;
&lt;li&gt;-t (tcp)：显示tcp相关选项&lt;/li&gt;
&lt;li&gt;-u (udp)：仅显示udp相关选项&lt;/li&gt;
&lt;li&gt;-n ：拒绝显示别名，能显示数字的全部转化成数字。&lt;/li&gt;
&lt;li&gt;-l ：仅列出有在 Listen (监听) 的服务状态&lt;/li&gt;
&lt;li&gt;-p ：显示建立相关链接的程序名&lt;/li&gt;
&lt;li&gt;-r ：显示路由信息，路由表，除了显示有效路由外，还显示当前有效的连接&lt;/li&gt;
&lt;li&gt;-e ：显示扩展信息，例如uid等&lt;/li&gt;
&lt;li&gt;-s ：按各个协议进行统计&lt;/li&gt;
&lt;li&gt;-c ：每隔一个固定时间，执行该netstat命令。&lt;/li&gt;
&lt;li&gt;-v ：显示当前的有效连接，与-n选项类似&lt;/li&gt;
&lt;li&gt;-I ：显示自动匹配接口的信息&lt;/li&gt;
&lt;li&gt;-e ：显示关于以太网的统计数据。它列出的项目包括传送的数据报的总字节数、错误数、删除数、数据报的数量和广播的数量。这些统计数据既有发送的数据报数量，也有接收的数据报数量。这个选项可以用来统计一些基本的网络流量。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.7.3结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6addb3a87100d1ff1b6d8de377906e19.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Iface：表示网络设备的接口名称。&lt;/li&gt;
&lt;li&gt;MTU：表示最大传输单元，单位为字节。&lt;/li&gt;
&lt;li&gt;RX-OK/TX-OK：表示已经准确无误地接收/发送了多少数据包。&lt;/li&gt;
&lt;li&gt;RX-ERR/TX-ERR：表示接收/发送数据包时候产生了多少错误。&lt;/li&gt;
&lt;li&gt;RX-DRP/TX-DRP：表示接收/发送数据包时候丢弃了多少数据包。&lt;/li&gt;
&lt;li&gt;RX-OVR/TX-OVR：表示由于误差而丢失了多少数据包。&lt;/li&gt;
&lt;li&gt;Flg表示接口标记，其中&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;B 已经设置了一个广播地址。&lt;/p&gt;
&lt;p&gt;L 该接口是一个回送设备。&lt;/p&gt;
&lt;p&gt;M 接收所有数据包（混乱模式）。&lt;/p&gt;
&lt;p&gt;N 避免跟踪。&lt;/p&gt;
&lt;p&gt;O 在该接口上，禁用A R P。&lt;/p&gt;
&lt;p&gt;P 这是一个点到点链接。&lt;/p&gt;
&lt;p&gt;R 接口正在运行。&lt;/p&gt;
&lt;p&gt;U 接口处于“活动”状态。&lt;/p&gt;
&lt;p&gt;其中RX-ERR/TX-ERR、 RX-DRP/TX-DRP和RX-OVR/TX-OVR的值应该都为0，如果不为0，并且很大，那么网络质量肯定有问题，网络传输性能也一代会下降。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/eec8735e6b628b9770e5bb6d708f6924.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Recv-Q：表示接收队列。&lt;/li&gt;
&lt;li&gt;Send-Q ：表示发送队列。&lt;/li&gt;
&lt;li&gt;Local Address ：表示本地机器名、端口&lt;/li&gt;
&lt;li&gt;Foreign Address ：表示远程机器名、端口&lt;/li&gt;
&lt;li&gt;State：表示状态，其中&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;LISTEN ：在监听状态中。&lt;br&gt;
ESTABLISHED：已建立联机的联机情况。&lt;br&gt;
TIME_WAIT：该联机在目前已经是等待的状态。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.8 uptime&lt;/h3&gt;
&lt;h4&gt;1.8.1 命令说明&lt;/h4&gt;
&lt;p&gt;Uptime主要是用来统计系统当前的运行状态&lt;/p&gt;
&lt;h4&gt;1.8.2参数说明&lt;/h4&gt;
&lt;p&gt;-V  显示版本&lt;/p&gt;
&lt;h4&gt;1.8.3 结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1cd52079b5fc329ab5af65b9634b4927.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输出信息依次是：系统现在的时间，系统从上次开机到现在运行了多长时间，系统当前有多少个登录用户，系统在一分钟内、5分钟内、15分钟内的平均负载&lt;/li&gt;
&lt;li&gt;注意点：如果load average值长期大于系统CPU的个数则说明CPU很繁忙，负载很高，可能会影响系统性能&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.9 ps&lt;/h3&gt;
&lt;h4&gt;1.9.1命令说明&lt;/h4&gt;
&lt;p&gt;Ps命令是进程查看命令，使用这个命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等。&lt;/p&gt;
&lt;h4&gt;1.9.2参数说明&lt;/h4&gt;
&lt;p&gt;常用参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-A 显示所有进程（等价于-e）(utility)&lt;/li&gt;
&lt;li&gt;-a 显示一个终端的所有进程，除了会话引线&lt;/li&gt;
&lt;li&gt;-N 忽略选择。&lt;/li&gt;
&lt;li&gt;-d 显示所有进程，但省略所有的会话引线(utility)&lt;/li&gt;
&lt;li&gt;-x 显示没有控制终端的进程，同时显示各个命令的具体路径。dx不可合用。（utility）&lt;/li&gt;
&lt;li&gt;-p pid 进程使用cpu的时间&lt;/li&gt;
&lt;li&gt;-u uid or username 选择有效的用户id或者是用户名&lt;/li&gt;
&lt;li&gt;-g gid or groupname 显示组的所有进程。&lt;/li&gt;
&lt;li&gt;U username 显示该用户下的所有进程，且显示各个命令的详细路径。如:ps U zhang;(utility)&lt;/li&gt;
&lt;li&gt;-f 全部列出，通常和其他选项联用。如：ps -fa or ps -fx and so on.&lt;/li&gt;
&lt;li&gt;-l 长格式（有F,wchan,C 等字段）&lt;/li&gt;
&lt;li&gt;-j 作业格式&lt;/li&gt;
&lt;li&gt;-o 用户自定义格式。&lt;/li&gt;
&lt;li&gt;v 以虚拟存储器格式显示&lt;/li&gt;
&lt;li&gt;s 以信号格式显示&lt;/li&gt;
&lt;li&gt;-m 显示所有的线程&lt;/li&gt;
&lt;li&gt;-H 显示进程的层次(和其它的命令合用，如：ps -Ha)（utility）&lt;/li&gt;
&lt;li&gt;e 命令之后显示环境（如：ps -d e; ps -a e）(utility)&lt;/li&gt;
&lt;li&gt;h 不显示第一行&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常用用法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ps a： 显示现行终端机下的所有程序，包括其他用户的程序。&lt;/li&gt;
&lt;li&gt;ps -A ：显示所有程序。&lt;/li&gt;
&lt;li&gt;ps c ：列出程序时，显示每个程序真正的指令名称，而不包含路径，参数或常驻服务的标示。&lt;/li&gt;
&lt;li&gt;ps -e ：此参数的效果和指定”A”参数相同。&lt;/li&gt;
&lt;li&gt;ps e ：列出程序时，显示每个程序所使用的环境变量。&lt;/li&gt;
&lt;li&gt;ps f ：用ASCII字符显示树状结构，表达程序间的相互关系。&lt;/li&gt;
&lt;li&gt;ps -H：显示树状结构，表示程序间的相互关系。&lt;/li&gt;
&lt;li&gt;ps –N：显示所有的程序，除了执行ps指令终端机下的程序之外。&lt;/li&gt;
&lt;li&gt;ps s：采用程序信号的格式显示程序状况。&lt;/li&gt;
&lt;li&gt;ps S ：列出程序时，包括已中断的子程序资料。&lt;/li&gt;
&lt;li&gt;ps -t&amp;lt;终端机编号&amp;gt; ：指定终端机编号，并列出属于该终端机的程序的状况。&lt;/li&gt;
&lt;li&gt;ps u：以用户为主的格式来显示程序状况。&lt;/li&gt;
&lt;li&gt;ps x：显示所有程序，不以终端机来区分。&lt;/li&gt;
&lt;li&gt;Ps -l：较长较详细的显示该pid信息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最常用的方法是ps -aux,然后再利用一个管道符号导向到grep去查找特定的进程,然后再对特定的进程进行操作。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.9.3结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d09d684a1f22ecbd69d32c1af7c45bee.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;USER    用户名&lt;/li&gt;
&lt;li&gt;UID    用户ID（User ID）&lt;/li&gt;
&lt;li&gt;PID    进程ID（Process ID）&lt;/li&gt;
&lt;li&gt;PPID    父进程的进程ID（Parent Process id）&lt;/li&gt;
&lt;li&gt;SID    会话ID（Session id）&lt;/li&gt;
&lt;li&gt;%CPU    进程的cpu占用率&lt;/li&gt;
&lt;li&gt;%MEM    进程的内存占用率&lt;/li&gt;
&lt;li&gt;VSZ    进程所使用的虚存的大小（Virtual Size）&lt;/li&gt;
&lt;li&gt;RSS    进程使用的驻留集大小或者是实际内存的大小，Kbytes字节。&lt;/li&gt;
&lt;li&gt;TTY    与进程关联的终端（tty）&lt;/li&gt;
&lt;li&gt;STAT    进程的状态：进程状态使用字符表示的（STAT的状态码）
&lt;ul&gt;
&lt;li&gt;R 运行    Runnable (on run queue)            正在运行或在运行队列中等待。&lt;/li&gt;
&lt;li&gt;S 睡眠    Sleeping                休眠中, 受阻, 在等待某个条件的形成或接受到信号。&lt;/li&gt;
&lt;li&gt;I 空闲    Idle&lt;/li&gt;
&lt;li&gt;Z 僵死    Zombie（a defunct process)        进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放。&lt;/li&gt;
&lt;li&gt;D 不可中断    Uninterruptible sleep (ususally IO)    收到信号不唤醒和不可运行, 进程必须等待直到有中断发生。&lt;/li&gt;
&lt;li&gt;T 终止    Terminate                进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行。&lt;/li&gt;
&lt;li&gt;P 等待交换页&lt;/li&gt;
&lt;li&gt;W 无驻留页    has no resident pages        没有足够的记忆体分页可分配。&lt;/li&gt;
&lt;li&gt;X 死掉的进程&lt;/li&gt;
&lt;li&gt;&amp;lt; 高优先级进程                    高优先序的进程&lt;/li&gt;
&lt;li&gt;N 低优先    级进程                    低优先序的进程&lt;/li&gt;
&lt;li&gt;L 内存锁页    Lock                有记忆体分页分配并缩在记忆体内&lt;/li&gt;
&lt;li&gt;s 进程的领导者（在它之下有子进程）；&lt;/li&gt;
&lt;li&gt;l 多进程的（使用 CLONE_THREAD, 类似 NPTL pthreads）&lt;/li&gt;
&lt;li&gt;+ 位于后台的进程组&lt;/li&gt;
&lt;li&gt;START    进程启动时间和日期&lt;/li&gt;
&lt;li&gt;TIME    进程使用的总cpu时间&lt;/li&gt;
&lt;li&gt;COMMAND    正在执行的命令行命令&lt;/li&gt;
&lt;li&gt;NI    优先级(Nice)&lt;/li&gt;
&lt;li&gt;PRI    进程优先级编号(Priority)&lt;/li&gt;
&lt;li&gt;WCHAN    进程正在睡眠的内核函数名称；该函数的名称是从/root/system.map文件中获得的。&lt;/li&gt;
&lt;li&gt;FLAGS    与进程相关的数字标识&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.10 watch&lt;/h3&gt;
&lt;h4&gt;1.10.1命令说明&lt;/h4&gt;
&lt;p&gt;实时监测命令，还可以检测其他命令运行情况的命令&lt;/p&gt;
&lt;h4&gt;1.10.2参数说明&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;-d 高亮显示变动&lt;/li&gt;
&lt;li&gt; -n 周期（秒）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;1.10.3结果说明&lt;/h4&gt;
&lt;p&gt;Watch –d –n 1 netstat -ant&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3fd9f157309957b0c4ef4c3ba359a6d2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;每秒监测网络，高亮显示变化。&lt;/p&gt;
&lt;h3&gt;1.11 strace&lt;/h3&gt;
&lt;h4&gt;1.11.1命令说明&lt;/h4&gt;
&lt;p&gt;Strace命令用来跟踪进程执行时的系统调用和所接收的信号。在Linux世界，进程不能直接访问硬件设备，当进程需要访问硬件设备(比如读取磁盘文件，接收网络数据等等)时，必须由用户态模式切换至内核态模式，通过系统调用访问硬件设备。strace可以跟踪到一个进程产生的系统调用,包括参数，返回值，执行消耗的时间&lt;/p&gt;
&lt;h4&gt;1.11.2参数说明&lt;/h4&gt;
&lt;p&gt;strace使用参数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-p：跟踪指定的进程。&lt;/li&gt;
&lt;li&gt;-f：跟踪由fork子进程系统调用。&lt;/li&gt;
&lt;li&gt;-F：尝试跟踪vfork子进程系统调吸入，与-f同时出现时, vfork不被跟踪。&lt;/li&gt;
&lt;li&gt;-o filename：默认strace将结果输出到stdout。通过-o可以将输出写入到filename文件中。&lt;/li&gt;
&lt;li&gt;-ff：常与-o选项一起使用，不同进程(子进程)产生的系统调用输出到filename.PID文&lt;/li&gt;
&lt;li&gt;-r：打印每一个系统调用的相对时间。&lt;/li&gt;
&lt;li&gt;-t：在输出中的每一行前加上时间信息。 -tt 时间确定到微秒级。还可以使用-ttt打印相对时间。&lt;/li&gt;
&lt;li&gt;-v：输出所有系统调用。默认情况下，一些频繁调用的系统调用不会输出。&lt;/li&gt;
&lt;li&gt;-s：指定每一行输出字符串的长度,默认是32。文件名一直全部输出。&lt;/li&gt;
&lt;li&gt;-c：统计每种系统调用所执行的时间，调用次数，出错次数。&lt;/li&gt;
&lt;li&gt;-e expr：输出过滤器，通过表达式，可以过滤出掉你不想要输出。&lt;/li&gt;
&lt;li&gt;-d：输出strace关于标准错误的调试信息。&lt;/li&gt;
&lt;li&gt;-h：输出简要的帮助信息。&lt;/li&gt;
&lt;li&gt;-i：输出系统调用的入口指针。&lt;/li&gt;
&lt;li&gt;-q：禁止输出关于脱离的消息。&lt;/li&gt;
&lt;li&gt;-tt：在输出中的每一行前加上时间信息,微秒级。&lt;/li&gt;
&lt;li&gt;-T：显示每一调用所耗的时间。&lt;/li&gt;
&lt;li&gt;-V ：输出strace的版本信息。&lt;/li&gt;
&lt;li&gt;-x：以十六进制形式输出非标准字符串。&lt;/li&gt;
&lt;li&gt;-xx：所有字符串以十六进制形式输出。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.11.3结果说明&lt;/h4&gt;
&lt;p&gt;strace -ff -F -o ls.log ls –l   跟踪ls –l命令的执行情况&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d76526f14f5cb02e296926e7ebfe1f98.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;当某个函数执行失败时，那么返回值一般为-1&lt;/p&gt;
&lt;h3&gt;1.12  lsof&lt;/h3&gt;
&lt;h4&gt;1.12.1命令说明&lt;/h4&gt;
&lt;p&gt;Lsof的原始功能是列出打开的文件的进程。Linux下一切皆文件。&lt;/p&gt;
&lt;h4&gt;1.12.2参数说明&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;-a ：列出打开文件存在的进程&lt;/li&gt;
&lt;li&gt;-c&amp;lt;进程名&amp;gt; ：列出指定进程所打开的文件&lt;/li&gt;
&lt;li&gt;-g ：列出GID号进程详情&lt;/li&gt;
&lt;li&gt;-d&amp;lt;文件号&amp;gt; ：列出占用该文件号的进程&lt;/li&gt;
&lt;li&gt;+d&amp;lt;目录&amp;gt; ：列出目录下被打开的文件&lt;/li&gt;
&lt;li&gt;+D&amp;lt;目录&amp;gt; ：递归列出目录下被打开的文件&lt;/li&gt;
&lt;li&gt;-n&amp;lt;目录&amp;gt; ：列出使用NFS的文件&lt;/li&gt;
&lt;li&gt;-i&amp;lt;条件&amp;gt; ：列出符合条件的进程。&lt;/li&gt;
&lt;li&gt;-p&amp;lt;进程号&amp;gt;： 列出指定进程号所打开的文件&lt;/li&gt;
&lt;li&gt;-u 后面跟username：列出该用户相关进程所打开文件&lt;/li&gt;
&lt;li&gt;-U ：仅列出系统socket文件类型&lt;/li&gt;
&lt;li&gt;-h：显示帮助信息&lt;/li&gt;
&lt;li&gt;-v：显示版本信息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.12.3结果说明&lt;/h4&gt;
&lt;p&gt;列出所有root用户下的socket文件进程&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/2cd3ebbdca3d1fa68a2ad4b422b72565.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;COMMAND：进程的名称&lt;/li&gt;
&lt;li&gt;PID：进程标识符&lt;/li&gt;
&lt;li&gt;USER：进程所有者&lt;/li&gt;
&lt;li&gt;FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等&lt;/li&gt;
&lt;li&gt;TYPE：文件类型，如DIR、REG等&lt;/li&gt;
&lt;li&gt;DEVICE：指定磁盘的名称&lt;/li&gt;
&lt;li&gt;SIZE：文件的大小&lt;/li&gt;
&lt;li&gt;NODE：索引节点（文件在磁盘上的标识）&lt;/li&gt;
&lt;li&gt;NAME：打开文件的确切名称&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如有遗漏处，欢迎评论，逐渐补充。&lt;/p&gt;
&lt;div id=&quot;MySignature&quot;&gt;凌风出品，文武兼备&lt;/div&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Wed, 17 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-17-81173-86eab02cd.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-17-81173-86eab02cd.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>为什么社交网络中数据翻页技术复杂</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;为开发者打造的Linux视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;今天讨论了一个传统的问题，问题本身比较简单，就是针对key-list类型的数据，如何优化方案做到性能与成本的tradeoff。Key-list在用户类型的产品中非常普遍，如一个用户的好友关系 {“uid”:{1,2,3,4,5}}，表示uid包含有5个好友；一条微博下面的评论id列表{“weibo_id”: {comment_id1, comment_id2……}}，一个用户发表的微博id列表等。&lt;/p&gt;
&lt;p&gt;在list长度较少时候，我们可以直接的使用数据库的翻页功能，如&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT * FROM LIST_TABLE LIMIT offset, row_count;&lt;/pre&gt;
&lt;p&gt;根据经验，在大部分场景下，单个业务的list数据长度99%在1000条以下，在数据规模较小时候，上面的方法非常适合。但剩下的1%的数据可能多达100万条，在数据规模较大的时候，当访问offset较大的数据，上述方法非常低效（可参看&lt;a href=&quot;http://stackoverflow.com/questions/4481388/why-does-mysql-higher-limit-offset-slow-the-query-down&quot;&gt;Why does MYSQL higher LIMIT offset slow the query down?&lt;/a&gt;），但在实现方案的时候不能忽视这些超大数据集的问题，因此要实现一个适合各种变长list的翻页方案，考虑到数据的长尾问题，并没有简单高效的方案。这也体现了常说的80%+的时间在优化20%-的功能。&lt;/p&gt;
&lt;p&gt;List数据访问模型常见的有两种方式&lt;br&gt;
1. 扶梯方式&lt;br&gt;
扶梯方式在导航上通常只提供上一页/下一页这两种模式，部分产品甚至不提供上一页功能，只提供一种“更多/more”的方式，也有下拉自动加载更多的方式，在技术上都可以归纳成扶梯方式。&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fbabe6705a3ac4e242be3f8339155ec5.jpg&quot;&gt;&lt;br&gt;
（图：blogspot的导航条）&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b34808bdbbbf01345794ff800181aa0e.jpg&quot;&gt;&lt;br&gt;
（图：很多瀑布流式的产品只提供一个more的导航条）&lt;/p&gt;
&lt;p&gt;扶梯方式在技术实现上比较简单及高效，根据当前页最后一条的偏移往后获取一页即可，在MySQL可使用以下方法实现。&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT * FROM LIST_TABLE WHERE id &amp;gt; offset_id LIMIT n;&lt;/pre&gt;
&lt;p&gt;由于where条件中指定了位置，因此算法复杂度是O(log n)&lt;/p&gt;
&lt;p&gt;2. 电梯方式&lt;br&gt;
另外一种数据获取方式在产品上体现成精确的翻页方式，如1,2,3……n，同时在导航上也可以由用户输入直达n页。国内大部分产品经理对电梯方式有特殊的喜好，如图&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5993eadae1c0c142e3c20a03e8d16cfe.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;但电梯方式在技术实现上相对成本较高，当使用以下SQL时&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT * FROM LIST_TABLE LIMIT offset, row_count;&lt;/pre&gt;
&lt;p&gt;我们可以使用MySQL explain来分析，从下文可以看到，当offset=10000时候，实际上MySQL也扫描了10000行记录。&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/16ff67aeda384a11d50ef19722bad657.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;为什么会这样？在MySQL中，索引通常是b-tree方式（但存储引擎如InnoDB实际是b+tree），如图&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/484d7282d3330a4e0be469741ac96ad4.jpg&quot;&gt;&lt;br&gt;
从图中可以看到，使用电梯方式时候，当用户指定翻到第n页时候，并没有直接方法寻址到该位置，而是需要从第一楼逐个count，scan到count*page时候，获取数据才真正开始，所以导致效率不高。对应的算法复杂度是O(n)，n指offset，也就是page*count。&lt;/p&gt;
&lt;p&gt;另外Offset并不能有效的缓存，这是由于&lt;br&gt;
1、在数据存在新增及删除的情况下，只要有一条变化，原先的楼层可能会全部发生变化。在一个用户并发访问的场景，频繁变化的场景比较常见。&lt;br&gt;
2、电梯使用比较离散，可能一个20万条的list，用户使用了一次电梯直达100楼之后就走了，这样即使缓存100楼之下全部数据也不能得到有效利用。&lt;/p&gt;
&lt;p&gt;以上描述的场景属于单机版本，在数据规模较大时候，互联网系统通常使用分库的方式来保存，实现方法更为复杂。&lt;br&gt;
在面向用户的产品中，数据分片通常会将同一用户的数据存在相同的分区，以便更有效率的获取当前用户的数据。如下图所示&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/337b38dc0f2b712c5c275d8cfc384f2b.jpg&quot;&gt;&lt;br&gt;
（图：数据按用户uid进行hash拆分）&lt;/p&gt;
&lt;p&gt;图中的不同年份的数据的格子是逻辑概念，实际上同一用户的数据是保存在一张表中。因此方案在常见的使用场景中存在很大不足，大部分产品用户只访问最近产生的数据，历史的数据只有极小的概率被访问到，因此同一个区域内部的数据访问是非常不均匀，如图中2014年生成的属于热数据，2012年以前的属于冷数据，只有极低的概率被访问到。但为了承担红色部分的访问，数据库通常需要高速昂贵的设备如SSD，因此上面方案所有的数据都需要存在SSD设备中，即使这些数据已经不被访问。&lt;/p&gt;
&lt;p&gt;简单的解决方案是按时间远近将数据进行进一步分区，如图。&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/4dd567cde869476b9a2dc8a0d6f72812.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;注意在上图中使用时间方式sharding之后，在一个时间分区内，也需要用前一种方案将数据进行sharding，因为一个时间片区通常也无法用一台服务器容纳。&lt;/p&gt;
&lt;p&gt;上面的方案较好的解决了具体场景对于key list访问性能及成本的tradeoff，但是它存在以下不足&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据按时间进行滚动无法全自动，需要较多人为介入或干预&lt;/li&gt;
&lt;li&gt;数据时间维度需要根据访问数据及模型进行精巧的设计，如果希望实现一个公用的key-list服务来存储所有业务的数据，这个公用服务可能很难实现&lt;/li&gt;
&lt;li&gt;为了实现电梯直达功能，需要增加额外的二级索引，比如2013年某用户总共有多少条记录&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于以上问题，尤其是二级索引的引入，显然它不是理想中的key list实现，后文继续介绍适合长尾翻页key list设计的一些思路及尝试。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Mon, 15 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-15-81268-fba7bccf7.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-15-81268-fba7bccf7.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>Worktile中百万级实时消息推送服务的实现</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;为开发者打造的Linux视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;本文由 &lt;a href=&quot;https://worktile.com?hmsr=http%3A%2F%2Fblog.jobbole.com%2F&amp;amp;hmmd=%E6%96%87%E5%AD%97&amp;amp;hmpl=&amp;amp;hmkw=&amp;amp;hmci=&quot; target=&quot;_blank&quot;&gt;Worktile&lt;/a&gt; – 研发团队 分享&lt;/p&gt;
&lt;p&gt;在团队协同工具&lt;a href=&quot;https://worktile.com?hmsr=http%3A%2F%2Fblog.jobbole.com%2F&amp;amp;hmmd=%E6%96%87%E5%AD%97&amp;amp;hmpl=&amp;amp;hmkw=&amp;amp;hmci=&quot; target=&quot;_blank&quot;&gt;Worktile&lt;/a&gt;的使用过程中，你会发现无论是右上角的消息通知，还是在任务面板中拖动任务，还有用户的在线状态，都是实时刷新。Worktile中的推送服务是采用的是基于xmpp协议、erlang语言实现的ejabberd，并在其源码基础上，结合我们的业务，对源码作了修改以适配我们自身的需求。另外，基于amqp协议也可以作为实时消息推送的一种选择，踢踢网就是采用 rabbitmq+stomp 协议实现的消息推送服务。本文将结合我在Worktile和踢踢网的项目实践，介绍下消息推送服务的具体实现。&lt;/p&gt;
&lt;h2&gt;实时推送的几种实现方式&lt;/h2&gt;
&lt;p&gt;相较于手机端的消息推送（一般都是以socket方式实现），web端是基于http协议，很难像tcp一样保持长连接。但随着技术的发展，出现了websocket, comet等新的技术可以达到类似长连接的效果，这些技术大体可分为以下几类：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1）短轮询&lt;/strong&gt;。页面端通过js定时异步刷新，这种方式实时效果较差。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2）长轮询&lt;/strong&gt;。页面端通过js异步请求服务端，服务端在接收到请求后，如果该次请求没有数据，则挂起这次请求，直到有数据到达或时间片（服务端设定）到，则返回本次请求，客户端接着下一次请求。示例如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter size-full wp-image-81129&quot; alt=&quot;1&quot; src=&quot;/images/jobbole.com/ace2e1f25f23fad6337356424e566791.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3）Websocket&lt;/strong&gt;。浏览器通过websocket协议连接服务端，实现了浏览器和服务器端的全双工通信。需要服务端和浏览器都支持websocket协议。&lt;/p&gt;
&lt;p&gt;以上几种方式中，方式1实现较简单，但效率和实时效果较差。方式2对服务端实现的要求比较高，尤其是并发量大的情况下，对服务端的压力很大。方式3效率较高，但对较低版本的浏览器不支持，另外服务端也需要有支持websocket的实现。Worktile的web端实时消息推送，采用的是xmpp扩展协议xep-0124 BOSH(&lt;a href=&quot;http://xmpp.org/extensions/xep-0124.html&quot; target=&quot;_blank&quot;&gt;http://xmpp.org/extensions/xep-0124.html&lt;/a&gt;)，本质是采用方式2长轮询的方式。踢踢网则采用了websocket连接rabbitmq的方式实现，下面我会具体介绍如何用这两种方式实现Server Push。&lt;/p&gt;
&lt;h2&gt;运行时环境准备&lt;/h2&gt;
&lt;p&gt;服务端的实现中，无论采用ejabberd还是rabbitmq，都是基于erlang语言开发的，所以必须安装erlang运行时环境。Erlang是一种函数式语言，具有容错、高并发的特点，借助OTP的函数库，很容易构建一个健壮的分布式系统。目前，基于erlang开发的产品有，数据库方面：Riak（Dynamo实现）、CouchDB， Webserver方面：Cowboy、Mochiweb， 消息中间件有rabbitmq等。对于服务端程序员来说，erlang提供的高并发、容错、热部署等特性是其他语言无法达到的。无论在实时通信还是在游戏程序中，用erlang可以很容易为每一个上线用户创建一个对应的process，对一台4核8个G的服务器来说，承载上百万个这样的process是非常轻松的事。下图是erlang程序发起process的一般性示意图：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter size-full wp-image-81131&quot; alt=&quot;2&quot; src=&quot;/images/jobbole.com/302f7ea0b47b013067f6b3d7e7a6d3fd.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;如图所示，Session manager(or gateway)负责为每个用户（uid）创建相对应的process， 并把这个对应关系（map）存放到数据表中。每个process则对应用户数据，并且他们之间可以相互发送消息。Erlang的优势就是在内存足够的情况下创建上百万个这样的process，而且它的创建和销毁比java的thread要轻量的多，两者不是一个数量级的。&lt;/p&gt;
&lt;p&gt;好了，我们现在开始着手erlang环境的搭建（实验的系统为ubuntu12.04, 4核8个G内存）：&lt;/p&gt;
&lt;p&gt;1、依赖库安装&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt; sudo apt-get install build-essential
 sudo apt-get install libncurses5-dev
 sudo apt-get install libssl-dev libyaml-dev
 sudo apt-get install m4
 sudo apt-get install unixodbc unixodbc-dev
 sudo apt-get install freeglut3-dev libwxgtk2.8-dev
 sudo apt-get install xsltproc
 sudo apt-get install fop tk8.5 libxml2-utils&lt;/pre&gt;
&lt;p&gt;2、官网下载otp源码包(&lt;a href=&quot;http://www.erlang.org/download.html&quot; target=&quot;_blank&quot;&gt;http://www.erlang.org/download.html&lt;/a&gt;), 解压并安装：&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;tar zxvf otpsrcR16B01.tar.gz
cd otpsrcR16B01
configure
make &amp;amp; make install&lt;/pre&gt;
&lt;p&gt;至此，erlang运行环境就完成了。下面将分别介绍rabbitmq和ejabberd构建实时消息服务。&lt;/p&gt;
&lt;h2&gt;基于RabbitMQ的实时消息服务&lt;/h2&gt;
&lt;p&gt;RabbitMQ是在业界广泛应用的消息中间件，也是对AMQP协议实现最好的一种中间件。AMQP协议中定义了Producer、 Consumer、MessageQueue、Exchange、Binding、Virtual Host等实体，他们的关系如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;3&quot; src=&quot;/images/jobbole.com/8e24adab99b47ccfd977fb75da6c031c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;消息发布者(Producer)连接交换器（Exchange）, 交换器和消息队列（Message Queue）通过key进行Binding，Binding是根据Exchange的类型（分为fanout、direct、topic、header）分别对消息作不同形式的派发。Message Queue又分为durable、temporary、auto-delete三种类型，durable queue是持久化队列，不会因为服务shutdown而消失，temporary queue则服务重启后会消失，auto-delete则是在没有consumer连接时自动删除。另外RabbitMQ有很多第三方插件，可以基于AMQP协议基础之上做出很多扩展的应用。下面我们将介绍web stomp插件构建基于AMQP之上的stomp文本协议，通过浏览器websocket达到实时的消息传输。系统的结构如图：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter size-full wp-image-81137&quot; alt=&quot;4&quot; src=&quot;/images/jobbole.com/f67cff5a22bae9cde1ec6054fd986e5b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;如图所示，web端我们使用stomp.js和sockjs.js与rabbitmq的web stomp plugin通信，手机端可以用stompj, gozirra(Android)或者objc-stomp(IOS)通过stomp协议与rabbitmq收发消息。因为我们是实时消息系统通常都是要与已有的用户系统结合，rabbitmq可以通过第三方插件rabbitmq-auth-backend-http来适配已有的用户系统，这个插件可以通过http接口完成用户连接时的认证过程。当然，认证方式还有ldap等其他方式。下面介绍具体步骤：&lt;/p&gt;
&lt;p&gt;从官网（&lt;a href=&quot;http://rabbitmq.com/download.html&quot; target=&quot;_blank&quot;&gt;http://rabbitmq.com/download.html&lt;/a&gt;）下载最新版本的源码包，解压并安装：&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;tar zxf rabbitmq-server-x.x.x.tar.gz
cd rabbitmq-server-x.x.x
make &amp;amp; make install&lt;/pre&gt;
&lt;p&gt;为rabbitmq安装web-stomp插件&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;cd /path/to/your/rabbitmq
./sbin/rabbitmq-plugins enable rabbitmq_web_stomp
./sbin/rabbitmq-plugins enable rabbitmq_web_stomp_examples
./sbin/rabbitmqctl stop
./sbin/rabbitmqctl start
./sbin/rabbitmqctl status&lt;/pre&gt;
&lt;p&gt;将会显示下图所示的运行的插件列表&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/4e44f1ac85cd60e3caa56bfd4afb675e.jpeg&quot; rel=&quot;lightbox[81125]&quot; title=&quot;Worktile中百万级实时消息推送服务的实现&quot;&gt;&lt;img class=&quot;aligncenter size-full wp-image-81140&quot; alt=&quot;4.2&quot; src=&quot;/images/jobbole.com/9ea26bd914523b80adb866b5fcd1cf50.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;安装用户授权插件&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;cd /path/to/your/rabbitmq/plugins
wget http://www.rabbitmq.com/community-plugins/v3.3.x/rabbitmq_auth_backend_http-3.3.x-e7ac6289.ez
cd ..
./sbin/rabbitmq-plugins enable rabbitmq_auth_backend_http&lt;/pre&gt;
&lt;p&gt;编辑rabbitmq.config文件（默认存放于/etc/rabbitmq/下），添加：&lt;/p&gt;
&lt;pre class=&quot;brush: xml; gutter: true&quot;&gt;[
 ...
 {rabbit, [{auth_backends, [rabbit_auth_backend_http]}]},
 ...
 {rabbitmq_auth_backend_http,
 [{user_path, “http://your-server/auth/user”},
 {vhost_path, “http://your-server/auth/vhost”},
 {resource_path, “http://your-server/auth/resource”}
 ]}
 ...
].&lt;/pre&gt;
&lt;p&gt;其中，user_path是根据用户名密码进行校验，vhost_path是校验是否有权限访问vhost， resource_path是校验用户对传入的exchange、queue是否有权限。我下面的代码是用nodejs实现的这三个接口的示例：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;var express = require(&#39;express&#39;);
 var app = express();
 app.get(&#39;/auth/user&#39;, function(req, res){
 var name = req.query.username;
 var pass = req.query.password;
 console.log(&quot;name : &quot; + name + &quot;, pass : &quot; + pass);
 if(name === &#39;guest&#39; &amp;amp;&amp;amp; pass === &quot;guest&quot;){
 console.log(&quot;allow&quot;);
 res.send(&quot;allow&quot;);
 }else{
 res.send(&#39;deny&#39;);
 }
 });
 app.get(&#39;/auth/vhost&#39;, function(req, res){
 console.log(&quot;/auth/vhost&quot;);
 res.send(&quot;allow&quot;);
 });
 app.get(&#39;/auth/resource&#39;, function(req, res){
 console.log(&quot;/auth/resource&quot;);
 res.send(&quot;allow&quot;);
 });
 app.listen(3000);&lt;/pre&gt;
&lt;p&gt;浏览器端js实现，示例代码如下：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;......
 var ws = new SockJS(&#39;http://&#39; + window.location.hostname + &#39;:15674/stomp&#39;);
 var client = Stomp.over(ws);
 // SockJS does not support heart-beat: disable heart-beats
 client.heartbeat.outgoing = 0;
 client.heartbeat.incoming = 0;
 client.debug = pipe(&#39;#second&#39;);
 var print_first = pipe(&#39;#first&#39;, function(data) {
 client.send(&#39;/exchange/feed/user_x&#39;, {&quot;content-type&quot;:&quot;text/plain&quot;}, data);
 });
 var on_connect = function(x) {
 id = client.subscribe(&quot;/exchange/feed/user_x&quot;, function(d) {
 print_first(d.body);
 });
 };
 var on_error = function() {
 console.log(&#39;error&#39;);
 };
 client.connect(&#39;guest1&#39;, &#39;guest1&#39;, on_connect, on_error, &#39;/&#39;);
 ......&lt;/pre&gt;
&lt;p&gt;需要说明的时，在这里我们首先要在rabbitmq实例中创建feed这个exchange，我们用stomp.js连接成功后，根据当前登陆用户的id（user_x）绑定到这个exchange，即 subscribe(“/exchange/feed/user_x”, …) 这个操作的行为，这样在向rabbitmq中feed exchange发送消息并指定用户id(user_x)为key，页面端就会通过websocket实时接收到这条消息。&lt;/p&gt;
&lt;p&gt;到目前为止，基于rabbitmq+stomp实现web端消息推送就已经完成，其中很多的细节需要小伙伴们亲自去实践了，这里就不多说了。实践过程中可以参照官方文档：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://rabbitmq.com/stomp.html&quot; target=&quot;_blank&quot;&gt;http://rabbitmq.com/stomp.html&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;http://rabbitmq.com/web-stomp.html&quot; target=&quot;_blank&quot;&gt;http://rabbitmq.com/web-stomp.html&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://github.com/simonmacmullen/rabbitmq-auth-backend-http&quot; target=&quot;_blank&quot;&gt;https://github.com/simonmacmullen/rabbitmq-auth-backend-http&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;以上的实现是我本人在踢踢网时采用的方式，下面接着介绍一下现在在Worktile中如何通过ejabberd实现消息推送。&lt;/p&gt;
&lt;h2&gt;基于ejabberd的实时消息推送&lt;/h2&gt;
&lt;p&gt;与rabbitmq不同，ejabberd是xmpp协议的一种实现，与amqp相比，xmpp广泛应用于即时通信领域。Xmpp协议的实现有很多种，比如java的openfire，但相较其他实现，ejabberd的并发性能无疑使最优秀的。Xmpp协议的前身是jabber协议，早期的jabber协议主要包括在线状态（presence）、好友花名册（roster）、IQ（Info/Query）几个部分。现在jabber已经成为rfc的官方标准，如rfc2799, rfc4622, rfc6121，以及xmpp的扩展协议（xep）。Worktile Web端的消息提醒功能就是基于XEP-0124、XEP-0206定义的BOSH扩展协议。&lt;/p&gt;
&lt;p&gt;由于自身业务的需要，我们对ejabberd的用户认证和好友列表模块的源码进行修改，通过redis保存用户的在线状态，而不是mnesia和mysql。另外好友这块我们是从已有的数据库中（mongodb）中获取项目或团队的成员。Web端通过strophe.js来连接（http-bind），strophe.js可以以长轮询和websocket两种方式来连接，由于ejabberd还没有好的websocket的实现，就采用了BOSH的方式模拟长连接。整个系统的结构如下：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/4e44f1ac85cd60e3caa56bfd4afb675e.jpeg&quot; rel=&quot;lightbox[81125]&quot; title=&quot;Worktile中百万级实时消息推送服务的实现&quot;&gt;&lt;img alt=&quot;5&quot; src=&quot;/images/jobbole.com/2c970cd29b1e2a84a68dc717926f2264.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Web端用strophe.js通过http-bind进行连接nginx代理，nginx反向代理ejabberd cluster。iOS用xmpp-framwork连接, Android可以用smack直接连ejabberd服务器集群。这些都是现有的库，无需对client进行开发。在线状态根据用户uid作为key定义了在线、离线、忙等状态存放于redis中。好友列表从mongodb的project表中获取。用户认证直接修改了ejabberd_auth_internal.erl文件，通过mongodb驱动连接用户库，在线状态等功能是新加了模块，其部分代码如下:&lt;/p&gt;
&lt;pre class=&quot;brush: erlang; gutter: true&quot;&gt;-module(wt_mod_proj).
 -behaviour(gen_mod).
 -behaviour(gen_server).
 -include(&quot;ejabberd.hrl&quot;).
 -include(&quot;logger.hrl&quot;).
 -include(&quot;jlib.hrl&quot;).
 -define(SUPERVISOR, ejabberd_sup).
 ...
 -define(ONLINE, 1).
 -define(OFFLINE, 0).
 -define(BUSY, 2).
 -define(LEAVE, 3).
 ...
 %% API
 -export([start_link/2, get_proj_online_users/2]).
 %% gen_mod callbacks
 -export([start/2, stop/1]).
 %% gen_server callbacks
 -export([init/1, terminate/2, handle_call/3, handle_cast/2, handle_info/2, code_change/3]).
 %% Hook callbacks
 -export([user_available/1, unset_presence/3, set_presence/4]).
 -export([get_redis/1, remove_online_user/3, append_online_user/3]).
 ...
 -record(state,{host = &amp;amp;lt;&amp;amp;lt;&quot;&quot;&amp;amp;gt;&amp;amp;gt;, server_host, rconn, mconn}).
start_link(Host, Opts) -&amp;amp;gt;
 Proc = gen_mod:get_module_proc(Host, ?MODULE),
 gen_server:start_link({local, Proc}, ?MODULE, [Host, Opts], []).
 user_available(New) -&amp;amp;gt;
 LUser = New#jid.luser, LServer = New#jid.lserver,
 Proc = gen_mod:get_module_proc(LServer, ?MODULE),
 gen_server:cast(Proc, {user_available, LUser, LServer}).
append_online_user(Uid, Proj, Host) -&amp;amp;gt;
 Proc = gen_mod:get_module_proc(Host, ?MODULE),
 gen_server:call(Proc, {append_online_user, Uid, Proj}).
 remove_online_user(Uid, Proj, Host) -&amp;amp;gt;
 Proc = gen_mod:get_module_proc(Host, ?MODULE),
 gen_server:call(Proc, {remove_online_user, Uid, Proj}).
 ...
 set_presence(User, Server, Resource, Packet) -&amp;amp;gt;
 Proc = gen_mod:get_module_proc(Server, ?MODULE),
 gen_server:cast(Proc, {set_presence, User, Server, Resource, Packet}).
 ...
start(Host, Opts) -&amp;amp;gt;
 Proc = gen_mod:get_module_proc(Host, ?MODULE),
 ChildSpec = {Proc, {?MODULE, start_link, [Host, Opts]},
 transient, 2000, worker, [?MODULE]},
 supervisor:start_child(?SUPERVISOR, ChildSpec).
stop(Host) -&amp;amp;gt;
 Proc = gen_mod:get_module_proc(Host, ?MODULE),
 gen_server:call(Proc, stop),
 supervisor:delete_child(?SUPERVISOR, Proc).
init([Host, Opts]) -&amp;amp;gt;
 MyHost = gen_mod:get_opt_host(Host, Opts, &amp;amp;lt;&amp;amp;lt;&quot;wtmuc.@HOST@&quot;&amp;amp;gt;&amp;amp;gt;),
 RedisHost = gen_mod:get_opt(redis_host, Opts, fun(B) -&amp;amp;gt; B end,?REDIS_HOST),
 RedisPort = gen_mod:get_opt(redis_port, Opts, fun(I) when is_integer(I), I&amp;amp;gt;0 -&amp;amp;gt; I end, ?REDIS_PORT),
 ejabberd_hooks:add(set_presence_hook, Host, ?MODULE, set_presence, 100),
 ejabberd_hooks:add(user_available_hook, Host, ?MODULE, user_available, 50),
 ejabberd_hooks:add(sm_remove_connection_hook, Host, ?MODULE, unset_presence, 50),
 MongoHost = gen_mod:get_opt(mongo_host, Opts, fun(B) -&amp;amp;gt; binary_to_list(B) end, ?MONGO_HOST),
 MongoPort = gen_mod:get_opt(mongo_port, Opts, fun(I) when is_integer(I), I&amp;amp;gt;0 -&amp;amp;gt; I end, ?MONGO_PORT),
 {ok, Mongo} = mongo_connection:start_link({MongoHost, MongoPort}),
 C = c(RedisHost, RedisPort),
 ejabberd_router:register_route(MyHost), {ok, #state{host = Host, server_host = MyHost, rconn = C, mconn = Mongo}}.
 terminate(_Reason, #state{host = Host, rconn = C, mconn = Mongo}) -&amp;amp;gt;
 ejabberd_hooks:delete(set_presence_hook, Host, ?MODULE, set_presence, 100),
 ejabberd_hooks:delete(user_available_hook, Host, ?MODULE, user_available, 50),
 ejabberd_hooks:delete(unset_presence_hook, Host, ?MODULE, unset_presence, 50),
 eredis:stop(C),
 ok.
 ...
 handle_call({append_online_user, Uid, ProjId}, _From, State) -&amp;amp;gt;
 C = State#state.rconn,
 Key = &amp;amp;lt;&amp;lt;!--?PRE_RPOJ_ONLINE_USERS /binary, ProjId/binary--&amp;gt;&amp;amp;gt;,
 Resp = eredis:q(C, [&quot;SADD&quot;, Key, Uid]),
 {reply, Resp, State};
 handle_call({remove_online_user, Uid, ProjId}, _From, State) -&amp;amp;gt;
 ...
 handle_call({get_proj_online_users, ProjId}, _From, State) -&amp;amp;gt;
 ...
 handle_cast({set_presence, User, Server, Resource, Packet}, #state{mconn = Mongo} = State) -&amp;amp;gt;
 C = State#state.rconn,
 Key = &amp;amp;lt;&amp;lt;!--?USER_PRESENCE /binary, User/binary--&amp;gt;&amp;amp;gt;,
 Pids = get_user_projs(User, Mongo),
 Cmd = get_proj_key(Pids, [&quot;SUNION&quot;]),
 case xml:get_subtag_cdata(Packet, &amp;amp;lt;&amp;amp;lt;&quot;show&quot;&amp;amp;gt;&amp;amp;gt;) of
 &amp;amp;lt;&amp;amp;lt;&quot;away&quot;&amp;amp;gt;&amp;amp;gt; -&amp;amp;gt;
 eredis:q(C, [&quot;SET&quot;, Key, ?LEAVE]);
 &amp;amp;lt;&amp;amp;lt;&quot;offline&quot;&amp;amp;gt;&amp;amp;gt; -&amp;amp;gt;
 ...
 handle_cast(_Msg, State) -&amp;amp;gt; {noreply, State}.
handle_info({route, From, To, Packet}, #state{host = Host, server_host = MyHost, rconn = RedisConn, mconn = Mongo} = State) -&amp;amp;gt;
 case catch do_route(Host, MyHost, From, To, Packet, RedisConn, Mongo) of
 {&#39;EXIT&#39;, Reason} -&amp;amp;gt;
 ?ERROR_MSG(&quot;~p&quot;, [Reason]);
 _ -&amp;amp;gt;
 ok
 end,
 {noreply, State};
handle_info(_Info, State) -&amp;amp;gt; {noreply, State}.
code_change(_OldVsn, State, _Extra) -&amp;amp;gt; {ok, State}.
 ...&lt;/pre&gt;
&lt;p&gt;其中，user\_available\_hook和sm\_remove\_connection\_hook 就是用户上线和用户断开连接触发的事件，ejabberd 中正是由于这些hook，才能很容易扩展功能。&lt;/p&gt;
&lt;p&gt;在用tsung对ejabberd进行压力测试，测试机器为4核心8G内存的普通PC，以3台客户机模拟用户登录、设置在线状态、发送一条文本消息、关闭连接操作，在同时在线达到30w时，CPU占用不到3%，内存大概到3个G左右，随着用户数增多，主要内存的损耗较大。由于压力测试比较耗时，再等到有时间的时候，会在做一些更深入的测试。&lt;/p&gt;
&lt;p&gt;对于ejabberd的安装与集群的搭建，大家可以参照官方文档，这里不再赘述。如果在使用过程中有什么问题，可以加入&lt;a href=&quot;https://worktile.com?hmsr=http%3A%2F%2Fblog.jobbole.com%2F&amp;amp;hmmd=%E6%96%87%E5%AD%97&amp;amp;hmpl=&amp;amp;hmkw=&amp;amp;hmci=&quot; target=&quot;_blank&quot;&gt;Worktile&lt;/a&gt;官方群(110257147)，进行讨论。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Mon, 15 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-15-81125-28848f539.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-15-81125-28848f539.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>一个成功的 Git 分支模型</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69?from=jobboleblog&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181?from=jobboleblog&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;在这篇文章中介绍的开发模型在大约一年前已经在我的私有项目和工作引入的，而且已经被证明是非常成功的。我想写一些关于这个模型的东西已经好一段时间了，但是一直苦于没有时间，不过现在可以了。我不想探讨任何项目细节，只讨论分支策略和发布管理。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/24b04fd5f739b36d90727cfa07aa886d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;这篇文章围绕着Git做为我们所有的源代码版本控制工具而展开的。&lt;/p&gt;
&lt;h2&gt;为什么是Git&lt;/h2&gt;
&lt;p&gt;为了深入探讨git和集中式源码版本控制系统的利弊，&lt;a href=&quot;http://www.whygitisbetterthanx.com/&quot;&gt;参见&lt;/a&gt;这些&lt;a href=&quot;https://git.wiki.kernel.org/index.php/GitSvnComparsion&quot;&gt;文章&lt;/a&gt;。这方面有太多的激烈争论。作为一个开发者，相比其他工具，当前我更喜欢Git。Git的确改变了开发者关于合并与分支的思考方式。在那些经典的CVS/Subversion管理工具的世界中，合并/分支被认为是有些吓人的(“当心合并冲突，它们咬你!”)，而且偶尔你得做些操作解决一些问题。&lt;/p&gt;
&lt;p&gt;但是使用Git，这些操作都变得极度简单，这些操作被认为是你日常工作流程核心部分之一。例如，&lt;a href=&quot;http://svnbook.red-bean.com/&quot;&gt;在CVS/Subversion 这本书中&lt;/a&gt;，分支与合并在很后的章节中才被第一次讨论(针对高级用户)。但是在&lt;a href=&quot;http://git-scm.com/book/en/v2&quot;&gt;每一本&lt;/a&gt;&lt;a href=&quot;pragprog.com/titles/tsgit/pragmatic-version-control-using-git&quot;&gt;Git&lt;/a&gt;&lt;a href=&quot;github.com/progit/progit&quot;&gt;书籍&lt;/a&gt;中，在第三章就讲到了(基础部分)。&lt;/p&gt;
&lt;p&gt;由于它的简单性和操作命令的重复性，分支与合并操作变得不再可怕。版本控制工具被认为在分支/合并方面提供操作便利性比什么都重要&lt;/p&gt;
&lt;p&gt;关于工具本身，已经讨论的足够多了，下面针对开发模型进行展开。我将要介绍的这个模型不会比任何一套流程内容多，每个团队成员都必须遵守，这样便于管理软件开发过程。&lt;/p&gt;
&lt;h2&gt;既分散又集中&lt;/h2&gt;
&lt;p&gt;我们使用的，且与这个分支模型配合的非常好的库，他有一个“真正”的中央仓库。注意，这个库只是被认为是中央仓库(因为Git是一个分布式的版本控制工具，在技术层面没有所谓的中央仓库)。我们将会为这个仓库起名为&lt;code&gt;origin&lt;/code&gt;，因为所有的Git用户对这个名字都比较熟悉。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/96afd39407d6531b1c545913d2e90214.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;每个开发者从origin拉取和推送代码。除了集中式的推送拉取关系，每个开发者也有可能从别的开发者处拉取代码，形成自己的团队。例如当与两个或者更多的人开发一个大的特性时，或者在将代码推送到&lt;code&gt;origin&lt;/code&gt;之前，这种代码管理模式可能有用。在上图中，存在Alice和Bob，Alice和David，Clair 和David三个子团队&lt;/p&gt;
&lt;p&gt;技术上而言，这只不过意味着Alice定义了一个远程Git仓库，起名为bob，实际上指向Bob的版本库，反之亦然(Bob定义了一个远程Git仓库，起名为alice，实际上指向Alice的版本库)。&lt;/p&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;h2&gt;主分支&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/504f548086e67e6a1147da77a43da6ff.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;老实说，我们讨论的开发模型受到了当前已存在模型的很大启发。集中式的版本库有两个永久存在的主分支：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;master分支&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;develop分支&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;&lt;code&gt;origin&lt;/code&gt;的master&lt;/code&gt;分支每个Git用户都很熟悉。平行的另外一个分支叫做&lt;code&gt;develop&lt;/code&gt;分支。&lt;/p&gt;
&lt;p&gt;我们认为&lt;code&gt;origin/master&lt;/code&gt;这个分支上&lt;code&gt;HEAD&lt;/code&gt;引用所指向的代码都是可发布的。&lt;/p&gt;
&lt;p&gt;我们认为&lt;code&gt;origin/develop&lt;/code&gt;这个分支上&lt;code&gt;HEAD&lt;/code&gt;引用所指向的代码总是反应了下一个版本所要交付特性的最新的代码变更。一些人管它叫“整合分支”。它也是自动构建系统执行构建命令的分支。&lt;/p&gt;
&lt;p&gt;当&lt;code&gt;develop&lt;/code&gt;分支上的代码达到了一个稳定状态，并且准备发布时，所有的代码变更都应该合并到master分支，然后打上发布版本号的tag。具体如何进行这些操作，我们将会讨论&lt;/p&gt;
&lt;p&gt;因此，每次代码合并到master分支时，它就是一个人为定义的新的发布产品。理论上而言，在这我们应该非常严格，当master分支有新的提交时，我们应该使用Git的钩子脚本执行自动构建命令，然后将软件推送到生产环境的服务器中进行发布。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2&gt;辅助性分支&lt;/h2&gt;
&lt;p&gt;紧邻&lt;code&gt;master&lt;/code&gt;和&lt;code&gt;develop&lt;/code&gt;分支，我们的开发模型采用了另外一种辅助性的分支，以帮助团队成员间的并行开发，特性的简单跟踪，产品的发布准备事宜，以及快速的解决线上问题。不同于主分支，这些辅助性分支往往只要有限的生命周期，因为他们最终会被删除。&lt;/p&gt;
&lt;p&gt;我们使用的不同类型分支包括:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;特性分支&lt;/li&gt;
&lt;li&gt;Release分支&lt;/li&gt;
&lt;li&gt;Hotfix 分支&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上述的每一个分支都有其特殊目的，也绑定了严格的规则：哪些分支是自己的拉取分支，哪些分支是自己的目标合并分支。&lt;/p&gt;
&lt;p&gt;从技术角度看，这些分支的特殊性没有更多的含义。只是按照我们的使用方式对这些分支进行了归类。他们依旧是原Git分支的样子。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;特性分支&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c184c28a1551540c859851e640cddccf.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;特性分支可以从develop分支拉取建立，最终必须合并会develop分支。特性分支的命名，除了 &lt;code&gt;master&lt;/code&gt;， &lt;code&gt;develop&lt;/code&gt;， &lt;code&gt;release-*&lt;/code&gt;，或&lt;code&gt;hotfix-*&lt;/code&gt;以外，可以随便起名。&lt;/p&gt;
&lt;p&gt;特性分支(有时候也成主题分支)用于开发未来某个版本新的特性。当开始一个新特性的开发时，这个特性未来将发布于哪个目标版本，此刻我们是不得而知的。特性分支的本质特征就是只要特性还在开发，他就应该存在，但最终这些特性分支会被合并到develop分支(目的是在新版本中添加新的功能)或者被丢弃(它只是一个令人失望的试验)&lt;/p&gt;
&lt;p&gt;特性分支只存在开发者本地版本库，不在远程版本库。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;创建特性分支&lt;/h4&gt;
&lt;p&gt;当开始开发一个新特性时，从develop分支中创建特性分支&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout -b myfeature develop
Switched to a new branch &quot;myfeature&quot;&lt;/pre&gt;
&lt;h4&gt;在develop分支整合已经开发完成的特性&lt;/h4&gt;
&lt;p&gt;开发完成的特性必须合并到develop分支，即添加到即将发布的版本中。&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout develop
Switched to branch &#39;develop&#39;
$ git merge --no-ff myfeature
Updating ea1b82a..05e9557
(Summary of changes)
$ git branch -d myfeature
Deleted branch myfeature (was 05e9557).
$ git push origin develop&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;--no-ff&lt;/code&gt;参数的作用是在合并的时候，会创建一个新的提交对象，即使是fast-forward方式的合并。这就避免了丢失特性分支的历史记录信息以及提交记录信息。比较一下&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/4502bb84bffab2acb8fc87b0d86b008a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;在右面的例子中，是不可能从Git历史记录中看到一个已经实现了的特性的所有提交对象-除非你去查看所有的日志信息。要想获取整个特性分支信息，在右面的例子中的确是一个头疼的问题，但是如果使用&lt;code&gt;--no-ff&lt;/code&gt;参数就没有这个问题。&lt;/p&gt;
&lt;p&gt;使用这个参数后，的确创建了一些新的提交对象(那怕是空提交对象)，但是很值得。&lt;/p&gt;
&lt;p&gt;不幸的是，我还没有找到一种方法使Git默认的merge操作带着&lt;code&gt;--no-ff&lt;/code&gt;参数，但的确应该这样。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;发布分支&lt;/h3&gt;
&lt;p&gt;从&lt;code&gt;develop&lt;/code&gt;分支去建立Release分支，Release分支必须合并到develop分支和master分支，Release分支名可以这样起名:&lt;code&gt;release-*。&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Release分支用于支持一个新版本的发布。他们允许在最后时刻进行一些小修小改。甚至允许进行一些小bug的修改，为新版本的发布准要一些元数据(版本号，构建时间等)。通过在release分支完成这些工作，&lt;code&gt;develop&lt;/code&gt;分支将会合并这些特性以备下一个大版本的发布。&lt;/p&gt;
&lt;p&gt;从&lt;code&gt;develop&lt;/code&gt;分支拉取新的release分支的时间点是当开发工作已经达到了新版本的期望值。至少在这个时间点，下一版本准备发布的所有目标特性必须已经合并到了&lt;code&gt;develop&lt;/code&gt;分支。更远版本的目标特性不必合并会develop分支。这些特性必须等到个性分支创建后，才能合并回develop分支&lt;/p&gt;
&lt;p&gt;在release分支创建好后，就会获取到一个分配好即将发布的版本号，不能更早，就在这个时间点。在此之前，develop分支代码反应出了下一版本的代码变更，但是到底下一版本是 0.3 还是 1.0，不是很明确，直到release分支被建立后一切都确定了。这些决定在release分支开始建立，项目版本号等项目规则出来后就会做出。&lt;/p&gt;
&lt;h4&gt;创建release分支&lt;/h4&gt;
&lt;p id=&quot;creating-a-release-branch&quot;&gt;从&lt;code&gt;develop&lt;/code&gt;分支创建release分支。例如1.1.5版本是当前产品的发布版本，我们即将发布一个更大的版本。&lt;code&gt;develop&lt;/code&gt;分支此时已经为下一版本准备好了，我们决定下一版的版本号是1.2(1.1.6或者2.0也可以)。所以我们创建release分支，并给分支赋予新的版本号:&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout -b release-1.2 develop
Switched to a new branch &quot;release-1.2&quot;
$ ./bump-version.sh 1.2
Files modified successfully, version bumped to 1.2.
$ git commit -a -m &quot;Bumped version number to 1.2&quot;
[release-1.2 74d9424] Bumped version number to 1.2
1 files changed, 1 insertions(+), 1 deletions(-)&lt;/pre&gt;
&lt;p&gt;创建好分支并切到这个分支后，我们给分支打上版本号。&lt;code&gt;bump-version.sh是一个虚构的shell脚本，它更改了工作空间的&lt;code&gt;某些文件来&lt;/code&gt;反映新版本特征。(当然也可以手动改变这些文件)，然后版本就被提交了。&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;新的分支会存在一段时间，直到新版本最终发布。在这段时间里，bug的解决可以在这个分支进行(不要在&lt;code&gt;develop&lt;/code&gt;分支进行)。此时是严禁添加新的大特性。这些修改必须合并回develop分支，之后就等待新版本的发布。&lt;/p&gt;
&lt;h4&gt;结束一个release分支&lt;/h4&gt;
&lt;p&gt;当release分支的准备成为一个真正的发布版本时，一些操作必须需要执行。首先，将release分支合并回&lt;code&gt;master&lt;/code&gt;分支(因为&lt;code&gt;master&lt;/code&gt;分支的每一次提交都是预先定义好的一个新版本，谨记)。然后为这次提交打tag，为将来去查看历史版本。最后在release分支做的更改也合并到develop分支，这样的话，将来的其他版本也会包含这些已经解决了的bug。&lt;/p&gt;
&lt;p&gt;在Git中需要两步完成:&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout master
Switched to branch &#39;master&#39;
$ git merge --no-ff release-1.2
Merge made by recursive.
(Summary of changes)
$ git tag -a 1.2&lt;/pre&gt;
&lt;p&gt;这样release分支已经完成工作，tag也已经打了。&lt;/p&gt;
&lt;p&gt;备注:你可以使用&lt;code&gt;-s&lt;/code&gt; or &lt;code&gt;-u &amp;lt;key&amp;gt;&lt;/code&gt;参数为你的tag设置标签签名。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;为了保存这些在release分支所做的变更，我们需要将这些变更合并回develop分支。执行如下Git命令:&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout develop
Switched to branch &#39;develop&#39;
$ git merge --no-ff release-1.2
Merge made by recursive.
(Summary of changes)&lt;/pre&gt;
&lt;p&gt;这步有可能会有合并冲突(极有可能，因为我们已经改变了版本号)。如果有冲突，解决掉他，然后提交。&lt;br&gt;
现在我们已经完成了工作，release分支可以删除了，因为我们不在需要他:&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git branch -d release-1.2
Deleted branch release-1.2 (was ff452fe).&lt;/pre&gt;
&lt;h2&gt;Hotfix分支&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/225f93ac35cb4238b4c05ede833d3490.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;Hotfix分支从master分支建立，必须合并回&lt;code&gt;develop&lt;/code&gt;分支和&lt;code&gt;master&lt;/code&gt;分支，为Hotfix分支可以这样起名:&lt;code&gt;hotfix-*&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Hotfix分支在某种程度上非常像release分支，他们都意味着为某个新版本发布做准备，并且都是预先不可知的。Hotfix分支是基于当前生产环境的产品的一个bug急需解决而必须创建的。当某个版本的产品有一个严重bug需要立即解决，Hotfix分支需要从master分支上该版本对应的tag上进行建立，因为这个tag标记了产品版本&lt;/p&gt;
&lt;h4&gt;创建hotfix分支&lt;/h4&gt;
&lt;p&gt;Hotfix分支从&lt;code&gt;master&lt;/code&gt;分支进行创建。例如当前线上1.2版本产品因为server端的一个Bug导致系统有问题。但是在&lt;code&gt;develop分支进行&lt;/code&gt;更改是不靠谱的，所以我们需要建立hotfix分支，然后开始解决问题:&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout -b hotfix-1.2.1 master
Switched to a new branch &quot;hotfix-1.2.1&quot;
$ ./bump-version.sh 1.2.1
Files modified successfully, version bumped to 1.2.1.
$ git commit -a -m &quot;Bumped version number to 1.2.1&quot;
[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1
1 files changed, 1 insertions(+), 1 deletions(-)&lt;/pre&gt;
&lt;p&gt;千万别忘记在创建分支后修改版本号。&lt;/p&gt;
&lt;p&gt;然后解决掉bug，提交一次或多次。&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git commit -m &quot;Fixed severe production problem&quot;
[hotfix-1.2.1 abbe5d6] Fixed severe production problem
5 files changed, 32 insertions(+), 17 deletions(-)&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;结束hotfix 分支&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;完成工作后，解决掉的bug代码需要合并回master分支，但同时也需要合并到&lt;code&gt;develop&lt;/code&gt;分支，目的是保证在下一版中该bug已经被解决。这多么像release分支啊。&lt;/p&gt;
&lt;p&gt;首先，对master分支进行合并更新，然后打tag&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout master
Switched to branch &#39;master&#39;
$ git merge --no-ff hotfix-1.2.1
Merge made by recursive.
(Summary of changes)
$ git tag -a 1.2.1&lt;/pre&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;备注:你可以使用&lt;code&gt;-s&lt;/code&gt; or &lt;code&gt;-u &amp;lt;key&amp;gt;&lt;/code&gt;参数为你的tag设置标签签名。&lt;/p&gt;
&lt;p&gt;紧接着，在develop分支合并bugfix代码&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout develop
Switched to branch &#39;develop&#39;
$ git merge --no-ff hotfix-1.2.1
Merge made by recursive.
(Summary of changes)&lt;/pre&gt;
&lt;p&gt;这里可能会有一些异常情况，&lt;strong&gt;当一个release分支存在时，hotfix 分支需要合并到release 分支，而不是&lt;code&gt;develop&lt;/code&gt;分支。&lt;/strong&gt;当release分支的使命完成后，合并回release分支的bugfix代码最终也会被合并到develop分支。(当&lt;code&gt;develop&lt;/code&gt;分支急需解决这些bug，而等不到release分支的结束，你可以安全的将这些bugfix代码合并到develop分支，这样做也是可以的)。&lt;/p&gt;
&lt;p&gt;最后删除这些临时分支&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git branch -d hotfix-1.2.1
Deleted branch hotfix-1.2.1 (was abbe5d6).&lt;/pre&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;这个分支模型其实没有什么震撼人心的新东西，这篇文章开始的那个“最大图片”已经证明了他在我们工程项目中的巨大作用。它会形成一种优雅的理想模型，而且很容易理解，该模型也允许团队成员形成一个关于分支和版本发布过程的相同理念。&lt;/p&gt;
&lt;p&gt;这里有提供一个高质量的分支模型图的PDF版本。去吧，把它挂在墙上随时快速参考。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://nvie.com/files/Git-branching-model.pdf&quot;&gt;&lt;img class=&quot;aligncenter&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/61c41705125bfe5e7aede02f6046b8cd.jpg&quot; width=&quot;128&quot;&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;http://nvie.com/files/Git-branching-model.pdf&quot;&gt; Git-branching-model.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;更新：&lt;/strong&gt;任何需要他的人,这里有一个主图的&lt;a href=&quot;http://github.com/downloads/nvie/gitflow/Git-branching-model-src.key.zip&quot;&gt;gitflow-model.src.key&lt;/a&gt;文件&lt;/p&gt;
&lt;p&gt;如果想和我取得联系，在推特上&lt;a href=&quot;http://twitter.com/nvie&quot;&gt;@nvie&lt;/a&gt;&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81196-6bf51109d.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81196-6bf51109d.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列基础篇（索引运算总结）</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上几篇文章我们介绍了如何&lt;a href=&quot;http://blog.jobbole.com/81176/&quot; target=&quot;_blank&quot;&gt;查看查询计划的方式&lt;/a&gt;、常用运算符（&lt;a href=&quot;http://blog.jobbole.com/81182/&quot; target=&quot;_blank&quot;&gt;连接运算符&lt;/a&gt;、&lt;a href=&quot;http://blog.jobbole.com/81184/&quot; target=&quot;_blank&quot;&gt;联合运算符&lt;/a&gt;）的介绍、并行运算的方式（&lt;a href=&quot;http://blog.jobbole.com/81186/&quot; target=&quot;_blank&quot;&gt;1&lt;/a&gt;、&lt;a href=&quot;http://blog.jobbole.com/81189/&quot; target=&quot;_blank&quot;&gt;2&lt;/a&gt;），有兴趣的可以点击查看。 本篇将分析在SQL Server中，如何利用先有索引项进行查询性能优化，通过了解这些索引项的应用方式可以指导我们如何建立索引、调整我们的查询语句，达到性能优化的目的。 闲言少叙，进入本篇的正题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt; 基于SQL Server2008R2版本，利用微软的一个更简洁的案例库（Northwind）进行解析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;简介&lt;/strong&gt; 所谓的索引应用就是在我们日常写的T-SQL语句中，如何利用现有的索引项，再分析的话就是我们所写的查询条件，其实大部分情况也无非以下几种：&lt;/p&gt;
&lt;p&gt;1、等于谓词：select …where…column=@parameter&lt;/p&gt;
&lt;p&gt;2、比较谓词：select …where…column&amp;gt; or &amp;lt; or  &amp;lt;&amp;gt; or &amp;lt;= or &amp;gt;= @parameter&lt;/p&gt;
&lt;p&gt;3、范围谓词：select …where…column in or not in  or between and @parameter&lt;/p&gt;
&lt;p&gt;4、逻辑谓词：select …where…一个谓词 or、and 其它谓词 or、and 更多谓词…. 我们就依次分析上面几种情况下，如何利用索引进行查询优化的&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、动态索引查找&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所谓的动态索引查找就是SQL Server在执行语句的时候，才格式化查询条件，然后根据查询条件的不同自动的去匹配索引项，达到性能提升的目的。 来举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SET SHOWPLAN_TEXT ON
GO
SELECT OrderID
FROM Orders
WHERE ShipPostalCode IN (N&#39;05022&#39;,N&#39;99362&#39;)&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/959475861d0ef7ebba7b411da09ea32b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;因为我们在表Orders的列ShipPostalCode列中建立了非聚集索引列，所以这里查询的计划利用了索引查找的方式。这也是需要建立索引的地方。 我们来利用文本的方式来查看该语句的详细的执行计划脚本，语句比较长，我用记事本换行，格式化查看 &lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f83962f492e6673824acebcc8893c34a.jpg&quot;&gt;我们知道这张表的该列里存在一个非聚集索引，所以在查询的时候要尽量使用，如果通过索引扫描的方式消耗就比价大了，所以SQL Server尽量想采取索引查找的方式，其实IN关键字和OR关键字逻辑是一样的。&lt;/p&gt;
&lt;p&gt;于是上面的查询条件就转换成了：&lt;/p&gt;
&lt;p&gt;[Northwind].[dbo].[Orders].[ShipPostalCode]=N’05022′&lt;/p&gt;
&lt;p&gt;OR&lt;/p&gt;
&lt;p&gt;[Northwind].[dbo].[Orders].[ShipPostalCode]=N’99362′&lt;/p&gt;
&lt;p&gt;这样就可以采用索引查找了，先查找第一个结果，然后再查找第二个，而这个过程在SQL Server中就被称为：动态索引查找。&lt;/p&gt;
&lt;p&gt;是不是有点智能的感觉了….&lt;/p&gt;
&lt;p&gt;所以有时候我们写语句的时候，尽量要使用SQL Server的这点智能了，让其能自动的查找到索引，提升性能。&lt;/p&gt;
&lt;p&gt;有时候偏偏我们写的语句让SQL Server的智能消失，举个例子：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;--参数化查询条件
DECLARE @Parameter1 NVARCHAR(20),@Parameter2 NVARCHAR(20)
SELECT @Parameter1=N&#39;05022&#39;,@Parameter2=N&#39;99362&#39;
SELECT OrderID
FROM Orders
WHERE ShipPostalCode IN (@Parameter1,@Parameter2)&lt;/pre&gt;
&lt;p&gt;我们将这两个静态的筛序值改成参数，有时候我们写的存储过程灰常喜欢这么做！我们来看这种方式的生成的查询计划 &lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fbc7f2e2425189ed01a993aa2b8cf8f1.jpg&quot;&gt;本来很简单的一个非聚集索引查找搞定的执行计划，我们只是将这两个数值没有直接写入IN关键字中，而是利用了两个变量来代替。&lt;/p&gt;
&lt;p&gt;看看上面SQL Server生成的查询计划！尼玛…这都是些啥？？？还用起来嵌套循环，我就查询了一个Orders表…你嵌套循环个啥….上面动态索引查找的能力去哪了？？？ 好吧，我们用文本查询计划来查看下，这个简单的语句到底在干些啥…&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt; |--Nested Loops(Inner Join, OUTER REFERENCES:([Expr1009], [Expr1010], [Expr1011]))
       |--Merge Interval
       |    |--Sort(TOP 2, ORDER BY:([Expr1012] DESC, [Expr1013] ASC, [Expr1009] ASC, [Expr1014] DESC))
       |         |--Compute Scalar(DEFINE:([Expr1012]=((4)&amp;amp;[Expr1011]) = (4) AND NULL = [Expr1009], [Expr1013]=(4)&amp;amp;[Expr1011], [Expr1014]=(16)&amp;amp;[Expr1011]))
       |              |--Concatenation
       |                   |--Compute Scalar(DEFINE:([Expr1004]=[@Parameter2], [Expr1005]=[@Parameter2], [Expr1003]=(62)))
       |                   |    |--Constant Scan
       |                   |--Compute Scalar(DEFINE:([Expr1007]=[@Parameter1], [Expr1008]=[@Parameter1], [Expr1006]=(62)))
       |                        |--Constant Scan
       |--Index Seek(OBJECT:([Northwind].[dbo].[Orders].[ShipPostalCode]), SEEK:([Northwind].[dbo].[Orders].[ShipPostalCode] &amp;gt; [Expr1009] AND [Northwind].[dbo].[Orders].[ShipPostalCode] &amp;lt; [Expr1010]) ORDERED FORWARD)&lt;/pre&gt;
&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;挺复杂的是吧，其实我分析了一下脚本，关于为什么会生成这个计划脚本的原因，是为了解决如下几个问题：&lt;/p&gt;
&lt;p&gt;1、前面我们写的脚本在IN里面写的是两个常量值，并且是不同的值，所以形成了两个索引值的查找通过OR关键字组合， 这种方式貌似没问题，但是我们将这两个数值变成了参数，这就引来了新的问题，假如这两个参数我们输入的是相等的，那么利用前面的执行计划就会生成如下&lt;/p&gt;
&lt;p&gt;[Northwind].[dbo].[Orders].[ShipPostalCode]=N’05022′&lt;/p&gt;
&lt;p&gt;OR&lt;/p&gt;
&lt;p&gt;[Northwind].[dbo].[Orders].[ShipPostalCode]=N’05022′&lt;/p&gt;
&lt;p&gt;这样执行产生的输出结果就是2条一样的输出值！…但是表里面确实只有1条数据…所以这样输出结果不正确！ 所以变成参数后首先解决的问题就是去重问题，2个一样的变成1个。&lt;/p&gt;
&lt;p&gt;2、上面变成参数，还引入了另外一个问题，加入我们两个值有一个传入的为Null值，或者两个都为Null值，同样输出结果面临着这样的问题。所以这里还要解决的去Null值的问题。   为了解决上面的问题，我们来粗略的分析一下执行计划，看SQL Server如何解决这个问题的 &lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a5932aa87d836f49e0475da3da6cb8e7.jpg&quot;&gt;简单点将就是通过扫描变量中的值，然后将内容进行汇总值，然后在进行排序，再将参数中的重复值去掉，这样获取的值就是一个正确的值，最后拿这些去重后的参数值参与到嵌套循环中，和表Orders进行索引查找。&lt;/p&gt;
&lt;p&gt;但是分析的过程中，有一个问题我也没看明白，就是最好的经过去重之后的常量汇总值，用来嵌套循环连接的时候，在下面的索引查找的时候的过滤条件变成了 and  查找 &lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3e9829cc38b921fe11ddc313ad89106f.jpg&quot;&gt;我将上面的最后的索引查找条件，整理如下：&lt;/p&gt;
&lt;p&gt;|–Index Seek(OBJECT:([Northwind].[dbo].[Orders].[ShipPostalCode]), SEEK:&lt;/p&gt;
&lt;p&gt;(&lt;/p&gt;
&lt;p&gt;[Northwind].[dbo].[Orders].[ShipPostalCode] &amp;gt; [Expr1009]&lt;/p&gt;
&lt;p&gt;AND&lt;/p&gt;
&lt;p&gt;[Northwind].[dbo].[Orders].[ShipPostalCode] &amp;lt; [Expr1010]&lt;/p&gt;
&lt;p&gt;) ORDERED FORWARD)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这个地方怎么搞的？我也没弄清楚，还望有看明白童鞋的稍加指导下….&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;好了，我们继续&lt;/p&gt;
&lt;p&gt;上面的执行计划中，提到了一个新的运算符：合并间隔（merge interval operator）&lt;/p&gt;
&lt;p&gt;我们来分析下这个运算符的作用，其实在上面我们已经在执行计划的图中标示出该运算符的作用了，去掉重复值。&lt;/p&gt;
&lt;p&gt;其实关于去重的操作有很多的，比如前面文章中我们提到的各种去重操作。&lt;/p&gt;
&lt;p&gt;这里怎么又冒出个合并间隔去重？其实原因很简单，因为我们在使用这个运算符之前已经对结果进行了排序操作，排序后的结果项重复值是紧紧靠在一起的，所以就引入了合并间隔的方式去处理，这样性能是最好的。&lt;/p&gt;
&lt;p&gt;更重要的是合并间隔这种运算符应用场景不仅仅局限于重复值的去除，更重要的是还应用于重复区间的去除。 来看下面的例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;--参数化查询条件
DECLARE @Parameter1 DATETIME,@Parameter2 DATETIME
SELECT @Parameter1=&#39;1998-01-01&#39;,@Parameter2=&#39;1998-01-04&#39;
SELECT OrderID 
FROM ORDERS
WHERE OrderDate BETWEEN @Parameter1 AND DATEADD(DAY,6,@Parameter1)
OR OrderDate BETWEEN @Parameter2 AND DATEADD(DAY,6,@Parameter2)&lt;/pre&gt;
&lt;p&gt;我们看看这个生成的查询计划项 &lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/47c1a3d7eb97048994de1d1ae9ba62d6.jpg&quot;&gt;可以看到，SQL Server为我们生成的查询计划，和前面我们写的语句是一模一样的，当然我们的语句也没做多少改动，改动的地方就是查询条件上。&lt;/p&gt;
&lt;p&gt;我们来分析下这个查询条件：&lt;/p&gt;
&lt;p&gt;WHERE OrderDate BETWEEN @Parameter1 AND DATEADD(DAY,6,@Parameter1)&lt;/p&gt;
&lt;p&gt;OR OrderDate BETWEEN @Parameter2 AND DATEADD(DAY,6,@Parameter2)&lt;/p&gt;
&lt;p&gt;很简单的筛选条件，要获取订单日期在1998-01-01开始到1998-01-07内的值或者1998-01-04开始到1998-01-10内的值（不包含开始日期）&lt;/p&gt;
&lt;p&gt;这里用的逻辑谓词为：OR…其实也就等同于我们前面写的IN&lt;/p&gt;
&lt;p&gt;但是我们这里再分析一下，你会发现这两个时间段是重叠的 &lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/07e07944fc7d7b01be834be7e674b6d1.jpg&quot;&gt;这个重复的区间值，如果用到前面的直接索引查找，在这段区间之内的搜索出来的范围值就是重复的，所以为了避免这种问题，SQL Server又引入了“合并间隔”这个运算符。&lt;/p&gt;
&lt;p&gt;其实，经过上面的分析，我们已经分析出这种动态索引查找的优缺点了，有时候我们为了避免这种复杂的执行计划生成，使用最简单的方式就是直接传值进入语句中（当然这里需要重编译），当然大部分的情况我们写的程序都是只定义的参数，然后进行的运算。可能带来的麻烦就是上面的问题，当然有时候参数多了，为了合并间隔所应用的排序就消耗的内存就会增长。怎么使用，根据场景自己酌情分析。&lt;/p&gt;
&lt;p&gt;二&lt;strong&gt;、索引联合&lt;/strong&gt; 所谓的索引联合，就是根据就是根据筛选条件的不同，拆分成不同的条件，去匹配不同的索引项。 举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT OrderID 
FROM ORDERS
WHERE OrderDate BETWEEN &#39;1998-01-01&#39; AND &#39;1998-01-07&#39;
OR ShippedDate BETWEEN &#39;1998-01-01&#39; AND &#39;1998-01-07&#39;&lt;/pre&gt;
&lt;p&gt;这段代码是查询出订单中的订单日期在1998年1月1日到1998年1月7日的或者发货日期同样在1998年1月1日到1998年1月7日的。&lt;/p&gt;
&lt;p&gt;逻辑很简单，我们知道在这种表里面这两个字段都有索引项。所以这个查询在SQL Server中就有了两个选择：&lt;/p&gt;
&lt;p&gt;1、一次性的来个索引扫描根据匹配结果项输出，这样简单有效，但是如果订单表数据量比较大的话，性能就会很差，因为大部分数据就根本不是我们想要的，还要浪费时间去扫描。&lt;/p&gt;
&lt;p&gt;2、就是通过两列的索引字段直接查找获取这部分数据，这样可以直接减少数据表的扫描量，但是带来的问题就是，如果分开扫描，有一部分数据就是重复的：那些同时在1998年1月1日到1998年1月7日的订单，发货日期也在这段时间内，因为两个扫描项都包含，所以再输出的时候需要将这部分重复数据去掉。&lt;/p&gt;
&lt;p&gt;我们来看SQL Server如何选择&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/cffdc85f7c4eb6f5ff90954bdfc6bdce.jpg&quot;&gt;看来SQL Server经过评估选择了第2中方法。但是上面的方法也不尽完美，采用去重操作耗费了64%的资源。&lt;/p&gt;
&lt;p&gt;其实，上面的方法，我们根据生成的查询计划可以变通的使用以下逻辑，其效果和上面的语句是一样的，并且生成的查询计划也一样&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT OrderID 
FROM ORDERS
WHERE OrderDate BETWEEN &#39;1998-01-01&#39; AND &#39;1998-01-07&#39;
UNION 
SELECT OrderID 
FROM ORDERS
WHERE  ShippedDate BETWEEN &#39;1998-01-01&#39; AND &#39;1998-01-07&#39;&lt;/pre&gt;
&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/e3dd1707e5cac9631f2a430698a7a1a9.jpg&quot;&gt;  我们再来看一个索引联合的例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT OrderID 
FROM ORDERS
WHERE OrderDate = &#39;1998-01-01&#39; 
OR ShippedDate = &#39;1998-01-01&#39;&lt;/pre&gt;
&lt;p&gt;我们将上面的Between and不等式筛选条件改成等式筛选条件，我们来看一下这样形成的执行计划&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/242b70cdee9e76d80a6c2fa6be3982ab.jpg&quot;&gt;基本相同的语句，只是我们改变了不同的查询条件，但是生成的查询计划还是变化蛮大的，有几点不同之处：&lt;/p&gt;
&lt;p&gt;1、前面的用between…and  的筛选条件，通过索引查找返回的值进行组合是用的串联的方式，所谓的串联就是两个数据集拼凑在一起就行，无所谓顺序连接什么的。&lt;/p&gt;
&lt;p&gt;2、前面的用between…and  的筛选条件，通过串联拼凑的结果集去重的方式，是排序去重（Sort Distinct）…并且耗费了大量的资源。这里采用了流聚合来干这个事，基本不消耗&lt;/p&gt;
&lt;p&gt;我们来分析以下产生着两点不同的原因有哪些：&lt;/p&gt;
&lt;p&gt;首先、这里改变了筛选条件为等式连接，所通过索引查找所产生的结果项是排序的，并且按照我们所要查询的OrderID列排序，因此在两个数据集进行汇总的时候，正适合合并连接的条件！需要提前排序。所以这里最优的方式就是采用合并连接！&lt;/p&gt;
&lt;p&gt;那么前面我们用between…and  的筛选条件通过索引查找获取的结果项也是排序的，但是这里它没有按照OrderID排序，它是按照OrderDate或者ShippedDate列排序的，而我们的结果是要OrderID列，所以这里的排序是没用的……所以SQL Server只能选择一个串联操作，将结果汇聚到一起，然后在排序了……我希望这里我已经讲明白了…&lt;/p&gt;
&lt;p&gt;其次、关于去重操作，毫无疑问采用流聚合（Aggregate）这种方式最好，消耗内存少，速度又快…但是前提是要提前排序…前面选用的排序去重（Sort Distinct）纯属无奈之举…&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总结下：我们在写语句的时候能确定为等式连接，最好采用等式连接。还有就是如果能确定输出条件的最好能写入，避免多余的书签查找，还有万恶的SELEECT *….&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果写了万恶的SELECT *…那么你所写的语句基本上就可以和非聚集索引查找告别了….顶多就是聚集索引扫描或者RID查找…&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;瞅瞅以下语句&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT * 
FROM ORDERS
WHERE OrderDate = &#39;1998-01-01&#39; 
OR ShippedDate = &#39;1998-01-01&#39;&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3ac389d29ae91913e9790cc1ed0824fd.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;最后，奉上一个AND的一个连接谓词的操作方式，这个方式被称为：索引交叉，意思就是说如果两个或多个筛选条件如果采用的索引是交叉进行的，那么使用一个就可以进行查询。 来看个语句就明白了&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT OrderID 
FROM ORDERS
WHERE OrderDate = &#39;1998-01-01&#39; 
AND ShippedDate = &#39;1998-03-05&#39;&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9bc407cf9b8ab45689330c9cfb764165.jpg&quot;&gt;这里我们采用了的谓词连接方式为AND，所以在实际执行的时候，虽然两列都存在非聚集索引，理论都可以使用，但是我们只要选一个最优的索引进行查找，另外一个直接使用书签查找出来就可以。省去了前面介绍的各种神马排序去重….流聚合去重….等等不人性的操作。 看来AND连接符是一个很帅的运算符…所以很多时候我们在尝试写OR的情况下，不如换个思路改用AND更高效。   &lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微软联机丛书&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/ms191158(SQL.90).aspx&quot; target=&quot;_blank&quot;&gt;逻辑运算符和物理运算符引用&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;参照书籍《SQL.Server.2005.技术内幕》系列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt; 此篇文章主要介绍了索引运算的一些方式，主要是描述了我们平常在写语句的时候所应用的方式，并且举了几个例子，算作抛砖引玉吧，其实我们平常所写的语句中无非也就本篇文章中介绍的各种方式的更改，拼凑。而且根据此，我们该怎样建立索引也作为一个指导项。 下一篇我们介绍子查询一系列的内容，有兴趣可提前关注，关于SQL Server性能调优的内容涉及面很广，后续文章中依次展开分析。 有问题可以留言或者私信，随时恭候有兴趣的童鞋加入SQL SERVER的深入研究。共同学习，一起进步。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81193-13e555725.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81193-13e555725.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列基础篇（并行运算总结篇二）</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/81186/&quot; target=&quot;_blank&quot;&gt;上一篇文章我们介绍了查看查询计划的并行运行方式&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;本篇我们接着分析SQL Server的并行运算。&lt;/p&gt;
&lt;p&gt;闲言少叙，直接进入本篇的正题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;同前几篇一样，基于SQL Server2008R2版本，利用微软的一个更简洁的案例库（Northwind）进行解析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;内容&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;文章开始前，我们先来回顾上一篇中介绍的并行运算，来看文章最后介绍的并行运算语句：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT B1.[KEY],B1.DATA,B2.DATA 
FROM BigTable B1 JOIN BigTable2 B2
ON B1.[KEY]=B2.[KEY]
WHERE B1.DATA&amp;lt;100&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1626f90d3b4dabe350f056ff7212e1ad.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面是详细的执行计划，从右边依次向左执行，上图中有一个地方很有意思，就是在聚集索引扫描后获取的数据，又重新了使用了一次重新分配任务的过程&lt;/p&gt;
&lt;p&gt;（Repartition Streams），就是上图的将获取的100行数据重新分配到并行的各个线程中。&lt;/p&gt;
&lt;p&gt;其实这里本可以直接将索引扫描出来的100行数据直接扔到嵌套循环中执行。它这里又重新分配任务的目的就是为了后面嵌套循环的并行执行，最大限度的利用硬件资源！&lt;/p&gt;
&lt;p&gt;但这样做又带了另一个弊端就是执行完嵌套循环之后，需要将结果重新汇总，就是下面的（Gather Sreams）运算符。&lt;/p&gt;
&lt;p&gt;我们来看看该语句如果不并行的执行计划&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT B1.[KEY],B1.DATA,B2.DATA 
FROM BigTable B1 JOIN BigTable2 B2
ON B1.[KEY]=B2.[KEY]
WHERE B1.DATA&amp;lt;100
option(maxdop 1)&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/2979eea75768313c334555ad258aa585.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这才是正宗的串行执行计划。&lt;/p&gt;
&lt;p&gt;和上面的并行执行计划相比较，你会发现SQL Server充分利用硬件资源而形成的并行计划，是不是很帅！&lt;/p&gt;
&lt;p&gt;如果还没感觉到SQL Server并行执行计划的魅力，我们再来举个例子，看如下语句&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT BIG_TOP.[KEY],BIG_TOP.DATA,B2.DATA
FROM 
(
   SELECT TOP 100 B.[KEY],B.DATA
   FROM BigTable B
   ORDER BY DATA
) BIG_TOP,
BigTable2 B2
WHERE BIG_TOP.[KEY]=B2.[KEY]&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;先来分析下上面的语句，这个语句我们在外表中加入了TOP 100…..ORDER BY DATA关键字，这个关键字是很有意思….&lt;/p&gt;
&lt;p&gt;因为我们知道这个语句是获取根据DATA关键字排序，然后获取出前100行的意思…&lt;/p&gt;
&lt;p&gt;1、根据DATA排序…..丫的多线程我看你怎么排序？每个线程排列自己的？那你排列完了在汇聚在一起…那岂不是还得重新排序！！&lt;/p&gt;
&lt;p&gt;2、获取前100行数据，丫多线程怎么获取？假如我4个线程扫描每个线程获取25条数据？这样出来的结果对嘛？&lt;/p&gt;
&lt;p&gt;3、我们的目标是让外表和上面的100行数据还要并行嵌套循环连接，因为这样才能充分利用资源，这个怎么实现呢？&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;上面的这些问题，我们来看强大的SQL Server将为我们怎样生成强悍的执行计划&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1e79b272b6e8f5452bcc8fac03e5b1b2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面的执行计划已经解决了我们以上所述的三个问题，我们依次来分析下，这几个问题的解决方法&lt;/p&gt;
&lt;p&gt;第一个问题，关于并列排序问题&lt;/p&gt;
&lt;p&gt;首选根据聚集索引扫描的方式采用并列的方式从表中获取出数据&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/487dc679d9ad8caa187844b2dc0115d1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后，在并行的根据各个线程中的数据进行排序，获取前几列值，我们知道，我们的目标获取的是前100行，它这里获取的方式是冗余获取，也就是说每个线程各自排序自己的数据&lt;/p&gt;
&lt;p&gt;然后获取出前面的数据，通过循环赛的方式进行交换，获取出一部分数据&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6ca7f892d188fd3cce023fa3163eee0f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;第二个问题，关于并列获取前100行数据问题&lt;/p&gt;
&lt;p&gt;我们知道要想获取前100行数据，就必须将各个线程的数据汇总到一起，然后通过比较获取前100行数据，这是必须的，于是在这一步里SQL Server又的重新将数据汇总到一起&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6fe31a22e4c6fcf8d318f445f31486c1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;第三个问题，下一步需要将这100行数据和外表进行连接，获取出结果，这里面采用的嵌套循环连接的方式，为了充分利用资源，提升性能，SQL Server又不得不将这100行数据均分到各个线程中去执行，所以这里又采用了一个拆分任务的运算符分发流（Distribute Sreams）任务&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/20cc1cb7827ae5132d5df187b6dfbe95.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;所以经过此步骤又将系统的硬件资源充分利用起来了，然后下一步同样就是讲过嵌套循环进行关联获取结果，然后再重新将结果汇总，然后输出&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1036eb78eb39f30ec963d5eee2a9403d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们可以看到上面的一个流程，SQLServer经过了：先拆分（并行扫描）——》再并行（获取TOP 100….）——》再拆分(为了并行嵌套循环)——》再并行（为了合并结果）&lt;/p&gt;
&lt;p&gt;总之，SQL Server在运行语句的时候，经过各种评估之后，利用各种拆分、各种汇总，目的就是充分的利用硬件资源，达到一个性能最优化的方式！这就是SQL Server并行运算的精髓。&lt;/p&gt;
&lt;p&gt;当然凡事有利就有弊，我们通过这条语句来对比一下串行和并行在SQL Server中的优劣项&lt;/p&gt;
&lt;p&gt;一下是串行执行计划：&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT BIG_TOP.[KEY],BIG_TOP.DATA,B2.DATA
FROM 
(
   SELECT TOP 100 B.[KEY],B.DATA
   FROM BigTable B
   ORDER BY DATA
) BIG_TOP,
BigTable2 B2
WHERE BIG_TOP.[KEY]=B2.[KEY]
option(maxdop 1)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/bfbca3d3053c9945a90891abf2dcaf2a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;串行执行的执行计划：简单、大气、没有复杂的各种拆分、各种汇总及并行。&lt;/p&gt;
&lt;p&gt;我们来比较下两者的不同项，先比较一个T-SQL语句的各个参数值：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1abd65bdb45130ef3a1e60a5667897e0.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/244b04328ef4be0ca04e591295a715f7.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;前者是串行、后者是并行&lt;/p&gt;
&lt;p&gt;串行编译耗费CPU：2、并行编译耗费CPU:10&lt;/p&gt;
&lt;p&gt;串行编译耗费内存：184、并行编译耗费内存：208&lt;/p&gt;
&lt;p&gt;串行编译耗时：2、并行编译耗时：81&lt;/p&gt;
&lt;p&gt;上面是采取并行的缺点：1、更消耗CPU、2、编译更消耗内存、3、编译时间更久&lt;/p&gt;
&lt;p&gt;我们来看一下并行的优点：&lt;/p&gt;
&lt;p&gt;上图中串行内存使用（1024），并行内存（448）&lt;/p&gt;
&lt;p&gt;优点就是：并行执行消耗内存更小&lt;/p&gt;
&lt;p&gt;当然还有一个更重要的优点：执行速度更快！&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/585e2d4fa48d56d564661000ab8475e0.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9ab8bc0581a6de1ba794097455ec9ab3.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;采用并行的执行方式，执行时间从218毫秒提升到187毫秒！数据量少，我机器性能差所以提升不明显！&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;在并行运算执行过程中，还有一种运算符经常遇到：位图运算符，这里我们顺带也介绍一下&lt;/p&gt;
&lt;p&gt;举个例子：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT B1.[KEY],B1.DATA,B2.[KEY] 
FROM BigTable B1 JOIN BigTable2 B2
ON B1.DATA=B2.DATA
WHERE B1.[KEY]&amp;lt;10000&lt;/pre&gt;
&lt;p&gt;这里我们获取大表中Key列小于10000行的数据。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/536ba709ea5f347994d2ff0bbcb80035.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上述的执行语句，就引入了位图计算。&lt;/p&gt;
&lt;p&gt;其实位图计算的目标很简单：&lt;strong&gt;提前过滤&lt;/strong&gt;，因为我们的语句中要求获取的结果项比较多10000行数据，在我们后面的线程中采用的并行扫描的方式获取出数据。由于数据量比较多的原因，各个线程在执行的过程中获取完数据的时间不同，为了避免因某个线程执行速度缓慢，导致整体堵塞，索引引入了位图运算，先将获取出来的部分结果过滤输出到前面的哈希匹配，完整执行。&lt;/p&gt;
&lt;p&gt;关于位图运算符更多详细可参照：&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/bb510541&quot;&gt;http://msdn.microsoft.com/zh-cn/library/bb510541&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此篇文章先到此吧，本篇主要是上一篇并行运算的一个延续，两篇文章介绍了SQL Server中关于并行运算的原理和使用方式，关于并行运算这块就到这吧，下一篇我们补充SQL Server中关于索引的利用方式和动态索引的内容，关于索引我相信很多了解数据库产品的人都熟悉，但是SQL Server中一些语句利用索引的方式可能还不清楚，我们下一篇分析这块，借此了解索引的建立方式和优化技巧，有兴趣可提前关注，关于SQL Server性能调优的内容涉及面很广，后续文章中依次展开分析。&lt;/p&gt;
&lt;p&gt;有问题可以留言或者私信，随时恭候有兴趣的童鞋加入SQL SERVER的深入研究。共同学习，一起进步。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81189-e246d0739.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81189-e246d0739.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列基础篇（并行运算总结）</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上三篇文章我们介绍了&lt;a href=&quot;http://blog.jobbole.com/81176/&quot; target=&quot;_blank&quot;&gt;查看查询计划的方式&lt;/a&gt;，以及一些&lt;a href=&quot;http://blog.jobbole.com/81182/&quot; target=&quot;_blank&quot;&gt;常用的连接运算符&lt;/a&gt;、&lt;a href=&quot;http://blog.jobbole.com/81184/&quot; target=&quot;_blank&quot;&gt;联合运算符的优化技巧&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;本篇我们分析SQL Server的并行运算，作为多核计算机盛行的今天，SQL Server也会适时调整自己的查询计划，来适应硬件资源的扩展，充分利用硬件资源，最大限度的提高性能。&lt;/p&gt;
&lt;p&gt;闲言少叙，直接进入本篇的正题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;同前几篇一样，基于SQL Server2008R2版本，利用微软的一个更简洁的案例库（Northwind）进行解析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、并行运算符&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在我们日常所写的T-SQL语句，并不是所有的最优执行计划都是一样的，其最优的执行计划的形成需要多方面的评估才可以，大部分根据SQL Server本身所形成的统计信息，然后对形成的多个执行计划进行评估，进而选出最优的执行方式。&lt;/p&gt;
&lt;p&gt;在SQL Server根据库内容形成的统计信息进行评估的同时，还要参照当前运行的硬件资源，有时候它认为最优的方案可能当前硬件资源不支持，比如：内存限制、CPU限制、IO瓶颈等，所以执行计划的优劣还要依赖于底层硬件。&lt;/p&gt;
&lt;p&gt;当SQL Server发现某个处理的数据集比较大，耗费资源比较多时，但此时硬件存在多颗CPU时，SQL Server会尝试使用并行的方法，把数据集拆分成若干个，若干个线程同时处理，来提高整体效率。&lt;/p&gt;
&lt;p&gt;在SQL Server中可以通过如下方法，设置SQL Server可用的CPU个数&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c2f0bdc73b4c0b418cddf36583eae542.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;默认SQL Server会自动选择CPU个数，当然不排除某些情况下，比如高并发的生产环境中，防止SQL Server独占所有CPU，所以提供了该配置的界面。&lt;/p&gt;
&lt;p&gt;还有一个系统参数，就是我们熟知的MAXDOP参数，也可以更改此系统参数配置，该配置也可以控制每个运算符的并行数（记住：这里是每个运算符的，而非全部的），我们来查看该参数&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/bb02def16855f529a1a109601c7301de.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个并行运算符的设置数，指定的是每个运算符的最大并行数，所以有时候我们利用查看系统任务数的DMV视图sys.dm_os_tasks来查看，很可能看到大于并行度的线程数据量，也就是说线程数据可能超过并行度，原因就是两个运算符重新划分了数据，分配到不同的线程中。&lt;/p&gt;
&lt;p&gt;这里如没特殊情况的话，建议采用默认设置最佳。&lt;/p&gt;
&lt;p&gt;我们举一个分组的例子，来理解并行运算&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/15f5fa26bffbcf5469f2e5f3e84b0e8a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;采用并行运算出了提升性能还有如下几个优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不依赖于线程的数量，在运行时自动的添加或移除线程，在保证系统正常吞吐率的前提下达到一个性能最优值&lt;/li&gt;
&lt;li&gt;能够适应倾斜和负载均衡，比如一个线程运行速度比其它线程慢，这个线程要扫描或者运行的数量会自动减少，而其它跑的快的线程会相应提高任务数，所以总的执行时间就会平稳的减少，而非一个线程阻塞整体性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面我们来举个例子，详细的说明一下&lt;/p&gt;
&lt;p&gt;并行计划一般应用于数据量比较大的表，小表采用串行的效率是最高的，所以这里我们新建一个测试的大表，然后插入部分测试数据，我们插入250000行，整体表超过6500页，脚本如下&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;--新建表，建立主键，形成聚集索引
CREATE TABLE BigTable
(
   [KEY] INT,
   DATA INT,
   PAD CHAR(200),
   CONSTRAINT [PK1] PRIMARY KEY ([KEY])
)
GO
--批量插入测试数据250000行
SET NOCOUNT ON 
DECLARE @i INT
BEGIN TRAN
    SET @i=0
    WHILE @i&amp;lt;250000
    BEGIN
       INSERT BigTable VALUES(@i,@i,NULL)
       SET @i=@i+1
       IF @i%1000=0
       BEGIN
          COMMIT TRAN
          BEGIN TRAN
       END
END    
COMMIT TRAN
GO&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;我们来执行一个简单查询的脚本&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT [KEY],[DATA]
FROM BigTable&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8d7127de51524ed8295a0571fa7a9ff7.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里对于这种查询脚本，没有任何筛选条件的情况下，没必要采用并行扫描，因为采用串行扫描的方式得到数据的速度反而比并行扫描获取的快，所以这里采用了clustered scan的方式，我们来加一个筛选条件看看&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT [KEY],[DATA]
FROM BigTable
WHERE DATA&amp;lt;1000&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/efeac598ce77d13a3421d821357576fa.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;对于这个有筛选条件的T-SQL语句，这里SQL Server果断的采用的并行运算的方式，聚集索引也是并行扫描，因为我电脑为4个逻辑CPU(其实是2颗物理CPU，4线程)，所以这里使用的是4线程并行扫描四次表，每个线程扫描一部分数据，然后汇总。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/18bea2d366c1ce1ce047e3fdf9e13610.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里总共用了4个线程，其中线程0为调度线程，负责调度所有的其它线程，所以它不执行扫描，而线程1到线程4执行了这1000行的扫描！当然这里数据量比较少，有的线程分配了0个任务，但是总得扫描次数为4次，所以这4个线程是并行的扫描了这个表。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;可能上面获取的结果比较简单，有的线程任务还没有给分配满，我们来找一个相对稍复杂的语句&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT MIN([DATA])
FROM BigTable&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/49bfae5d5064e6e4c7b77f1537f3e719.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个执行计划挺简单的，我们依次从右边向左分析，依次执行为：&lt;/p&gt;
&lt;p&gt;4个并行聚集索引扫描——&amp;gt;4个线程并行获取出前当前线程的最小数——&amp;gt;执行4个最小数汇总——&amp;gt;执行流聚合获取出4个数中的最小值——&amp;gt;输出结果项。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c6c10f5c90a956c8ffb12e7a799a5335.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后4个线程，每个线程一个流聚合获取当前线程的最小数&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/887a15feab88feb064098e28350e64da.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后，将这个四个最小值经过下一个“并行度”的运算符汇聚成一个表&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1d2e19d10e78e99e0926ff42fde59075.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后下一个就是流聚合，从这个4行数据中获取出最小值，进行输出，关于流聚合我们上一篇文章中已经介绍&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ab028e94471985a779f5b7b5ee102074.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;以上就一个一个标准的多线程并行运算的过程。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;上面的过程中，因为我们使用的并行聚集索引扫描数据，4个线程基本上是平均分摊了任务量，也就是说每个线程扫描的数据量基本相等，下面我们将一个线程使其处于忙碌状态，看看SQL Server会不会将任务动态的平摊到其它几个不忙碌的线程上。&lt;/p&gt;
&lt;p&gt;我们在来添加一个大数据量表，脚本如下&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT [KEY],[DATA],[PAD] 
INTO BigTable2
FROM BigTable&lt;/pre&gt;
&lt;p&gt;我们来写一个大量语句的查询，使其占用一个线程，并且我们这里强制指定只用一个线程运行&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT MIN(B1.[KEY]+B2.[KEY]) 
FROM BigTable B1 CROSS JOIN BigTable2 B2
OPTION(MAXDOP 1)&lt;/pre&gt;
&lt;p&gt;以上代码想跑出结果，就我这个电脑配置估计少说五分钟以上，并且我们还强行串行运算，速度可想而知，&lt;br&gt;
我们接着执行上面的获取最小值的语句，查看执行计划&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT MIN([DATA])
FROM BigTable&lt;/pre&gt;
&lt;p&gt;我们在执行计划中，查看到了聚集索引扫描的线程数量&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c97eacdc3b1747bbaf7d9bec918c9988.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看到，线程1已经数量减少了近四分之的数据，并且从线程1到线程4，所扫描的数据量是依次增加的。&lt;/p&gt;
&lt;p&gt;我们上面的语句很明确的指定了MAXDOP为1，理论上讲只可能会影响一个线程，为什么这几个线程都影响呢？其实这个原因很简单，我的电脑是物理CPU只有两核，所谓的线程数只是超线程，所以非传统意义上的真正的4核数，所以线程之间是互相影响的。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;我们来看一个并行连接操作的例子，我们查看并行嵌套循环是怎样利用资源的&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT B1.[KEY],B1.DATA,B2.DATA 
FROM BigTable B1 JOIN BigTable2 B2
ON B1.[KEY]=B2.[KEY]
WHERE B1.DATA&amp;lt;100&lt;/pre&gt;
&lt;p&gt;上面的语句中，我们在BigTable中Key列存在聚集索引，而查询条件中DATA列不存在，所以这里肯定为聚集索引扫描，对数据进行查找&lt;/p&gt;
&lt;p&gt;来看执行计划&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/42b6fa34356413c5640274ddd1c68763.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们依次来分析这个流程，结合文本的执行计划分析更为准确，从右边依次向左分析&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/aa1bbf8be5c6e789049bf9672b3d3ab7.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;第一步，就是利用全表通过聚集索引扫描获取出数据，因为这里采用的并行的聚集索引扫描，我们来看并行的线程数和扫描数&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/10bf43a9be037d77d11d2925ef16517e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;四个线程扫描，这里线程3获取出数据100行数据。&lt;/p&gt;
&lt;p&gt;然后将这100行数据，重新分配线程，这里每个线程平均分配到25行数据&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3c082a7f60509cb026af80e202bd4420.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;到此，我们要获取的结果已经均分成4个线程共同执行，每个线程分配了25行数据，下一步就是交给嵌套循环连接了，因为我们上面的语句中需要从BigTable2中获取数据行，所以这里选择了嵌套循环，依次扫描BigTable2获取数据。&lt;/p&gt;
&lt;p&gt;关于嵌套循环连接运算符，可以参照我的第二篇文章。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/527240fbb764e3637717a2ef2e55a13b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们知道这是外表的循环数，也就是说这里会有4个线程并行执行嵌套循环。如果每个线程均分25行，数据那么内部表就要执行&lt;/p&gt;
&lt;p&gt;4*25=100次。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ade88dfef52c75f3dc22799955d7b481.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后，执行完，嵌套扫描获取结果后，下一步就是，将各个线程执行的结果通过并行运算符汇总，然后输出&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9111291744a2a80ea310ab4bc1dfca9d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上述过程就是一个并行嵌套循环的执行流程。充分利用了四核的硬件资源。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微软联机丛书&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/ms191158(SQL.90).aspx&quot; target=&quot;_blank&quot;&gt;逻辑运算符和物理运算符引用&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;参照书籍《SQL.Server.2005.技术内幕》系列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此篇文章先到此吧，文章短一点，便于理解掌握，后续关于并行操作还有一部分内容，后续文章补充吧，本篇主要介绍了查询计划中的并行运算符，下一篇我们接着补充一部分SQL Server中的并行运算，然后分析下我们日常所写的增删改这些操作符的优化项，有兴趣可提前关注，关于SQL Server性能调优的内容涉及面很广，后续文章中依次展开分析。&lt;/p&gt;
&lt;p&gt;有问题可以留言或者私信，随时恭候有兴趣的童鞋加入SQL SERVER的深入研究。共同学习，一起进步。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81186-49d084331.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81186-49d084331.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列基础篇（联合运算符总结）</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上两篇文章我们介绍了&lt;a href=&quot;http://blog.jobbole.com/81176/&quot; target=&quot;_blank&quot;&gt;查看查询计划的方式&lt;/a&gt;，以及一些&lt;a href=&quot;http://blog.jobbole.com/81182/&quot; target=&quot;_blank&quot;&gt;常用的连接运算符的优化技巧&lt;/a&gt;，本篇我们总结联合运算符的使用方式和优化技巧。&lt;/p&gt;
&lt;p&gt;废话少说，直接进入本篇的主题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;基于SQL Server2008R2版本，利用微软的一个更简洁的案例库（Northwind）进行解析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、联合运算符&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所谓的联合运算符，其实应用最多的就两种：UNION ALL和UNION。&lt;/p&gt;
&lt;p&gt;这两个运算符用法很简单，前者是将两个数据集结果合并，后者则是合并后进行去重操作，如果有过写T-SQL语句的码农都不会陌生。&lt;/p&gt;
&lt;p&gt;我们来分析下这两个运算符在执行计划中的显示，举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT FirstName+N&#39;&#39;+LastName,City,Country FROM Employees
UNION ALL
SELECT ContactName,City,Country FROM Customers&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a573e1f1c88074e1831001ecce1cbd97.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;就是上面这个图标了，这就是UNION ALL联合运算符的图标。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0d877d98b1c0d32a7df2a9e13bfe632d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个联合运算符很简单的操作，将两个数据集合扫描完通过联合将结果汇总。&lt;/p&gt;
&lt;p&gt;我们来看一下UNION 这个运算符，例子如下&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;select City,Country from Employees
UNION
SELECT City,Country FROM Customers&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3ad0527989de6b497b6dbc9c1bf06240.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们可以看到，UNION 运算符是在串联运算符之后发生了一个Distinct Sort排序操作，经过这个操作会将结果集合中的重复值去掉。&lt;/p&gt;
&lt;p&gt;我们一直强调：大数据表的排序是一个非常耗资源的动作！&lt;/p&gt;
&lt;p&gt;所以，到这里我们已经找到了可优化的选项，去掉排序，或者更改排序方式。&lt;/p&gt;
&lt;p&gt;替换掉Distinct Sort排序操作的方式就是哈序聚合。Distinct Sort排序操作需要的内存和去除重复之前数据集合的数据量成正比，而哈希聚合需要的内存则是和去除重复之后的结果集成正比！&lt;/p&gt;
&lt;p&gt;所以如果数据行中重复值很多，那么相比而言通过哈希聚合所消耗的内存会少。&lt;/p&gt;
&lt;p&gt;我们来举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;select ShipCountry from Orders
UNION
SELECT ShipCountry FROM Orders&lt;/pre&gt;
&lt;p&gt;这个例子其实没啥用处，这里就是为了演示，我们来看一下结果&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/10a6f9571e62d7962386b8e51325f75e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们知道，这张表里这个ShipCountry是存在大面积重复值的，所以采用了哈希匹配来去重操作是最优的方式。&lt;/p&gt;
&lt;p&gt;其实，相比哈希匹配连接还有一种更轻量级的去重的连接方式：合并连接&lt;/p&gt;
&lt;p&gt;上一篇我已经分析了这个连接方法，用于两个数据集的连接方式，这里其实类似，应用前都必须先将原结果集合排序！&lt;/p&gt;
&lt;p&gt;我们知道优化的方式可以采用建立索引来提高排序速度。&lt;/p&gt;
&lt;p&gt;我们来重现这种去重方式，我们新建一个表，然后建立索引，代码如下&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;--新建表
SELECT EmployeeID,FirstName+N&#39; &#39;+LastName AS ContactName,City,Country
INTO NewEmployees
FROM Employees
GO
--添加索引
ALTER TABLE NewEmployees ADD CONSTRAINT PK_NewEmployees PRIMARY KEY(EmployeeID)
CREATE INDEX ContactName ON NewEmployees(ContactName)
CREATE INDEX ContactName ON CUSTOMERS(ContactName)
GO
--新建查询，这里一定要加上一个显示的Order by才能出现合并连接去重
SELECT ContactName FROM NewEmployees
UNION ALL
SELECT ContactName FROM Customers
ORDER BY ContactName&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/17ddcf5853ea7eb207bab193975799d1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;我们采用索引扫描的方式可以避免显式的排序操作。&lt;/p&gt;
&lt;p&gt;我们将UNION ALL改成UNION，该操作将会对两个数据集进行去重操作。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;--新建查询，这里一定要加上一个显示的Order by才能出现合并连接去重
SELECT ContactName FROM NewEmployees
UNION 
SELECT ContactName FROM Customers
ORDER BY ContactName&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8be518bdedfb55620994cc6a9257510e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里我们知道UNION操作会对结果进行去重操作，上面应用了流聚合操作，流聚合一般应用于分组操作中，当然这里用它进行了分组去重。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;在我们实际的应用环境中，最常用的方式还是合并连接，但是有一种情况最适合哈希连接，那就是一个小表和大表进行联合操作，尤其适合哪种大表中存在大量重复值的情况下。&lt;/p&gt;
&lt;p&gt;哈希算法真是个好东西！&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微软联机丛书&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/ms191158(SQL.90).aspx&quot; target=&quot;_blank&quot;&gt;逻辑运算符和物理运算符引用&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;参照书籍《SQL.Server.2005.技术内幕》系列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此篇文章先到此吧，简短一点，便于理解掌握，本篇主要介绍了查询计划中的联合操作运算符，下一篇我们分析SQL Server中的并行运算，在多核超线程云集的今天，来看SQL Server如何利用并行运算来最大化的利用现有硬件资源提升性能，有兴趣可提前关注，关于SQL Server性能调优的内容涉及面很广，后续文章中依次展开分析。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SQL Server这个软件一旦深入进去，你会发现它真的非常深，基本可以用深不见底来描述，如果想研究里面的性能调优这块，可以关注本系列内容，我们一起研究！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;而且到现在还有很多人对SQL Server这套产品有误解，或者说观点有待纠正，以前就遇到过客户直接当我面大谈神马SQL Server导入数据一多就宕机了….&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;神马SQL Server只能做小数据量的应用…神马不如Oracle云云….!!!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;还有一部分童鞋单纯的认为SQL Server是小儿科，没啥技术含量…简单的很….&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关于这些观点，我不想吐槽啥，我只想让那些真正了解SQL Server的朋友一起来为SQL Server证明点什么。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81184-b98707bf0.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81184-b98707bf0.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列基础篇（常用运算符总结）</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/81176/&quot; target=&quot;_blank&quot;&gt;上一篇我们介绍了如何查看查询计划&lt;/a&gt;，本篇将介绍在我们查看的查询计划时的分析技巧，以及几种我们常用的运算符优化技巧，同样侧重基础知识的掌握。&lt;/p&gt;
&lt;p&gt;通过本篇可以了解我们平常所写的T-SQL语句，在SQL Server数据库系统中是如何分解执行的，数据结果如何通过各个运算符组织形成的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;基于SQL Server2008R2版本，利用微软的一个更简洁的案例库（Northwind）进行解析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、数据连接&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据连接是我们在写T-SQL语句的时候最常用的，通过两个表之间关联获取想要的数据。&lt;/p&gt;
&lt;p&gt;SQL Server默认支持三种物理连接运算符：嵌套循环连接、合并连接以及哈希连接。三种连接各有用途，各有特点，不同的场景会数据库会为我们选择最优的连接方式。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;a、嵌套循环连接（nested loops join)&lt;/p&gt;
&lt;p&gt;嵌套循环连接是最简单也是最基础的连接方式。两张表通过关键字进行关联，然后通过双层循环依次进行两张表的行进行关联，然后通过关键字进行筛选。&lt;/p&gt;
&lt;p&gt;可以参照下图进行理解分析&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0874fd611a6f3672c0d2c599d6a28a44.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;其实嵌套扫描是很简单的获取数据的方式，简单点就是两层循环过滤出结果值。&lt;/p&gt;
&lt;p&gt;我们可以通过如下代码加深理解&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;for each row R1 in the outer table
   for each row R2 int the inner table
       if R1 join with R2
       return (R1,R2)&lt;/pre&gt;
&lt;p&gt;举个列子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT o.OrderID
FROM Customers C JOIN Orders O
ON C.CustomerID=O.CustomerID
WHERE C.City=N&#39;London&#39;&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/05f41e19adbfb416d6bcaa2e85419ab9.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;以上这个图标就是嵌套循环连接的图标了。而且解释的很明确。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/70a0b415fcc526028e8e67b7c8d5d546.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这种方法的消耗就是外表和内表的乘积，其实就是我们所称呼的笛卡尔积。所以消耗的大小是随着两张表的数据量增大而增加的，尤其是内部表，因为它是多次重复扫描的，所以我们在实践中的采取的措施就是减少每个外表或者内表的行数来减少消耗。&lt;/p&gt;
&lt;p&gt;对于这种算法还有一种提高性能的方式，因为两张表是通过关键字进行关联的，所以在查询的时候对于底层的数据获取速度直接关乎着此算法的性能，这里优化的方式尽量使用两个表关键字为索引查询，提高查询速度。&lt;/p&gt;
&lt;p&gt;还有一点就是在嵌套循环连接中，在两张表关联的时候，对外表都是有筛选条件的，比如上面例子中【WHERE C.City=N’London’】就是对外表（Customers）的筛选，并且这里的City列在该表中存在索引，所以该语句的两个子查询都为索引查找（Index Seek）。&lt;/p&gt;
&lt;p&gt;但是，有些情况我们的查询条件不是索引所覆盖的，这时候，在嵌套循环连接下的子运算符就变成了索引扫描（Index scan）或者RID查找。&lt;/p&gt;
&lt;p&gt;举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT E1.EmployeeID,COUNT(*)
FROM Employees E1 JOIN Employees E2
ON E1.HireDate&amp;lt;E2.HireDate
GROUP BY E1.EmployeeID&lt;/pre&gt;
&lt;p&gt;以上代码是从职工表中获取出每位职工入职前的人员数。我们看一下该查询的执行计划&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/10c3ce0032fbfdc625752099b274c37e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里很显然两个表的关联通过的是HireDate列进行，而此列又不为索引项所覆盖，所以两张表的获取只能通过全表的聚集索引扫描进行，如果这两张表数据量特别大的话，无疑又是一个非常耗性能的查询。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a56b0b56208dc3a14aac1d54014994c7.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;通过文本可以看出，该T-SQL的查询结果的获取是通过在嵌套循环运算符中，对两个表经过全表扫描之后形成的笛卡儿积进行过滤筛选的。这种方式其实不是一个最优的方式，因为我们获取的结果其实是可以先通过两个表过滤之后，再通过嵌套循环运算符获取结果，这样的话性能会好很多。&lt;/p&gt;
&lt;p&gt;我们尝试改一下这个语句&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT E1.EmployeeID,ECNT.CNT 
FROM Employees E1 CROSS APPLY
(
   SELECT COUNT(*) CNT
   FROM Employees E2
   WHERE E1.HireDate&amp;lt;E2.HireDate
)ECNT&lt;/pre&gt;
&lt;p&gt;通过上述代码查询的结果项，和上面的是一样的，只是我们根据外部表的结果对内部表进行了过滤，这样执行的时候就不需要获取全部数据项了。&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5b4fb491c63a22c116564037f41026c2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们查看下文本执行计划&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b96a531bed7d3f704aef2cbfb74e461a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们比较一下，前后两条语句的执行消耗，对比一下执行效率&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/e02f0191c46caa4f50b9b36dbd090fdd.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/4eb668c160b958ecee8f2ebdea64bebc.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;执行时间从1秒179毫秒减少至93毫秒。效果明显。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ff23cb3cc99abd5b5621a602e8bab060.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/555314ae6b3a71130a35352aec28c4e0.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;对比CPU消耗、内存、编译时间等总体消耗都有所降低，参考上图。&lt;/p&gt;
&lt;p&gt;所以对嵌套循环连接连接的优化方式就是集中在这几点：对两张表数据量的减少、连接关键字上建立索引、谓词查询条件上覆盖索引最好能减少符合谓词条件的记录数。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;b、合并连接(merge join)&lt;/p&gt;
&lt;p&gt;上面提到的嵌套循环连接方式存在着诸多的问题，尤其不适合两张表都是大表的情况下，因为它会产生N多次的全表扫描，很显然这种方式会严重的消耗资源。&lt;/p&gt;
&lt;p&gt;鉴于上述原因，在数据库里又提供了另外一种连接方式：合并连接。记住这里没有说SQL Server所提供的，是因为此连接算法是市面所有的RDBMS所共同使用的一种连接算法。&lt;/p&gt;
&lt;p&gt;合并连接是依次读取两张表的一行进行对比。如果两个行是相同的，则输出一个连接后的行并继续下一行的读取。如果行是不相同的，则舍弃两个输入中较少的那个并继续读取，一直到两个表中某一个表的行扫描结束，则执行完毕，所以该算法执行只会产生每张表一次扫描，并且不需要整张表扫描完就可以停止。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f3b087e8bd1d85315898e22614365d2a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;该算法要求按照两张表进行依次扫描对比，但是有两个前提条件：1、必须预先将两张表的对应列进行排序；2、对两张表进行合并连接的条件必须存在等值连接。&lt;/p&gt;
&lt;p&gt;我们可以通过以下代码进行理解&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;get first row R1 from input1
get first row R2 from input2
while not at the end of either input
begin
     if R1 joins with R2
         begin
              output(R1,R2)
              get next row R2 from input2
         end
     else if R1&amp;lt;R2   
             get next row R1 from input1
          else
             get next row R2 from input2
end&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;合并连接运算符总的消耗是和输入表中的行数成正比的，而且对表最多读取一次，这个和嵌套循环连接不一样。因此，合并连接对于大表的连接操作是一个比较好的选择项。&lt;/p&gt;
&lt;p&gt;对于合并连接可以从如下几点提高性能：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;两张表间的连接值内容列类型，如果两张表中的关联列都为唯一列，也就说都不存在重复值，这种关联性能是最好的，或者有一张表存在唯一列也可以，这种方式关联为一对多关联方式，这种方式也是我们最常用的，比我们经常使用的主从表关联查询；如果两张表中的关联列存在重复值，这样在两表进行关联的时候还需要借助第三张表来暂存重复的值，这第三张表叫做”worktable “是存放在Tempdb或者内存中，而这样性能就会有所影响。所以鉴于此，我们常做的优化方式有：关联连尽量采用聚集索引（唯一性）&lt;/li&gt;
&lt;li&gt;我们知道采用该种算法的前提是，两张表都经过排序，所以我们在应用的时候，最好优先使用排序后的表关联。如果没有排序，也要选择的关联项为索引覆盖项，因为大表的排序是一个很耗资源的过程，我们选择索引覆盖列进行排序性能要远远好于普通列的排序。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们来举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT O.CustomerID,C.CustomerID,C.ContactName 
FROM Orders O JOIN Customers C
ON O.CustomerID=C.CustomerID&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/eaf6913315c1808e552750fa6d57385f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们知道这段T-SQL语句中关联项用的是CustomerID，而此列为主键聚集索引，都是唯一的并且经过排序的，所以这里面没有显示的排序操作。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/46062d4dfd905b3a1b6e82b0def2e6f2.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9fc238c29a50d57a0e0e7f76b37bc011.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;而且凡是采用合并连接的所有输出结果项，都是已经经过排序的。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5d237a0209b5507fa45229ee3118b05a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们找一个稍复杂的情况，没有提前排序的利用合并查询的T-SQL&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT O.OrderID,C.CustomerID,C.ContactName
FROM Orders O JOIN Customers C
ON O.CustomerID=C.CustomerID AND O.ShipCity&amp;lt;&amp;gt;C.City
ORDER BY C.CustomerID&lt;/pre&gt;
&lt;p&gt;上述代码返回那些客户的发货订单不在客户本地的。&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a09453991d584a4363eeed7a7b545b39.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面的查询计划可以看出，排序的消耗总是巨大的，其实我们上面的语句按照逻辑应该是在合并连接获取数据后，才采用显示的按照CustomerID进行排序。&lt;/p&gt;
&lt;p&gt;但是因为合并连接运算符之前本身就需要排序，所以此处SQL Server采取了优先排序的策略，把排序操作提前到了合并连接之前进行，并且在合并连接之后，就不需要在做额外的排序了。&lt;/p&gt;
&lt;p&gt;这其实这里我们要求对查询结果排序，正好也利用了合并连接的特点。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;c、哈希连接(hash join)&lt;/p&gt;
&lt;p&gt;我们分析了上面的两种连接算法，两种算法各有特点，也各有自己的应用场景：嵌套循环连接适合于相对小的数据集连接，合并连接则应对与中型的数据集，但是又有它自己的缺点，比如要求必须有等值连接，并且需要预先排序等。&lt;/p&gt;
&lt;p&gt;那对于大型的数据集合的连接数据库是怎么应对的呢？那就是哈希连接算法的应用场景了。&lt;/p&gt;
&lt;p&gt;哈希连接对于大型数据集合的并行操作上都比其它方式要好很多，尤其适用于OLAP数据仓库的应用场景中。&lt;/p&gt;
&lt;p&gt;哈希连接很多地方和合并连接类似，比如都需要至少一个等值连接，同样支持所有的外连接操作。但不同于合并连接的是，哈希连接不需要预先对输入数据集合排序，我们知道对于大表的排序操作是一个很大的消耗，所以去除排序操作，哈希操作性能无疑会提升很多。&lt;/p&gt;
&lt;p&gt;哈希连接在执行的时候分为两个阶段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;构建阶段&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在构建阶段，哈希连接从一个表中读入所有的行，将等值连接键的行机型哈希话处理，然后创建形成一个内存哈希表，而将原来列中行数据依次放入不同的哈希桶中。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/78c0754b74ad0935ebb38511da47ee40.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;探索阶段&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在第一个阶段完成之后，开始进入第二个阶段探索阶段，该阶段哈希连接从第二个数据表中读入所有的行，同样也是在相同的等值连接键上进行哈希。哈希过程桶上一阶段，然后再从哈希表中探索匹配的行。&lt;/p&gt;
&lt;p&gt;上述的过程中，在第一个阶段的构建阶段是阻塞的，也就是说在，哈希连接必须读入和处理所有的构建输入，之后才能返回行。而且这一过程是需要一块内存存储提供支持，并且利用的是哈希函数，所以相应的也会消耗CPU等。&lt;/p&gt;
&lt;p&gt;并且上述流程过程中一般采用的是并发处理，充分利用资源，当然系统会对哈希的数量有所限制，如果数据量超大，也会发生内存溢出等问题，而对于这些问题的解决，SQL Server有它自身的处理方式。&lt;/p&gt;
&lt;p&gt;我们可通过以下代码进行理解&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;--构建阶段
for each row R1 in the build table
begin
   calculate hash value on R1 join key(s)
   insert R1 into the appropriate hash bucket
end
--探索阶段
for each row R2 in the probe table
begin
   calculate hash value on R2 join key(s)   
   for each row R1 in the corresponding hash bucket
       if R1 joins with R2
          output(R1,R2)
end&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;在哈希连接执行之前，SQL Server会估算需要多少内存来构建哈希表。基本估算的方式就是通过表的统计信息来估算，所以有时候统计信息不准确，会直接影响其运算性能。&lt;/p&gt;
&lt;p&gt;SQL Server默认会尽力预留足够的内存来保证哈希连接成功的构建，但是有时候内存不足的情况下，就必须采取将一小部分的哈希表分配到硬盘中，这里就存入到了tempdb库中，而这一过程会反复多次循环执行。&lt;/p&gt;
&lt;p&gt;举个列子来看看&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT O.OrderID,O.OrderDate,C.CustomerID,C.ContactName
FROM Orders O JOIN Customers C
ON O.CustomerID=C.CustomerID&amp;lt;img alt=&quot;&quot; src=&quot;http://ww1.sinaimg.cn/mw690/69ab9b51gw1en6z7bth1nj20hj05swf5.jpg&quot; /&amp;gt;&lt;/pre&gt;
&lt;p&gt;我们来分析上面的执行语句，上面的执行结果通过CustomerID列进行关联，理论将最合适的应该是采用合并连接操作，但是合并连接需要排序，但是我们在语句中没有指定Order by 选项，所以经过评估，此语句采用了哈希连接的方式进行了连接。&lt;/p&gt;
&lt;p&gt;我们给它加上一个显示的排序，它就选用合并连接作为最优的连接方式&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/aa672a5702c447f7a014cba691f6297b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们来总结一下这个算法的特点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;和合并连接一样算法复杂度基本就是分别遍历两边的数据集各一遍&lt;/li&gt;
&lt;li&gt;它不需要对数据集事先排序，也不要求上面有什么索引，通过的是哈希算法进行处理&lt;/li&gt;
&lt;li&gt;基本采取并行的执行计划的方式&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是，该算法也有它自身的缺点，因为其利用的是哈希函数，所以运行时对CPU消耗高，同样对内存也比较大，但是它可以采用并行处理的方式，所以该算法用于超大数据表的连接查询上显示出自己独有的优势。&lt;/p&gt;
&lt;p&gt;关于哈希算法在哈希处理过程的时候对内存的占用和分配方式，是有它自己独有哈希方法，比如：左深度树、右深度树、浓密哈希连接树等，这里不做详细介绍了，只需要知道其使用方式就可以了。&lt;/p&gt;
&lt;p&gt;Hash Join并不是一种最优的连接算法，只是它对输入不优化，因为输入数据集特别大，并且对连接符上有没有索引也没要求。其实这也是一种不得已的选择，但是该算法又有它适应的场景，尤其在OLAP的数据仓库中，在一个系统资源相对充足的环境下，该算法就得到了它发挥的场景。&lt;/p&gt;
&lt;p&gt;当然前面所介绍的两种算法也并不是一无是处，在业务的OLTP系统库中，这两种轻量级的连接算法，以其自身的优越性也获得了认可。&lt;/p&gt;
&lt;p&gt;所以这三种算法，没有谁好谁坏，只有合适的场景应用合适的连接算法，这样才能发挥它自身的长处，而恰巧这些就是我们要掌握的技能。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;这三种连接算法我们也可以显示的指定，但是一般不建议这么做，因为默认SQL Server会为我们评估最优的连接方式进行操作，当然有时候它评估不对的时候就需要我们自己指定了，方法如下：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b1a5c562b85195a87687311a2eae36f2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/bda08be3a2a943778bea86fd4323102b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ccd05be9a08c5fed7b8cc0820bb8e42a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二、聚合操作&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;聚合也是我们在写T-SQL语句的时候经常遇到的，我们来分析一下一些常用的聚合操作运算符的特性和可优化项。&lt;/p&gt;
&lt;p&gt;a、标量聚合&lt;/p&gt;
&lt;p&gt;标量聚合是一种常用的数据聚合方式，比如我们写的语句中利用的以下聚合函数：MAX()、MIN()、AVG()、COUNT()、SUM()&lt;/p&gt;
&lt;p&gt;以上的这些数据结果项的输出基本都是通过流聚合的方式产生，并且这个运算符也被称为：标量聚合&lt;/p&gt;
&lt;p&gt;先来看一个列子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT COUNT(*) FROM Orders&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0f4963b4042b2c62b7a6ad061f51a6b6.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面的图表就是流聚合的运算符了。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/dce72423a51e37772c4c6be82f43ba92.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上图还有一个计算标量的运算符，这是因为在流聚合产生的结果项数据类型为Bigint类型，而默认输出为int类型，所以增加了一个类型转换的运算符。&lt;/p&gt;
&lt;p&gt;我们来看一个不需要转换的&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT MIN(OrderDate),MAX(OrderDate) FROM Orders&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1c6a46e576d11b887f98de044df2ed32.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;看一下求平均数的运算符&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT AVG(Freight) FROM Orders&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/040d82d11f03f5b39ac529a78438f85b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;求平均数的时候，在SQL Server执行的时候也给我们添加了一个case when分类，防止分母为0的情况发生。&lt;/p&gt;
&lt;p&gt;我们来看DISTINCT下的情况下，执行计划&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT COUNT(DISTINCT ShipCity) FROM Orders
SELECT COUNT(DISTINCT OrderID) FROM Orders&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/94e9167165195a5173aafce85fe84d13.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a1fb0e6e0b53a85cd8552c515c548578.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面相同的语句，但是产生了不同的执行计划，只是因为发生在不同列的数量汇总上，因为OrderID不存在重复列，所以SQL Server不需要排序直接流聚合就可以产生汇总值，而ShipCity不同它会有重复的值，所以只能经过排序后再流聚合依次获取汇总值。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;其实，流聚合这种算法最常用的方式是分组（GROUP BY）计算，上面的标量计算也是利用这个特性，只不过把整体形成了一个大组进行聚合。&lt;/p&gt;
&lt;p&gt;我么通过如下代码理解&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;clear the current aggredate results
clear the current group by columns
for each input row
begin
    if the input row does not match the current group by columns
    begin
       output the current aggreagate results(if any)
       clear the current aggreagate results
       set the current group by columns to the input row
    end
   update the aggregate results with the input row
end&lt;/pre&gt;
&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;流聚合运算符其实过程很简单，维护一个聚合组和聚合值，依次扫描表中的数据，如果能匹配聚合组则忽略，如果不匹配，则加入到聚合组中并且更新聚合值结果项。&lt;/p&gt;
&lt;p&gt;举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT ShipAddress,ShipCity,COUNT(*)
FROM Orders
GROUP BY ShipAddress,ShipCity&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b2d5176fd70d3bd98facb16af6d93bde.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里使用了流聚合，并且之前先对两列进行排序，排序的消耗总是很大。&lt;/p&gt;
&lt;p&gt;如下代码就不会产生排序&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT CustomerID,COUNT(*)
FROM Orders
GROUP BY CustomerID&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b9b6b10d4b05788e11294b1808770069.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;所以这里我们已经总结出对于流聚合的一种优化方式：尽量避免排序产生，而要避免排序就需要将分组（Group by）字段在索引覆盖范围内。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;b、哈希聚合&lt;/p&gt;
&lt;p&gt;上述的流聚合的方式需要提前排序，我们知道排序是一个非常大的消耗过程，所以不适合大表的分组聚合操作，为了解决这个问题，又引入了另外一种聚合运算：哈希聚合&lt;/p&gt;
&lt;p&gt;所谓的哈希聚合内部的方法和本篇前面提到的哈希连接机制一样。&lt;/p&gt;
&lt;p&gt;哈希聚合不需要排序和过大的内存消耗，并且很容易并行执行计划，利用多CPU同步进行，但是有一个缺点就是：这一过程是阻塞的，也就说哈希聚合不会产生任何结果直到完整的输入。&lt;/p&gt;
&lt;p&gt;所以在大数据表中采用哈希聚合是一个很好的应用场景。&lt;/p&gt;
&lt;p&gt;通过如下代码加深理解&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;for each input row
begin
   calculate hash value on group by columns
   check for a matching row in the hash table
   if maching row not found
      insert a new row into the hash table
   else
      update the matching row with the input row
end
--最后输出结果
ouput all rows in the hash table&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;简单点将就是在进行运算匹配前，先将分组列进行哈希处理，分配至不同的哈希桶中，然后再依次匹配，最后才输出结果。&lt;/p&gt;
&lt;p&gt;举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT ShipCountry,COUNT(*)
FROM Orders
GROUP BY ShipCountry&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0479f31e25076cbc44ef65acc4e08465.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;这个语句很有意思，我们利用了ShipCountry进行了分组，我们知道该列没有被索引覆盖，按照道理，其实选择流聚合应该也是不错的方式，跟上面我们列举的列子一样，先对这个字段进行排序，然后利用流聚合形成结果项输出。&lt;/p&gt;
&lt;p&gt;但是，为什么这个语句SQL Server为我们选择了哈希匹配作为了最优的算法呢！！！&lt;/p&gt;
&lt;p&gt;我么来比较两个分组字段：ShipCountry和前面的ShipAddress&lt;/p&gt;
&lt;p&gt;前面是国家，后面是地址，国家是很多重复的，并且只有少数的唯一值。而地址就不一样了，离散型的分布，我们知道排序是很耗资源的一件事情，但是利用哈希匹配只需要将不同的列值进行提取就可以，所以相比性能而言，无疑哈希匹配算法在这里是略胜一筹的算法。&lt;/p&gt;
&lt;p&gt;而上面关于这两列内容分布类型SQL Server是怎样知道的？这就是SQL Server的强大的统计信息在支撑了。&lt;/p&gt;
&lt;p&gt;在SQL Server中并不是固定的语句就会形成特定的计划，并且生成的特定计划也不是总是最优的，这和数据库现有数据表中的内容分布、数据量、数据类型等诸多因素有关，而记录这些详细信息的就是统计信息。&lt;/p&gt;
&lt;p&gt;所有的最优计划的选择都是基于现有统计信息来评估，如果我们的统计信息未及时更新，那么所评估出来最优的执行计划将不是最好的，有时候反而是最烂的。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微软联机丛书&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/ms191158(SQL.90).aspx&quot; target=&quot;_blank&quot;&gt;逻辑运算符和物理运算符引用&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;参照书籍《SQL.Server.2005.技术内幕》系列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此篇文章先到此吧，本篇主要介绍了关于T-SQL语句调优从执行计划下手，并介绍了三个常见的连接运算符和聚合操作符，下一篇将着重介绍我们其它最常用的一些运算符和调优技巧，包括：CURD等运算符、联合运算符、索引运算、并行运算等吧，关于SQL Server性能调优的内容涉及面很广，后续文章中依次展开分析。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81182-05c6e8f15.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81182-05c6e8f15.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列基础篇</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;关于SQL Server调优系列是一个庞大的内容体系，非一言两语能够分析清楚，本篇先就在SQL 调优中所最常用的查询计划进行解析，力图做好基础的掌握，夯实基本功！而后再谈谈整体的语句调优。&lt;/p&gt;
&lt;p&gt;通过本篇了解如何阅读和理解查询计划、并且列举一系列最常用的查询执行运算符。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;基于SQL Server2008R2版本，利用微软的一个更简洁的案例库（Northwind）进行解析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、区别不同的运算符&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在所有T-SQL语句在执行的时候，都会将语句分解为一些基本的结构单元，这些结构单元统称为：运算符。每一个运算符都实现一个单独的基本操作，比如：表扫描、索引查找、索引扫描、过滤等。每个运算符可以循环迭代，也可以延续子运算符，这样就可以组成查询树，即：查询计划。&lt;/p&gt;
&lt;p&gt;每个T-SQL语句都会通过多种运算符进行组合形成不同的查询计划，并且这些查询计划对于结果的筛选都是有效的，但在执行的时候，SQL Server的查询优化器会自动为我们找到一个最优的。&lt;/p&gt;
&lt;p&gt;每一个运算符都会有源数据的传入和结果数据的输出，源数据的输入可以来源于其它的运算符或者直接从数据源表中读取，经过本身的运算进行结果的输出。所以每一个运算符是独立的。互不关心的。&lt;/p&gt;
&lt;p&gt;如下例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT COUNT(*) FROM Orders&lt;/pre&gt;
&lt;p&gt;此语句会生成两个简单的运算符&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/7a0247d9ef3142d616a23e9995b11524.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;当然，在SQL Server中上述的两个运算符有它自己的表达方式，Count(*)是流聚合运算符进行的。&lt;/p&gt;
&lt;p&gt;每一个运算符会有三个属性影响其执行的效率&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、内存消耗&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所有的运算符都需要一定量的固定内存用以完成执行。当一个T-SQL语句经过编译后生成查询计划后，SQL Server会为认为最优的查询计划尝试去固定内存，目的是为了再次执行的时候不需要再重新申请内存而浪费时间，加快执行速度。&lt;/p&gt;
&lt;p&gt;然后，有一些运算符需要额外的内存空间来存储行数据，这样的运算符所需要的内存量通常就和处理的数据行数成正比。如果出现如下几种情况则会导致内存不能申请到，而影响执行性能&lt;/p&gt;
&lt;p&gt;a、如果服务器上正在执行其它的类似的内存消耗巨大的查询，导致系统内存剩余不足的时候，当前的查询就得延迟进行，直接影响性能。&lt;/p&gt;
&lt;p&gt;b、当并发量过大的的情况下，多个查询竞争有限的内存资源，服务器会适当的控制并发和减少吞吐量来维护机器性能，这时候同样也会影响性能&lt;/p&gt;
&lt;p&gt;c、如果当前申请的到可用内存很少的情况下，SQL Server会在执行过程中和磁盘进行交换数据，通常是使用Tempdb临时库进行操作，而这个过程会很慢。更有甚者，会耗尽Tempdb上的磁盘空间以失败结束&lt;/p&gt;
&lt;p&gt;通常比较消耗内存的运算符主要有分类、哈希连接以及哈希聚合等连接操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、阻断运算和非阻断运算&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所谓阻断和非阻断的区别就是：运算符是否在输入数据的时候能够直接输出结果数据。&lt;/p&gt;
&lt;p&gt;a、当一个运算符在消耗输入行的同时生成输出行，这种运算符就是非阻断式的。&lt;/p&gt;
&lt;p&gt;比如我们经常使用的 Select Top …操作，此操作就是输入行的同时进行输出行操作，所以此操作就是非阻断式的。&lt;/p&gt;
&lt;p&gt;b、当一个运算符所产生的输出结果需要等待所有的数据输入的时候，这个操作运算就是阻断运算的。&lt;/p&gt;
&lt;p&gt;比如上面我们举的例子Count(*)操作，此操作就需要等待所有的数据行输入才能计算出，所以为阻断式运算，另外还有分组计算。&lt;/p&gt;
&lt;p&gt;提示：并不是所有的阻断式操作就需要消耗内存，比如Count(*)就为阻断式，但它不消耗内存，但大部分阻断式操作都会消耗内存。&lt;/p&gt;
&lt;p&gt;在大部分的OLTP系统中，我们要尽量的使用非阻断式操作来代替阻断式操作，这样才能更好的提高相应时间，比如有时候我们用EXISTS子查询来判断，比用SELECT count(*)&amp;gt;0的速度要理想的多。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二、查看查询计划&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在SQL Server2005版本以上，系统提供了三种展示方式：图像方式、文本方式和XML方式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、图像方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;图像方式这种方式是最为常见的一种方式，清晰、简洁、易懂。非常适合入门级，当然也有它自身的缺点比如复杂的T-SQL语句会产生较大的图像，查看必须收缩操作，比较麻烦。&lt;/p&gt;
&lt;p&gt;SSMS默认给我们提供了查看该查询计划的便捷按钮，需要查看某一条语句的时候，只需要点击上就可以&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d9ddfeef25f1607c7886d8a1064212f5.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们来看一个图像方式展示的查询计划图&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/69cec43308e06e63af202b13f465dc0a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;以上查询语句所产生的实际执行计划，将其分成了各个不同的运算符进行组合，从最右侧的聚集索引扫描（index scan）然后经过一系列的运算符加工形成最左侧的结果输出（select）。&lt;/p&gt;
&lt;p&gt;需要注意的是图中箭头的方向指向的是数据的流向，箭头线的粗细表示了数据量的多少。&lt;/p&gt;
&lt;p&gt;在图形化执行计划中，每一个不同的运算符都有它自身的属性值，我们可以把鼠标移至运算符图标上查看&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/33eb87e7910d7d74402698af9caa5956.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;当然也可以直接在图标上右键，查看属性，进入到属性面板，查看更详细的属性值&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b98f80451b3edbb618164c5ae07488a2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;关于这里面各个运算符的详细指标值，我们在后面介绍，不过这里面有几个关键的值这里可以说是先稍微提一下，关于影响此语句的整体的性能参数，我们可以选择最开始的Select运算符，右键查看属性值&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/41ac1c29c6e9532f27093ec28786134c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;此运算符包含了整条语句的编译时间、所需内存、缓存计划大小、并行度、内存授权、编译执行所需要的参数以及变量值等信息。&lt;/p&gt;
&lt;p&gt;此方式作为一种相对直观的方式展示给用户，所以在我们语句调优中占据很大的指导地位，我们知道一条T-SQL语句可能会生成很多不同的执行计划，而SQL Server会帮助我们选择最优的执行计划，当然我们也可以利用它选择的执行计划去调整自己的语句达到优化的目的。&lt;/p&gt;
&lt;p&gt;鉴于以上目标，SSMS为我们提供了“评估执行计划”选项，此选项只为评估指导使用，并未实际执行，所以它不包含实际行等具体信息&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5b2a274822fdcc5a4a951a17e5e9dba1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、文本方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此方式在SSMS中默认没有提供快捷键，我们需要自己用语句开启，开启的方式有两种&lt;/p&gt;
&lt;p&gt;a、只开启执行计划，不包括详细的评估值&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SET SHOWPLAN_TEXT ON&lt;/pre&gt;
&lt;p&gt;b、开启所有的执行计划明细，包括各个属性的评估值&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SET SHOWPLAN_ALL ON&lt;/pre&gt;
&lt;p&gt;文本方式展现的方式，没有了明确的箭头指示，改用竖线（|）标示子运算符和当前运算的子父关系。并且数据流方向都是从子运算符流向父运算符的，虽然文本展现方式不够直观，但是如果掌握了文本的阅读方式，此方式会更易阅读，尤其在涉及很大的大型计划的时候，此方式更容易保存、处理、搜索和比较。&lt;/p&gt;
&lt;p&gt;我们来看一个列子&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/bf6240c7315f2be978d4250f41ff2268.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;此种方式输出的形式为文本方式，我们可以拷贝至文本编辑器中分析，方便于查找分析等操作&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/45ba5b511e44b6fa9274568e0cb29146.jpg&quot;&gt; 以上是文本查询计划的分析方式，简单点的就是从最里面的运算符开始执行，数据流方向也是依次从子运算符流向父运算符。&lt;/p&gt;
&lt;p&gt;上面的方式看起来有点图像方式，分析起来简单更易用。但是或许缺少的是每个运算符的属性运算信息，我们通过b方法里来查看明细&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/085fbae0143af20ed9a12583119892c2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;利用此方式可以直观的分析出每个运算符操作的属性评估值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、XML方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;XML展现查询计划的方式是SQL Server2005中新加入的功能，此方式结合了文本方式和图形计划方式的优点。利用XML元素的方式展现查询计划。&lt;/p&gt;
&lt;p&gt;更主要的特点是利用XML方式是一种规范的方式，可以利用编程的方式进行标准XML操作，利于查询。并且在SQL Server2005中还加入的XML的数据类型，并且内置了XQuery功能进行查询。此方式尤其对与超大型的查询计划查看非常的方便。&lt;/p&gt;
&lt;p&gt;通过以下语句开启&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SET STATISTICS XML ON&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f9b5a64352f5f92f7e09d7146674bd46.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们可以点击输出的XML进行查看&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f7666d75f178b2e7872f91308fe64e3d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;XML方式展现了非常详细的查询计划信息，我们可以简单的分析下&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;StmtSimple：描述了T-SQL的执行文本，并且详细分析了该语句的类型，以及各个属性的评估值。&lt;/li&gt;
&lt;li&gt;StatementSetOptions：描述该语句的各种属性值的Set值&lt;/li&gt;
&lt;li&gt;QueryPlan：是详细的执行计划，包括执行计划的并行的线程数、编译时间、内存占有量等&lt;/li&gt;
&lt;li&gt;OutputList：输出参数列表&lt;/li&gt;
&lt;li&gt;在中间这部分就是具体的不同的执行运算符的信息了，并且包括详细的预估值等&lt;/li&gt;
&lt;li&gt;ParameterList：输出参数列表&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;XML方式提供的信息是最为全面的，并且在SQL Server内部存储的查询计划类型也为XML数据类型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三、分析查询计划&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当我们拿到一个语句的查询计划，我们应该会分析里面的执行计划的含义，以及各个运算符的属性值，学会如何调整各个运算符的属性值来整体的提高该语句的运行效率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、扫描以及查找&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于扫描（scan）和查找（seek）这两种方式是数据库里面从基础数据表里获取的数据的基本方式。&lt;/p&gt;
&lt;p&gt;a、当一张表为堆表（没有任何索引）的时候或者获取的数据列不存在任何索引来供查找，此种数据的获取只能通过全表扫描过滤获取，如果存在索引项会通过索引项的扫描来获取数据，提高获取数据的速度。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ef796e7e79e2bb244d9de3c14d503077.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3c83430dbd1ed96aeb395cae8dc170dd.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;该方法是最为简单的获取数据的方式&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ba8c7ba0bfb9dd6e7bd5a95b906db01f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;b、如果当前搜寻的数据行存在索引项，那么会采取索引查找（seek）进行数据检索。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5bc4cb43325dff2280546bf351a5722d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;该条语句就是执行的索引查找，因为在Orders表中的OrderDate列存在非聚集索引项。这里顺便提一下如果引入静态变量，SQL Server会自动参数化该值，目的是为了减少编译次数，重复利用执行计划。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1013258f6d033168e3d86fc4dbab9d6d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;由于查找只是搜寻符合条件的这些页进行输出操作，所以查找效率只和符合条件的行数、页数成正比，和整个表中的总行数没有关系。&lt;/p&gt;
&lt;p&gt;c、当所选的索引列不包含输出列的时候，也就是说要筛选出的列项不为索引所覆盖，对于这种情况又引出了另外一种查找方式&lt;/p&gt;
&lt;p&gt;书签查找（Bookmark Lookup）&lt;/p&gt;
&lt;p&gt;其实该方式是扫描和查找之间的一个折中方式，我们知道，如果通过聚集索引扫描，则会获取所有的列，但是这涉及表中的每一行数据，影响性能，相反如果只是通过聚集索引方式进行查找，则有一些列不能获取得到，如果这些列正是我们需要的，这就是不准确的，所以，鉴于此，引入了折中的方式：书签查找（Bookmark Lookup)&lt;/p&gt;
&lt;p&gt;简单点讲：书签查找就是通过索引页节点数据查找相关的列数据。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d0e8879ecc4ac6cf213b0a1fd786b61c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们来看一个具体的查询列子&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/48252f25ec3834f1f1f15afe7850ad2b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里需要解释一下，在SQL Server2005 SP2版本以上，书签查找也被称为键查找，其实是一个概念。&lt;/p&gt;
&lt;p&gt;这种方式有一些弊端，就是在进行书签查找的时候，如果通过非聚集索引的叶节点查找到聚集索引数据，这种情况通过聚集索引能够快速的获取到数据，如果非聚集索引关键字和聚集索引关键字不存在任何关联，这种情况下，书签查找就会执行随机的I/O操作到聚集索引或者堆表中，而这种情况是非常耗时的，相比而言顺序I/O扫描都要比随机I/O扫描性能好很多。&lt;/p&gt;
&lt;p&gt;为了解决上面所述的问题，在SQL Server2005以后的版本中，在创建index的时候引入了INCLUDE关键字。通过创建索引的时候，直接将书签要查找的项直接包含进去，这样就不会发生随机I/O操作。此种方式的缺点会造成索引存储增大一部分，但相比带来的好处，基本可以忽略不计。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a60f7d60c3a7299cd68770ec28e9dd72.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此篇文章先到此吧，本篇主要介绍了关于T-SQL语句调优从执行计划该如下下手，并介绍了几个常见的简单运算符，下一篇将着重介绍我们最常用的一些运算符和调优技巧，包括：连接运算符、聚合运算符、联合运算符、并行运算等吧，关于SQL Server性能调优的内容涉及面很广，后续文章中依次展开分析。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81176-ff22b67f4.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81176-ff22b67f4.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>实现键值对存储（五）：哈希表实现</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/75842/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（0）：目录&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/75844/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（1）：什么是键值对存储，为什么要实现它&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/77750/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（2）：以现有键值对存储为模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/78869/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（3）：Kyoto Cabinet和LevelDB的架构比较分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/81083/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（4）：API设计&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在本文中，我将会研究C++中哈希表的实际实现以理解其瓶颈。哈希函数是CPU密集型的并且应该维持而优化。然而，大部分哈希表的内部机制只关心内存效率和I/O访问，这将是本文主要注意的东西。我将会研究三个不同的哈希表的C++实现，既有内存中的又有硬盘上的，并看看数据是怎么组织和访问的。本文将包括：&lt;/p&gt;
&lt;p&gt;1.哈希表&lt;br&gt;
1.1 哈希表简介&lt;br&gt;
1.2 哈希函数&lt;br&gt;
2.实现&lt;br&gt;
2.1 TR1的unordered_map&lt;br&gt;
2.2 SparseHash的dense_hash_map&lt;br&gt;
2.3 Kyoto Cabinet的HashDB&lt;br&gt;
3.结论&lt;br&gt;
4.参考文献&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/4ab340f93b16d29fab6f7212c680c0ee.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h1&gt;1.哈希表&lt;/h1&gt;
&lt;p&gt;&lt;a name=&quot;ci_title1&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;1.1 哈希表简介&lt;/h2&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;哈希表可以高效的访问关联数据。每个条目都有一对对应的&lt;em&gt;键名&lt;/em&gt;和&lt;em&gt;键值&lt;/em&gt;，并且能仅通过键名来快速的取回和赋值。为了达到这个目的，键名通过&lt;em&gt;哈希函数&lt;/em&gt;进行哈希，以将键名从原始形式转换为整数。此整数之后作为索引来得到要访问的条目的值所在的bucket在&lt;em&gt;bucket数组&lt;/em&gt;中的地址。很多键名可以被哈希为相同的值，这表示这些key在bucket数组中回出现碰撞。有数种方法解决&lt;em&gt;碰撞&lt;/em&gt;，如使用链表的&lt;em&gt;分离链表&lt;/em&gt;（&lt;em&gt;separate chaining&lt;/em&gt; 亦称&lt;em&gt;开链&lt;/em&gt;或&lt;em&gt;单独链表&lt;/em&gt;）或&lt;em&gt;自平衡二叉树&lt;/em&gt;或线性或者二次探测的&lt;em&gt;开放寻址&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;从现在开始，我默认你知道什么是哈希表。如果你认为自己需要温习一下知识，Wikipedia的“Hash table”词条&lt;a href=&quot;#ref&quot;&gt;[1]&lt;/a&gt;（及其底部的扩展链接一节）和Cormen 等人写的Introduction to Algorithms一书中Hash table一章&lt;a href=&quot;#ref&quot;&gt;[2]&lt;/a&gt;都是很好的参考文献。&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;ci_title2&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;1.2 哈希函数&lt;/h2&gt;
&lt;p&gt;哈希函数的选择相当重要。一个好哈希函数的基本需求是输出的哈希值比较均匀。这样可以使碰撞的发生最小化，同时使得各个bucket中碰撞的条目比较平均。&lt;/p&gt;
&lt;p&gt;可用的哈希函数有很多，除非你确切的知道数据会变成什么样子，最安全的方法是找一个能够将随机数据分布均匀的哈希函数，如果可能的话符合雪崩效应&lt;a href=&quot;#ref&quot;&gt;[3]&lt;/a&gt;。有少数人对哈希函数做过比较&lt;a href=&quot;#ref&quot;&gt;[4]&lt;/a&gt; &lt;a href=&quot;#ref&quot;&gt;[5]&lt;/a&gt; &lt;a href=&quot;#ref&quot;&gt;[6]&lt;/a&gt; &lt;a href=&quot;#ref&quot;&gt;[7]&lt;/a&gt;，而他们的结论是MurmurHash3 &lt;a href=&quot;#ref%22&quot;&gt;[8]&lt;/a&gt;和CityHash &lt;a href=&quot;#ref&quot;&gt;[9]&lt;/a&gt; 是在写本文的时候最好的哈希函数。&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;ci_title3&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;2.实现&lt;/h1&gt;
&lt;p&gt;和哈希函数的比较一样，只有很少比较各个C++的内存哈希表库性能的博文。我见到的最出名的是Nick Welch 的&lt;em&gt;“Hash Table Benchmarks&lt;/em&gt;” &lt;a href=&quot;#ref&quot;&gt;[10]&lt;/a&gt;，和Jeff Preshing 的“&lt;em&gt;Hash Table Performance Test&lt;/em&gt;s” &lt;a href=&quot;#ref%22&quot;&gt;[11]&lt;/a&gt;。而其他文章也值得一看&lt;a href=&quot;#ref&quot;&gt;[12]&lt;/a&gt; &lt;a href=&quot;#ref&quot;&gt;[13]&lt;/a&gt; &lt;a href=&quot;#ref&quot;&gt;[14]&lt;/a&gt;。从这些比较中，我发现两个研究起来比较有意思的部分：GCC的TR1的unordered_map和SparseHash 库（以前叫Google SparseHash）的dense_hash_map，我将会在下文中介绍他们。另外，我同样会描述Kyoto Cabinet中HashDB的数据结构。显然因为unordered_map 和dense_hash_map是内存哈希表，不会像HashDB那样和我的键值对存储相关。尽管如此，稍微看一下其内部数据结构的组织和其内存模式也是很有意思的。&lt;/p&gt;
&lt;p&gt;在下述三个哈希表库的描述中，我的通用示例是把一组城市名作为键名其各自的GPS坐标作为键值。unordered_map的源代码可以在GCC代码中作为libstdc++-v3的一部分找到。我将会着眼于GCC v4.8.0的libstdc++-v3 release 6.0.18&lt;a href=&quot;#ref&quot;&gt;[15]&lt;/a&gt;，SparseHash v2.0.2中的dense_hash_map&lt;a href=&quot;#ref&quot;&gt;[16]&lt;/a&gt;，和Kyoto Cabinet v1.2.76中的HashDB&lt;a href=&quot;#ref&quot;&gt;[17]&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Matthew Austern的“&lt;em&gt;A Proposal to Add Hash Tables to the Standard Library (revision 4)&lt;/em&gt;”一文&lt;a href=&quot;#ref&quot;&gt;[18]&lt;/a&gt;和SparseHash的“&lt;em&gt;Implementation notes&lt;/em&gt;”页面&lt;a href=&quot;#ref&quot;&gt;[19]&lt;/a&gt;也有很有意思的关于哈希表实现的讨论。&lt;/p&gt;
&lt;h2&gt;2.1 TR1中的unordered_map&lt;/h2&gt;
&lt;p&gt;TR1的unordered_map提供了一个用链表（分离链）解决碰撞的哈希表。Bucket数组位于堆中，并且基于哈希表的负载系数自动调整大小。而bucket的链表则是用叫做&lt;code&gt;_Hash_node&lt;/code&gt;的节点结构体创建。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* from gcc-4.8.0/libstdc++-v3/include/tr1/hashtable_policy.h */ 
template
  struct _Hash_node&amp;lt;_Value, false&amp;gt;
  {
    _Value       _M_v;
    _Hash_node*  _M_next;
  };&lt;/pre&gt;
&lt;p&gt;如果键和值都是整型，其可以直接存储在&lt;code&gt;_M_v&lt;/code&gt;结构体中。否则将会存储指针，同时需要额外的内存。Bucket数组是在堆中一次性分配的，但并不分配节点的空间，节点的空间是通过各自调用C++内存分配器来分配的。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* from gcc-4.8.0/libstdc++-v3/include/tr1/hashtable.h */ 
Node* _M_allocate_node(const value_type&amp;amp; __v)
    {
      _Node* __n = _M_node_allocator.allocate(1);
      __try
    {
      _M_get_Value_allocator().construct(&amp;amp;__n-&amp;gt;_M_v, __v);
      __n-&amp;gt;_M_next = 0;
      return __n;
    }
      __catch(...)
    {
      _M_node_allocator.deallocate(__n, 1);
      __throw_exception_again;&lt;/pre&gt;
&lt;p&gt;因为这些节点是各自分配的，分配过程中可能浪费大量的内存。这取决于编译器和操作系统使用的内存分配过程。我甚至还没说每次分配中系统执行的调用。SGI哈希表的原始实现为这些节点做了一些资源预分配工作，但这个方法没有保留在TR1的 unordered_map实现中。&lt;/p&gt;
&lt;p&gt;下文的图5.1展示了TR1中unordered_map的内存和访问模式。让我们来看看当我们访问和键名“Johannesburg”相关的GPS坐标的时候会发生什么。这个键名被哈希并映射到了bucket #0。在那我们跳到了此bucket的链表的第一个节点（bucket #0左边的橙色箭头），我们可以访问堆中存储了键“Johannesburg”所属数据的内存区域（节点右侧的黑色箭头）。如果键名所指向的第一个节点不可用，就必须遍历其他的节点来访问。&lt;/p&gt;
&lt;p&gt;至于CPU性能，不能指望所有的数据都在处理器的同一个缓存行中。实际上，基于bucket数组的大小，初始bucket和初始节点不会在同一个缓存行中，而和节点相关的外部数据同样不太可能在同一个缓存行中。而随后的节点机器相关数据同样不会在同一个缓存行中并且需要从RAM中取回。如果你不熟悉CPU优化和缓存行，维基上的“CPU Cache”文章是一个很好的介绍&lt;a href=&quot;#ref&quot;&gt;[20]&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/4641e18d4587c0050af836b594a9c6be.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;图5.1&lt;/p&gt;
&lt;h2&gt;2.2 SparseHash的dense_hash_map&lt;/h2&gt;
&lt;p&gt;SparseHash库提供了两个哈希表实现，sparse_hash_map和dense_hash_map。sparse_hash_map在低成本下提供了出色的内存占用，并使用一个特定的数据结构sparsetable来打到这个目的。在SparseHash的“Implementation notes”页面&lt;a href=&quot;#ref&quot;&gt;19&lt;/a&gt;可以找到更多关于sparsetables 和sparse_hash_map的信息。在此我只讨论dense_hash_map。&lt;/p&gt;
&lt;p&gt;dense_hash_map用二次内部探测处理碰撞。和unordered_map一样，bucket数组也是在堆中一次分配，并基于哈希表的负载因子调整大小。bucket数组的元素是&lt;code&gt;std::pair&lt;/code&gt;的实例，其中&lt;code&gt;Key&lt;/code&gt;和&lt;code&gt;T&lt;/code&gt;分别是键名和键值的模版参数。在64位架构下储存字符串的时候，pair的实例大小是16字节。&lt;/p&gt;
&lt;p&gt;下文的图5.2是dense_hash_map内存和访问模式的展示。如果我们要寻找“Johannesburg”的坐标，我们一开始会进入bucket #0，其中有“Paris”（译注：图上实际应为“Dubai”）的数据（bucket #0右侧的黑色箭头）。因此必须探测然后跳转到bucket (i + 1) = (0 + 1) = 1（bucket #0左侧的橙色箭头），然后就能在bucket #1中找到“Johannesburg”的数据。这看上去和unordered_map中做的事情差不多，但其实完全不同。当然，和unordered_map一样，键名和键值都必须存储在分配于堆中的内存，这将导致对键名和键值的寻找会使缓存行无效化。但为碰撞的条目寻找一个bucket相对较快一些。实际上既然每个pair都是16字节而大多数处理器上的缓存行都是64字节，每次探测就像是在同一个缓存行上。这将急剧提高运算速度，与之相反的是unordered_map中的链表需要在RAM中跳转以寻找余下的节点。&lt;/p&gt;
&lt;p&gt;二次内部探测提供的缓存行优化使得dense_hash_map成为所有内存哈希性能测试中的赢家（至少是在我目前读过的这些中）。你应该花点时间来看看Nick Welch的文章“Hash Table Benchmarks” &lt;a href=&quot;#ref&quot;&gt;[10]&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/d46a2dac88be675429c619cb30a3b2b6.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;图5.2&lt;/p&gt;
&lt;h2&gt;2.3 Kyoto Cabinet的HashDB&lt;/h2&gt;
&lt;p&gt;Kyoto Cabinet实现了很多数据结构，其中就有哈希表。这个哈希表HashDB虽然有一个选项可以用来把他用作代替&lt;code&gt;std::map&lt;/code&gt;的内存哈希表，但其是设计用于在硬盘上持久化的。哈希表的元数据和用户数据一起用文件系统依次存储在硬盘上唯一的文件中。&lt;br&gt;
Kyoto Cabinet使用每个bucket中独立的二叉树处理碰撞。Bucket数组长度固定且不改变大小，无视负载因子的状态。这是Kyoto Cabinet的哈希表实现的主要缺陷。实际上，如果数据库创建的时候定义的bucket数组的长度低于实际需求，当条目开始碰撞的时候性能会急剧下降。&lt;/p&gt;
&lt;p&gt;允许硬盘上的哈希表实现改变bucket数组大小是很难的。首先，其需要bucket数组和条目存储到两个不同的文件中，其大小会各自独立的增长。第二，因为调整bucket数组大小需要将键名重新哈希到新bucket数组的新位置，这需要从硬盘中读取所有条目的键名，这对于相当大的数据库来说代价太高以至于几乎不可能。避免这种重新哈希过程的一种方法是，存储哈希后键名的时候每个条目预留4或8个字节（取决于哈希是长度32还是64 bit）。因为这些麻烦事，固定长度的bucket数组更简单，而Kyoto Cabinet中采用了这个方法。&lt;/p&gt;
&lt;p&gt;图5.3显示出文件中存储的一个HashDB的结构。我是从&lt;code&gt;calc_meta()&lt;/code&gt;方法的代码，和kchashdb.h尾部HashDB类中属性的注释中得到的这个内部结构。此文件以如下几个部分组织：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;头部有数据库所有的元数据&lt;/li&gt;
&lt;li&gt;包含数据区域中可用空间的空块池&lt;/li&gt;
&lt;li&gt;bucket数组&lt;/li&gt;
&lt;li&gt;记录（数据区域）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一条记录包含一个条目（键值对），以及此独立链的二叉树节点。这里是Record结构体：&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* from kyotocabinet-1.2.76/kchashdb.h */ 
  /**
   * Record data.
   */
  struct Record {
    int64_t off;                         ///&amp;lt; offset
    size_t rsiz;                         ///&amp;lt; whole size
    size_t psiz;                         ///&amp;lt; size of the padding
    size_t ksiz;                         ///&amp;lt; size of the key
    size_t vsiz;                         ///&amp;lt; size of the value
    int64_t left;                        ///&amp;lt; address of the left child record
    int64_t right;                       ///&amp;lt; address of the right child record
    const char* kbuf;                    ///&amp;lt; pointer to the key
    const char* vbuf;                    ///&amp;lt; pointer to the value
    int64_t boff;                        ///&amp;lt; offset of the body
    char* bbuf;                          ///&amp;lt; buffer of the body
  };&lt;/pre&gt;
&lt;p&gt;图5.4可以看到记录在硬盘上的组织。我从kchashdb.h中的&lt;code&gt;write_record()&lt;/code&gt;方法中得到组织方法。注意其和Record结构体不同：保存在硬盘上的目标是最小化硬盘占用，然而结构体的目标是使记录在编程的时候用起来比较方便。图5.4的所有变量都有固定长度，除了&lt;code&gt;key&lt;/code&gt;、&lt;code&gt;value&lt;/code&gt;、 和&lt;code&gt;padding&lt;/code&gt;，其当然是取决于数据条目中数据的尺寸。变量&lt;code&gt;left&lt;/code&gt; 和&lt;code&gt;righ&lt;/code&gt;t是二叉树节点的一部分，储存文件中其他记录的offset。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/b2ed0471f7ae7023f703ff0705f7ba2c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;图5.3&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/429b4576d15cf69216323f483eb93613.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;图5.4如果我们要访问键名”Paris”的键值，一开始要获得相关bucket的初始记录，在本例中是bucket #0.。然后跳转到此bucket二叉树的头节点（bucket #0右侧的橙色箭头），其保存键名为”Johannesburg”.的数据。键名为”Paris”的数据需要通过当前节点的右侧节点来访问（”Johannesburg”记录右侧的黑色箭头）。二叉树需要一个可比较的类型来对节点分类。这里用的可比较类型是用&lt;code&gt;fold_hash()&lt;/code&gt;方法将哈希过的键名缩减得到的。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* from kyotocabinet-1.2.76/kchashdb.h */ 
uint32_t fold_hash(uint64_t hash) {
  _assert_(true);
  return (((hash &amp;amp; 0xffff000000000000ULL) &amp;gt;&amp;gt; 48) | ((hash &amp;amp; 0x0000ffff00000000ULL) &amp;gt;&amp;gt; 16)) ^
      (((hash &amp;amp; 0x000000000000ffffULL) &amp;lt;&amp;lt; 16) | ((hash &amp;amp; 0x00000000ffff0000ULL) &amp;gt;&amp;gt; 16));
}&lt;/pre&gt;
&lt;p&gt;把数据条目和节点一起存储在单一记录中，乍一看像是设计失误，但其实是相当聪明的。为了存储一个条目的数据，总是需要保持三种不同的数据：bucket、碰撞和条目。既然bucket数组中的bucket必须顺序存储，其需要就这样存储并且没有任何该进的方法。假设我们保存的不是整型而是不能存储在bucket中的字符或可变长度字节数组，这使其必须访问此bucket数组区域之外的其他内存。这样当添加一个新条目的时候，需要即保存冲突数据结构的数据，又要保存该条目键名和键值的数据。&lt;/p&gt;
&lt;p&gt;如果冲突和条目数据分开保存，其需要访问硬盘两次，再加上必须的对bucket的访问。如果要设置新值，其需要总计3次写入，并且写入的位置可能相差很远。这表示是在硬盘上的随机写入，这差不多是I/O的最糟糕的情况了。现在既然Kyoto Cabinet的HashDB中节点数据和条目数据存储在一起，其就可以只用一次写入写到硬盘中。当然，仍然必须访问bucket，但如果bucket数组足够小，就可以通过操作系统将其从硬盘中缓存到RAM中。如规范中”Effective Implementation of Hash Database”一节&lt;a href=&quot;#ref&quot;&gt;[17]&lt;/a&gt;声明的，Kyoto Cabinet可能采用这种方式。&lt;/p&gt;
&lt;p&gt;然而在硬盘上用二叉树存储条目需要注意的一点是，其会降低读取速度，至少当碰撞出现的时候会是这样。实际上，因为节点和条目存储在一起，处理一个bucket中的碰撞实际上是在一个二叉树中寻找要找的条目，这可能需要大量的对硬盘的随机读取。这可以让我们理解当条目的数量超过bucket数量时Kyoto Cabinet的性能急剧下降的原因。&lt;/p&gt;
&lt;p&gt;最后，因为所有的东西都是存在文件中，Kyoto Cabinet是自己处理内存管理，而非像unordered_map 和dense_hash_map那样交给操作系统处理。FreeBlock结构体保存着和文件中空闲空间的信息，其基本上是offset和大小，如下：&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* from kyotocabinet-1.2.76/kchashdb.h */ 
  /**
   * Free block data.
   */
  struct FreeBlock {
    int64_t off;                         ///&amp;lt; offset
    size_t rsiz;                         ///&amp;lt; record size
    /** comparing operator */
    bool operator &amp;lt;(const FreeBlock&amp;amp; obj) const {
      _assert_(true);
      if (rsiz &amp;lt; obj.rsiz) return true;
      if (rsiz == obj.rsiz &amp;amp;&amp;amp; off &amp;gt; obj.off) return true;
      return false;
    }
  };&lt;/pre&gt;
&lt;p&gt;所有的FreeBlock实例都加载在std::set中，其可以像&lt;code&gt;fetch_free_block()&lt;/code&gt;方法中那样使用std::set的upper_bound()方法来释放内存块，从而实现“最佳拟合”的内存分配策略。当可用空间显得过分细碎或者FreeBlock池中没有空间了，文件将进行碎片整理。此碎片整理过程通过移动各条记录来减少数据库文件的整体大小。&lt;/p&gt;
&lt;h1&gt;3.结论&lt;/h1&gt;
&lt;p&gt;本文中，我展示了三个不同哈希表库的数据组织和内存访问模式。TR1的unordered_map和SparseHash的dense_hash_map是在内存中的，而Kyoto Cabinet的HashDB是在硬盘上的。此三者用不同的访问处理碰撞，并对性能有不同的英雄。将bucket数据、碰撞数据和条目数据各自分开将影响性能，这是unordered_map中出现的情况。如dense_hash_map及其二次内部探测那样，将碰撞数据和bucket存储在一起；或者像HashDB那样，将碰撞数据和条目数据存储在一起都可以大幅提高速度。此两者都可以提高写入速度，但将碰撞数据和bucket存储在一起可以使读取更快。&lt;/p&gt;
&lt;p&gt;如果让我说从这些哈希表中学到的最重要的东西是什么的话，我会说在设计哈希表的数据组织的时候，首选的解决方案是将碰撞数据和bucket数据存储在一起。因为即便是在硬盘上，bucket数组和碰撞数据也会相当小，足够它们存储在RAM中，随机读取的花费将会比在硬盘上低得多。&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;ref&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;4.参考文献&lt;/h1&gt;
&lt;p&gt;[1] http://en.wikipedia.org/wiki/Hash_table&lt;br&gt;
[2] http://www.amazon.com/Introduction-Algorithms-Thomas-H-Cormen/dp/0262033844/&lt;br&gt;
[3] http://en.wikipedia.org/wiki/Avalanche_effect&lt;br&gt;
[4] http://blog.reverberate.org/2012/01/state-of-hash-functions-2012.html&lt;br&gt;
[5] http://www.strchr.com/hash_functions&lt;br&gt;
[6] http://programmers.stackexchange.com/questions/49550/which-hashing-algorithm-is-best-for-uniqueness-and-speed/145633#145633&lt;br&gt;
[7] http://blog.aggregateknowledge.com/2012/02/02/choosing-a-good-hash-function-part-3/&lt;br&gt;
[8] https://sites.google.com/site/murmurhash/&lt;br&gt;
[9] http://google-opensource.blogspot.fr/2011/04/introducing-cityhash.html&lt;br&gt;
[10] http://incise.org/hash-table-benchmarks.html&lt;br&gt;
[11] http://preshing.com/20110603/hash-table-performance-tests&lt;br&gt;
[12] http://attractivechaos.wordpress.com/2008/08/28/comparison-of-hash-table-libraries/&lt;br&gt;
[13] http://attractivechaos.wordpress.com/2008/10/07/another-look-at-my-old-benchmark/&lt;br&gt;
[14] http://blog.aggregateknowledge.com/2011/11/27/big-memory-part-3-5-google-sparsehash/&lt;br&gt;
[15] http://gcc.gnu.org/&lt;br&gt;
[16] https://code.google.com/p/sparsehash/&lt;br&gt;
[17] http://fallabs.com/kyotocabinet/spex.html&lt;br&gt;
[18] http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2003/n1456.html&lt;br&gt;
[1\9] http://sparsehash.googlecode.com/svn/trunk/doc/implementation.html&lt;br&gt;
[20] http://en.wikipedia.org/wiki/CPU_cache&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81091-62ce72541.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81091-62ce72541.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>实现键值对存储（四）：API设计</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;为开发者打造的Linux视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/75842/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（0）：目录&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/75844/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（1）：什么是键值对存储，为什么要实现它&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/77750/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（2）：以现有键值对存储为模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/78869/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（3）：Kyoto Cabinet和LevelDB的架构比较分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我终于为这个键值对存储项目确定了一个名字，从现在开始我将叫它&lt;span style=&quot;text-decoration: line-through;&quot;&gt;FelixDB&lt;/span&gt; &lt;strong&gt;KingDB&lt;/strong&gt;。（译注：改成这么土的名字也是醉了）&lt;/p&gt;
&lt;p&gt;在本文中，我将对带着大家看一看四个键值对存储和数据库系统的API：LevelDB, Kyoto Cabinet, BerkekeyDB 和 SQLite3。对于其API中的每个主要功能，我将会比较他们的命名习惯和方法原型，以平衡其优缺点并为正在开发的键值对存储KingDB设计API。本文将包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;API设计的一般准则&lt;/li&gt;
&lt;li&gt;定义KingDB公共API的功能&lt;/li&gt;
&lt;li&gt;比较现有数据库的API&lt;br&gt;
3.1 打开和关闭数据库&lt;br&gt;
3.2 读写操作&lt;br&gt;
3.3 遍历&lt;br&gt;
3.4 参数处理&lt;br&gt;
3.5 错误管理&lt;/li&gt;
&lt;li&gt;结论&lt;/li&gt;
&lt;li&gt;参考文献&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;1.API设计的一般准则&lt;/h1&gt;
&lt;p&gt;设计一个好的API很难，相当难。但我在这说的不是什么新东西，而只是在重复之前很多人告诉我的东西。到目前为止我发现的最好的资料是Joshua Bloch的演讲“How to Design a Good API &amp;amp; Why it Matters（如何设计一个好的API及为什么这很重要）”&lt;a href=&quot;#ref&quot;&gt;[1]&lt;/a&gt;，及其摘要版本&lt;a href=&quot;#ref&quot;&gt;[2]&lt;/a&gt;。如果你还没有看过这个演讲，我强烈建议你找时间去看一下。在这个演讲中，Bloch清晰的陈述了听众需要记住的两个很重要的东西。我复制了摘要版本的要点并添加了一些评论：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;strong&gt;不确定的时候，先放一边。&lt;/strong&gt;当不确定某功能、类、方法或参数是否要添加在API中的时候，不要添加。&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;不要让用户做库可以做的事情。&lt;/strong&gt;如果你的API让客户执行一系列函数调用的时候，需要将每个函数的输出塞到下一个函数的输入里，那你应该在API中添加一个函数来执行这一系列的函数调用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;另一个关于API设计的好资源是Joshua Bloch写的《Effective Java》&lt;a href=&quot;#ref&quot;&gt;4&lt;/a&gt;和Scott Meyers写的《Effective C++》&lt;a href=&quot;#ref&quot;&gt;3&lt;/a&gt;第四章“Designs and Declarations”。&lt;/p&gt;
&lt;p&gt;这些资源对于当前阶段的这个键值对存储项目来说十分重要，尽管我觉得这些资源没有包含一个很重要的因素：用户期望。将API从草图上设计出来是很难的，但这个键值对存储的例子来说，是有例可循的。用户一直和他们的键值对存储或数据库系统的API打交道。因此，当面对一个新的键值对存储的时候，用户希望有一个类似的环境，而不关心这潜规则只会提高用户对新API的学习曲线，并让用户不高兴。&lt;/p&gt;
&lt;p&gt;鉴于这个原因，即便我牢记上文列出的这些资料中的所有好建议，但我仍认为我必须尽可能多的复制已有库的API，因为这可以在用户使用我正创建的API时更简单。&lt;/p&gt;
&lt;h1&gt;2.定义KingDB公共API的功能&lt;/h1&gt;
&lt;p&gt;考虑到这只是万里长征的第一步，我打算实现一个最小且可靠的键值对存储，我当然不会包含所有的，像Kyoto Cabinet 和LevelDB那样的成熟项目提供的高级功能。我打算先让基本功能实现，然后我将逐渐增加其他功能。对于我来说，基本功能严格限制在：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;打开和关闭数据库&lt;/li&gt;
&lt;li&gt;读写数据库&lt;/li&gt;
&lt;li&gt;遍历数据库中所有的键值对集合&lt;/li&gt;
&lt;li&gt;提供参数调整的方法&lt;/li&gt;
&lt;li&gt;提供一个合适的错误通知接口&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我意识到这些功能对于一些用例来说过于局限了，但暂时应该对付的过来。我不打算添加任何事务机制、分类查询、或原子操作。同样，现在我不打算提供快照功能。&lt;/p&gt;
&lt;h1&gt;3.比较现有数据库的API&lt;/h1&gt;
&lt;p&gt;为了比较现有数据库的C++ API，我将会比较每个功能的示例代码。 这些示例代码是修改自或直接取自于官方代码“Fundamental Specifications of Kyoto Cabinet” &lt;a href=&quot;#ref&quot;&gt;[5]&lt;/a&gt;, “LevelDB’s Detailed Documentation” &lt;a href=&quot;#ref&quot;&gt;[6]&lt;/a&gt;, “Getting Started with Berkeley DB” &lt;a href=&quot;#ref%22&quot;&gt;[7]&lt;/a&gt;, 和 “SQLite in 5 minutes or less” &lt;a href=&quot;#ref&quot;&gt;[8]&lt;/a&gt;。 我同样会使用不同的颜色来标示来自不同的API。&lt;/p&gt;
&lt;h2&gt;3.1 打开和关闭数据库&lt;/h2&gt;
&lt;p&gt;下述示例代码显示出研究的系统是如何打开数据库的。为了更清晰的显示代码原理，选项设置和错误管理没有在此显示，并且会在下述各节中解释更多的细节。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* LevelDB */
leveldb::DB* db;
leveldb::DB::Open(leveldb::Options, &quot;/tmp/testdb&quot;, &amp;amp;db);
...
delete db;&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Kyoto Cabinet */
HashDB db;
db.open(&quot;dbfile.kch&quot;, HashDB::OWRITER | HashDB::OCREATE);
...
db.close()&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* SQLite3 */
sqlite3 *db;
sqlite3_open(&quot;askyb.db&quot;, &amp;amp;db);
...
sqlite3_close(db);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Berkeley DB */
Db db(NULL, 0);
db.open(NULL, &quot;my_db.db&quot;, NULL, DB_BTREE, DB_CREATE, 0);
...
db.close(0);&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;在打开数据库部分出现了两种清晰的模式。一方面，LevelDB 和SQLite3的API请求创建一个数据库对象的指针（句柄）。然后调用打开函数的时候将这个指针的引用作为参数，以定位对象的内存空间，然后设置这个数据库对象。另一方面，Kyoto Cabinet 和Berkeley DB的API以实例化一个数据库对象为开始，然后调对象的用open()方法来设置这个数据库对象。&lt;/p&gt;
&lt;p&gt;说到关闭数据库部分，LevelDB只需要请求删除指针就行了，但SQLite3必须调用关闭函数。Kyoto Cabinet 和BerkeleyDB的数据库对象自身有一个close()方法。&lt;/p&gt;
&lt;p&gt;我相信像LevelDB 和SQLite3那样强制使用数据库对象的指针，然后将指针传递给打开函数是很“C风格”的。另外，我认为LevelDB处理关闭的方法—通过删除指针—是一个设计缺陷。因为这会导致API的&lt;strong&gt;不对称&lt;/strong&gt;。在API中，函数的对称应该尽可能的对称，因为这样更加直观和逻辑。“如果我调用了open() 那我就应该调用close()”的想法比“如果我调用了open() 那我就应该删除指针”的想法合乎逻辑一万倍。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;设计决策&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因此我决定使用在KingDB上的是类似于Kyoto Cabinet 和Berkeley DB的，先实例化一个数据库对象，然后调用对象的Open() 和Close()方法。至于命名，我仍使用传统的Open() 和Close()。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2&gt;3.2 读写&lt;/h2&gt;
&lt;p&gt;在本节，我比较他们读写功能的API。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* LevelDB */
std::string value;
db-&amp;amp;gt;Get(leveldb::ReadOptions(), &quot;key1&quot;, &amp;amp;amp;value);
db-&amp;amp;gt;Put(leveldb::WriteOptions(), &quot;key2&quot;, value);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Kyoto Cabinet */
string value;
db.get(&quot;key1&quot;, &amp;amp;amp;value);
db.set(&quot;key2&quot;, &quot;value&quot;);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* SQLite3 */
int szErrMsg;
char *query = “INSERT INTO table col1, col2 VALUES (‘value1’, ‘value2’)”;
sqlite3_exec(db, query, NULL, 0, &amp;amp;amp;szErrMsg);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Berkeley DB */
/* reading */
Dbt key, data;

key.set_data(&amp;amp;amp;money);
key.set_size(sizeof(float));

data.set_data(description);
data.set_ulen(DESCRIPTION_SIZE + 1);
data.set_flags(DB_DBT_USERMEM);

db.get(NULL, &amp;amp;amp;key, &amp;amp;amp;data, 0);

/* writing */
char *description = &quot;Grocery bill.&quot;;
float money = 122.45;

Dbt key(&amp;amp;amp;money, sizeof(float));
Dbt data(description, strlen(description) + 1);

db.put(NULL, &amp;amp;amp;key, &amp;amp;amp;data, DB_NOOVERWRITE);

int const DESCRIPTION_SIZE = 199;
float money = 122.45;
char description[DESCRIPTION_SIZE + 1];&lt;/pre&gt;
&lt;p&gt;我不会考虑SQLite3的设计，因为其是基于SQL的，因此其读写是通过SQL请求进行的，而非方法调用。Berkeley DB请求Dbt类对象的创建，并在上面进行一大堆设置，因此我也不会考虑这个设计。剩下的只有LevelDB 和Kyoto Cabinet，而他们有很漂亮的getter/setter对称接口。LevelDB 有Get() 和Put(), 而Kyoto Cabinet 有get() 和set()。Setter方法的原型——Put() 和set()十分相似：键名是值传递，而键值是传递的指针使得调用时可以更改。键值并不通过调用返回，返回值是给错误管理使用的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;设计决策&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于KingDB，我打算使用和LevelDB 及Kyoto Cabinet相似的方法，对于setter方法使用一个相似的原型，即用值传递键值而用指针传递键值。至于命名，一开始我觉得Get() 和Set()是最好的选择，但仔细思考之后我更倾向于LevelDB那样，使用Get() 和Put()。其原因是Get/Set 和Get/Put都很对称，但“Get” 和 “Set”两个词太相似，只差了一个字母。因此阅读代码的时候使用“Get” 和“Put”会更加清晰且更易辨认，因此我会使用Get/Put。&lt;/p&gt;
&lt;h2&gt;3.3 遍历&lt;/h2&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* LevelDB */
leveldb::Iterator* it = db-&amp;amp;gt;NewIterator(leveldb::ReadOptions());
for (it-&amp;amp;gt;SeekToFirst(); it-&amp;amp;gt;Valid(); it-&amp;amp;gt;Next()) {
  cout &amp;amp;lt;&amp;amp;lt; it-&amp;amp;gt;key().ToString() &amp;amp;lt;&amp;amp;lt; &quot;: &quot;  &amp;amp;lt;&amp;amp;lt; it-&amp;amp;gt;value().ToString() &amp;amp;lt;&amp;amp;lt; endl;
}
delete it;&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Kyoto Cabinet */
DB::Cursor* cur = db.cursor();
cur-&amp;amp;gt;jump();
string ckey, cvalue;
while (cur-&amp;amp;gt;get(&amp;amp;amp;ckey, &amp;amp;amp;cvalue, true)) {
  cout &amp;amp;lt;&amp;amp;lt; ckey &amp;amp;lt;&amp;amp;lt; &quot;:&quot; &amp;amp;lt;&amp;amp;lt; cvalue &amp;amp;lt;&amp;amp;lt; endl;
}
delete cur;&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* SQLite3 */
static int callback(void *NotUsed, int argc, char **argv, char **szColName) {
  for(int i = 0; i &amp;amp;lt; argc; i++) {
    printf(&quot;%s = %s\n&quot;, szColName[i], argv[i] ? argv[i] : &quot;NULL&quot;);
  }
  printf(&quot;\n&quot;);
  return 0;
}

char *query = “SELECT * FROM table”;
sqlite3_exec(db, query, callback, 0, &amp;amp;amp;szErrMsg);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Berkeley DB */
Dbc *cursorp;
db.cursor(NULL, &amp;amp;amp;cursorp, 0);
Dbt key, data;
while (cursorp-&amp;amp;gt;get(&amp;amp;amp;key, &amp;amp;amp;data, DB_NEXT) == 0) {
  // do things
}
cursorp-&amp;amp;gt;close();&lt;/pre&gt;
&lt;p&gt;在上一节中，SQLite3不被考虑是因为其不满足键值对存储的需求。但看看它是如何将一个SELECT请求发送到数据库，然后在取回来的每一行上调用回调函数是比较有趣的。大多数MySQL 和 PostgreSQL的API用循环并调用一个能够填充本地变量的函数来做到，而非这样使用一个回调函数。我发现这种回调函数比较棘手，因为这对于那些想执行合计操作或对取回来的行进行计算的用户来说，会让事情变得复杂。但这是另一方面的讨论，现在回到我们的键值对存储上来！&lt;/p&gt;
&lt;p&gt;这里有两种方法：使用游标或者使用遍历器。Kyoto Cabinet 和BerkeleyDB使用游标，一开始创建一个指向游标对象的指针并实例化对象，然后在while循环中重复调用游标的get()方法来获取数据库中所有的值。LevelDB使用遍历器设计模式，一开始创建一个指向遍历器对象的指针并实例化对象（这部分和游标一样），但是使用一个for循环来遍历集合中的项目。注意这里的while和for循环只是习惯：游标可以使用for循环而遍历器也可以使用while循环。其主要的不同是，在游标中，键和值是指针传递然后在游标的get()方法中填充内容，但在迭代器中，键和值是通过迭代器方法的返回值来访问的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;设计决策&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;同样，游标和其while循环是相当“C风格”的。我发现迭代器的方法更加清晰并更符合“C++风格”，因为这正是C++中STL的集合的访问方式。因此对于KingDB来说，我选择使用LevelDB那样的遍历器。至于命名，我简单的复制了LevelDB中的方法名。&lt;/p&gt;
&lt;h2&gt;3.4 参数处理&lt;/h2&gt;
&lt;p&gt;参数在IKVS系列文章中第三部分3.4节已经简要叙述了，但我还想在这提一下。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* LevelDB */
leveldb::DB* db;
leveldb::Options options;
options.create_if_missing = true;
options.compression = leveldb::kNoCompression;
leveldb::DB::Open(options, &quot;/tmp/testdb&quot;, &amp;amp;amp;db);
...
leveldb::WriteOptions write_options;
write_options.sync = true;
db-&amp;amp;gt;Put(write_options, &quot;key&quot;, &quot;value&quot;);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Kyoto Cabinet */
db.tune_options(GrassDB::TCCOMPESS);
db.tune_buckets(500LL * 1000);
db.tune_page(32768);
db.tune_page_cache(1LL &amp;amp;lt;&amp;amp;lt; 20);
db.open(...);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* SQLite3 */ 
sqlite3_config(SQLITE_CONFIG_MULTITHREAD);
sqlite3_config(SQLITE_CONFIG_MEMSTATUS, 1);
sqlite3_config(SQLITE_CONFIG_LOG, SqliteLogger, NULL);
sqlite3_initialize();
sqlite3_open(...);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Berkeley DB */
db.set_flags(DB_DUPSORT);
db.set_bt_compare(compare_fct);
db.open(NULL, file_name, NULL, DB_BTREE, DB_CREATE, 0);&lt;/pre&gt;
&lt;p&gt;SQLite3是通过sqlite3_config()修改全局参数，然后在所有后续连接建立的时候应用。Kyoto Cabinet 和Berkeley DB中，选项是在调用open()之前通过调用数据库对象的方法来设置选项的，和SQlite3的做法比较相似。在这些方法之上，更通用的选项是通过open()方法的参数来设置的（见上文3.1节）。这表示选项被分为两部分，一些通过方法的调用来设置，而另一些是通过open()的调用来设置。&lt;/p&gt;
&lt;p&gt;LevelDB的做法不大一样。选项是在自己的类中一起定义，而参数是通过这些类的属性来更改。之后这些设置类的对象以方法参数的形式传递，并总是第一个参数。例如LevelDB数据对象的open()方法的第一个参数是leveldb::Options类的对象，而Get()和Put()方法的第一个参数分别是leveldb::ReadOptions 和leveldb::WriteOptions。这种设计的一个好处是在同时创建多个数据库的情况下可以很简单的共享设置，尽管在Kyoto Cabinet 和 Berkeley DB的例子中可以为一组设置创建一个方法，然后通过调用这个方法来设置这组设定。像LevelDB那样把设置放到一个特定的类中真正的优势在于，其接口更稳定，因为扩展设置只需要修改这个选项类，而不用修改数据库对象的任何方法。&lt;/p&gt;
&lt;p&gt;尽管我想用这种选项类，但我必须说的是LevelDB这种总是将选项作为第一个参数在各个方法中传递的方式我不是很习惯。如果没有需要修改的选项，这导致代码中需要使用默认选项，就像这样：&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;db.Put(leveldb::WriteOptions, &quot;key&quot;, &quot;value&quot;);&lt;/pre&gt;
&lt;p&gt;这可能导致代码膨胀，而另一种可能是将选项作为最后一个参数，然后为这个参数设定一个缺省值，使得不需要设置选项的时候可以省掉这项。而另一种源自于C++的解决方式是函数的重载，有数个带有原型的方法使其可以省略掉选项的对象。把选项放到参数的最后对于我来说看上去更符合逻辑，因为其是可能省略的。但我相信LevelDB的作者把选项作为第一个参数是有很好的原因的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;设计决策&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于参数处理，我觉得将选项作为类是最简洁的方式，同时其符合面向对象设计。&lt;/p&gt;
&lt;p&gt;对于KingDB来说，我会像LevelDB那样使用独立的类来处理选项，不过我会将作为方法的最后一个参数。我或许以后能明白将选项作为最后一个参数是真正正确的方法——或者有谁能帮我解释下——但现在我坚持将其放到最后。最后，命名子啊这儿不是很重要，因此Options, ReadOption 和WriteOption都可以。&lt;/p&gt;
&lt;h2&gt;3.5 错误管理&lt;/h2&gt;
&lt;p&gt;在IKVS系列第三部分3.6节，有关于错误管理的一些讨论，基本上是说用户看不到的代码是如何管理错误的。本节再次讨论这个话题但稍有不同，不讨论库中错误的细节，而是关于错误发生后是怎么报告给使用公共接口的用户的。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* LevelDB */
leveldb::Status s = db-&amp;amp;gt;Put(leveldb::WriteOptions(), &quot;key&quot;, &quot;value&quot;);
if (!s.ok()) {
  cerr &amp;amp;lt;&amp;amp;lt; s.ToString() &amp;amp;lt;&amp;amp;lt; endl;
}&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Kyoto Cabinet */
if (!db.set(&quot;baz&quot;, &quot;jump&quot;)) {
  cerr &amp;amp;lt;&amp;amp;lt; &quot;set error: &quot; &amp;amp;lt;&amp;amp;lt; db.error().name() &amp;amp;lt;&amp;amp;lt; endl;
}&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* SQLite3 */
int rc = sqlite3_exec(db, query, callback, 0, &amp;amp;amp;zErrMsg);
if (rc != SQLITE_OK) {
  fprintf(stderr, &quot;SQL error: %s\n&quot;, zErrMsg);
  sqlite3_free(zErrMsg);
}&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Berkeley DB */
int ret = my_database.put(NULL, &amp;amp;amp;key, &amp;amp;amp;data, DB_NOOVERWRITE);
if (ret == DB_KEYEXIST) {
  my_database.err(ret, &quot;Put failed because key %f already exists&quot;, money);
}&lt;/pre&gt;
&lt;p&gt;Kyoto Cabinet, Berkeley DB 和SQLite3使用相同的方法处理错误，即其方法返回一个整型的错误代码。如在IKVS系列第三部分3.6节所述，Kyoto Cabinet内部将值设置在数据库对象中，这就是为何上述示例代码中，错误信息是从db.error().name()取出的。&lt;/p&gt;
&lt;p&gt;LevelDB有个一特别的Status类，包含错误类型和提供了关于此错误更多信息的消息。LevelDB库中的所有方法都返回了此类的一个对象，这使错误测试和将错误传递给系统各部分以进行进一步的检查更加简单。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;设计决策&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;返回错误代码而避免使用C++的异常处理机制是十分正确的，然而整形并不足以携带有意义的信息。Kyoto Cabinet, Berkeley DB 和SQLite3都有其自己的存储错误信息的方法，然而即便是在在Kyoto Cabinet 和Berkeley例子中，创建了错误管理和数据库类的强耦合，，仍然会为取得信息添加额外的步骤。像LevelDB那样使用一个Status类可以避免使用C++异常处理，同时也避免了和架构其他部分的耦合。&lt;/p&gt;
&lt;h1&gt;4.结论&lt;/h1&gt;
&lt;p&gt;API的预设比较有意思，因为去看不同的工程师如何解决相同的问题总是很有意思的。这同样让我意识到Kyoto Cabinet 和Berkeley DB的API有多么相似。Kyoto Cabinet 的作者Mikio Hirabayashi清楚地声明了他的键值对存储是基于Berkeley DB的，而在看完API相似性之后这一点更加清晰了。&lt;/p&gt;
&lt;p&gt;LevelDB的设计相当好，但我还是对于一些我认为可以以其他方式实现的细节有些意见。例如数据库打开和关闭以及方法原型。&lt;/p&gt;
&lt;p&gt;我吸取了每个系统的一点长处，而我现在对于KingDB的API设计的各个选择感觉更加自信了。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;ref&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;5.参考文献&lt;/h1&gt;
&lt;p&gt;[1] http://www.infoq.com/presentations/effective-api-design&lt;br&gt;
[2] http://www.infoq.com/articles/API-Design-Joshua-Bloch&lt;br&gt;
[3] http://www.amazon.com/Effective-Specific-Improve-Programs-Designs/dp/0321334876&lt;br&gt;
[4] http://www.amazon.com/Effective-Java-Edition-Joshua-Bloch/dp/0321356683&lt;br&gt;
[5] http://fallabs.com/kyotocabinet/spex.html&lt;br&gt;
[6] http://leveldb.googlecode.com/svn/trunk/doc/index.html&lt;br&gt;
[7] http://docs.oracle.com/cd/E17076_02/html/gsg/CXX/index.html&lt;br&gt;
[8] http://www.sqlite.org/quickstart.html&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81083-a39d9afd4.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81083-a39d9afd4.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>What Happened to NSMethodSignature?</title>
        <description>

						
						

						&lt;p class=&quot;update&quot;&gt;UPDATE: We’ve added the Request.playground file to this post so you can download it and easily experiment with the code yourself.&lt;/p&gt;
&lt;p&gt;Bringing the Cocoa frameworks to Swift gave us a unique opportunity to look at our APIs with a fresh perspective. We found classes that we didn&#39;t feel fit with the goals of Swift, most often due to the priority we give to safety.  For instance, some classes related to dynamic method invocation are not exposed in Swift, namely &lt;span class=&quot;keyword&quot;&gt;NSInvocation&lt;/span&gt; and &lt;span class=&quot;keyword&quot;&gt;NSMethodSignature&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We recently received a bug report from a developer who noticed this absence. This developer was using &lt;span class=&quot;keyword&quot;&gt;NSMethodSignature&lt;/span&gt; in Objective-C to introspect the types of method arguments, and in the process of migrating this code to Swift, noticed that &lt;span class=&quot;keyword&quot;&gt;NSMethodSignature&lt;/span&gt; is not available. The code being migrated could accept HTTP handlers of varying signatures, such as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&lt;span class=&quot;key&quot;&gt;func&lt;/span&gt; handleRequest(request: &lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, queryStringArguments: [&lt;span class=&quot;title&quot;&gt;String&lt;/span&gt;: &lt;span class=&quot;title&quot;&gt;String&lt;/span&gt;]) { }
&lt;span class=&quot;key&quot;&gt;func&lt;/span&gt; handleRequest(request: &lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, jsonBody: &lt;span class=&quot;title&quot;&gt;JSON&lt;/span&gt;) { }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In Objective-C, &lt;span class=&quot;keyword&quot;&gt;NSMethodSignature&lt;/span&gt; can be used to determine that the API of the first method would require a &lt;span class=&quot;keyword&quot;&gt;[String: String]&lt;/span&gt; argument, and the second method would require a &lt;span class=&quot;keyword&quot;&gt;JSON&lt;/span&gt; value. However, Swift is a powerful language and can easily handle this scenario without using &lt;span class=&quot;keyword&quot;&gt;NSMethodSignature&lt;/span&gt;, and in a way that doesn&#39;t undermine the help that the compiler provides for type and memory safety.&lt;/p&gt;
&lt;p&gt;Here is an alternative way to solve the same problem in Swift:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&lt;span class=&quot;key&quot;&gt;struct&lt;/span&gt; HTTPRequest {
	&lt;span class=&quot;comment&quot;&gt;// ...&lt;/span&gt;
}

&lt;span class=&quot;key&quot;&gt;protocol&lt;/span&gt; HTTPHandlerType {
	&lt;span class=&quot;key&quot;&gt;typealias&lt;/span&gt; Data

	&lt;span class=&quot;comment&quot;&gt;/// :returns: true if the request was handled; false otherwise&lt;/span&gt;
	&lt;span class=&quot;key&quot;&gt;func&lt;/span&gt; handle(request: &lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, data: &lt;span class=&quot;title&quot;&gt;Data&lt;/span&gt;) -&amp;gt; &lt;span class=&quot;title&quot;&gt;Bool&lt;/span&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we&#39;ll use a protocol to define that whatever is going to handle our &lt;span class=&quot;keyword&quot;&gt;HTTPRequest&lt;/span&gt; does so via this interface. This protocol is very simple, with only a single method.&lt;/p&gt;
&lt;p&gt;Why use a protocol here, instead of subclassing an &lt;span class=&quot;keyword&quot;&gt;HTTPHandler&lt;/span&gt; class? Because protocols give the flexibility of leaving the implementation details up to the clients of this code. If we were to make an &lt;span class=&quot;keyword&quot;&gt;HTTPHandler&lt;/span&gt; class, we would require clients to also use classes, forcing upon them the semantics of reference types. However, by using a protocol, clients can decide for themselves the appropriate type to use in their code, whether it be class, struct, or even enum.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&lt;span class=&quot;key&quot;&gt;class&lt;/span&gt; HTTPServer {
	&lt;span class=&quot;key&quot;&gt;func&lt;/span&gt; addHandler&amp;lt;T: HTTPHandlerType&amp;gt;(handler: &lt;span class=&quot;title&quot;&gt;T&lt;/span&gt;) {
		handlers.append { (request: &lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, args: &lt;span class=&quot;title&quot;&gt;Any&lt;/span&gt;) -&amp;gt; Bool &lt;span class=&quot;key&quot;&gt;in&lt;/span&gt;
			&lt;span class=&quot;key&quot;&gt;if let&lt;/span&gt; typedArgs = args &lt;span class=&quot;key&quot;&gt;as&lt;/span&gt;? &lt;span class=&quot;pointer&quot;&gt;T&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Data&lt;/span&gt; {
				&lt;span class=&quot;key&quot;&gt;return&lt;/span&gt; handler.handle(request, data: typedArgs)
			}
			&lt;span class=&quot;key&quot;&gt;return false&lt;/span&gt;
		}
	}

	&lt;span class=&quot;comment&quot;&gt;// ...&lt;/span&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, our &lt;span class=&quot;keyword&quot;&gt;HTTPServer&lt;/span&gt; class has a generic method that accepts an &lt;span class=&quot;keyword&quot;&gt;HTTPHandlerType&lt;/span&gt; as a parameter. By using the handler&#39;s associated type, it can perform the conditional downcast of the &lt;span class=&quot;keyword&quot;&gt;args&lt;/span&gt; parameter to determine if this handler should be given an opportunity to handle the request. Here we can see the benefit of defining &lt;span class=&quot;keyword&quot;&gt;HTTPHandlerType&lt;/span&gt; as a protocol. The &lt;span class=&quot;keyword&quot;&gt;HTTPServer&lt;/span&gt; doesn&#39;t need to know &lt;em&gt;how&lt;/em&gt; the handler is reacting to the request, nor does it even need to care about the nature of the handler itself. All it needs to know is that the value can handle requests.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&lt;span class=&quot;key&quot;&gt;class&lt;/span&gt; HTTPServer {
	&lt;span class=&quot;comment&quot;&gt;// ...&lt;/span&gt;

	&lt;span class=&quot;key&quot;&gt;private var&lt;/span&gt; handlers: [(&lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, &lt;span class=&quot;title&quot;&gt;Any&lt;/span&gt;) -&amp;gt; &lt;span class=&quot;title&quot;&gt;Bool&lt;/span&gt;] = []

	&lt;span class=&quot;key&quot;&gt;func&lt;/span&gt; dispatch(req: &lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, args: &lt;span class=&quot;title&quot;&gt;Any&lt;/span&gt;) -&amp;gt; &lt;span class=&quot;title&quot;&gt;Bool&lt;/span&gt; {
		&lt;span class=&quot;key&quot;&gt;for&lt;/span&gt; handler &lt;span class=&quot;key&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;pointer&quot;&gt;handlers&lt;/span&gt; {
			&lt;span class=&quot;key&quot;&gt;if&lt;/span&gt; handler(req, args) {
				&lt;span class=&quot;key&quot;&gt;return true&lt;/span&gt;
			}
		}
		&lt;span class=&quot;key&quot;&gt;return false&lt;/span&gt;
	}
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When our &lt;span class=&quot;keyword&quot;&gt;HTTPServer&lt;/span&gt; receives a request, it will iterate through its handlers and see if any can deal with the request.&lt;/p&gt;
&lt;p&gt;Now we can easily create a custom &lt;span class=&quot;keyword&quot;&gt;HTTPHandlerType&lt;/span&gt; with varying argument types and register it with the &lt;span class=&quot;keyword&quot;&gt;HTTPServer&lt;/span&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&lt;span class=&quot;key&quot;&gt;class&lt;/span&gt; MyHandler : &lt;span class=&quot;pointer&quot;&gt;HTTPHandlerType&lt;/span&gt; {
	&lt;span class=&quot;key&quot;&gt;func&lt;/span&gt; handle(request: &lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, data: &lt;span class=&quot;title&quot;&gt;Int&lt;/span&gt;) -&amp;gt; &lt;span class=&quot;title&quot;&gt;Bool&lt;/span&gt; {
		&lt;span class=&quot;key&quot;&gt;return&lt;/span&gt; data &amp;gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;
	}
}

&lt;span class=&quot;key&quot;&gt;let&lt;/span&gt; server = &lt;span class=&quot;pointer&quot;&gt;HTTPServer&lt;/span&gt;()
&lt;span class=&quot;pointer&quot;&gt;server&lt;/span&gt;.&lt;span class=&quot;enum&quot;&gt;addHandler&lt;/span&gt;(&lt;span class=&quot;pointer&quot;&gt;MyHandler&lt;/span&gt;())
&lt;span class=&quot;pointer&quot;&gt;server&lt;/span&gt;.dispatch(&lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;(...), args: &lt;span class=&quot;string&quot;&gt;&quot;x&quot;&lt;/span&gt;) &lt;span class=&quot;comment&quot;&gt;// returns false&lt;/span&gt;
&lt;span class=&quot;pointer&quot;&gt;server&lt;/span&gt;.dispatch(&lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;(...), args: &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;)   &lt;span class=&quot;comment&quot;&gt;// returns false&lt;/span&gt;
&lt;span class=&quot;pointer&quot;&gt;server&lt;/span&gt;.dispatch(&lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;(...), args: &lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;)  &lt;span class=&quot;comment&quot;&gt;// returns true&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a combination of protocols and generics, we have written Swift code to elegantly create and register HTTP handlers of varying types. This approach also lets the compiler guarantee type safety, while ensuring excellent runtime performance.&lt;/p&gt;

						
												&lt;ul class=&quot;links small padding-top-20&quot;&gt;
														&lt;li class=&quot;download&quot;&gt;&lt;a href=&quot;/swift/blog/downloads/Request.zip&quot;&gt;Request.playground&lt;/a&gt;&lt;/li&gt;
													&lt;/ul&gt;
						

												
											

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12--id=19-96752c478.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12--id=19-96752c478.html</guid>
        
        
        <category>apple_swift</category>
        
      </item>
    
      <item>
        <title>超酷算法：Levenshtein自动机</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p align=&quot;left&quot;&gt;在上一期的超酷算法中，我们聊到了BK树，这是一种非常聪明的索引结构，能够在搜索过程中进行模糊匹配，它基于编辑距离（Levenshtein distance），或者任何其它服从三角不等式的度量标准。今天，我将继续介绍另一种方法，它能够在常规索引中进行模糊匹配搜索，我们将它称之为Levenshtein自动机。&lt;/p&gt;
&lt;h1&gt;简介&lt;/h1&gt;
&lt;p&gt;Levenshtein自动机背后的基本理念是：能够构建一个有限状态自动机，准确识别出和某个目标单词相距在给定编辑距离内的所有字符串集合。之后就好办了，我们可以输入任意单词，自动机能够判断这个单词到目标单词的距离是否大于我们在构建时指定的距离，并选择接收或拒绝。更进一步说，根据FSA的自然特性，这项工作可以在O(n)时间内完成，取决于测试字符串的长度。与此相比，标准动态编程距离向量算法需要消耗O(mn)时间，m和n分别是两个输入单词的长度。因此很显然，起码Levenshtein向量机提供了一种更快的方式，供我们针对一个目标单词和最大距离，检查所有的单词，这是一个不错的改进的开端。&lt;br&gt;
当然，如果Levenshtein向量机只有优点，那这篇文章将会很短。我们将会谈到很多，不过我们先来看一下Levenshtein向量机究竟是何物，以及我们如何建立一个Levenshtein自动机。&lt;/p&gt;
&lt;h1&gt;构建与评价&lt;/h1&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/979c4cce37819656ccc8e8f203276919.png&quot; rel=&quot;lightbox[80659]&quot; title=&quot;超酷算法：Levenshtein自动机&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-80663&quot; alt=&quot;levenstein-nfa-food&quot; src=&quot;/images/jobbole.com/2e670a18ce556bc41d7a6af4143c225d.jpg&quot;&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;上图展示了针对单词food的Levenshtein自动机的NFA（译者注：非确定性有限自动机），其最大编辑距离为2。你可以看到，它很普通，构建过程也非常直观。初始状态在左下部分，我们使用n&lt;sup&gt;e&lt;/sup&gt;记法对状态进行命名，n是指到目前为止被处理过的特性的数量，e是指错误的个数。水平线表示没有被修改的特性，垂直线表示插入的值，而两条对角线则分别表示交换（标记a*）和删除。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;我们来看一下如何通过一个给定的输入单词和最大编辑距离构建一个NFA，由于整个NFA类是非常标准化的，因此我就不赘述其源码了，如果你需要更多细节，请看&lt;a href=&quot;http://gist.github.com/491973&quot;&gt;Gist&lt;/a&gt;。以下是基于Python的相关方法：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;def levenshtein_automata(term, k):
  nfa = NFA((0, 0))
  for i, c in enumerate(term):
    for e in range(k + 1):
      # Correct character
      nfa.add_transition((i, e), c, (i + 1, e))
      if e &amp;lt; k:
        # Deletion
        nfa.add_transition((i, e), NFA.ANY, (i, e + 1))
        # Insertion
        nfa.add_transition((i, e), NFA.EPSILON, (i + 1, e + 1))
        # Substitution
        nfa.add_transition((i, e), NFA.ANY, (i + 1, e + 1))
  for e in range(k + 1):
    if e &amp;lt; k:
      nfa.add_transition((len(term), e), NFA.ANY, (len(term), e + 1))
    nfa.add_final_state((len(term), e))
  return nfa&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;这应该很容易实现，基本上我们用了一种最直接了当的方式构建前图中表示的变换，同时也指出了最终正确的状态集。状态标签是元组，而不是字符串，这与我们前面的描述是一致的。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;由于这是一个NFA，可以有多个活跃状态，它们表示目前被处理过的字符串的可能解释。举个例子，考虑一下，在处理字符f和x之后的活跃状态：&lt;br&gt;
&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/3682a608e5f46e40f44bbfd6a42c5f1b.png&quot; rel=&quot;lightbox[80659]&quot; title=&quot;超酷算法：Levenshtein自动机&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-80664&quot; alt=&quot;levenstein-nfa-food-fx&quot; src=&quot;/images/jobbole.com/19167bafc87acf89bff84640194770ff.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;这表明，在前两个字符f和x一致的情况下，会存在若干可能的变化：一次替换，如fxod；一次插入，如fxood；两次插入，如fxfood；或者一次交换和一次删除，如fxd。同时，这也会引入了一些冗余的情况，如一次删除和一次插入，结果也是fxod。随着越来越多的字符被处理，其中一些可能性会慢慢消失，而另一些可能性会逐渐产生。如果，在处理完整个单词的所有字符后，在当前状态集中存在一个接收状态（bolded state），那么就表明存在一种方式，能够将通过两次或更少次的变换，将输入单词转化为目标单词，那么我们就可以将该单词视为是有效的。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;实际上，要直接评价一个NFA，从计算的角度来讲是极其昂贵的，因为会存在多个活跃状态和epsilon变换（不需要输入符号的变换），所以通常的做法是首先使用powerset构建法将NFA转换为DFA（译者注：确定性有限自动机）。使用这个算法能够构建出一个DFA，使每一个状态都对应原来NFA中的一个活跃状态集。在这里我们不会涉及powerset的细节，因为这有点扯远了。以下是一个例子，展示了在一个容差下，单词food的NFA所对应的DFA：&lt;br&gt;
&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/243afd6875cd002f29536238499132c2.png&quot; rel=&quot;lightbox[80659]&quot; title=&quot;超酷算法：Levenshtein自动机&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-80665&quot; alt=&quot;levenstein-dfa-food&quot; src=&quot;/images/jobbole.com/d89c2910c066835ba29c6c6d1c8ac55e.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;记住，我们是在一个容差下描述DFA的，因为要找出完全匹配我们提到的NFA所对应的DFA实在是太复杂了！以上DFA能准确接收与单词food相距一个或更少编辑距离的单词集。试试看，选择任意一个单词，通过DFA跟踪它的路径，如果你最终能到达一个接收状态，则这个单词是有效的。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;我不会把power构建的源码贴在这里，同样的，如果你感兴趣，可以在&lt;a href=&quot;http://gist.github.com/491973&quot;&gt;GIST&lt;/a&gt;里找到。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;我们暂时回到执行效率的问题上来，你可能想知道Levenshtein DFA构建的效率怎么样。我们可以在O(kn)时间内构建NFA，k是指编辑距离，n是指目标单词的长度。将其变换为DFA的最坏情况需要O(2^n)时间，所以极端情况下会需要O(2^kn)运行时间！不过情况并没有那么糟糕，有两个原因：首先，Levenshtein自动机并不会充斥着2^n这种最坏情况的DFA构建；其次，一些智慧的计算机科学家已经提出了一些算法，能够在O(n)时间内直接构建出DFA，甚至还有人[&lt;a href=&quot;http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata#schulz2002fast&quot;&gt;SCHULZ2002FAST&lt;/a&gt;]完全避开了DFA构建，使用了一种基于表格的评价方法！&lt;/p&gt;
&lt;h1&gt;索引&lt;/h1&gt;
&lt;p align=&quot;left&quot;&gt;既然我们已经证实可以构建一个Levenshtein自动机，并演示了其工作原理，下面我们来看一看如何使用这项技术高效地模糊匹配搜索索引。第一个观点，同时也是很多论文[&lt;a href=&quot;http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata#schulz2002fast&quot;&gt;SCHULZ2002FAST&lt;/a&gt;] [&lt;a href=&quot;http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata#mihov2004fast&quot;&gt;MIHOV2004FAST&lt;/a&gt;]所采用的方法，就是去观测一本字典，即你所要搜索的记录集，它自身可以被视为是一个DFA。事实上，他们经常被存储为一种字典树或有向非循环字图，这两种结构都可以被视为是DFA的特例。假设字典和标准（Levenshtein自动机）都表示为DFA，之后我们就可以高效地通过这两个DFA，准确地在字典中找到符合标准的单词集，过程非常简单，如下：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;def intersect(dfa1, dfa2):
  stack = [(&quot;&quot;, dfa1.start_state, dfa2.start_state)]
  while stack:
    s, state1, state2 = stack.pop()
    for edge in set(dfa1.edges(state1)).intersect(dfa2.edges(state2)):
      state1 = dfa1.next(state1, edge)
      state2 = dfa2.next(state2, edge)
      if state1 and state2:
        s = s + edge
        stack.append((s, state1, state2))
        if dfa1.is_final(state1) and dfa2.is_final(state2):
          yield s&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;好了，我们按照两个DFA共有的边界同时进行遍历，并记录遍历的路径轨迹。只要两个DFA处于最终状态，单词在输出集内，我们就将其输出。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;如果你的索引是以DFA（或字典树，或有向非循环字图）的形式存储的话，这非常完美，但遗憾的是许多索引并不是：如果在内存中，它们很可能位于一个排序列表中；如果在磁盘上，它们很可能位于BTree或类似结构中。有没有办法可以让我们修改方案适应这些排序索引，继而继续提供一种速度极快的方法？事实证明是有的。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;这里的关键点在于，根据我们目前以DFA表示的标准，我们可以，对于一个不匹配的输入字符串，找到下一个（按字母排序）匹配的字符串。凭直觉来说，这相当容易：我们基于DFA去评估输入字符串，直到我们无法进一步处理为止，比如说没有针对下一个字符的有效变换，之后，我们可以反复遵照字母排序的最小标签的边界，直到到达终态。在这里我们应用了两个特殊事件：首先，在第一次变换中，我们需要遵照按字母排序的最小标签，同时这些标签要大于在准备步骤中没有有效变换的特性。第二，如果我们达到了一个状态而其没有有效的外边界，那么我们要回溯到之前的状态，并重试。这差不多是解决迷宫问题的一种“循墙”算法，应用在DFA上。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;以此举例，参照food(1)的DFA，我们来思考一下输入单词foogle。我们可以有效处理前4个单词，留下状态3&lt;sup&gt;1&lt;/sup&gt;4&lt;sup&gt;1&lt;/sup&gt;，这里唯一的外边界是d，下一个字符是l，因此我们可以向前回溯一步，到2&lt;sup&gt;1&lt;/sup&gt;3&lt;sup&gt;0&lt;/sup&gt;3&lt;sup&gt;1&lt;/sup&gt;4&lt;sup&gt;1&lt;/sup&gt;，现在下一个字符是g，有一个外边界f，所以我们接收这个边界，留下接收状态（事实上，和之前的状态是一样的，只不过路径不同），输出单词为fooh，这是在DFA中按字母排序在foogle之后的单词。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;以下是python代码，展示了在DFA类上的一个方法。和前面一样，我不会写出整个DFA的样板代码，它们都在&lt;a href=&quot;http://blog.notdot.net/2010/07/&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;def next_valid_string(self, input):
    state = self.start_state
    stack = []

    # Evaluate the DFA as far as possible
    for i, x in enumerate(input):
      stack.append((input[:i], state, x))
      state = self.next_state(state, x)
      if not state: break
    else:
      stack.append((input[:i+1], state, None))

    if self.is_final(state):
      # Input word is already valid
      return input

    # Perform a &#39;wall following&#39; search for the lexicographically smallest
    # accepting state.
    while stack:
      path, state, x = stack.pop()
      x = self.find_next_edge(state, x)
      if x:
        path += x
        state = self.next_state(state, x)
        if self.is_final(state):
          return path
        stack.append((path, state, None))
    return None&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;在这个方法的第一部分，我们以常见的方式评价DFA，记录下访问过的状态，这些状态包括它们的路径以及我们尝试寻找遵循它们的边界。之后，假设没有找到一个准确的匹配项，那么就进行一次回溯，尝试去寻找一个可以到达接收状态的最小变换集。关于这个方法的一般性说明，请继续阅读……&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;同时我们还需要一个工具函数find_next_edge，找出一个状态中按字母排序比指定输入大的最小外边界：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;def find_next_edge(self, s, x):
    if x is None:
      x = u&#39;&#39;
    else:
      x = unichr(ord(x) + 1)
    state_transitions = self.transitions.get(s, {})
    if x in state_transitions or s in self.defaults:
      return x
    labels = sorted(state_transitions.keys())
    pos = bisect.bisect_left(labels, x)
    if pos &amp;lt; len(labels):
      return labels[pos]
    return None&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;经过一些预处理，这可以更高效，打个比方，我们可以对每个字符和第一个大于它的外边界建立一个映射关系，而不是在茫茫大海中进行二进制检索。再强调一次，我会把这些优化工作作为练习题留给读者。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;既然我们已经找到了这一过程，那么我们就可以最终描述如何使用这一过程进行索引搜索，算法出人意料的简单：&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;1. 取得索引中的第一个元素，或者，比索引任意有效字符串更小的一个字符串，将其称之为“当前”字符串。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;2. 将“当前”字符串传入我们之前谈到的DFA算法，得到“下一个”字符串。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;3. 如果“下一个”字符串和“当前”字符串相等，那么你已经找到了一个匹配，将其输出，再从索引中获取下一个元素作为“当前”元素，重复步骤2。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;4. 如果“下一个”字符串和“当前”字符串不相等，那么在你的索引中搜索大于等于“下一个”字符串的第一个字符串，将其作为“当前”元素，重复步骤2。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;以下是用Python实现这一过程的代码：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;def find_all_matches(word, k, lookup_func):
  &quot;&quot;&quot;Uses lookup_func to find all words within levenshtein distance k of word.

  Args:
    word: The word to look up
    k: Maximum edit distance
    lookup_func: A single argument function that returns the first word in the
      database that is greater than or equal to the input argument.
  Yields:
    Every matching word within levenshtein distance k from the database.
  &quot;&quot;&quot;
  lev = levenshtein_automata(word, k).to_dfa()
  match = lev.next_valid_string(u&#39;&#39;)
  while match:
    next = lookup_func(match)
    if not next:
      return
    if match == next:
      yield match
      next = next + u&#39;&#39;
    match = lev.next_valid_string(next)&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;理解这一算法的一种方式是将Levenshtein DFA和索引都视为排序列表，那么以上过程就类似于App引擎中的“拉链合并连接”策略。我们重复地在一侧查找字符串，再跳转到另一侧的合适位置，等等。结果是，我们省去了大量不匹配的索引实体，以及大量不匹配的Levenshtein字符串，节省了枚举它们的工作量。这些描述表明，这一过程有潜力避免去评估所有的索引实体，或所有的候选Levenshtein字符串。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;补充说明一下，所有的DFA针对任意字符串都可以找到按字母排序的最小后继，这句话是错误的。比如说，考虑一下DFA中字符串a的后继，识别模式为a+b，答案是没有这样的后继，它必须由无限多的a字符跟随单个b字符构成！不过我们可以基于以上过程做一些简单的修改，比如返回一个字符串，确保它是DFA可以识别的下一个字符串的一个前缀，这能满足我们的需求。由于Levenshtein DFA总是有限的，因此我们总是会得到一个有限长度的后继（当然，除了最后一个字符串），我们把这样的扩展留给读者作为练习题。使用这种方法，会产生一些很有意思的应用程序，比如索引化正则表达式搜索。&lt;/p&gt;
&lt;h1&gt;测试&lt;/h1&gt;
&lt;p align=&quot;left&quot;&gt;首先，我们理论联系实际，定义一个简单的Matcher类，其中实现了一个lookup_func方法，它会被find_all_matches方法调用：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;class Matcher(object):
  def __init__(self, l):
    self.l = l
    self.probes = 0

  def __call__(self, w):
    self.probes += 1
    pos = bisect.bisect_left(self.l, w)
    if pos &amp;lt; len(self.l):
      return self.l[pos]
    else:
      return None&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;记住，在此我们实现一个可调用的类的唯一理由是：我们想要从程序中提取一些信息，比如探针的个数。通常来说，一个常规或嵌套函数已经足够完美，现在，我们需要一个简单的数据集，让我们加载web2字典：&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt;&amp;gt;&amp;gt;&amp;gt; words = [x.strip().lower().decode(&#39;utf-8&#39;) for x in open(&#39;/usr/share/dict/web2&#39;)]
&amp;gt;&amp;gt;&amp;gt; words.sort()
&amp;gt;&amp;gt;&amp;gt; len(words)
234936&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;我们也可以使用几个子集测试随着数据规模的变化，会发生什么：&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt;&amp;gt;&amp;gt;&amp;gt; words10 = [x for x in words if random.random() &amp;lt;= 0.1]
&amp;gt;&amp;gt;&amp;gt; words100 = [x for x in words if random.random() &amp;lt;= 0.01]&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;这里，我们看到了实践结果：&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt;&amp;gt;&amp;gt;&amp;gt; m = Matcher(words)
&amp;gt;&amp;gt;&amp;gt; list(automata.find_all_matches(&#39;nice&#39;, 1, m))
[u&#39;anice&#39;, u&#39;bice&#39;, u&#39;dice&#39;, u&#39;fice&#39;, u&#39;ice&#39;, u&#39;mice&#39;, u&#39;nace&#39;, u&#39;nice&#39;, u&#39;niche&#39;, u&#39;nick&#39;, u&#39;nide&#39;, u&#39;niece&#39;, u&#39;nife&#39;, u&#39;nile&#39;, u&#39;nine&#39;, u&#39;niue&#39;, u&#39;pice&#39;, u&#39;rice&#39;, u&#39;sice&#39;, u&#39;tice&#39;, u&#39;unice&#39;, u&#39;vice&#39;, u&#39;wice&#39;]
&amp;gt;&amp;gt;&amp;gt; len(_)
23
&amp;gt;&amp;gt;&amp;gt; m.probes
142&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;大赞啊！在拥有235000个单词的字典中找到了针对nice的23个模拟匹配，需要142个探针。注意，如果我们假设一个字母表包含26个字母，那么会有4+26*4+26*5=238个字符串在一个Levenshtein距离内是有效的，因此与详尽的测试相比，我们做出了合理的节省。考虑到有更大的字母表，更长的字符串，或更大的编辑距离，这种节省的效果应该会更明显。如果我们使用不同种类的输入去测试，看一下探针的个数随着单词长度和字典大小的变化情况，可能会更受启发：&lt;/p&gt;
&lt;table border=&quot;1&quot; cellpadding=&quot;0&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p align=&quot;left&quot;&gt;在这个表中，”max strings”表示与输入字符串在编辑距离内的字符串总数；small，med，full dict表示所有三种字典（包含web2字典的1%，10%和100%）所需要的探针个数。所有对应的行，至少在10个字符以内，都需要与第五行差不多的探针个数。我们采用的输入字符串的例子是由单词’abracadabra’的前缀构成的。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;我们可以立即看出一些端倪：&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;1. 对于很短的字符串和很大的字典，探针的个数并没有低很多，即使低一些，和有效字符串的最大个数相比也是小巫见大巫，所以这并没有节省什么。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;2. 随着字符串越来越长，探针的个数的增长出人意料的比预期结果慢，结果就是对于10个字符，我们仅仅需要探测821中的161个（大约20%）可能结果。对于一般的单词长度（在web2字典中，97%的单词至少有5个字符长），与朴素的检查每个字符串变化相比，我们已经节省了可观的代价。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;3. 虽然样本字典的大小以不同的数量级区分，但是探针的个数增长却不太明显，这是一项令人鼓舞的证据，它表明该方法可以很好的扩展到非常大的索引数量级上。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;我们再来看一下根据不同的编辑距离阈值，情况会有何变化，你同样能得到一些启发。下面是相同的表格，最大编辑距离为2：&lt;/p&gt;
&lt;table border=&quot;1&quot; cellpadding=&quot;0&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p align=&quot;left&quot;&gt;前途一片光明：在编辑距离为2的情况下，虽然我们被迫需要加入很多探针，但是与候选字符串的数量相比，仍然是很小的代价。对于一个长度为5、编辑距离为2的单词，需要使用3377个探针，但是比起做69258次（对每一个匹配字符串）或做234936次（对字典里的每个单词），这显然少得多了！&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;我们来做一个快速比较，对于一个长度为5的字符串，编辑距离为1（与上面的例子一样），一个标准的BK树实现，基于相同的字典，需要检查5858个节点，同时，相同的情况下，我们把编辑距离改为2，则需要检查58928个节点！应当承认，如果结构合理的话，这些节点中很多都应处于相同的磁盘页，但是依然存在惊人的查找数量级的差异。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;最后一点：我们在这篇文章中参考的第二篇论文，[&lt;a href=&quot;http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata#mihov2004fast&quot;&gt;MIHOV2004FAST&lt;/a&gt;]描述了一个非常棒的结构：一个广义的Levenshtein自动机。这是一种DFA，它能在线性时间内判断，任意一组单词对互相之间的距离是否小于给定的编辑距离。改造一下我们前面的方案，使其能适应这种自动机，这也是我们留给读者的练习。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;这篇文章是涉及的完整的源代码都可以在&lt;a href=&quot;http://gist.github.com/491973&quot;&gt;这里&lt;/a&gt;找到。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Wed, 10 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-10-80659-8f286134e.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-10-80659-8f286134e.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>HBase SSD优化案例：读策略优化和中断多核绑定</title>
        <description>

                &lt;p&gt;没有开场白，直接切主题！各位把这篇当成是报告来阅读吧：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;应用IO模型：&lt;/strong&gt;大量读线程同时访问多块SSD，请求均为4KB随机读，并且被请求的数据有一定间隔连续性；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;服务器硬件配置：&lt;/strong&gt;LSI SAS 2308直连卡 + 8块SSD&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;优化前应用QPS：27K&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一轮优化：读策略优化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过 /sys/block/sdx/queue/read_ahead_kb 观察到预读大小为128KB，进一步观察iostat情况：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/preopt_iostat.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-1781&quot; alt=&quot;preopt_iostat&quot; src=&quot;/images/noops.me/94d5b0edaa24c4a356c857a423e1cc35.jpg&quot; width=&quot;850&quot; height=&quot;523&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;观察到每块SSD的rMB/s十分高，平均已经达到了250MB/s+，初步判断是由于read_ahead_kb的设置影响了应用的读效率（即预先读取了过多不必要的数据）。遂将read_ahead_kb设置为0，观察iostat情况如下：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/preopt_iostat_rak0.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-1782&quot; alt=&quot;preopt_iostat_rak0&quot; src=&quot;/images/noops.me/36ecc992eed341f504b30a09820bd099.jpg&quot; width=&quot;858&quot; height=&quot;646&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;而应用QPS却下降至25K！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;分析原因：由于之前有预读功能存在，因此部分数据已经被预先读取而减轻了SSD的访问压力。将read_ahead_kb设置为0后，所有的读访问均通过随机读实现，一定程度上加重了SSD的访问压力（可以观察到之前%util大约在60~80%之间波动，而预读改成0之后%util则在80~90%之间波动）&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;尝试16K预读&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过IO模型了解到每次请求的数据大小为4KB，因此将read_ahead_kb设置为16KB进行尝试，&lt;span style=&quot;color: #ff0000;&quot;&gt;结果QPS由25K猛增到34K！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;观察iostat情况如下：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/preopt_iostat_rak16.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-1783&quot; alt=&quot;preopt_iostat_rak16&quot; src=&quot;/images/noops.me/d11439c036071bcc7447fb7e60f60450.jpg&quot; width=&quot;858&quot; height=&quot;647&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;%util降了不少，而且通过rrqm/s可以发现出现了一部分读合并的请求，这说明优化确有成效。&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;此时&lt;/span&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;CPU_WA也由原来的平均30%下降到20%，这说明处理器等待IO的时间减少了，进一步验证了IO优化的有效性。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二轮优化：直连卡中断多核绑定&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;考虑到SSD的随机读写能力较强（通过上面的iostat可以发现），在多盘环境下每秒产生的IO请求数也已接近100K，了解到LSI SAS 2308芯片的IOPs处理极限大约在250K左右，因此判断直连卡控制芯片本身并不存在瓶颈。&lt;/p&gt;
&lt;p&gt;其实我们担心更多的是如此大量的IO请求数必定会产生庞大数量的中断请求，如果中断请求全部落在处理器的一个核心上，可能会对单核造成较高的压力，甚至将单核压力打死。因此单核的中断请求的处理能力就有可能成为整个IO系统的瓶颈所在，于是我们通过mpstat观察每个核心上的中断数：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/mpstat_preopt.png&quot;&gt;&lt;img alt=&quot;mpstat_preopt&quot; src=&quot;/images/noops.me/08dfaec1aaee7dfe5f109e5532aaf575.jpg&quot; width=&quot;219&quot; height=&quot;349&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以发现第二个核心中断数已经达到了十分恐怖的80K！再来观察实际的处理器核心压力情况，为了能够更加直观地了解，我们用了比较准确的i7z工具来观察：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/i7z_preopt.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-1785&quot; alt=&quot;i7z_preopt&quot; src=&quot;/images/noops.me/93111b8ebcfd0fda1f13ded5f2cecfc3.jpg&quot; width=&quot;698&quot; height=&quot;180&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;果然不出所料，Core 1的Halt（idle）已经到了1，充分说明第二个核心确实已经满载。&lt;/p&gt;
&lt;p&gt;那么通过观察/proc/interrupt的情况再来进一步验证我们的假设，：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/inter.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-1786&quot; alt=&quot;inter&quot; src=&quot;/images/noops.me/9b55ac6011fd50bd15aca0dcb063514d.jpg&quot; width=&quot;756&quot; height=&quot;775&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我们截取了片段，可以发现mpt2sas0-misx的大部分压力都集中在了CPU 1上，并且我们发现直连卡模式是支持多队列的（注意观察irq号从107至122，mpt2sas驱动总共有16个中断号），因此我们将实际在处理中断的irq号107至118分别绑定至不同的核心上（这里就不再赘述有关多核绑定的原理，有兴趣的同学可以百度搜索以上命令的含义）：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/smp.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-1787&quot; alt=&quot;smp&quot; src=&quot;/images/noops.me/adc68b30e71a0d71bc8ccb2d04475615.jpg&quot; width=&quot;313&quot; height=&quot;158&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;随后我们惊奇地观察到应用的&lt;span style=&quot;color: #ff0000;&quot;&gt;QPS由34K再次猛增至39K！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;通过观察mpstat发现大量的中断被平均分散到了不同的处理器核心上：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/mpstat_after.png&quot;&gt;&lt;img alt=&quot;mpstat_after&quot; src=&quot;/images/noops.me/3cb3e08b38a142113205e283e2f428de.jpg&quot; width=&quot;213&quot; height=&quot;344&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;并且CPU_WA也由平均20%下降到15%，io wait被进一步优化！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化总结：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过以上两个优化方法将应用的QPS由27K优化至39K，并且处理器的iowait由30%下降至15%，优化收效显著；&lt;/li&gt;
&lt;li&gt;SSD的优化要根据实际的应用IO模型和设备的理论极限值进行综合考虑，同时还要考虑到各个层面的瓶颈（包括内核、IO策略、磁盘接口速率、连接控制芯片等）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
            

</description>
        <pubDate>Wed, 10 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-10--p=1778-c0a873ab4.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-10--p=1778-c0a873ab4.html</guid>
        
        
        <category>noops</category>
        
      </item>
    
      <item>
        <title>如何研究学习一个机器学习算法</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;机器学习算法都是一个个复杂的体系，需要通过研究来理解。学习算法的静态描述是一个好的开始，但是这并不足以使我们理解算法的行为，我们需要在动态中来理解算法。&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;机器学习算法的运行实验，会使你对于不同类型问题得出的实验结论，并对实验结论与算法参数两者的因果关系有一个直观认识。&lt;/p&gt;
&lt;p&gt;在这篇文章中，你将会知道怎么研究学习一个机器学习算法。你将会学到5个简单步骤，你可以用来设计和完成你的第一个机器学习算法实验&lt;/p&gt;
&lt;p&gt;你会发现机器学习实验不光是学者们的专利，你也可以；你也会知道实验是通往精通的必经之路，因为你可以从经验中学到因果关系的知识， 这是其它地方学不到的。&lt;/p&gt;
&lt;h2&gt;什么是研究机器学习算法&lt;/h2&gt;
&lt;p&gt;当研究一个机器学习算法的时候，你的目标是找到可得到好结果的机器算法行为，这些结果是可以推广到多个问题或者多个类型的问题上。&lt;/p&gt;
&lt;p&gt;你通过对算法状态做系统研究来研究学习机器学习算法。这项工作通过设计和运行可控实验来完成&lt;/p&gt;
&lt;p&gt;一旦你完成了一项实验，你可以对结论作出解释和提交。这些结论会让你得以管窥在算法变化中因果关系。这就是算法行为和你获得的结论间的关系。&lt;/p&gt;
&lt;h2&gt;怎样研究学习机器学习算法&lt;/h2&gt;
&lt;p&gt;在这一部分，我们将学到5个简单的步骤，你可以通过它来研究学习一个机器算法&lt;/p&gt;
&lt;h3&gt;1.选择一个算法&lt;/h3&gt;
&lt;p&gt;选择一个你有疑问的算法&lt;/p&gt;
&lt;p&gt;这个算法可能是你正在某个问题上应用的，或者你发现在其他环境中表现很好，将来你想使用&lt;/p&gt;
&lt;p&gt;就实验的意图来说，使用现成的算法是有帮助的。这会给你一个底线：存在bug几率最低&lt;/p&gt;
&lt;p&gt;自己实现一个算法可能是了解算法过程的一个好的方式，但是，实验期间，会引入额外的变量，比如bug，和大量必须为算法所做的微观决策&lt;/p&gt;
&lt;h3&gt;2.确定一个问题&lt;/h3&gt;
&lt;p&gt;你必须有一个你试图寻找答案的研究问题。问题越明确，问题越有用&lt;/p&gt;
&lt;p&gt;给出的示例问题包括以下几个方面：&lt;/p&gt;
&lt;p&gt;KNN算法中，作为样本空间中的一部分的K值在增大时有什么影响？&lt;/p&gt;
&lt;p&gt;在SVM算法中，选择不同的核函数在二分类问题上有什么影响 ？&lt;/p&gt;
&lt;p&gt;在二分类问题中，逻辑回归上的不同参数的缩放有什么影响 ？&lt;/p&gt;
&lt;p&gt;在随机森林模型中，在训练集上增加任意属性对在分类准确性上有什么影响？&lt;/p&gt;
&lt;p&gt;针对算法，设计你想回答的问题。仔细考虑，然后列出5个逐渐演变的问题，并且深入推敲那个最精确的&lt;/p&gt;
&lt;h3&gt;3.设计实验&lt;/h3&gt;
&lt;p&gt;从你的问题中挑选出关键元素然后组成你的实验内容。 例如，拿上面的示例问题为例：“二元分类问题中逻辑回归上的不同的参数缩放有什么影响？”&lt;/p&gt;
&lt;p&gt;你从这个问题中挑出来用来设计实验的元素是：&lt;/p&gt;
&lt;p&gt;属性缩放法：你可以采用像正态化、标准化，将某一属性提升至乘方、取对数等方法&lt;/p&gt;
&lt;p&gt;逻辑回归：你想使用哪种已经实现的逻辑回归。&lt;/p&gt;
&lt;p&gt;二元分类问题：存在数值属性不同的二分类问题标准。需要准备多种问题，其中一些问题的规模是相同的（像电离层），然而其他一些问题的属性有不同的缩放值（像糖尿病问题）。&lt;/p&gt;
&lt;p&gt;性能： 类似分类准确性的模型性能分数是需要的&lt;/p&gt;
&lt;p&gt;花时间仔细挑选你问题中的组成元素以便为你的问题给出最佳解答。&lt;/p&gt;
&lt;h3&gt;4. 进行试验并且报告你的结论&lt;/h3&gt;
&lt;p&gt;完成你的实验&lt;/p&gt;
&lt;p&gt;如果算法是随机的，你需要多次重复实验操作并且记录一个平均数和标准偏差&lt;/p&gt;
&lt;p&gt;如果你试图寻找在不同实验（比如带有不同的参数）之间结果的差异，你可能想要使用一种统计工具来标明差异是否统计上显著的（就像学生的t检验）&lt;/p&gt;
&lt;p&gt;一些工具像R和scikit-learn/SciPy完成这些类型的实验，但是你需要把它们组合在一起，并且为实验写脚本。其他工具像Weka带有图形用户界面，你所使用的工具不要影响问题和你实验设计的严密&lt;/p&gt;
&lt;p&gt;总结你的实验结论。你可能想使用图表。单独呈现结果是不够的，他们只是数字。你必须将数字和问题联系起来，并且通过你的实验设计提取出它们的意义&lt;/p&gt;
&lt;p&gt;对实验问题来说，实验结果又暗示着什么呢？&lt;/p&gt;
&lt;p&gt;保持怀疑的态度。你的结论上有留什么样的漏洞和局限呢。不要逃避这一部分。知道局限性和知道实验结果一样重要&lt;/p&gt;
&lt;h3&gt;5. 重复&lt;/h3&gt;
&lt;p&gt;重复操作&lt;/p&gt;
&lt;p&gt;继续研究你选择的算法。你甚至想要重复带有不同参数或者不同的测试数据集的同一个实验。你可能想要处理你试验中的局限性&lt;/p&gt;
&lt;p&gt;不要只停留在一个算法上，开始建立知识体系和对算法的直觉&lt;/p&gt;
&lt;p&gt;通过使用一些简单工具，提出好的问题，保持严谨和怀疑的态度，你对机器算法行为的理解很快就会到达世界级的水平&lt;/p&gt;
&lt;h2&gt;研究学习算法不仅仅是学者才能做的&lt;/h2&gt;
&lt;p&gt;你也可以学习研究机器学习算法。&lt;/p&gt;
&lt;p&gt;你不需要一个很高的学位，你不需要用研究的方式训练，你也不需要成为一名学者&lt;/p&gt;
&lt;p&gt;对每个拥有计算机和浓厚兴趣的人来说，机器学习算法的系统研究学习是开放的。事实上，如果你主修机器学习，你一定会适应机器学习算法的系统研究。知识根本不会自己出来，你需要靠自己的经验去得到&lt;/p&gt;
&lt;p&gt;当谈论你的发现的适用性时，你需要保持怀疑和谨慎&lt;/p&gt;
&lt;p&gt;你不一定提出独一无二的问题。通过研究一般的问题，你也将会收获很多，例如根据一些一般的标准数据集总结出一个参数的普遍影响。你保不住会发现某些具有最优方法的常例的局限性甚至反例。&lt;/p&gt;
&lt;h2&gt;行动步骤&lt;/h2&gt;
&lt;p&gt;在本篇文章中，通过可控实验你知道了研究学习机器学习算法行为的重要性。你掌握了简单的5个步骤，你可以在一个机器学习算法上设计和运行你的第一项实验&lt;/p&gt;
&lt;p&gt;采取行动。使用你在这篇博文中学到的步骤，来完成你的第一个机器学习实验。一旦你完成了一个，甚至是很小的一个，你将会获得自信，工具、能力来完成第二个以及更多&lt;/p&gt;

&lt;/div&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Tue, 09 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-09-80658-c67556c21.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-09-80658-c67556c21.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>Kibana 中几个不同的 filtering</title>
        <description>

  
  &lt;div style=&quot;background-color: #FFF;&quot;&gt;
    &lt;p&gt;用过 kibana 的都知道，kibana 的图表上，可以直接点击某个值，就能自动添加这个过滤条件到 filtering 里，然后整个 dashboard 上所有的图表都会刷新成在这个过滤条件下的新状态。但是如果你要想自己手动添加 filtering 的时候，就会发现，自己添加的，写法好像跟自动生成的长得不太一样。&lt;/p&gt;
&lt;p&gt;而今天，我在同事的提醒下，发现更进一步的情况，即使都是通过点击图表添加上的 filtering，其实长得也不一样，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/chenlinux.com/14899b570407acac411b3be94628b0a4.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;在 histogram 面板上拖拽鼠标，生成的是 range filtering&lt;/li&gt;
  &lt;li&gt;在 terms 面板上点击某个值，生成的是 term filtering&lt;/li&gt;
  &lt;li&gt;在 table 面板左侧列表上点击某个字段，浮出的小面板里点击某个值，生成的是 query filtering&lt;/li&gt;
  &lt;li&gt;在 filtering 手工添加，生成的是 query_string filtering&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这几个页面上的不同，反应在实际的请求 JSON 里又有什么区别呢？&lt;/p&gt;
&lt;p&gt;我们可以点开面板右上角的 inspect 按钮看生成的 curl 命令。其中 filtering 部分如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;s2&quot;&gt;&quot;filter&quot;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&quot;bool&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&quot;must&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&quot;range&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&quot;@timestamp&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&quot;from&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1418009781101&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&quot;to&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;now&quot;&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&quot;terms&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&quot;_type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
                &lt;span class=&quot;s2&quot;&gt;&quot;mweibo_webinf&quot;&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&quot;fquery&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&quot;query&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&quot;query_string&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&quot;query&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;host:(\&quot;web093.mweibo.tc.sinanode.com\&quot;)&quot;&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&quot;_cache&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&quot;fquery&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&quot;query&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&quot;query_string&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&quot;query&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;host:\&quot;web093.mweibo.tc.sinanode.com\&quot;&quot;&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&quot;_cache&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;前面两个不出意外，都是很标准的 api 示例的样子。比较特殊的是后面两个：&lt;/p&gt;
&lt;p&gt;第三个其实就是通过 table 左侧字段菜单点出来的，虽然通过鼠标点击操作，只可能生成一个单一的键值查询，但这里却给加上了一对小括号！这是完全没有必要的，简直可以怀疑是不是当初开发人员手抖了……&lt;/p&gt;
&lt;p&gt;当然，并不是说这种生成完全没有用。比方说，其实你本来是打算查询来自两台机器的日志。如果没想到用括号，可能直接在 query_string 里就写 &lt;code&gt;host:&quot;web001&quot; OR host:&quot;web002&quot;&lt;/code&gt; 了。但是在这个 query filtering 里，因为页面上已经有单独填字段的地方了。那就只用在 query 那栏写 &lt;code&gt;&quot;web001&quot; OR &quot;web002&quot;&lt;/code&gt; 好了。&lt;/p&gt;
&lt;p&gt;以上。不过我依然怀疑是开发人员手抖。&lt;/p&gt;
    &lt;hr&gt;
    
    &lt;hr&gt;
  &lt;!-- JiaThis Button BEGIN --&gt;
&lt;div class=&quot;jiathis_style&quot;&gt;
&lt;span class=&quot;jiathis_txt&quot;&gt;分享到：&lt;/span&gt;
&lt;a class=&quot;jiathis_button_tsina&quot;&gt;新浪微博&lt;/a&gt;
&lt;a class=&quot;jiathis_button_weixin&quot;&gt;微信&lt;/a&gt;
&lt;a class=&quot;jiathis_button_renren&quot;&gt;人人网&lt;/a&gt;
&lt;a class=&quot;jiathis_button_ydnote&quot;&gt;有道云笔记&lt;/a&gt;
&lt;a class=&quot;jiathis_button_gmail&quot;&gt;Gmail邮箱&lt;/a&gt;
&lt;a class=&quot;jiathis_button_twitter&quot;&gt;Twitter&lt;/a&gt;
&lt;a class=&quot;jiathis_button_googleplus&quot;&gt;Google+&lt;/a&gt;
&lt;a class=&quot;jiathis_button_hi&quot;&gt;百度空间&lt;/a&gt;
&lt;a class=&quot;jiathis_button_fb&quot;&gt;Facebook&lt;/a&gt;
&lt;a class=&quot;jiathis_button_douban&quot;&gt;豆瓣&lt;/a&gt;
&lt;a href=&quot;http://www.jiathis.com/share?uid=1589850&quot; class=&quot;jiathis jiathis_txt jiathis_separator jtico jtico_jiathis&quot; target=&quot;_blank&quot;&gt;更多&lt;/a&gt;
&lt;a class=&quot;jiathis_counter_style&quot;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var jiathis_config={
	data_track_clickback:true,
	summary:&quot;&quot;,
	ralateuid:{
		&quot;tsina&quot;:&quot;1035836154&quot;
	},
	shortUrl:false,
	hideMore:false
}
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://v3.jiathis.com/code/jia.js?uid=1589850&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;!-- JiaThis Button END --&gt;
&lt;!-- UY BEGIN --&gt;


&lt;!-- UY END --&gt;
  &lt;/div&gt;

</description>
        <pubDate>Mon, 08 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-08-difference-filterings-kibana-a2d6b87c1.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-08-difference-filterings-kibana-a2d6b87c1.html</guid>
        
        
        <category>chenlinux</category>
        
      </item>
    
  </channel>
</rss>
