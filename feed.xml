<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>IT技术干货</title>
    <description>[IT技术干货iftti.com] @KernelHacks</description>
    <link>http://iftti.com/</link>
    <atom:link href="http://iftti.com/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 25 Sep 2014 07:33:31 +0800</pubDate>
    <lastBuildDate>Thu, 25 Sep 2014 07:33:31 +0800</lastBuildDate>
    <generator>Jekyll v2.2.0</generator>
    
      <item>
        <title>在 logstash 里使用其他 RubyGems 模块</title>
        <description>

  
  &lt;div style=&quot;background-color: #FFF;&quot;&gt;
    &lt;p&gt;在开发和使用一些 logstash 自定义插件的时候，几乎不可避免会导入其他 RubyGems 模块 —— 因为都用不上模块的小型处理，直接写在 &lt;em&gt;filters/ruby&lt;/em&gt; 插件配置里就够了 —— 这时候，运行 logstash 命令可能会发现一个问题：这个 gem 模块一直是 “no found” 状态。&lt;/p&gt;
&lt;p&gt;这其实是因为我们一般是通过 java 命令来运行的 logstash，这时候它回去寻找的 Gem 路径跟我们预计中的是不一致的。&lt;/p&gt;
&lt;p&gt;要查看 logstash 运行时实际的 Gem 查找路径，首先要通过 &lt;code&gt;ps aux&lt;/code&gt; 命令确定 ruby 的实际运行方式：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ ps uax|grep logstash
raochenlin      27268  38.0  4.3  3268156 181344 s003  S+    7:10PM   0:22.36 /Library/Internet Plug-Ins/JavaAppletPlugin.plugin/Contents/Home/bin/java -Xmx500m -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -Djava.awt.headless=true -XX:CMSInitiatingOccupancyFraction=75 -XX:+UseCMSInitiatingOccupancyOnly -jar /Downloads/logstash-1.4.2/vendor/jar/jruby-complete-1.7.11.jar -I/Users/raochenlin/Downloads/logstash-1.4.2/lib /Users/raochenlin/Downloads/logstash-1.4.2/lib/logstash/runner.rb agent -f test.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;看，实际的运行方式应该是：&lt;code&gt;java -jar logstash-1.4.2/vendor/jar/jruby-complete-1.7.11.jar -Ilogstash-1.4.2/lib logstash-1.4.2/lib/logstash/runner.rb&lt;/code&gt; 这样。&lt;/p&gt;
&lt;p&gt;那么我们查看 gem 路径的命令也就知道怎么写了：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;java -jar logstash-1.4.2/vendor/jar/jruby-complete-1.7.11.jar `which gem` env
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;你会看到这样的输出：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;RubyGems Environment:
     - RUBYGEMS VERSION: 2.1.9
     - RUBY VERSION: 1.9.3 (2014-02-24 patchlevel 392) [java]
     - INSTALLATION DIRECTORY: file:/Downloads/logstash-1.4.2/vendor/jar/jruby-complete-1.7.11.jar!/META-INF/jruby.home/lib/ruby/gems/shared
     - RUBY EXECUTABLE: java -jar /Downloads/logstash-1.4.2/vendor/jar/jruby-complete-1.7.11.jar
     - EXECUTABLE DIRECTORY: file:/Downloads/logstash-1.4.2/vendor/jar/jruby-complete-1.7.11.jar!/META-INF/jruby.home/bin
     - SPEC CACHE DIRECTORY: /.gem/specs
     - RUBYGEMS PLATFORMS:
       - ruby
       - universal-java-1.7
     - GEM PATHS:
        - file:/Downloads/logstash-1.4.2/vendor/jar/jruby-complete-1.7.11.jar!/META-INF/jruby.home/lib/ruby/gems/shared
        - /.gem/jruby/1.9
     - GEM CONFIGURATION:
        - :update_sources =&amp;gt; true
        - :verbose =&amp;gt; true
        - :backtrace =&amp;gt; false
        - :bulk_threshold =&amp;gt; 1000
        - “install” =&amp;gt; “–no-rdoc –no-ri –env-shebang”
        - “update” =&amp;gt; “–no-rdoc –no-ri –env-shebang”
        - :sources =&amp;gt; [“http://ruby.taobao.org/”]
     - REMOTE SOURCES:
        - http://ruby.taobao.org/
     - SHELL PATH:
        - /usr/bin
        - /bin
        - /usr/sbin
        - /sbin
        - /usr/local/bin&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;看到其中的 GEM PATHS 部分，是一个以 &lt;strong&gt;file:&lt;/strong&gt; 开头的路径！也就是说，要求所有的 gem 包都打包在这个 jruby-complete-1.7.11.jar 里面才认。&lt;/p&gt;
&lt;p&gt;所以我们需要把额外的 gem 包，也加入这个 jar 里：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;jar uf jruby-completa-1.7.11.jar META-INF/jruby.home/lib/ruby/1.9/CUSTOM_RUBY_GEM_LIB
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;注：加入 jar 是用的相对路径，所以前面这串目录要提前创建然后复制文件进去。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;当然，其实还有另一个办法。&lt;/p&gt;
&lt;p&gt;让我们返回去再看一次 logstash 的进程，在 jar 后面，还有一个 &lt;code&gt;-I&lt;/code&gt; 参数！所以，其实我们还可以把文件安装在 &lt;code&gt;logstash-1.4.2/lib&lt;/code&gt; 目录下去。&lt;/p&gt;
&lt;p&gt;最后，你可能会问：那 &lt;code&gt;--pluginpath&lt;/code&gt; 参数指定的位置可不可以呢？&lt;/p&gt;
&lt;p&gt;答案是：也可以。&lt;/p&gt;
&lt;p&gt;这个参数指定的位置在 &lt;em&gt;logstash-1.4.2/lib/logstash/agent.rb&lt;/em&gt; 中，被加入了 &lt;code&gt;$LOAD_PATH&lt;/code&gt; 中：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;configure_plugin_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;paths&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;paths&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;Dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exists?&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;warn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;I18n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;logstash.agent.configuration.plugin_path_missing&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;ss&quot;&gt;:path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;plugin_glob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;File&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;logstash&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;{inputs,codecs,filters,outputs}&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;*.rb&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;glob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plugin_glob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty?&lt;/span&gt;
        &lt;span class=&quot;vi&quot;&gt;@logger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;warn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;no&quot;&gt;I18n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;logstash.agent.configuration.no_plugins_found&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                    &lt;span class=&quot;ss&quot;&gt;:path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;:plugin_glob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plugin_glob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
      &lt;span class=&quot;vi&quot;&gt;@logger&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;debug&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Adding plugin path&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;:path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;vg&quot;&gt;$LOAD_PATH&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unshift&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;$LOAD_PATH&lt;/code&gt; 是 Ruby 的一个特殊变量，类似于 Perl 的 &lt;code&gt;@INC&lt;/code&gt; 或者 Java 的 &lt;code&gt;class_path&lt;/code&gt; 。在这个数组里的路径下的文件，都可以被 require 导入。&lt;/p&gt;
&lt;p&gt;可以运行如下命令查看：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ java -jar logstash-1.4.2/vendor/jar/jruby-complete-1.7.11.jar -e &#39;p $LOAD_PATH&#39;
[&quot;file:/Users/raochenlin/Downloads/logstash-1.4.2/vendor/jar/rar/jruby-complete-1.7.11.jar!/META-INF/jruby.home/lib/ruby/1.9/site_ruby&quot;, &quot;file:/Users/raochenlin/Downloads/logstash-1.4.2/vendor/jar/rar/jruby-complete-1.7.11.jar!/META-INF/jruby.home/lib/ruby/shared&quot;, &quot;file:/Users/raochenlin/Downloads/logstash-1.4.2/vendor/jar/rar/jruby-complete-1.7.11.jar!/META-INF/jruby.home/lib/ruby/1.9&quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这三种方式，你喜欢哪种呢？&lt;/p&gt;
    &lt;hr&gt;
    
    &lt;hr&gt;
  &lt;!-- UY BEGIN --&gt;


&lt;!-- UY END --&gt;
  &lt;/div&gt;

</description>
        <pubDate>Wed, 24 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-24-howto-use-custom-rubygem-in-logstash-205f7f438.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-24-howto-use-custom-rubygem-in-logstash-205f7f438.html</guid>
        
        
        <category>chenlinux</category>
        
      </item>
    
      <item>
        <title>Kibana 认证鉴权方案</title>
        <description>

  
  &lt;div style=&quot;background-color: #FFF;&quot;&gt;
    &lt;p&gt;Kibana 作为一个纯 JS 项目，一直都没有提供完整的权限控制方面的功能。只是附带了一个 &lt;code&gt;nginx.conf&lt;/code&gt; 做基本的 Basic Auth。社区另外有在 nodejs 上实现的方案，则使用了 CAS 方式做认证。&lt;/p&gt;
&lt;p&gt;不过我对这两种方案都不太满意。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;认证方式太单一，适应性不强；&lt;/li&gt;
  &lt;li&gt;权限隔离不明确，只是通过修改 &lt;code&gt;kibana-int&lt;/code&gt; 成 &lt;code&gt;kiban-int-user&lt;/code&gt; 来区分不同用户的 dashboard，并不能限制用户对 ES 索引的访问。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;加上 nodejs 我也不熟，最终在多番考虑后，决定抽一个晚上自己写一版。&lt;/p&gt;
&lt;p&gt;最终代码见 &lt;a href=&quot;https://github.com/chenryn/kibana&quot;&gt;https://github.com/chenryn/kibana&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;section&quot;&gt;原理和实现&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;全站代理和虚拟响应&lt;/p&gt;
    &lt;p&gt;这里不单通过 config.js 限定了 kibana 默认连接的 Elasticsearch 服务器地址和端口，还拦截伪造了 &lt;code&gt;/_nodes&lt;/code&gt; 请求的 JSON 响应体。伪造的响应中也只包含自己这个带认证的 web 服务器地址和端口。&lt;/p&gt;
    &lt;p&gt;&lt;em&gt;这么做是因为我的 kibana 版本使用的 elasticjs 库比官方新增了 sniff 功能，默认会自动轮训所有 nodes 发送请求。&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;新增 &lt;code&gt;kibana-auth&lt;/code&gt; 鉴权索引&lt;/p&gt;
    &lt;p&gt;在通常的 &lt;code&gt;kibana-int-user&lt;/code&gt; 区分 dashboard 基础上，我新增加 &lt;code&gt;kibana-auth&lt;/code&gt; 索引，专门记录每个用户可以访问的 ES 集群地址和索引前缀。请求会固定代理到指定的 ES 集群上，并且确认是被允许访问的索引。&lt;/p&gt;
    &lt;p&gt;这样，多个用户通过一个 kibana auth 服务器网址，可以访问多个不同的 ES 集群后端。而同一个 ES 集群后端的索引，也不用担心被其他人访问到。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://metacpan.org/pod/Authen::Simple&quot;&gt;Authen::Simple&lt;/a&gt; 认证框架&lt;/p&gt;
    &lt;p&gt;这是 Perl 一个认证框架，支持十多种不同的认证方式。项目里默认采用最简单的 htpasswd 文件记录方式，实际我线上是使用了 LDAP 方式，都没问题。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;section-1&quot;&gt;部署&lt;/h2&gt;
&lt;p&gt;方案采用了 Mojolicious 框架开发，代码少不说，最关键的是 Mojolicious 无额外的 CPAN 模块依赖，这对于不了解 Perl 但是又有 Kibana 权限控制需求的人来说，大大减少了部署方面的麻烦。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
curl http://xrl.us/cpanm -o /usr/local/bin/cpanm
chmod +x /usr/local/bin/cpanm
cpanm Mojolicious Authen::Simple::Passwd
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;三行命令，就可以完成整个项目的安装需求了。然后运行目录下的:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
hypnotoad script/kbnauth
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;就可以通过 80 端口访问这个带有权限控制的 kibana 了。&lt;/p&gt;
&lt;h2 id=&quot;section-2&quot;&gt;权限赋值&lt;/h2&gt;
&lt;p&gt;因为 &lt;code&gt;kibana-auth&lt;/code&gt; 结构很简单，kibana 一般又都是内部使用，所以暂时还没做权限控制的管理页面。直接通过命令行方式即可赋权：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;
curl  -XPOST http://127.0.0.1:9200/kibana-auth/indices/sri -d &#39;{
  &quot;prefix&quot;:[&quot;logstash-sri&quot;,&quot;logstash-ops&quot;],
  &quot;server&quot;:&quot;192.168.0.2:9200&quot;
}&#39;
&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这样，sri 用户，就只能访问 192.168.0.2 集群上的 logstash-sri 或 logstash-ops 开头的日期型索引(即后面可以-YYYY, -YYYY.MM, -YYYY.MM.dd 三种格式)了。&lt;/p&gt;
&lt;h2 id=&quot;section-3&quot;&gt;下一步&lt;/h2&gt;
&lt;p&gt;考虑到新方案下各用户都有自己的 &lt;code&gt;kibana-int-user&lt;/code&gt; 索引，已经用着官方 kibana 的用户大批量的 dashboard 有迁移成本，找个时间可能做一个迁移脚本辅助这个事情。&lt;/p&gt;
&lt;p&gt;开发完成后，得到了 &lt;a href=&quot;http://weibo.com/u/1808998161&quot;&gt;@高伟&lt;/a&gt; 童鞋的主动尝试和各种 bug 反馈支持，在此表示感谢~也希望我这个方案能帮到更多 kibana 用户。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注：我的 kibana 仓库除了新增的这个 kbnauth 代理认证鉴权功能外，本身在 kibana 分析统计功能上也有一些改进，这方面已经得到多个小伙伴的试用和好评，自认在官方 Kibana v4 版本出来之前，应该会是最好用的版本。欢迎大家下载使用！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;新增功能包括：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;仿 stats 的百分比统计面板(利用 PercentileAggr 接口)&lt;/li&gt;
  &lt;li&gt;仿 terms 的区间比面板(利用 RangeFacets 接口)&lt;/li&gt;
  &lt;li&gt;给 bettermap 增强的高德地图支持(利用 leaflet provider 扩展)&lt;/li&gt;
  &lt;li&gt;给 map 增强的中国地图支持(利用 jvectormap 文件)&lt;/li&gt;
  &lt;li&gt;给 map 增强的 &lt;code&gt;term_stats&lt;/code&gt; 数据显示(利用 TermStatsFacets 接口)&lt;/li&gt;
  &lt;li&gt;给 query 增强的请求生成器(利用 getMapping/getFieldMapping 接口和 jQuery.multiSelect 扩展)&lt;/li&gt;
  &lt;li&gt;仿 terms 的 statisticstrend 面板(利用 TermStatsFacets 接口)&lt;/li&gt;
  &lt;li&gt;仿 histogram 增强的 multifieldhistogram 面板(可以给不同query定制不同的panel setting，比如设置某个抽样数据 * 1000 倍和另一个全量数据做对比)&lt;/li&gt;
  &lt;li&gt;仿 histogram 的 valuehistogram 面板(去除了 histogram 面板的 X 轴时间类型数据限制，可以用于做数据概率分布分析)&lt;/li&gt;
  &lt;li&gt;给 histogram 增强的 threshold 变色功能(利用了 &lt;code&gt;jquery.flot.threshold&lt;/code&gt; 扩展)&lt;/li&gt;
  &lt;li&gt;单个面板自己的刷新按钮(避免调试的时候全页面刷新的麻烦)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;效果截图同样在 &lt;a href=&quot;https://github.com/chenryn/kibana/blob/master/README.md&quot;&gt;README&lt;/a&gt; 里贴出。欢迎试用和反馈！&lt;/p&gt;
    &lt;hr&gt;
    
    &lt;hr&gt;
  &lt;!-- UY BEGIN --&gt;


&lt;!-- UY END --&gt;
  &lt;/div&gt;

</description>
        <pubDate>Tue, 23 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-23-kibana-auth-088ca6c86.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-23-kibana-auth-088ca6c86.html</guid>
        
        
        <category>chenlinux</category>
        
      </item>
    
      <item>
        <title>node.js Flame Graphs on Linux</title>
        <description>

&lt;p&gt;CPU &lt;a href=&quot;/flamegraphs.html&quot;&gt;flame graphs&lt;/a&gt; are a useful visualization application stack traces, allowing you to quickly identify and quantify what to tune to improve performance. For Node.js they have solved countless problems on systems which have DTrace for sampling stack traces. But what about Linux?&lt;/p&gt;

&lt;p&gt;At Netflix we have node.js in production at scale, on Linux instances in AWS EC2, and we create flame graphs using Linux &lt;a href=&quot;/perf.html&quot;&gt;perf_events&lt;/a&gt; and v8&#39;s &lt;a href=&quot;https://codereview.chromium.org/70013002&quot;&gt;--perf-basic-prof option&lt;/a&gt;. In this quick blog post, I&#39;ll share how it works and how you can do it, and what needs to be fixed to improve it further.&lt;/p&gt;

&lt;h2&gt;1. The problem&lt;/h2&gt;

&lt;p&gt;Using perf_events to profile CPU usage on node.js 0.10.23:&lt;/p&gt;

&lt;p&gt;&lt;object data=&quot;/images/brendangregg.com/da8a526902cf4e359d30f4104fbae443.svg&quot; type=&quot;image/svg+xml&quot; width=&quot;720&quot; height=&quot;875&quot;&gt;
&lt;img src=&quot;/images/brendangregg.com/da8a526902cf4e359d30f4104fbae443.jpg&quot; width=&quot;720&quot;&gt;
&lt;/object&gt;&lt;/p&gt;

&lt;p&gt;It&#39;s interactive: mouse-over elements for details, and click the &lt;a href=&quot;/blog/images/2014/node.js_flamegraph_nosymbols_01023.svg&quot;&gt;SVG&lt;/a&gt; to zoom. The &lt;a href=&quot;/FlameGraphs/cpuflamegraphs.html&quot;&gt;CPU flame graphs&lt;/a&gt; page explains how to interpret these, and this was created using the instructions in the &lt;a href=&quot;/FlameGraphs/cpuflamegraphs.html#perf&quot;&gt;Linux perf section&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This flame graph is partially-useful, as I can see system and v8 library symbols. However, it is missing JavaScript symbols (the blank rectangles), since v8, like the JVM, compiles and places symbols just in time (JIT).&lt;/p&gt;

&lt;h2&gt;2. Linux perf_events JIT support&lt;/h2&gt;

&lt;p&gt;In 2009, Linux &lt;a href=&quot;/perf.html&quot;&gt;perf_events&lt;/a&gt; added &lt;a href=&quot;https://lkml.org/lkml/2009/6/8/499&quot;&gt;JIT symbol support&lt;/a&gt;, so that symbols from language virtual machines like the JVM could be inspected. It works in the following amazingly simple way:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Your JIT application must be modified to create a /tmp/perf-&lt;em&gt;PID&lt;/em&gt;.map file, which is a simple text database containing symbol addresses (in hex), sizes, and symbol names.&lt;/li&gt;
&lt;li&gt;That&#39;s it.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;perf already looks for the /tmp/perf-&lt;em&gt;PID&lt;/em&gt;.map file, and if it finds it, it uses it for symbol translations. So only v8 needed to be modified.&lt;/p&gt;

&lt;h2&gt;3. v8 --perf-basic-prof support&lt;/h2&gt;

&lt;p&gt;In November 2013, &lt;a href=&quot;https://codereview.chromium.org/70013002&quot;&gt;v8 added perf_events support&lt;/a&gt;, enabled using the --perf-basic-prof option. This made it into node v0.11.13. It works like this:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;~/node-v0.11.13-linux-x64/bin/node --perf-basic-prof hello.js &amp;amp;&lt;/b&gt;
[1] 31441
# &lt;b&gt;ls -l /tmp/perf-31441.map&lt;/b&gt;
-rw-r--r-- 1 root root 81920 Sep 17 20:41 /tmp/perf-31441.map
# &lt;b&gt;tail /tmp/perf-31441.map&lt;/b&gt;
14cec4db98a0 f Stub:BinaryOpICWithAllocationSiteStub(ADD_CreateAllocationMementos:String*Generic-&amp;gt;String)
14cec4db9920 f Stub:BinaryOpICWithAllocationSiteStub(ADD_CreateAllocationMementos:String*String-&amp;gt;String)
14cec4db99a0 f Stub:BinaryOpICWithAllocationSiteStub(ADD_CreateAllocationMementos:String*Smi-&amp;gt;String)
14cec4db9a20 22c LazyCompile:~nextTick node.js:389
14cec4db9cc0 156 Stub:KeyedLoadElementStub
14cec4db9e80 22 KeyedLoadIC:
14cec4db9f20 22 KeyedLoadIC:
14cec4db9fc0 56 Stub:DoubleToIStub
14cec4dba080 10c Stub:KeyedStoreElementStub
&lt;/pre&gt;

&lt;p&gt;This text file is what perf_events reads.&lt;/p&gt;

&lt;h2&gt;4. node.js Flame Graphs&lt;/h2&gt;

&lt;p&gt;Now that we have node 0.11.13+ running with --perf-basic-prof, we can create a flame graph using:&lt;/p&gt;

&lt;pre&gt;
$ &lt;b&gt;sudo bash&lt;/b&gt;
# &lt;b&gt;perf record -F 99 -p `pgrep -n node` -g -- sleep 30&lt;/b&gt;
# &lt;b&gt;perf script &amp;gt; out.nodestacks01&lt;/b&gt;
# &lt;b&gt;git clone --depth 1 http://github.com/brendangregg/FlameGraph&lt;/b&gt;
# &lt;b&gt;cd FlameGraph&lt;/b&gt;
# &lt;b&gt;./stackcollapse-perf.pl  ../out.nodestacks01.svg&lt;/b&gt;
&lt;/pre&gt;

&lt;p&gt;You can also use &lt;a href=&quot;https://www.npmjs.org/package/stackvis&quot;&gt;stackvis&lt;/a&gt;, by Dave Pacheco, a node.js implementation which has extra features.&lt;/p&gt;

&lt;p&gt;Here&#39;s an example result:&lt;/p&gt;

&lt;p&gt;&lt;object data=&quot;/images/brendangregg.com/30123cd4d080cd350e66bf4366f40fc5.svg&quot; type=&quot;image/svg+xml&quot; width=&quot;720&quot; height=&quot;788&quot;&gt;
&lt;img src=&quot;/images/brendangregg.com/30123cd4d080cd350e66bf4366f40fc5.jpg&quot; width=&quot;720&quot;&gt;
&lt;/object&gt;&lt;/p&gt;

&lt;p&gt;Note the JavaScript symbols are now readable. Click the &lt;a href=&quot;/blog/images/2014/node.js_flamegraph_symbols_01113.svg&quot;&gt;SVG&lt;/a&gt; to zoom in. This actual flame graph isn&#39;t very interesting, as I&#39;m just testing a dummy app to test out --perf-basic-prof.&lt;/p&gt;

&lt;p&gt;Thanks to &lt;a href=&quot;https://twitter.com/trevnorris&quot;&gt;Trevor Norris&lt;/a&gt; for first posting the instructions for doing this in a short &lt;a href=&quot;https://gist.github.com/trevnorris/9616784&quot;&gt;gist&lt;/a&gt;, which you may find useful to read. He also provides a script to facilitate this.&lt;/p&gt;

&lt;h2&gt;WARNING: map file growth&lt;/h2&gt;

&lt;p&gt;We can currently only use --perf-basic-prof for short periods (hours), due to &lt;a href=&quot;https://code.google.com/p/v8/issues/detail?id=3453&quot;&gt;bug 3453&lt;/a&gt;: the perf.map file can grow endlessly, eating Gbytes in a few days. It looks like symbols are moving location (they are supposed to stay put with --perf-basic-prof), causing the map file to keep growing.&lt;/p&gt;

&lt;p&gt;So we can create flame graphs on Linux currently, but it will be ad hoc until that bug is fixed, and we can run with this option all the time.&lt;/p&gt;

&lt;p&gt;If this bug is a nuisance to you, too, and it isn&#39;t yet fixed, please upvote that bug! If it&#39;s too painful to wait for the fix, you could run on an OS with DTrace, where node.js stack profiling doesn&#39;t have this issue (or, at least, run a canary instance for performance analysis).&lt;/p&gt;

&lt;h2&gt;More&lt;/h2&gt;

&lt;p&gt;We&#39;re doing more at Netflix with node.js analysis. Stay tuned, and also see the &lt;a href=&quot;http://techblog.netflix.com/&quot;&gt;Netflix Tech Blog&lt;/a&gt;.&lt;/p&gt;


</description>
        <pubDate>Wed, 17 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-17-node-flame-graphs-on-linux.html-fd5090be6.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-17-node-flame-graphs-on-linux.html-fd5090be6.html</guid>
        
        
        <category>brendangregg</category>
        
      </item>
    
      <item>
        <title>魔咒 Mojolicious 框架的结构图</title>
        <description>

							&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/php-oa.com/366cad86e05b8761b814b4f39ed81eb7.jpg&quot; style=&quot;height: 765px; width: 800px;&quot;&gt;&lt;br&gt;
本图来源: &lt;a href=&quot;http://blog2.jamadam.com/?p=808&quot;&gt;http://blog2.jamadam.com/?p=808&lt;/a&gt;&lt;/p&gt;
						

</description>
        <pubDate>Tue, 16 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-16-mojolicious-class-diagram.html-67b45904e.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-16-mojolicious-class-diagram.html-67b45904e.html</guid>
        
        
        <category>php-oa</category>
        
      </item>
    
      <item>
        <title>The MSRs of EC2</title>
        <description>

&lt;p&gt;Is Intel Turbo Boost running for my AWS EC2 cloud instance (which is a Xen guest)?&lt;/p&gt;

&lt;pre&gt;
ec2-guest# &lt;b&gt;./showboost&lt;/b&gt;
CPU MHz     : 2500
Turbo MHz   : 2900 (10 active)
Turbo Ratio : 116% (10 active)
CPU 0 summary every 5 seconds...

TIME       C0_MCYC      C0_ACYC        UTIL  RATIO    MHz
06:11:35   6428553166   7457384521      51%   116%   &lt;b&gt;2900&lt;/b&gt;
06:11:40   6349881107   7365764152      50%   115%   &lt;b&gt;2899&lt;/b&gt;
06:11:45   6240610655   7239046277      49%   115%   &lt;b&gt;2899&lt;/b&gt;
06:11:50   6225704733   7221962116      49%   116%   &lt;b&gt;2900&lt;/b&gt;
[...]
&lt;/pre&gt;

&lt;p&gt;Yes! These 2500 MHz CPUs are currently running at 2900 MHz.&lt;/p&gt;

&lt;p&gt;I guess the CPUs are cold enough to boost. What&#39;s their temperature?&lt;/p&gt;

&lt;pre&gt;
ec2-guest# &lt;b&gt;./cputemp -l 1&lt;/b&gt;
CPU1 CPU2 CPU3 CPU4 CPU5 CPU6 CPU7 CPU8 CPU9 CPU10 CPU11 CPU12 CPU13 CPU14 CPU15 CPU16
70 68 68 65 63 63 61 60 68 64 64 63 62 61 70 68
70 68 69 65 63 63 61 61 68 65 63 63 61 61 70 69
70 69 69 65 63 63 61 60 69 65 64 63 61 61 69 69
69 69 69 66 64 64 61 61 68 65 64 64 61 61 70 69
[...]
&lt;/pre&gt;

&lt;p&gt;Relatively cool: between 60 and 70 degrees Celsius. This is another tool from my &lt;a href=&quot;https://github.com/brendangregg/msr-cloud-tools&quot;&gt;msr-cloud-tools&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this post I&#39;ll describe MSRs, how to read them, and why measuring turbo boost is important.&lt;/p&gt;

&lt;h2&gt;Model Specific Registers (MSRs)&lt;/h2&gt;

&lt;div style=&quot;float:right;padding-left:5px;padding-bottom:5px&quot;&gt;&lt;a href=&quot;/blog/images/2014/cputemps.png&quot;&gt;&lt;img src=&quot;/images/brendangregg.com/3fdcd8199d3b291f36be8145702e96c2.jpg&quot; width=&quot;455&quot;&gt;&lt;/a&gt;&lt;/div&gt;

&lt;p&gt;Aka &lt;em&gt;machine&lt;/em&gt; specific registers, these are described in &lt;a href=&quot;http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-3c-part-3-manual.pdf&quot;&gt;Vol 3c&lt;/a&gt; of the Intel 64 and IA-32 Architectures Software Developer&#39;s Manual. They access low level CPU information, including turbo boost ratios and temperature readings. They are read and written using the RDMSR and WRMSR instructions.&lt;/p&gt;

&lt;p&gt;The image on the right shows how CPU temperatures, measured using MSRs on an EC2 instance, vary based on CPU utilization (in blue). The workload is synthetic: all CPUs driven to 100% utilization for 5 minutes, then to 0% for a while, repeat. What&#39;s interesting is that temperature rises initially with CPU load, then drops sharply. Did system fans kick in? (So far I haven&#39;t found fan RPM MSRs, to confirm.)&lt;/p&gt;

&lt;p&gt;I&#39;m usually focused on the performance monitoring counters (PMCs; aka performance instrumentation counters (PICs), CPU performance counters (CPCs), etc.). These are read by RDPMC, and described in &lt;a href=&quot;http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-3b-part-3-manual.pdf&quot;&gt;Vol 3b&lt;/a&gt; of the same manual. These can measure data cache misses, stall cycles, and other useful performance events.&lt;/p&gt;

&lt;p&gt;On AWS EC2, within a cloud instance (Xen guest), I&#39;ve never seen the PMCs work, eg, via &quot;&lt;a href=&quot;http://www.brendangregg.com/perf.html#CPUstatistics&quot;&gt;perf stat&lt;/a&gt;&quot;. That doesn&#39;t mean they can&#39;t ever work, just that they (or their controlling MSRs) aren&#39;t currently available.&lt;/p&gt;

&lt;p&gt;But a small handful of MSRs &lt;em&gt;are&lt;/em&gt; available on EC2. Here are the more interesting ones I&#39;ve found:&lt;/p&gt;

&lt;div style=&quot;padding-left:20px&quot;&gt;
&lt;table border=&quot;1&quot;&gt;
&lt;tr&gt;
&lt;th&gt;Reg&lt;/th&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0xe7&lt;/td&gt;
&lt;td&gt;IA32_MPERF&lt;/td&gt;
&lt;td&gt;Bits 63:0 is TSC Frequency Clock Counter C0_MCNT TSC relative&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0xe8&lt;/td&gt;
&lt;td&gt;IA32_APERF&lt;/td&gt;
&lt;td&gt;Bits 63:0 is TSC Frequency Clock Counter C0_ACNT actual clocks&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x19c&lt;/td&gt;
&lt;td&gt;IA32_THERM_STATUS&lt;/td&gt;
&lt;td&gt;Bits 22:16 is the CPU therm status digital readout (DO)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x1a2&lt;/td&gt;
&lt;td&gt;MSR_TEMPERATURE_TARGET&lt;/td&gt;
&lt;td&gt;Bits 23:16 is temp target (TT)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x1ad&lt;/td&gt;
&lt;td&gt;MSR_TURBO_RATIO_LIMIT&lt;/td&gt;
&lt;td&gt;Bits 7:0 is the turbo boost ratio (x100 for MHz) for 1 core active&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;0x1ae&lt;/td&gt;
&lt;td&gt;MSR_TURBO_RATIO_LIMIT1&lt;/td&gt;
&lt;td&gt;Bits 15:8 (for example) is the turbo boost ratio for 10 cores active&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;center&gt;&lt;font size=&quot;-1&quot;&gt;&lt;i&gt;Table 1. MSRs for Intel(R) Xeon(R) CPU E5-2670 v2&lt;/i&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;These are used by various kernel routines, like the idle thread and cpufreq.&lt;/p&gt;

&lt;p&gt;Note that these are &lt;b&gt;model specific&lt;/b&gt;, which means they can vary between different processor models (micro-architectures). For example, Silvermont has a read/write target offset in MSR_TEMPERATURE_TARGET (bits 29:24), which can lower the throttle temperature (PROCHOT). Such differences make MSRs non-portable and tricky to use, which is why standards like &lt;a href=&quot;http://en.wikipedia.org/wiki/Performance_Application_Programming_Interface&quot;&gt;PAPI&lt;/a&gt; are important.&lt;/p&gt;

&lt;h2&gt;Reading MSRs&lt;/h2&gt;

&lt;p&gt;Here&#39;s how you can measure MSRs (assuming Intel):&lt;/p&gt;

&lt;h3&gt;1. Determine your CPU type and micro-architecture&lt;/h3&gt;

&lt;pre&gt;
# &lt;b&gt;head /proc/cpuinfo&lt;/b&gt;
processor       : 0
vendor_id       : GenuineIntel
&lt;b&gt;cpu family      : 6
model           : 62&lt;/b&gt;
model name      : Intel(R) Xeon(R) CPU E5-2670 v2 @ 2.50GHz
[...]
&lt;/pre&gt;

&lt;p&gt;The family and model numbers tell us that this is the Ivy Bridge micro-architecture (see the &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-architecture-and-processor-identification-with-cpuid-model-and-family-numbers&quot;&gt;Intel decoder&lt;/a&gt;). You can also use the cpuid tool (from the cpuid package), which should report micro-architecture directly.&lt;/p&gt;

&lt;h3&gt;2. Look up MSRs for your processor type

These are in Vol 3c of the &lt;a href=&quot;http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html&quot;&gt;Intel software developer manual&lt;/a&gt;. This is a 540 page volume, and if you&#39;re new to it, you&#39;ll get lost a few times before you get the hang of it.

&lt;h3&gt;3. Install and load msr-tools:&lt;/h3&gt;

&lt;pre&gt;
# &lt;b&gt;apt-get install msr-tools&lt;/b&gt;
# &lt;b&gt;modprobe msr&lt;/b&gt;
&lt;/pre&gt;

&lt;/h3&gt;
&lt;p&gt;(Assuming Ubuntu.) The msr-tools package adds the rdmsr and wrmsr tools, and the msr kernel module.&lt;/p&gt;

&lt;h3&gt;4. Use rdmsr&lt;/h3&gt;

&lt;p&gt;Based on the addresses from (2). Eg, to read the turbo boost ratio when 10 cores are active (Ivy Bridge):&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;rdmsr 0x1ae -f 15:8 -d&lt;/b&gt;
29
&lt;/pre&gt;

&lt;p&gt;Multiply by 100 to get MHz. The way these work is explained earlier in the manual.&lt;/p&gt;

&lt;p&gt;I did share a couple of tools in a &lt;a href=&quot;https://github.com/brendangregg/msr-cloud-tools&quot;&gt;msr-cloud-tools&lt;/a&gt; collection, however, I&#39;ve only written them for the processor type I&#39;m currently analyzing. You may need to edit these to get them using the right MSRs.&lt;/p&gt;

&lt;h2&gt;Why Measure Turbo Boost&lt;/h2&gt;

&lt;p&gt;We live in an annoying age for computer performance analysts: the error margin for many measurements &lt;em&gt;is over 10%&lt;/em&gt;, thanks to turbo boost, an Intel processor technology that can dynamically over-clock CPUs. Ubuntu is 10% faster than CentOS? Could just be turbo boost. New software version regressed by 5%? Could just be turbo boost. Tunable made things 10% faster? Could just be ... You get the picture.&lt;/p&gt;

&lt;p&gt;Turbo boost can make a 2500 MHz processor run at 3300 Mhz, depending on factors including temperature, power consumption, and the C-state of the cores. Colder servers run faster. I once had two identical servers at the top and bottom of a rack, and the top server ran 5% faster, as it received more cold air from the air conditioners. That&#39;s both great and maddening: I&#39;ll take the better performance, but it can also mess up measurements when I&#39;m comparing systems or software.&lt;/p&gt;

&lt;p&gt;There are three ways I&#39;ve historically dealt with this:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Turn off turbo boost in the BIOS when doing performance comparisons.&lt;/li&gt;
&lt;li&gt;Measure actual CPU cycles using CPU performance counters to observe the turbo boost rate.&lt;/li&gt;
&lt;li&gt;Run a short experiment (benchmark) to measure the current cycle rate, eg, &lt;a href=&quot;http://www.brendangregg.com/blog/2014-04-26/the-noploop-cpu-benchmark.html&quot;&gt;noploop&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If you run your own datacenter, you can do them all. But as a Xen guest on AWS EC2, you can&#39;t change the BIOS and do (1). You can do option (3), but that can be time-consuming and difficult (less reliable) on very busy systems. Until recently, I thought you couldn&#39;t do (2), either, and then I found the MSRs...&lt;/p&gt;

&lt;h2&gt;Discovering MSRs&lt;/h2&gt;

&lt;p&gt;I was working on a suspected turbo boost issue when a colleague at Netflix, Scott, mentioned that he liked using the i7z command to debug turbo boost. We didn&#39;t think it would work on EC2, but I tried anyway.&lt;/p&gt;

&lt;p&gt;Most of the output was clearly wrong, but a lone column of temperature readings showed that something was working. Using opensnoop from my ftrace &lt;a href=&quot;https://github.com/brendangregg/perf-tools&quot;&gt;perf-tools&lt;/a&gt; collection to see how:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;./opensnoop -n i7z&lt;/b&gt;
Tracing open()s issued by process name &quot;i7z&quot;. Ctrl-C to end.
COMM             PID      FD FILE
i7z              8427    0x3 /proc/cpuinfo
i7z              8427    0x3 /dev/cpu/0/msr
i7z              8427    0x3 /dev/cpu/0/msr
i7z              8427    0x3 /dev/cpu/0/msr
i7z              8427    0x3 /dev/cpu/0/msr
[...]
&lt;/pre&gt;

&lt;p&gt;This showed that i7z was reading /dev/cpu/0/msr, and led me to take a close look at the available MSRs.&lt;/p&gt;

&lt;p&gt;I&#39;d normally use CPU_CLK_Unhalted.Core, but that wasn&#39;t available. After some digging, I found I could use the ratio of IA32_APERF deltas to IA32_MPERF deltas, which shows how much faster the time stamp counter (TSC, which is cycle-based) is moving when the processor is in the C0 state.&lt;/p&gt;

&lt;p&gt;It was an enormous relief to find a way to directly measure real clock rates, and turbo boost. My error margins have vanished: &lt;strong&gt;I can measure performance again&lt;/strong&gt;.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;A handful of model-specific registers, MSRs, are available in Xen guests including on AWS EC2. These allow the real clock rate, and the degree of turbo boost, to be measured. This is important to know for any performance comparison, as variations in turbo boost can skew results by over 10%, based on how hot or cold servers were during the test.&lt;/p&gt;

&lt;p&gt;I&#39;ve written a couple of tools so far, in &lt;a href=&quot;https://github.com/brendangregg/msr-cloud-tools&quot;&gt;msr-cloud-tools&lt;/a&gt;, to measure CPU turbo boost and temperature. As is the nature of MSRs, they are specific to processor types, and these scripts only work (so far) on our Intel(R) Xeon(R) CPU E5-2670 v2s. If you want to use these tools or MSRs yourself, you may need to find out the right MSRs to use for your processor type. The good news is that the vendor documentation from Intel and AMD is very good, although it takes some time to dig through.&lt;/p&gt;


</description>
        <pubDate>Mon, 15 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-15-the-msrs-of-ec2.html-261b110e2.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-15-the-msrs-of-ec2.html-261b110e2.html</guid>
        
        
        <category>brendangregg</category>
        
      </item>
    
      <item>
        <title>Chrome 控制台不完全指南</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;Chrome的开发者工具已经强大到没朋友的地步了，特别是其功能丰富界面友好的console，使用得当可以有如下功效：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;更高「逼格」更快「开发调试」更强「进阶级的Frontender」&lt;/li&gt;
&lt;li&gt;Bug无处遁形「Console大法好」&lt;/li&gt;
&lt;/ul&gt;
&lt;p id=&quot;console.log&quot;&gt;&lt;strong&gt;console.log&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;大家都会用log，但鲜有人很好地利用&lt;code&gt;console.error&lt;/code&gt; , &lt;code&gt;console.warn&lt;/code&gt; 等将输出到控制台的信息进行分类整理。&lt;br&gt;
他们功能区别不大，意义在于将输出到控制台的信息进行归类，或者说让它们更语义化。&lt;br&gt;
各个所代表的语义如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;code&gt;console.log&lt;/code&gt;：普通信息&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;console.info&lt;/code&gt;：提示类信息&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;console.error&lt;/code&gt;：错误信息&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;console.warn&lt;/code&gt;：警示信息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当合理使用上述log方法后，可以很方便地在控制台选择查看特定类型的信息。&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;console.log(&#39;一颗红心向太阳&#39;,&#39;吼吼~&#39;);
console.info(&#39;楼上药不能停！&#39;);
console.warn(&#39;楼上嘴太贱！&#39;);
console.error(&#39;楼上关你毛事？&#39;);&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d5e95bb37e0c71af0bdd999b972baaaa.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;如果再配合&lt;code&gt;console.group&lt;/code&gt; 与&lt;code&gt;console.groupEnd&lt;/code&gt;，可以将这种分类管理的思想发挥到极致。这适合于在开发一个规模很大模块很多很复杂的Web APP时，将各自的log信息分组到以各自命名空间为名称的组里面。&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;console.group(&quot;app.foo&quot;);
console.log(&quot;来自foo模块的信息 blah blah blah...&quot;);
console.groupEnd();
console.group(&quot;app.bar&quot;);
console.log(&quot;来自bar模块的信息 blah blah blah...&quot;);
console.groupEnd();&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/914b4100ac5a5855232814d630b9d17a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;而关于&lt;code&gt;console.log&lt;/code&gt;，早已被玩儿坏了。一切都源于Chrome提供了这么一个API：第一个参数可以包含一些格式化的指令比如&lt;code&gt;%c&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;比如给&lt;code&gt;hello world&lt;/code&gt; 做件漂亮的嫁衣再拉出来见人：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;console.log(&#39;%chello world&#39;,&#39;font-size:25px;color:red;&#39;);&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0a91e566d84ea5f4b9574e12e526be28.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;如果你觉得不够过瘾，那就把你能写出来的最华丽的CSS样式都应用上吧，比如渐变。于是你可以得到如下华丽丽的效果：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;console.log(&#39;%chello world&#39;, &#39;background-image:-webkit-gradient( linear, left top, right top, color-stop(0, #f22), color-stop(0.15, #f2f), color-stop(0.3, #22f), color-stop(0.45, #2ff), color-stop(0.6, #2f2),color-stop(0.75, #2f2), color-stop(0.9, #ff2), color-stop(1, #f22) );color:transparent;-webkit-background-clip: text;font-size:5em;&#39;);&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f56abd73148e969921282b14399b2bf1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;各种招大招的节奏啊~&lt;/p&gt;
&lt;p&gt;看着上面密集的代码不用惊慌，上面&lt;code&gt;console.log()&lt;/code&gt;第二个参数全是纯CSS用来控制样式的，你不会陌生。而第一个参数里可以带用百分号开头的转义指令，如上面输出带样式的文字时使用的&lt;code&gt;%c&lt;/code&gt;指令。更详细的指令参见官方API文档的&lt;a href=&quot;https://developer.chrome.com/devtools/docs/console-api#consolelogobject-object&quot; target=&quot;_blank&quot;&gt;这个表格&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;如果还不够过瘾，那咱们来log一些图片吧，甚至。。。动图？&lt;br&gt;
对，你得先有图，我们拿&lt;a href=&quot;http://wayou.github.io/2014/09/10/chrome-console-tips-and-tricks/rabbit.gif&quot; target=&quot;_blank&quot;&gt;这张图&lt;/a&gt;为例。&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;console.log(&quot;%c&quot;, &quot;padding:50px 300px;line-height:120px;background:url(&#39;http://wayou.github.io/2014/09/10/chrome-console-tips-and-tricks/rabbit.gif&#39;) no-repeat;&quot;);&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/db01480fbeeebb529c351bc2e5475602.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;看着上面摇摆的豆比兔是不是有种抽它一脸的冲动。&lt;/p&gt;
&lt;p&gt;除此，&lt;code&gt;console.table&lt;/code&gt; 更是直接以表格的形式将数据输出，不能赞得太多！&lt;br&gt;
借用之前写过的&lt;a href=&quot;http://www.cnblogs.com/Wayou/p/things_you_dont_know_about_frontend.html&quot; target=&quot;_blank&quot;&gt;一篇博文&lt;/a&gt;里的例子：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;var data = [{&#39;品名&#39;: &#39;杜雷斯&#39;, &#39;数量&#39;: 4}, {&#39;品名&#39;: &#39;冈本&#39;, &#39;数量&#39;: 3}];
console.table(data);&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/7833b24728025a3efdc85e63209ffc5d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;另外，&lt;code&gt;console.log()&lt;/code&gt; 接收不定参数，参数间用逗号分隔，最终会输出会将它们以空白字符连接。&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;console.log(&#39;%c你好&#39;,&#39;color:red;&#39;,&#39;小明&#39;,&#39;你知道小红被妈妈打了么&#39;);&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/cb402cd38f1ec0315f42aa9b73c4e9c4.jpg&quot;&gt;&lt;/p&gt;
&lt;p id=&quot;console.assert&quot;&gt;&lt;strong&gt;console.assert&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当你想代码满足某些条件时才输出信息到控制台，那么你大可不必写&lt;code&gt;if&lt;/code&gt;或者三元表达式来达到目的，&lt;code&gt;cosole.assert&lt;/code&gt;便是这样场景下一种很好的工具，它会先对传入的表达式进行断言，只有表达式为假时才输出相应信息到控制台。&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;var isDebug=false;
console.assert(isDebug,&#39;开发中的log信息。。。&#39;);&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/4cadc5180db78fb6c85d657ffed27680.jpg&quot;&gt;&lt;/p&gt;
&lt;p id=&quot;console.count&quot;&gt;&lt;strong&gt;console.count&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;除了条件输出的场景，还有常见的场景是计数。&lt;br&gt;
当你想统计某段代码执行了多少次时也大可不必自己去写相关逻辑，内置的&lt;code&gt;console.count&lt;/code&gt;可以很地胜任这样的任务。&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;function foo(){
	//其他函数逻辑blah blah。。。
	console.count(&#39;foo 被执行的次数：&#39;);
}
foo();
foo();
foo();&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a93f97fb513473387ce84829106a7cdc.jpg&quot;&gt;&lt;/p&gt;
&lt;p id=&quot;console.dir&quot;&gt;&lt;strong&gt;console.dir&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将DOM结点以JavaScript对象的形式输出到控制台&lt;br&gt;
而&lt;code&gt;console.log&lt;/code&gt;是直接将该DOM结点以DOM树的结构进行输出，与在元素审查时看到的结构是一致的。不同的展现形式，同样的优雅，各种体位任君选择反正就是方便与体贴。&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;console.dir(document.body);
console.log(document.body);&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f28db380ab154d439975e8434a7f8f5c.jpg&quot;&gt;&lt;/p&gt;
&lt;p id=&quot;console.time-console.timeend&quot;&gt;&lt;strong&gt;console.time &amp;amp; console.timeEnd&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;输出一些调试信息是控制台最常用的功能，当然，它的功能远不止于此。当做一些性能测试时，同样可以在这里很方便地进行。&lt;br&gt;
比如需要考量一段代码执行的耗时情况时，可以用&lt;code&gt;console.time&lt;/code&gt;与 &lt;code&gt;console.timeEnd&lt;/code&gt;来做此事。&lt;/p&gt;
&lt;p&gt;这里借用官方文档的例子：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;console.time(&quot;Array initialize&quot;);
var array= new Array(1000000);
for (var i = array.length - 1; i &amp;gt;= 0; i--) {
    array[i] = new Object();
};
console.timeEnd(&quot;Array initialize&quot;);&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8121c10ec764ef115b42c701c3c93c9c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;当然，我们也可以选择自己写代码来计时：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;var start=new Date().getTime();
var array= new Array(1000000);
for (var i = array.length - 1; i &amp;gt;= 0; i--) {
    array[i] = new Object();
};
console.log(new Date().getTime()-start);&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5d660a0afb15c9d3bd7aa2b4e9b53714.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;相信你也看到了，用内置的&lt;code&gt;console.time&lt;/code&gt;是多么地方便，省去了自己写代码来计算的工作量。另外值得一提的是，通过调用内置的&lt;code&gt;console.time&lt;/code&gt;得到的结果要比自己手动计算的时间差更精确可靠。&lt;/p&gt;
&lt;p id=&quot;console.profile-console.timelime&quot;&gt;&lt;strong&gt;console.profile &amp;amp; console.timeLime&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当想要查看CPU使用相关的信息时，可以使用&lt;code&gt;console.profile&lt;/code&gt;配合 &lt;code&gt;console.profileEnd&lt;/code&gt;来完成这个需求。&lt;br&gt;
这一功能可以通过UI界面来完成，Chrome 开发者工具里面有个tab便是&lt;code&gt;Profile&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;与此类似的功能还有&lt;code&gt;console.timeLine&lt;/code&gt;配合 &lt;code&gt;console.timeLineEnd&lt;/code&gt;,它的作用是开始记录一段时间轴，同样可以通过Chrome开发者工具里的&lt;code&gt;Timeline&lt;/code&gt; 标签来进行相应操作。&lt;/p&gt;
&lt;p&gt;所以在我看来这两个方法有点鸡肋，因为都可以通过操作界面来完成。但至少他提供了一种命令行方式的交互，还是多了种姿势供选择吧。&lt;/p&gt;
&lt;p id=&quot;console.trace&quot;&gt;&lt;strong&gt;console.trace&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;堆栈跟踪相关的调试可以使用&lt;code&gt;console.trace&lt;/code&gt;。这个同样可以通过UI界面完成。当代码被打断点后，可以在&lt;code&gt;Call Stack&lt;/code&gt;面板中查看相关堆栈信息。&lt;/p&gt;
&lt;p&gt;上面介绍的都是挂在&lt;code&gt;window.console&lt;/code&gt;这个对象下面的方法，统称为&lt;a href=&quot;https://developer.chrome.com/devtools/docs/console-api&quot; target=&quot;_blank&quot;&gt;Console API&lt;/a&gt;，接下来的这些方法确切地说应该叫命令，是Chrome内置提供，在控制台中使用的，他们统称为&lt;a href=&quot;https://developer.chrome.com/devtools/docs/commandline-api&quot; target=&quot;_blank&quot;&gt;Command Line API&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;section&quot;&gt;$&lt;/h2&gt;
&lt;p&gt;似乎美刀总是被程序员及各种编程语言所青睐「你看看PHP代码就知道PHPer有多爱钱了」，在Chrome的控制台里，$用处还真是蛮多且方便的。&lt;br&gt;
&lt;code&gt;$_&lt;/code&gt;命令返回最近一次表达式执行的结果，功能跟按向上的方向键再回车是一样的，但它可以做为一个变量使用在你接下来的表达式中：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;2+2//回车，再
$_+1//回车得5&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/74aa2bd9c74b45ed3921afda86b9929e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面的&lt;code&gt;$_&lt;/code&gt;需要领悟其奥义才能使用得当，而$0~$4则代表了最近5个你选择过的DOM节点。&lt;br&gt;
什么意思？在页面右击选择&lt;code&gt;审查元素&lt;/code&gt;，然后在弹出来的DOM结点树上面随便点选，这些被点过的节点会被记录下来，而&lt;code&gt;$0&lt;/code&gt;会返回最近一次点选的DOM结点，以此类推，$1返回的是上上次点选的DOM节点，最多保存了5个，如果不够5个，则返回&lt;code&gt;undefined&lt;/code&gt;。&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b2ca526dd9d1de78e020c6f6f454fce6.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;另外值得一赞的是，Chrome 控制台中原生支持类jQuery的选择器，也就是说你可以用&lt;code&gt;$&lt;/code&gt;加上熟悉的css选择器来选择DOM节点，多么滴熟悉。&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;$(&#39;body&#39;)&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8f937d1e44ee23c353d497403bc8d03e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;$(selector)返回的是满足选择条件的首个DOM元素。&lt;br&gt;
剥去她伪善的外衣，其实&lt;code&gt;$(selector)&lt;/code&gt;是原生JavaScript &lt;code&gt;document.querySelector()&lt;/code&gt; 的封装。&lt;br&gt;
同时另一个命令 &lt;code&gt;$ $(selector) &lt;/code&gt;返回的是所有满足选择条件的元素的一个集合，是对&lt;code&gt;document.querySelectorAll()&lt;/code&gt; 的封装。&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt;$$(&#39;div&#39;)&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/e198b36215ca4a9ee9edc0dd44df8737.jpg&quot;&gt;&lt;/p&gt;
&lt;p id=&quot;copy&quot;&gt;&lt;strong&gt;copy&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过此命令可以将在控制台获取到的内容复制到剪贴板。&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;copy(document.body)&lt;/pre&gt;
&lt;p&gt;然后你就可以到处粘了：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ff779f3da420d243ef6b5a3771addfe5.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;看完此条命令行，机智的你是不是跟脑洞全开的我一样，冒出了这样一个想法：那就是通过这个命令可以在JavaScript里进行复制操作从而不用依赖Flash插件了。&lt;br&gt;
But现实是残酷的，如之前所述的，这里的控制台命令只能在控制台中环境中执行，因为他不依附于任何全局变量比如&lt;code&gt;window&lt;/code&gt;，所以其实在JS代码里是访问不了这个&lt;code&gt;copy&lt;/code&gt;方法的，所以从代码层面来调用复制功能也就无从谈起。但愿有天浏览器会提供相应的JS实现吧~&lt;/p&gt;
&lt;p id=&quot;keys-values&quot;&gt;&lt;strong&gt;keys &amp;amp; values&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这是一对基友。前者返回传入对象所有属性名组成的数据，后者返回所有属性值组成的数组。具体请看下面的例子：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;var tboy={name:&#39;wayou&#39;,gender:&#39;unknown&#39;,hobby:&#39;opposite to the gender&#39;};
keys(tboy);
values(tboy);&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8aaa34355859977d6b3a9d7650d45e4e.jpg&quot;&gt;&lt;/p&gt;
&lt;p id=&quot;monitor-unmonitor&quot;&gt;&lt;strong&gt;monitor &amp;amp; unmonitor&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;monitor(function)，它接收一个函数名作为参数，比如&lt;code&gt;function a&lt;/code&gt;,每次&lt;code&gt;a&lt;/code&gt;被执行了，都会在控制台输出一条信息，里面包含了函数的名称&lt;code&gt;a&lt;/code&gt;及执行时所传入的参数。&lt;/p&gt;
&lt;p&gt;而unmonitor(function)便是用来停止这一监听。&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;function sayHello(name){
	alert(&#39;hello,&#39;+name);
}
monitor(sayHello);
sayHello(&#39;wayou&#39;);
unmonitor(sayHello);
sayHello(&#39;wayou&#39;);&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ee020e40525748c7e11632da5d96140e.jpg&quot;&gt;&lt;/p&gt;
&lt;p id=&quot;debug-undebug&quot;&gt;&lt;strong&gt;debug &amp;amp; undebug&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;debug同样也是接收一个函数名作为参数。当该函数执行时自动断下来以供调试，类似于在该函数的入口处打了个断点，可以通过debugger来做到，同时也可以通过在Chrome开发者工具里找到相应源码然后手动打断点。&lt;br&gt;
而&lt;code&gt;undebug&lt;/code&gt; 则是解除该断点。&lt;/p&gt;
&lt;p&gt;而其他还有好些命令则让人没有说的欲望，因为好些都可以通过Chrome开发者工具的UI界面来操作并且比用在控制台输入要方便。&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Mon, 15 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-15-76985-0aa560f7c.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-15-76985-0aa560f7c.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>Git工作流指南</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;h3&gt;译序&lt;/h3&gt;
&lt;p&gt;工作流其实不是一个初级主题，背后的本质问题其实是有效的项目流程管理和高效的开发协同约定，不仅是&lt;code&gt;Git&lt;/code&gt;或&lt;code&gt;SVN&lt;/code&gt;等&lt;code&gt;SCM&lt;/code&gt;工具的使用。&lt;/p&gt;
&lt;p&gt;这篇指南以大家在&lt;code&gt;SVN&lt;/code&gt;中已经广为熟悉使用的集中式工作流作为起点，循序渐进地演进到其它高效的分布式工作流，还介绍了如何配合使用便利的&lt;code&gt;Pull Request&lt;/code&gt;功能，体系地讲解了各种工作流的应用。&lt;/p&gt;
&lt;p&gt;行文中实践原则和操作示例并重，对于&lt;code&gt;Git&lt;/code&gt;的资深玩家可以梳理思考提升，而新接触的同学，也可以跟着step-by-step操作来操练学习并在实际工作中上手使用。&lt;/p&gt;
&lt;p&gt;关于&lt;code&gt;Git&lt;/code&gt;工作流主题，网上体系的中文资料不多，主要是零散的操作说明，希望这篇文章能让你更深入理解并在工作中灵活有效地使用起来。&lt;/p&gt;
&lt;p&gt;PS：&lt;br&gt;
文中&lt;code&gt;Pull Request&lt;/code&gt;的介绍用的是&lt;code&gt;Bitbucket&lt;/code&gt;代码托管服务，由于和&lt;code&gt;GitHub&lt;/code&gt;基本一样，如果你用的是&lt;code&gt;GitHub&lt;/code&gt;（我自己也主要使用&lt;code&gt;GitHub&lt;/code&gt;托管代码），不影响理解和操作。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://weibo.com/oldratlee&quot;&gt;自己&lt;/a&gt;理解粗浅，译文源码在&lt;a href=&quot;https://github.com/quickhack/translations/tree/master/git-workflows-and-tutorials&quot;&gt;&lt;code&gt;GitHub&lt;/code&gt;上&lt;/a&gt;，翻译中不足和不对之处，欢迎建议（&lt;a href=&quot;https://github.com/quickhack/translations/issues&quot;&gt;提交Issue&lt;/a&gt;）和指正（&lt;a href=&quot;https://github.com/quickhack/translations/fork&quot;&gt;Fork后提交代码&lt;/a&gt;）！&lt;/p&gt;
&lt;h1&gt;
&lt;code&gt;Git&lt;/code&gt;工作流指南&lt;/h1&gt;
&lt;p&gt;工作流有各式各样的用法，但也正因此使得在实际工作中如何上手使用变得很头大。这篇指南通过总览公司团队中最常用的几种&lt;code&gt;Git&lt;/code&gt;工作流让大家可以上手使用。&lt;/p&gt;
&lt;p&gt;在阅读的过程中请记住，本文中的几种工作流是作为方案指导而不是条例规定。在展示了各种工作流可能的用法后，你可以从不同的工作流中挑选或揉合出一个满足你自己需求的工作流。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/jobbole.com/999470a3a4116e34d5427dc6bdf0cbf0.jpg&quot; alt=&quot;Git Workflows&quot;&gt;&lt;/p&gt;
&lt;h2&gt;概述&lt;/h2&gt;
&lt;h3&gt;集中式工作流&lt;/h3&gt;
&lt;p&gt;如果你的开发团队成员已经很熟悉&lt;code&gt;Subversion&lt;/code&gt;，集中式工作流让你无需去适应一个全新流程就可以体验&lt;code&gt;Git&lt;/code&gt;带来的收益。这个工作流也可以作为向更&lt;code&gt;Git&lt;/code&gt;风格工作流迁移的友好过渡。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/76847/&quot;&gt;了解更多 »&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/jobbole.com/13e406eae8561ee406f34639b631d0fd.jpg&quot; alt=&quot;Git Workflows: SVN-style&quot;&gt;&lt;/p&gt;
&lt;h3&gt;功能分支工作流&lt;/h3&gt;
&lt;p&gt;功能分支工作流以集中式工作流为基础，不同的是为各个新功能分配一个专门的分支来开发。这样可以在把新功能集成到正式项目前，用&lt;code&gt;Pull Requests&lt;/code&gt;的方式讨论变更。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/76857/&quot;&gt;了解更多 »&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/jobbole.com/21c6e654d3850b1caa45473dcb550d6b.jpg&quot; alt=&quot;Git Workflows: Feature Branch&quot;&gt;&lt;/p&gt;
&lt;h3&gt;
&lt;code&gt;Gitflow&lt;/code&gt;工作流&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Gitflow&lt;/code&gt;工作流通过为功能开发、发布准备和维护分配独立的分支，让发布迭代过程更流畅。严格的分支模型也为大型项目提供了一些非常必要的结构。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/76867/&quot;&gt;了解更多 »&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/jobbole.com/11d5a90aefab6129bb07c97b9abb7378.jpg&quot; alt=&quot;Git Workflows: Gitflow Cycle&quot;&gt;&lt;/p&gt;
&lt;h3&gt;
&lt;code&gt;Forking&lt;/code&gt;工作流&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Forking&lt;/code&gt;工作流是分布式工作流，充分利用了&lt;code&gt;Git&lt;/code&gt;在分支和克隆上的优势。可以安全可靠地管理大团队的开发者（&lt;code&gt;developer&lt;/code&gt;），并能接受不信任贡献者（&lt;code&gt;contributor&lt;/code&gt;）的提交。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/76861/&quot;&gt;了解更多 »&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/jobbole.com/dea8475fb42b1b660538152beebdb833.jpg&quot; alt=&quot;Git Workflows: Forking&quot;&gt;&lt;/p&gt;
&lt;h3&gt;&lt;code&gt;Pull Requests&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Pull requests&lt;/code&gt;是&lt;code&gt;Bitbucket&lt;/code&gt;提供的让开发者更方便地进行协作的功能，提供了友好的&lt;code&gt;Web&lt;/code&gt;界面可以在提议的修改合并到正式项目之前对修改进行讨论。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/76854/&quot;&gt;了解更多 »&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/jobbole.com/bc5080dfa0f5a2e57f2d8b2551ca08fa.jpg&quot; alt=&quot;Workflows: Pull Requests&quot;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;　　　　　　　　&lt;a href=&quot;http://blog.jobbole.com/76847/&quot;&gt;集中式工作流 »&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;译注&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;
&lt;a href=&quot;http://weibo.com/oldratlee&quot;&gt;自己&lt;/a&gt;理解粗浅，译文源码在&lt;a href=&quot;https://github.com/quickhack/translations/tree/master/git-workflows-and-tutorials&quot;&gt;&lt;code&gt;GitHub&lt;/code&gt;上&lt;/a&gt;，翻译中不足和不对之处，欢迎建议（&lt;a href=&quot;https://github.com/quickhack/translations/issues&quot;&gt;提交Issue&lt;/a&gt;）和指正（&lt;a href=&quot;https://github.com/quickhack/translations/fork&quot;&gt;Fork后提交代码&lt;/a&gt;）！&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Sun, 14 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-14-76843-9b68e8736.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-14-76843-9b68e8736.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>适合码农工作时玩的游戏：Scrum</title>
        <description>
&lt;p&gt;&lt;img src=&quot;/images/devtang.com/ac3545959ccea6d9abb3418a92b5b607.jpg&quot;&gt;&lt;/p&gt;

&lt;h1&gt;前言&lt;/h1&gt;

&lt;p&gt;昨天遇到一个来自微软的面试者，在面试的最后，我简单介绍了一下我们团队使用一周一次的Scrum来做项目管理。他回答说：”我在微软也用Scrum，不过我们一周两次，时间在周二和周四上午，每次15分钟“。我听了就笑了，我说：“同学，你说的这个应该是Scrum的站立会议，Scrum实际上有4个会议，站立会议只是其中一个。另外，标准的站立会议应该每天一次，不是每周两次。”接着我给他介绍了Scrum的4个会议，每个会议的意义是什么，他若有所思。&lt;/p&gt;

&lt;p&gt;今天和同事吃饭说起这件事情，同事pw说：在他所了解到的使用Scrum的公司里面，我们应该是执行Scrum做得最规范的，同时我们从Scrum实践中，收获了非常多。&lt;/p&gt;

&lt;p&gt;大约在3年前（当时我们团队还在网易），我们团队开始尝试用Scrum来进行软件开发的项目管理。在经过了3年的摸索和调整后，我们不但多次保证了项目的顺利上线，而且建立起了适合自己团队的工作方式。&lt;/p&gt;

&lt;p&gt;正如Scrum官方指南所说，“Scrum是易于理解，但难以精通的”，在此向大家分享我们实践的心得体会，希望更多的开发团队能够运用Scrum来流化自己的开发流程。&lt;/p&gt;

&lt;h1&gt;Scrum是游戏规则&lt;/h1&gt;

&lt;p&gt;在&lt;a href=&quot;https://www.scrum.org/Scrum-Guide&quot;&gt;Scrum官方网站&lt;/a&gt;上，提供了中文版本的&lt;a href=&quot;https://www.scrum.org/Portals/0/Documents/Scrum%20Guides/2013/Scrum-Guide-CN.pdf#zoom=100&quot;&gt;《Scrum指南》&lt;/a&gt;，这份只有14页的文档的封面上，写下了其最核心原则：游戏规则。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/devtang.com/f36e7670b3f9eeafc833e0ee003b78cc.jpg&quot;&gt;&lt;/p&gt;

&lt;p&gt;什么是游戏规则？游戏规则是玩游戏的人为了更好地娱乐而制定的规则。所以Scrum的规则是为了让大家更开心，更有效地工作，而不是约束大家。事实上由于Scrum只是一个框架，所以在实践Scrum时，更多的规则需要团队成员共同制定，这更加体现了游戏规则的思想——大家自己制定的规则，必定是得到大家一致同意的、能让大家舒服工作的规则。&lt;/p&gt;

&lt;h1&gt;Scrum是基于经验的&lt;/h1&gt;

&lt;p&gt;Scrum强调经验的重要性，但是经验又是需要不断调整的，所以Scrum通过迭代增量的开发方式，来每次调整整个团队的经验，从而来优化可预测性。&lt;/p&gt;

&lt;p&gt;例如，我们在开发猿题库时，在每轮Scrum的结束时，我们会开回顾会议，将大家每天处理待办事项的速度（我们称做日均Story Point）总结在Wiki中，如下图所示。这样当我们估计一个新一轮的迭代工作是否能够完成时，就可以参考前面几十次的经验，做出更加理性地判断。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/devtang.com/21266d4f76795f6e8c2a2f639c3a26c5.jpg&quot;&gt;&lt;/p&gt;

&lt;h1&gt;Scrum的三大支柱&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/images/devtang.com/a6460ae3f5ac875b4bb168b36e0c6e27.jpg&quot;&gt;&lt;/p&gt;

&lt;p&gt;透明性、检视、调整是Scrum的三大支柱。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;透明性是指：团队成员要达到对信息的完全共享，以便对观察到的信息有相同的理解。&lt;/li&gt;
&lt;li&gt;检视是指：团队成员要不停地检查自己的状态，类似汽车的定期检查一样，通过检视了解当前项目的状态。&lt;/li&gt;
&lt;li&gt;调整是指：团队成员发现出现了会影响项目进度的事件后，要及时寻找对策。&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;以上的说法有些学术化，我们可以这样理解：&lt;/p&gt;

&lt;p&gt;群体智商常常会出现低于个体智商的现象，这是因为个体之间的信息通常不一致，每个人的信息都是片面的，所以造成了观点的片面，而通常情况下团队领导由于接受到的信息更全面，所以他的决策考虑会更周到一些。&lt;/p&gt;

&lt;p&gt;但是Scrum又强调团队需要是“自组织”的，这就需要群体进行决策而不是领导。为了群体更好的决策，所以Scrum特别强调信息的透明，这样大家的信息都是充分共享的，而检视是一种保证信息透明的方法，即定期地查看自己和团队的状态，有了信息的透明，这样团队成员就能共同发现项目执行中的问题，进而一起寻找解决办法，从而达到“自组织”的团队。&lt;/p&gt;

&lt;h1&gt;Scrum的基础游戏规则&lt;/h1&gt;

&lt;p&gt;Scrum定义了基础的游戏规则，在基础的游戏规则之上，团队可以依据自己的经验，制定更细致的规则。但更细致的规则不应该违背基础的规则。这就像国家的宪法一样，其它法律不能与宪法违背。&lt;/p&gt;

&lt;p&gt;那我们来看看Scrum有哪些基础的游戏规则。&lt;/p&gt;

&lt;h2&gt;角色定义&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/devtang.com/787a539aca009a1d0db5fb98e5c085c4.jpg&quot;&gt;&lt;/p&gt;

&lt;p&gt;玩三国杀的同学都知道，玩之前大家会抽身份：主公、反賊、忠臣、内奸。而Scrum的游戏规则里面，有以下几种身份角色：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;产品负责人：产品负责人是管理产品待办列表的唯一责任人，也是产品最终的责任人。（稍后我们在介绍计划会议时，解释什么是产品待办列表。）简单来说，最终如果产品没做好，应该扣产品负责人的工资。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;开发团队：开发团队是负责将每轮Scrum迭代中计划的功能（可能是产品稿+美术稿的形式），交付成可发布的产品的各种专业人员。这里的各种专业人员包括：服务器端开发、Javascript前端开发、客户端开发、测试人员等。开发团队是真正在玩这个Scrum游戏的人，其他人（例如产品负责人都只是部分参与）。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Scrum Master：Scrum Master类似于杀人游戏中的法官，即游戏组织者。Scrum Master并不是团队的领导，他仅仅是做一些组织工作，而对于一个“自组织”的团队来说，其实真正需要组织的事情也不太多，所以他常常由开发团队中的某一个人兼任。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;h3&gt;没有子团队&lt;/h3&gt;

&lt;p&gt;在Scrum的官方文档中，这样说道：&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Scrum 不认可开发团队中的所谓“子团队”,无论是测试还是业务分析的成员都不能划分为“子团队”。此规则无一例外。&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;所以我们看到，Scrum在定义角色的时候，强调开发团队中一个整体，包含把产品发布出来的所有相关的专业技术人员，并且开发团队共同承担开发的责任，只有这样，大家才能形成利益共同体，共同努力把产品做好。&lt;/p&gt;

&lt;p&gt;这一点也解释了为什么很多大公司玩不好Scrum。拿百度举例，百度的一个项目就有很多“子团队”。在百度，前端开发人员属于前端组，移动端开发人员属于移动端组，测试有专门的QA组，PM也有专门的组。这样的划分，进而造成大家的绩效评估并不是完全由项目执行的好坏来决定，而PM也需要花很大精力去推动大家，这样的团队没有共同的利益，是很难做到“自组织”的。&lt;/p&gt;

&lt;h3&gt;强调平等&lt;/h3&gt;

&lt;p&gt;Scrum中仅定义了“开发团队”这个整体的角色，在“开发团队”内部，大家都是平等的。因为只有这样，大家才能更加自由的共享信息，共同决策，否则决策权仍然掌握在少部分人手里。在Scrum的官方文档中，是这样说的：&lt;/p&gt;

&lt;blockquote&gt;&lt;p&gt;Scrum 不认可开发团队成员的头衔，无论承担哪种工作他们都叫做开发人员。此规则无一例外。&lt;/p&gt;&lt;/blockquote&gt;

&lt;h3&gt;游戏人数规则&lt;/h3&gt;

&lt;p&gt;开发团队还有一个不能不说的特点，就是他的规模必须足够小，因为他强调信息的透明，如果人数过大，光沟通的成本就大到无法承受了，所以官方文档上推荐的人数是 10人以内（不包括产品负责人和Scrum Master，除非他们也参与开发）。&lt;/p&gt;

&lt;p&gt;但是在实际执行中，由于业务的增长，团队人数很容易就超过10人。比如我们猿题库在创业时只有不到10人，现在已经成长到几十人了。这个时候，比较好的做法是进行团队的切分，比如我们试过将猿题库的服务器端和客户端进行拆分，这样保证每个团队还是在10人以内。如果以后再增长，可能客户端会再进行拆分成iOS团队和Android团队。&lt;/p&gt;

&lt;h3&gt;游戏时间&lt;/h3&gt;

&lt;p&gt;Scrum对每一轮的迭代时间并没有严格的规定，但它要求是小于一个月。对于每一轮的迭代，Scrum把它称作Sprint（冲刺）。&lt;/p&gt;

&lt;p&gt;作为创业公司，我们在最近两年都实践着一周一次Sprint的方式来工作。一周一次Sprint能够保证调整足够快，Sprint执行中是不鼓励需求改动的。所以一周一次的Sprint能够做到，对于比较急迫的需求改动，在下次Sprint时（下周）就可以执行。&lt;/p&gt;

&lt;p&gt;一周一次的Sprint也有不少问题，由于偏离本文主题，所以就不展开介绍了。现在我们的猿题库直播课项目组也在尝试进行2周一次的Sprint。总之，Sprint多长是由开发团队根据项目的具体特点来决定的，只要不超过一个月即可。&lt;/p&gt;

&lt;h2&gt;游戏玩法&lt;/h2&gt;

&lt;p&gt;讲了半天，终于讲到核心了，到底怎么玩这个游戏啊！为了更好的理解，我们先看看杀人游戏的玩法，杀人游戏定义了如下几个事件：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;天黑请闭眼，这个时候大家都闭上眼睛&lt;/li&gt;
&lt;li&gt;杀手睁眼，杀手杀人，杀手闭眼&lt;/li&gt;
&lt;li&gt;警察睁眼，警察检查，警察闭眼&lt;/li&gt;
&lt;li&gt;天亮了，宣布谁死了，大家讨论并投票谁是杀手，投出的嫌疑人被杀死。如果警察或杀手死了，宣布游戏结束，否则跳到第1步。&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;刚好，Scrum也定义了4个事件，分别是：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;计划会议&lt;/li&gt;
&lt;li&gt;每日站立会议&lt;/li&gt;
&lt;li&gt;评审会议&lt;/li&gt;
&lt;li&gt;回顾会议&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;以下我们来详细介绍一下这4个会议到底要具体怎么做。&lt;/p&gt;

&lt;h3&gt;计划会议&lt;/h3&gt;

&lt;p&gt;计划会议主要通过讨论，完成两件事情：做什么、怎么做。&lt;/p&gt;

&lt;p&gt;关于“做什么”：产品负责人会给出一个产品待办列表，然后由团队成员来根据预计的工作量以及以往的表现，来挑选接下来的Sprint需要完成的待办项。这里的特点是：由开发团队成员自己来挑选待办项，而不是由传统意义上的Tech Leader或产品负责人来挑选。这样保证了开发任务是由团队成员自己决定的，他更有责任心把事情完成。同时作为产品负责人，有必要非常明确地告诉开发团队每一个待办项的意义和重要性，这样开发团队才能做出有利于产品的挑选工作。&lt;/p&gt;

&lt;p&gt;关于“怎么做”：开发团队从待办列表中挑选完需要完成的待办项之后，就需要对每个要做的待办项进行评估。评估的工作就是讨论具体怎么做，这包括技术架构、实现细节的讨论。只有讨论得非常清楚之后，这项工作的工作量才会比较清楚。&lt;/p&gt;

&lt;p&gt;在讨论怎么做之后，一些敏捷公司推荐使用“出牌”的方式来评估工作量，我们也采用了这种方式，我们还专门做了一套Scrum扑克，用于出牌。如下图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/devtang.com/0a67592fc1aeaaee160b6e72166be585.jpg&quot;&gt;&lt;/p&gt;

&lt;p&gt;出牌的规则是每个人出一张牌，用牌上的数字表示当前工作的工作量。通常大家还会事先约定好数字2代表的工作量，以保证大家的标准相同。为了避免相互影响，大家先把要出的牌扣着，然后同时翻开。之后，出最高分的和出最低分的同学要表达意见，说明为什么自己估计成这样，大家讨论，这样的过程可以保证大家的信息都是透明的，即没有忽略掉的技术实现难度或细节，在信息充分共享的情况下，通常大家第二次出牌时就可以达成一致了。&lt;/p&gt;

&lt;h3&gt;每日站立会议&lt;/h3&gt;

&lt;p&gt;每日站立会议是进行检视的方法。通常选择固定时间（我们是每天早上10点10分开），以养成团队工作习惯来避免组织成本。站立会议要尽量的短，通常控制在15分钟以内，选择站着开会，也是让大家有更大的预期快速结束。&lt;/p&gt;

&lt;p&gt;站立会议主要是为了沟通，以及发现潜在可能的问题，在站立会议上，团队成员每个人要讲3句话：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;我昨天做了什么&lt;/li&gt;
&lt;li&gt;我今天打算做什么&lt;/li&gt;
&lt;li&gt;我遇到了什么问题&lt;/li&gt;
&lt;/ol&gt;


&lt;p&gt;通过这3句话来达到高效沟通的目的，对于会上提到的问题，通常是下来相关人员自行解决。&lt;/p&gt;

&lt;p&gt;站立会议通常能够发现项目进展的状态是否顺利，从而尽早采取相应的措施。时间较长的Sprint可以配合燃尽图，更方便地审视项目进展速度。&lt;/p&gt;

&lt;h3&gt;评审会议&lt;/h3&gt;

&lt;p&gt;Sprint 评审会议在 Sprint 结束时举行，用于检查计划中的工作，哪些完成了，哪些没有完成。在我们的实践中，我们会让开发的同事演示自己所做的功能，然后PM会看这个功能是否达到了要求。&lt;/p&gt;

&lt;h3&gt;回顾会议&lt;/h3&gt;

&lt;p&gt;回顾会议是开发团队检视自己，发现团队运转中的问题，并且定制游戏规则的过程。通过对前一个Sprint中的人、关系、过程、工具进行检视，团队成员能够总结出做得好的，和做得不好的。进而制定一个改进的方案。&lt;/p&gt;

&lt;p&gt;回顾会议是Scrum创建“自组织”团队的关键，它将团队自我改进变成了一个例行的会议，在这个会议中，讨论的都是大家对该游戏的感受，包括好的和不好的，最终大家为了玩得更爽，就会发扬好的，努力避免不好的，成为一个能够自我进化的集体。&lt;/p&gt;

&lt;p&gt;需要注意的是，回顾会议不应该成为吐槽大会，大家应该本着发现问题，解决问题的态度来讨论。例如：如果在回顾会议仅仅是抱怨产品老是改需求，或者抱怨时间不够，而不提出解决方案的话，是非常不好的。&lt;/p&gt;

&lt;p&gt;提出问题是容易的，麻烦的是提出解决方案。我们的老大郭常圳提出了一个办法，即我们思考：“如果再来一次，我们能不能做得更好”？如果我们发现，如果再来一次，由于客观原则，我们可能仍然无法避免同样的问题，那么我们就选择坦然接受而不是抱怨。&lt;/p&gt;

&lt;p&gt;因为很多时候本来就没有完美的、没有任何问题的解决方案，这就像软件都有Bug一样，如果Bug不可避免，我们就选择发现的时候尽量修复而不是编码的时候避免。&lt;/p&gt;

&lt;h3&gt;框架图&lt;/h3&gt;

&lt;p&gt;下图介绍了Scrum的整个框架：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/devtang.com/cd095ee776cea67c25f10846160db4a2.jpg&quot;&gt;&lt;/p&gt;

&lt;h2&gt;一些问题&lt;/h2&gt;

&lt;h3&gt;有什么辅助Scrum的工具？&lt;/h3&gt;

&lt;p&gt;我们使用的是Redmine的Scrum插件来开相关的Scrum会议。我们Scrum的回顾会议总结放在内部的Wiki上。也有团队喜欢直接用白板+便签来完成Scrum的相关会议。像JIRA一类的专业项目管理软件，也都支持Scrum。&lt;/p&gt;

&lt;h3&gt;游戏超时怎么办？&lt;/h3&gt;

&lt;p&gt;游戏超时通常就意味着游戏结束。在Scrum这个游戏中，团队成员不接受Sprint延期。所以不管有没有完成所有任务，评审会议和回顾会议都需要按时开，没有完成的任务需要进行仔细讨论，分析其原因到底是什么，从而在下一轮Sprint中尽量避免出现同样的问题。&lt;/p&gt;

&lt;h3&gt;开发团队自己挑任务，会不会造成项目进度很慢？&lt;/h3&gt;

&lt;p&gt;通常情况下不会。如果我们真正把Scrum做好，大家能享受到Scrum带来的各种好处，例如团队每个人都能参与决策团队做事方式，每个人都能积极的追求效率，而一次次成功的Scrum，带给大家的成就感也是巨大的。&lt;/p&gt;

&lt;p&gt;好的Scrum执行还能保证团队不会随意加班，我们已经很久没有周末加班了，平时晚上大部分时间也都能做到按时下班，这对于互联网公司来说，几乎是不可想像的。&lt;/p&gt;

&lt;p&gt;不加班只是一个附属品，最重要的是按时发布产品，我们创业2年多来从来没有延期发布过产品。这样使得我们的运营推广计划能够非常有序地执行。&lt;/p&gt;

&lt;p&gt;需要强调的是，不加班并不是代表我们的工作轻松，通常情况下我们的Scrum安排还是比较紧张的，因为我们都想创业时跑得快一些。不加班也不是我们的原则，我们的原则是按时发布产品，所以当有一些特殊情况产生时，我们也会适当的加班。我们只是不把加班当作一个常态的工作方式，因为我们认为工作效率比工作时长更为重要。另一方面我们认为创业是长跑，保持良好的发布节奏已经非常好了，长期加班造成的身体懈怠可能会造成工作效率的损失。&lt;/p&gt;

&lt;h3&gt;Scrum适合所有团队吗？&lt;/h3&gt;

&lt;p&gt;首先Scrum是非常适合程序员的，因为程序员天生就不喜欢约束。Scrum的“自组织”团队的思想很容易让程序员感觉到自己是团队的主人。另外Scrum是非常反会议的，4个会议都严格地规定了时间长度，所以可以让程序员有充足的时间花在编码上。Scrum也是比较反需求临时变更的，由于Sprint周期短（我们才一周），所以变更可以根据重要程度放到下一个Sprint中。&lt;/p&gt;

&lt;p&gt;Scrum非常强调团队作为一个整体来做事情，所以并没有刻意地去评估每个人具体的工作量。这需要团队每个人都比较自觉。当然，由于强调透明和检视，所以团队内如果有人懈怠的话，团队里其他人是很容易发现的。&lt;/p&gt;

&lt;p&gt;所以，如果你的团队人数在10人左右，又能保证团队是一个整体为项目负责，那就有了尝试Scrum的基础。&lt;/p&gt;

&lt;h3&gt;为什么很多公司用不好Scrum？&lt;/h3&gt;

&lt;p&gt;Scrum指南里面也提到，Scrum是“易于学习，难于精通的”。所以Scrum本来就比较难做好。我感觉到几个比较容易出现的问题是：&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;团队里面有人不信Scrum能比以前的软件开发方式更好。游戏规则使终是游戏规则，如果有人不想玩游戏的话，游戏玩起来就没有那么愉快了。真正想做好Scrum就得认真学习Scrum指南，然后努力遵守Scrum的规则。只有当大家都努力玩这个游戏时，才能享受游戏的乐趣。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;随意更改Scrum的规则。例如我以前在有道的团队就把Scrum的每日站会改成了每周二，周四开一个坐会，开会的方式也变成产品经理询问进度，各个技术人员汇报的方式，会议一次要开半个多小时。这一下子就把每日站会做得变味了。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;难以组建团队。之前说过像百度这类大公司，其公司文化不是一朝一夕形成的。Scrum的工作方式要求大家都为项目完全负责，而很多传统公司按职能来划分团队，例如PM团队、客户端团队、前端团队等，这会影响Scrum的执行。&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;h3&gt;Scrum是终极大招吗&lt;/h3&gt;

&lt;p&gt;Scrum不是银弹，它并不能解决所有问题，实际上，很多时候它根本不提供解决问题的方法。Scrum本身只是一个框架，通过这个框架，我们更容易发现项目运行中的问题，通过定期的回顾会议来解决问题。&lt;/p&gt;

&lt;h1&gt;结束语&lt;/h1&gt;

&lt;p&gt;本文旨在通过介绍Scrum的核心思想和基本框架，吸引大家了解Scrum。要实践Scrum，还是需要进一步的学习才行。欢迎大家详细阅读&lt;a href=&quot;https://www.scrum.org/Portals/0/Documents/Scrum%20Guides/2013/Scrum-Guide-CN.pdf#zoom=100&quot;&gt;《Scrum指南》&lt;/a&gt;，然后尝试使用Scrum来让自己每天的工作变得轻松愉快。&lt;/p&gt;

&lt;p&gt;PS：我们的公司猿题库创业两年，做在线教育方向，不久前顺利拿到了1500万美元的C轮融资。我们现在很缺人，也欢迎大家加入我们，和我们一起玩Scrum游戏，感兴趣的可以看：&lt;a href=&quot;http://www.yuantiku.com/campus/&quot;&gt;职位介绍&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;愿大家玩得开心～&lt;/p&gt;

</description>
        <pubDate>Sat, 13 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-13-scrum-introduction-3e0aca621.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-13-scrum-introduction-3e0aca621.html</guid>
        
        
        <category>devtang</category>
        
      </item>
    
      <item>
        <title>Git工作流指南：Gitflow工作流</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;&lt;img alt=&quot;Git Workflows: Gitflow Cycle&quot; src=&quot;/images/jobbole.com/11d5a90aefab6129bb07c97b9abb7378.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这节介绍的&lt;a href=&quot;http://nvie.com/posts/a-successful-git-branching-model/&quot;&gt;&lt;code&gt;Gitflow&lt;/code&gt;工作流&lt;/a&gt;借鉴自在&lt;a href=&quot;http://nvie.com/&quot;&gt;nvie&lt;/a&gt;的&lt;em&gt;Vincent Driessen&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Gitflow&lt;/code&gt;工作流定义了一个围绕项目发布的严格分支模型。虽然比&lt;a href=&quot;http://blog.jobbole.com/76857/&quot;&gt;功能分支工作流&lt;/a&gt;复杂几分，但提供了用于一个健壮的用于管理大型项目的框架。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Gitflow&lt;/code&gt;工作流没有用超出功能分支工作流的概念和命令，而是为不同的分支分配一个很明确的角色，并定义分支之间如何和什么时候进行交互。除了使用功能分支，在做准备、维护和记录发布也使用各自的分支。当然你可以用上功能分支工作流所有的好处：&lt;code&gt;Pull Requests&lt;/code&gt;、隔离实验性开发和更高效的协作。&lt;/p&gt;
&lt;h2&gt;工作方式&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Gitflow&lt;/code&gt;工作流仍然用中央仓库作为所有开发者的交互中心。和其它的工作流一样，开发者在本地工作并&lt;code&gt;push&lt;/code&gt;分支到要中央仓库中。&lt;/p&gt;
&lt;h3&gt;历史分支&lt;/h3&gt;
&lt;p&gt;相对使用仅有的一个&lt;code&gt;master&lt;/code&gt;分支，&lt;code&gt;Gitflow&lt;/code&gt;工作流使用2个分支来记录项目的历史。&lt;code&gt;master&lt;/code&gt;分支存储了正式发布的历史，而&lt;code&gt;develop&lt;/code&gt;分支作为功能的集成分支。这样也方便&lt;code&gt;master&lt;/code&gt;分支上的所有提交分配一个版本号。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/384db8bc89bb61260643861ee7d81a68.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;剩下要说明的问题围绕着这2个分支的区别展开。&lt;/p&gt;
&lt;h3&gt;功能分支&lt;/h3&gt;
&lt;p&gt;每个新功能位于一个自己的分支，这样可以&lt;a href=&quot;https://www.atlassian.com/git/tutorial/remote-repositories#!push&quot;&gt;&lt;code&gt;push&lt;/code&gt;到中央仓库以备份和协作&lt;/a&gt;。但功能分支不是从&lt;code&gt;master&lt;/code&gt;分支上拉出新分支，而是使用&lt;code&gt;develop&lt;/code&gt;分支作为父分支。当新功能完成时，&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-branches#!merge&quot;&gt;合并回&lt;code&gt;develop&lt;/code&gt;分支&lt;/a&gt;。新功能提交应该从不直接与&lt;code&gt;master&lt;/code&gt;分支交互。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6f6009c65d3b29ab4bd6dbe8daf98680.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;注意，从各种含义和目的上来看，功能分支加上&lt;code&gt;develop&lt;/code&gt;分支就是功能分支工作流的用法。但&lt;code&gt;Gitflow&lt;/code&gt;工作流没有在这里止步。&lt;/p&gt;
&lt;h3&gt;发布分支&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/eea51bc17ceb40fcdad466ed6dcf9ff1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;一旦&lt;code&gt;develop&lt;/code&gt;分支上有了做一次发布（或者说快到了既定的发布日）的足够功能，就从&lt;code&gt;develop&lt;/code&gt;分支上&lt;code&gt;fork&lt;/code&gt;一个发布分支。新建的分支用于开始发布循环，所以从这个时间点开始之后新的功能不能再加到这个分支上 —— 这个分支只应该做&lt;code&gt;Bug&lt;/code&gt;修复、文档生成和其它面向发布任务。一旦对外发布的工作都完成了，发布分支合并到&lt;code&gt;master&lt;/code&gt;分支并分配一个版本号打好&lt;code&gt;Tag&lt;/code&gt;。另外，这些从新建发布分支以来的做的修改要合并回&lt;code&gt;develop&lt;/code&gt;分支。&lt;/p&gt;
&lt;p&gt;使用一个用于发布准备的专门分支，使得一个团队可以在完善当前的发布版本的同时，另一个团队可以继续开发下个版本的功能。&lt;br&gt;
这也打造定义良好的开发阶段（比如，可以很轻松地说，『这周我们要做准备发布版本4.0』，并且在仓库的目录结构中可以实际看到）。&lt;/p&gt;
&lt;p&gt;常用的分支约定：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;用于新建发布分支的分支: develop&lt;br&gt;
用于合并的分支: master&lt;br&gt;
分支命名: release-* 或 release/*&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;维护分支&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/2b4add96df6d739a5d9715e28a91e3d7.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;维护分支或说是热修复（&lt;code&gt;hotfix&lt;/code&gt;）分支用于生成快速给产品发布版本（&lt;code&gt;production releases&lt;/code&gt;）打补丁，这是唯一可以直接从&lt;code&gt;master&lt;/code&gt;分支&lt;code&gt;fork&lt;/code&gt;出来的分支。修复完成，修改应该马上合并回&lt;code&gt;master&lt;/code&gt;分支和&lt;code&gt;develop&lt;/code&gt;分支（当前的发布分支），&lt;code&gt;master&lt;/code&gt;分支应该用新的版本号打好&lt;code&gt;Tag&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;为&lt;code&gt;Bug&lt;/code&gt;修复使用专门分支，让团队可以处理掉问题而不用打断其它工作或是等待下一个发布循环。你可以把维护分支想成是一个直接在&lt;code&gt;master&lt;/code&gt;分支上处理的临时发布。&lt;/p&gt;
&lt;h2&gt;示例&lt;/h2&gt;
&lt;p&gt;下面的示例演示本工作流如何用于管理单个发布循环。假设你已经创建了一个中央仓库。&lt;/p&gt;
&lt;h3&gt;创建开发分支&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/2087d023b1fa4a8ef7cdb655be5b70b6.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;第一步为&lt;code&gt;master&lt;/code&gt;分支配套一个&lt;code&gt;develop&lt;/code&gt;分支。简单来做可以&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-branches#!branch&quot;&gt;本地创建一个空的&lt;code&gt;develop&lt;/code&gt;分支&lt;/a&gt;，&lt;code&gt;push&lt;/code&gt;到服务器上：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git branch develop&lt;br&gt;
git push -u origin develop&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;以后这个分支将会包含了项目的全部历史，而&lt;code&gt;master&lt;/code&gt;分支将只包含了部分历史。其它开发者这时应该&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-basics#!clone&quot;&gt;克隆中央仓库&lt;/a&gt;，建好&lt;code&gt;develop&lt;/code&gt;分支的跟踪分支：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git clone ssh://user@host/path/to/repo.git&lt;br&gt;
git checkout -b develop origin/develop&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;现在每个开发都有了这些历史分支的本地拷贝。&lt;/p&gt;
&lt;h3&gt;小红和小明开始开发新功能&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fbd7737bbd5776f2a1fd81e0b4212386.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个示例中，小红和小明开始各自的功能开发。他们需要为各自的功能创建相应的分支。新分支不是基于&lt;code&gt;master&lt;/code&gt;分支，而是应该&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-branches#!checkout&quot;&gt;基于&lt;code&gt;develop&lt;/code&gt;分支&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git checkout -b some-feature develop&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;他们用老套路添加提交到各自功能分支上：编辑、暂存、提交：&lt;br&gt;
&lt;code&gt;git status&lt;br&gt;
git add&lt;br&gt;
git commit&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;小红完成功能开发&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/932f2e68b86d0efdfb7672efadd68daf.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;添加了提交后，小红觉得她的功能OK了。如果团队使用&lt;code&gt;Pull Requests&lt;/code&gt;，这时候可以发起一个用于合并到&lt;code&gt;develop&lt;/code&gt;分支。否则她可以直接合并到她本地的&lt;code&gt;develop&lt;/code&gt;分支后&lt;code&gt;push&lt;/code&gt;到中央仓库：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git pull origin develop&lt;br&gt;
git checkout develop&lt;br&gt;
git merge some-feature&lt;br&gt;
git push&lt;br&gt;
git branch -d some-feature&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;第一条命令在合并功能前确保&lt;code&gt;develop&lt;/code&gt;分支是最新的。注意，功能决不应该直接合并到&lt;code&gt;master&lt;/code&gt;分支。冲突解决方法和&lt;a href=&quot;http://blog.jobbole.com/76847/&quot;&gt;集中式工作流&lt;/a&gt;一样。&lt;/p&gt;
&lt;h3&gt;小红开始准备发布&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9f61d51173637803af25ff88af98da5a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个时候小明正在实现他的功能，小红开始准备她的第一个项目正式发布。像功能开发一样，她用一个新的分支来做发布准备。这一步也确定了发布的版本号：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git checkout -b release-0.1 develop&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个分支是清理发布、执行所有测试、更新文档和其它为下个发布做准备操作的地方，像是一个专门用于改善发布的功能分支。&lt;/p&gt;
&lt;p&gt;只要小红创建这个分支并&lt;code&gt;push&lt;/code&gt;到中央仓库，这个发布就是功能冻结的。任何不在&lt;code&gt;develop&lt;/code&gt;分支中的新功能都推到下个发布循环中。&lt;/p&gt;
&lt;h3&gt;小红完成发布&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8b7653292f34d8d3176bfac1a80717d1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;一旦准备好了对外发布，小红合并修改到&lt;code&gt;master&lt;/code&gt;分支和&lt;code&gt;develop&lt;/code&gt;分支上，删除发布分支。合并回&lt;code&gt;develop&lt;/code&gt;分支很重要，因为在发布分支中已经提交的更新需要在后面的新功能中也要是可用的。另外，如果小红的团队要求&lt;code&gt;Code Review&lt;/code&gt;，这是一个发起&lt;code&gt;Pull Request&lt;/code&gt;的理想时机。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git checkout master&lt;br&gt;
git merge release-0.1&lt;br&gt;
git push&lt;br&gt;
git checkout develop&lt;br&gt;
git merge release-0.1&lt;br&gt;
git push&lt;br&gt;
git branch -d release-0.1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;发布分支是作为功能开发（&lt;code&gt;develop&lt;/code&gt;分支）和对外发布（&lt;code&gt;master&lt;/code&gt;分支）间的缓冲。只要有合并到&lt;code&gt;master&lt;/code&gt;分支，就应该打好&lt;code&gt;Tag&lt;/code&gt;以方便跟踪。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git tag -a 0.1 -m &quot;Initial public release&quot; master&lt;br&gt;
git push --tags&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Git&lt;/code&gt;有提供各种勾子（&lt;code&gt;hook&lt;/code&gt;），即仓库有事件发生时触发执行的脚本。可以配置一个勾子，在你&lt;code&gt;push&lt;/code&gt;中央仓库的&lt;code&gt;master&lt;/code&gt;分支时，自动构建好对外发布。&lt;/p&gt;
&lt;h3&gt;最终用户发现&lt;code&gt;Bug&lt;/code&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/acbdff5c1fb4a3e412fbd534a1e11a1c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;对外发布后，小红回去和小明一起做下个发布的新功能开发，直到有最终用户开了一个&lt;code&gt;Ticket&lt;/code&gt;抱怨当前版本的一个&lt;code&gt;Bug&lt;/code&gt;。为了处理&lt;code&gt;Bug&lt;/code&gt;，小红（或小明）从&lt;code&gt;master&lt;/code&gt;分支上拉出了一个维护分支，提交修改以解决问题，然后直接合并回&lt;code&gt;master&lt;/code&gt;分支：&lt;/p&gt;
&lt;p&gt;“`&lt;br&gt;
git checkout -b issue-#001 master&lt;/p&gt;
&lt;h1&gt;Fix the bug&lt;/h1&gt;
&lt;p&gt;git checkout master&lt;br&gt;
git merge issue-#001&lt;br&gt;
git push&lt;br&gt;
“`&lt;/p&gt;
&lt;p&gt;就像发布分支，维护分支中新加这些重要修改需要包含到&lt;code&gt;develop&lt;/code&gt;分支中，所以小红要执行一个合并操作。然后就可以安全地&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-branches#!branch&quot;&gt;删除这个分支&lt;/a&gt;了：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git checkout develop&lt;br&gt;
git merge issue-#001&lt;br&gt;
git push&lt;br&gt;
git branch -d issue-#001&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;下一站&lt;/h2&gt;
&lt;p&gt;到了这里，但愿你对&lt;a href=&quot;http://blog.jobbole.com/76847/&quot;&gt;集中式工作流&lt;/a&gt;、&lt;a href=&quot;http://blog.jobbole.com/76857/&quot;&gt;功能分支工作流&lt;/a&gt;和&lt;code&gt;Gitflow&lt;/code&gt;工作流已经感觉很舒适了。你应该也牢固的掌握了本地仓库的潜能，&lt;code&gt;push&lt;/code&gt;/&lt;code&gt;pull&lt;/code&gt;模式和&lt;code&gt;Git&lt;/code&gt;健壮的分支和合并模型。&lt;/p&gt;
&lt;p&gt;记住，这里演示的工作流只是可能用法的例子，而不是在实际工作中使用&lt;code&gt;Git&lt;/code&gt;不可违逆的条例。所以不要畏惧按自己需要对工作流的用法做取舍。不变的目标就是让&lt;code&gt;Git&lt;/code&gt;为你所用。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/76857/&quot;&gt;« 功能分支工作流&lt;/a&gt;　　　　&lt;a href=&quot;http://blog.jobbole.com/76861/&quot;&gt;&lt;code&gt;Forking&lt;/code&gt;工作流 »&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;译注&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;
&lt;a href=&quot;http://weibo.com/oldratlee&quot;&gt;自己&lt;/a&gt;理解粗浅，译文源码在&lt;a href=&quot;https://github.com/quickhack/translations/tree/master/git-workflows-and-tutorials&quot;&gt;&lt;code&gt;GitHub&lt;/code&gt;上&lt;/a&gt;，翻译中不足和不对之处，欢迎建议（&lt;a href=&quot;https://github.com/quickhack/translations/issues&quot;&gt;提交Issue&lt;/a&gt;）和指正（&lt;a href=&quot;https://github.com/quickhack/translations/fork&quot;&gt;Fork后提交代码&lt;/a&gt;）！&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Sat, 13 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-13-76867-05517d972.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-13-76867-05517d972.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>Git工作流指南：Forking工作流</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;&lt;code&gt;Forking&lt;/code&gt;工作流和前面讨论的几种工作流有根本的不同。这种工作流不是使用单个服务端仓库作为『中央』代码基线，而让各个开发者都有一个服务端仓库。这意味着各个代码贡献者有2个&lt;code&gt;Git&lt;/code&gt;仓库而不是1个：一个本地私有的，另一个服务端公开的。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/916693eb04687b42b8581c20d664206c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Forking&lt;/code&gt;工作流的一个主要优势是，贡献的代码可以被集成，而不需要所有人都能&lt;code&gt;push&lt;/code&gt;代码到仅有的中央仓库中。开发者&lt;code&gt;push&lt;/code&gt;到自己的服务端仓库，而只有项目维护者才能&lt;code&gt;push&lt;/code&gt;到正式仓库。这样项目维护者可以接受任何开发者的提交，但无需给他正式代码库的写权限。&lt;/p&gt;
&lt;p&gt;效果就是一个分布式的工作流，能为大型、自发性的团队（包括了不受信的第三方）提供灵活的方式来安全的协作。也让这个工作流成为开源项目的理想工作流。&lt;/p&gt;
&lt;h2&gt;工作方式&lt;/h2&gt;
&lt;p&gt;和其它的&lt;code&gt;Git&lt;/code&gt;工作流一样，&lt;code&gt;Forking&lt;/code&gt;工作流要先有一个公开的正式仓库存储在服务器上。但一个新的开发者想要在项目上工作时，不是直接从正式仓库克隆，而是&lt;code&gt;fork&lt;/code&gt;正式项目在服务器上创建一个拷贝。&lt;/p&gt;
&lt;p&gt;这个仓库拷贝作为他个人公开仓库 —— 其它开发者不允许&lt;code&gt;push&lt;/code&gt;到这个仓库，但可以&lt;code&gt;pull&lt;/code&gt;到修改（后面我们很快就会看这点很重要）。在创建了自己服务端拷贝之后，和之前的工作流一样，开发者执行&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-basics#!clone&quot;&gt;&lt;code&gt;git clone&lt;/code&gt;命令&lt;/a&gt;克隆仓库到本地机器上，作为私有的开发环境。&lt;/p&gt;
&lt;p&gt;要提交本地修改时，&lt;code&gt;push&lt;/code&gt;提交到自己公开仓库中 —— 而不是正式仓库中。然后，给正式仓库发起一个&lt;code&gt;pull request&lt;/code&gt;，让项目维护者知道有更新已经准备好可以集成了。对于贡献的代码，&lt;code&gt;pull request&lt;/code&gt;也可以很方便地作为一个讨论的地方。&lt;/p&gt;
&lt;p&gt;为了集成功能到正式代码库，维护者&lt;code&gt;pull&lt;/code&gt;贡献者的变更到自己的本地仓库中，检查变更以确保不会让项目出错，&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-branches#!merge&quot;&gt;合并变更到自己本地的&lt;code&gt;master&lt;/code&gt;分支&lt;/a&gt;，然后&lt;a href=&quot;https://www.atlassian.com/git/tutorial/remote-repositories#!push&quot;&gt;&lt;code&gt;push&lt;/code&gt;&lt;/a&gt;&lt;code&gt;master&lt;/code&gt;分支到服务器的正式仓库中。到此，贡献的提交成为了项目的一部分，其它的开发者应该执行&lt;code&gt;pull&lt;/code&gt;操作与正式仓库同步自己本地仓库。&lt;/p&gt;
&lt;h3&gt;正式仓库&lt;/h3&gt;
&lt;p&gt;在&lt;code&gt;Forking&lt;/code&gt;工作流中，『官方』仓库的叫法只是一个约定，理解这点很重要。从技术上来看，各个开发者仓库和正式仓库在&lt;code&gt;Git&lt;/code&gt;看来没有任何区别。事实上，让正式仓库之所以正式的唯一原因是它是项目维护者的公开仓库。&lt;/p&gt;
&lt;h3&gt;
&lt;code&gt;Forking&lt;/code&gt;工作流的分支使用方式&lt;/h3&gt;
&lt;p&gt;所有的个人公开仓库实际上只是为了方便和其它的开发者共享分支。各个开发者应该用分支隔离各个功能，就像在&lt;a href=&quot;http://blog.jobbole.com/76857/&quot;&gt;功能分支工作流&lt;/a&gt;和&lt;a href=&quot;http://blog.jobbole.com/76861/&quot;&gt;&lt;code&gt;Gitflow&lt;/code&gt;工作流&lt;/a&gt;一样。唯一的区别是这些分支被共享了。在&lt;code&gt;Forking&lt;/code&gt;工作流中这些分支会被&lt;code&gt;pull&lt;/code&gt;到另一个开发者的本地仓库中，而在功能分支工作流和&lt;code&gt;Gitflow&lt;/code&gt;工作流中是直接被&lt;code&gt;push&lt;/code&gt;到正式仓库中。&lt;/p&gt;
&lt;h2&gt;示例&lt;/h2&gt;
&lt;h3&gt;项目维护者初始化正式仓库&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b82733ae63c882c6b70b14c905bce278.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;和任何使用&lt;code&gt;Git&lt;/code&gt;项目一样，第一步是创建在服务器上一个正式仓库，让所有团队成员都可以访问到。通常这个仓库也会作为项目维护者的公开仓库。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-basics#!init&quot;&gt;公开仓库应该是裸仓库&lt;/a&gt;，不管是不是正式代码库。所以项目维护者会运行像下面的命令来搭建正式仓库：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ssh user@host&lt;br&gt;
git init --bare /path/to/repo.git&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Bitbucket&lt;/code&gt;和&lt;code&gt;Stash&lt;/code&gt;提供了一个方便的&lt;code&gt;GUI&lt;/code&gt;客户端以完成上面命令行做的事。这个搭建中央仓库的过程和前面提到的工作流完全一样。如果有现存的代码库，维护者也要&lt;code&gt;push&lt;/code&gt;到这个仓库中。&lt;/p&gt;
&lt;h3&gt;开发者&lt;code&gt;fork&lt;/code&gt;正式仓库&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/7c6801ba6a7afecb818271ada4831f11.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;其它所有的开发需要&lt;code&gt;fork&lt;/code&gt;正式仓库。可以用&lt;code&gt;git clone&lt;/code&gt;命令&lt;a href=&quot;https://confluence.atlassian.com/display/BITBUCKET/Set+up+SSH+for+Git&quot;&gt;用&lt;code&gt;SSH&lt;/code&gt;协议连通到服务器&lt;/a&gt;，拷贝仓库到服务器另一个位置 —— 是的，&lt;code&gt;fork&lt;/code&gt;操作基本上就只是一个服务端的克隆。&lt;code&gt;Bitbucket&lt;/code&gt;和&lt;code&gt;Stash&lt;/code&gt;上可以点一下按钮就让开发者完成仓库的&lt;code&gt;fork&lt;/code&gt;操作。&lt;/p&gt;
&lt;p&gt;这一步完成后，每个开发都在服务端有一个自己的仓库。和正式仓库一样，这些仓库应该是裸仓库。&lt;/p&gt;
&lt;h3&gt;开发者克隆自己&lt;code&gt;fork&lt;/code&gt;出来的仓库&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/089f2d34fe90855c9f4041290bd466f0.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;下一步，各个开发者要克隆自己的公开仓库，用熟悉的&lt;code&gt;git clone&lt;/code&gt;命令。&lt;/p&gt;
&lt;p&gt;在这个示例中，假定用&lt;code&gt;Bitbucket&lt;/code&gt;托管了仓库。记住，如果这样的话各个开发者需要有各自的&lt;code&gt;Bitbucket&lt;/code&gt;账号，使用下面命令克隆服务端自己的仓库：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git clone https://user@bitbucket.org/user/repo.git&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;相比前面介绍的工作流只用了一个&lt;code&gt;origin&lt;/code&gt;远程别名指向中央仓库，&lt;code&gt;Forking&lt;/code&gt;工作流需要2个远程别名 —— 一个指向正式仓库，另一个指向开发者自己的服务端仓库。别名的名字可以任意命名，常见的约定是使用&lt;code&gt;origin&lt;/code&gt;作为远程克隆的仓库的别名（这个别名会在运行&lt;code&gt;git clone&lt;/code&gt;自动创建），&lt;code&gt;upstream&lt;/code&gt;（上游）作为正式仓库的别名。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git remote add upstream https://bitbucket.org/maintainer/repo&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;需要自己用上面的命令创建&lt;code&gt;upstream&lt;/code&gt;别名。这样可以简单地保持本地仓库和正式仓库的同步更新。注意，如果上游仓库需要认证（比如不是开源的），你需要提供用户：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git remote add upstream https://user@bitbucket.org/maintainer/repo.git&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这时在克隆和&lt;code&gt;pull&lt;/code&gt;正式仓库时，需要提供用户的密码。&lt;/p&gt;
&lt;h3&gt;开发者开发自己的功能&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/987063d75bdea4e149f32a435873dfc2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;在刚克隆的本地仓库中，开发者可以像其它工作流一样的编辑代码、&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-basics#!commit&quot;&gt;提交修改&lt;/a&gt;和&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-branches#!branch&quot;&gt;新建分支&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git checkout -b some-feature&lt;br&gt;
// Edit some code&lt;br&gt;
git commit -a -m &quot;Add first draft of some feature&quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;所有的修改都是私有的直到&lt;code&gt;push&lt;/code&gt;到自己公开仓库中。如果正式项目已经往前走了，可以用&lt;a href=&quot;https://www.atlassian.com/git/tutorial/remote-repositories#!pull&quot;&gt;&lt;code&gt;git pull&lt;/code&gt;命令&lt;/a&gt;获得新的提交：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git pull upstream master&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;由于开发者应该都在专门的功能分支上工作，&lt;code&gt;pull&lt;/code&gt;操作结果会都是&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-branches#!merge&quot;&gt;快进合并&lt;/a&gt;。&lt;/p&gt;
&lt;h3&gt;开发者发布自己的功能&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b4a640a60cc06a66fe561a4065c68b45.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;一旦开发者准备好了分享新功能，需要做二件事。首先，通过&lt;code&gt;push&lt;/code&gt;他的贡献代码到自己的公开仓库中，让其它的开发者都可以访问到。他的&lt;code&gt;origin&lt;/code&gt;远程别名应该已经有了，所以要做的就是：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git push origin feature-branch&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这里和之前的工作流的差异是，&lt;code&gt;origin&lt;/code&gt;远程别名指向开发者自己的服务端仓库，而不是正式仓库。&lt;/p&gt;
&lt;p&gt;第二件事，开发者要通知项目维护者，想要合并他的新功能到正式库中。&lt;code&gt;Bitbucket&lt;/code&gt;和&lt;code&gt;Stash&lt;/code&gt;提供了&lt;a href=&quot;https://confluence.atlassian.com/display/STASH/Using+pull+requests+in+Stash&quot;&gt;&lt;code&gt;Pull Request&lt;/code&gt;&lt;/a&gt;按钮，弹出表单让你指定哪个分支要合并到正式仓库。一般你会想集成你的功能分支到上游远程仓库的&lt;code&gt;master&lt;/code&gt;分支中。&lt;/p&gt;
&lt;h3&gt;项目维护者集成开发者的功能&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ca354b957ccbbf2c7be5109f8e3823b4.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;当项目维护者收到&lt;code&gt;pull request&lt;/code&gt;，他要做的是决定是否集成它到正式代码库中。有二种方式来做：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;直接在&lt;code&gt;pull request&lt;/code&gt;中查看代码&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;pull&lt;/code&gt;代码到他自己的本地仓库，再手动合并&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第一种做法更简单，维护者可以在&lt;code&gt;GUI&lt;/code&gt;中查看变更的差异，做评注和执行合并。但如果出现了合并冲突，需要第二种做法来解决。这种情况下，维护者需要从开发者的服务端仓库中&lt;a href=&quot;https://www.atlassian.com/git/tutorial/remote-repositories#!fetch&quot;&gt;&lt;code&gt;fetch&lt;/code&gt;&lt;/a&gt;功能分支，合并到他本地的&lt;code&gt;master&lt;/code&gt;分支，解决冲突：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git fetch https://bitbucket.org/user/repo feature-branch&lt;br&gt;
// 查看变更&lt;br&gt;
git checkout master&lt;br&gt;
git merge FETCH_HEAD&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;变更集成到本地的&lt;code&gt;master&lt;/code&gt;分支后，维护者要&lt;code&gt;push&lt;/code&gt;变更到服务器上的正式仓库，这样其它的开发者都能访问到：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git push origin master&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;注意，维护者的&lt;code&gt;origin&lt;/code&gt;是指向他自己公开仓库的，即是项目的正式代码库。到此，开发者的贡献完全集成到了项目中。&lt;/p&gt;
&lt;h3&gt;开发者和正式仓库做同步&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3d978acc5444789b040c49092aade99f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;由于正式代码库往前走了，其它的开发需要和正式仓库做同步：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git pull upstream master&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;下一站&lt;/h2&gt;
&lt;p&gt;如果你之前是使用&lt;code&gt;SVN&lt;/code&gt;，&lt;code&gt;Forking&lt;/code&gt;工作流可能看起来像是一个激进的范式切换（paradigm shift）。但不要害怕，这个工作流实际上就是在&lt;a href=&quot;http://blog.jobbole.com/76857/&quot;&gt;功能分支工作流&lt;/a&gt;之上引入另一个抽象层。不是直接通过单个中央仓库来分享分支，而是把贡献代码发布到开发者自己的服务端仓库中。&lt;/p&gt;
&lt;p&gt;示例中解释了，一个贡献如何从一个开发者流到正式的&lt;code&gt;master&lt;/code&gt;分支中，但同样的方法可以把贡献集成到任一个仓库中。比如，如果团队的几个人协作实现一个功能，可以在开发之间用相同的方法分享变更，完全不涉及正式仓库。&lt;/p&gt;
&lt;p&gt;这使得&lt;code&gt;Forking&lt;/code&gt;工作流对于松散组织的团队来说是个非常强大的工具。任一开发者可以方便地和另一开发者分享变更，任何分支都能有效地合并到正式代码库中。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/76867/&quot;&gt;« &lt;code&gt;Gitflow&lt;/code&gt;工作流&lt;/a&gt;　　　　&lt;a href=&quot;http://blog.jobbole.com/76854/&quot;&gt;&lt;code&gt;Pull Requests&lt;/code&gt; »&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;译注&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;
&lt;a href=&quot;http://weibo.com/oldratlee&quot;&gt;自己&lt;/a&gt;理解粗浅，译文源码在&lt;a href=&quot;https://github.com/quickhack/translations/tree/master/git-workflows-and-tutorials&quot;&gt;&lt;code&gt;GitHub&lt;/code&gt;上&lt;/a&gt;，翻译中不足和不对之处，欢迎建议（&lt;a href=&quot;https://github.com/quickhack/translations/issues&quot;&gt;提交Issue&lt;/a&gt;）和指正（&lt;a href=&quot;https://github.com/quickhack/translations/fork&quot;&gt;Fork后提交代码&lt;/a&gt;）！&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Sat, 13 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-13-76861-7ea1d0906.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-13-76861-7ea1d0906.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>Git工作流指南：功能分支工作流</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d5bda9a0d553f06781a4a82728c6351c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;一旦你玩转了&lt;a href=&quot;http://blog.jobbole.com/76847/&quot; target=&quot;_blank&quot;&gt;集中式工作流&lt;/a&gt;，在开发过程中可以很简单地加上功能分支，用来鼓励开发者之间协作和简化交流。&lt;/p&gt;
&lt;p&gt;功能分支工作流背后的核心思路是所有的功能开发应该在一个专门的分支，而不是在&lt;code&gt;master&lt;/code&gt;分支上。这个隔离可以方便多个开发者在各自的功能上开发而不会弄乱主干代码。另外，也保证了&lt;code&gt;master&lt;/code&gt;分支的代码一定不会是有问题的，极大有利于集成环境。&lt;/p&gt;
&lt;p&gt;功能开发隔离也让&lt;a href=&quot;http://blog.jobbole.com/76854/&quot;&gt;&lt;code&gt;pull requests&lt;/code&gt;工作流&lt;/a&gt;成功可能，&lt;code&gt;pull requests&lt;/code&gt;工作流能为每个分支发起一个讨论，在分支合入正式项目之前，给其它开发者有表示赞同的机会。另外，如果你在功能开发中有问题卡住了，可以开一个&lt;code&gt;pull requests&lt;/code&gt;来向同学们征求建议。这些做法的重点就是，&lt;code&gt;pull requests&lt;/code&gt;让团队成员之间互相评论工作变成非常方便！&lt;/p&gt;
&lt;h2&gt;工作方式&lt;/h2&gt;
&lt;p&gt;功能分支工作流仍然用中央仓库，并且&lt;code&gt;master&lt;/code&gt;分支还是代表了正式项目的历史。但不是直接提交本地历史到各自的本地&lt;code&gt;master&lt;/code&gt;分支，开发者每次在开始新功能前先创建一个新分支。功能分支应该有个有描述性的名字，比如&lt;code&gt;animated-menu-items&lt;/code&gt;或&lt;code&gt;issue-#1061&lt;/code&gt;，这样可以让分支有个清楚且高聚焦的用途。&lt;/p&gt;
&lt;p&gt;在&lt;code&gt;master&lt;/code&gt;分支和功能分支之间，&lt;code&gt;Git&lt;/code&gt;是没有技术上的区别，所以开发者可以用和集中式工作流中完全一样的方式编辑、暂存和提交修改到功能分支上。&lt;/p&gt;
&lt;p&gt;另外，功能分支也可以（且应该）&lt;code&gt;push&lt;/code&gt;到中央仓库中。这样不修改正式代码就可以和其它开发者分享提交的功能。由于&lt;code&gt;master&lt;/code&gt;仅有的一个『特殊』分支，在中央仓库上存多个功能分支不会有任何问题。当然，这样做也可以很方便地备份各自的本地提交。&lt;/p&gt;
&lt;h3&gt;&lt;code&gt;Pull Requests&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;功能分支除了可以隔离功能的开发，也使得通过&lt;a href=&quot;http://blog.jobbole.com/76854/&quot;&gt;&lt;code&gt;Pull Requests&lt;/code&gt;&lt;/a&gt;讨论变更成为可能。一旦某个开发完成一个功能，不是立即合并到&lt;code&gt;master&lt;/code&gt;，而是&lt;code&gt;push&lt;/code&gt;到中央仓库的功能分支上并发起一个&lt;code&gt;Pull Request&lt;/code&gt;请求去合并修改到&lt;code&gt;master&lt;/code&gt;。在修改成为主干代码前，这让其它的开发者有机会先去&lt;code&gt;Review&lt;/code&gt;变更。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Code Review&lt;/code&gt;是&lt;code&gt;Pull Requests&lt;/code&gt;的一个重要的收益，但&lt;code&gt;Pull Requests&lt;/code&gt;目的是讨论代码一个通用方式。你可以把&lt;code&gt;Pull Requests&lt;/code&gt;作为专门给某个分支的讨论。这意味着可以在更早的开发过程中就可以进行&lt;code&gt;Code Review&lt;/code&gt;。比如，一个开发者开发功能需要帮助时，要做的就是发起一个&lt;code&gt;Pull Request&lt;/code&gt;，相关的人就会自动收到通知，在相关的提交旁边能看到需要帮助解决的问题。&lt;/p&gt;
&lt;p&gt;一旦&lt;code&gt;Pull Request&lt;/code&gt;被接受了，发布功能要做的就和集中式工作流就很像了。首先，确定本地的&lt;code&gt;master&lt;/code&gt;分支和上游的&lt;code&gt;master&lt;/code&gt;分支是同步的。然后合并功能分支到本地&lt;code&gt;master&lt;/code&gt;分支并&lt;code&gt;push&lt;/code&gt;已经更新的本地&lt;code&gt;master&lt;/code&gt;分支到中央仓库。&lt;/p&gt;
&lt;p&gt;仓库管理的产品解决方案像&lt;a href=&quot;http://bitbucket.org/&quot;&gt;&lt;code&gt;Bitbucket&lt;/code&gt;&lt;/a&gt;或&lt;a href=&quot;http://www.atlassian.com/stash&quot;&gt;&lt;code&gt;Stash&lt;/code&gt;&lt;/a&gt;，可以良好地支持&lt;code&gt;Pull Requests&lt;/code&gt;。可以看看&lt;code&gt;Stash&lt;/code&gt;的&lt;a href=&quot;https://confluence.atlassian.com/display/STASH/Using+pull+requests+in+Stash&quot;&gt;&lt;code&gt;Pull Requests&lt;/code&gt;文档&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;示例&lt;/h2&gt;
&lt;p&gt;下面的示例演示了如何把&lt;code&gt;Pull Requests&lt;/code&gt;作为&lt;code&gt;Code Review&lt;/code&gt;的方式，但注意&lt;code&gt;Pull Requests&lt;/code&gt;可以用于很多其它的目的。&lt;/p&gt;
&lt;h3&gt;小红开始开发一个新功能&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6a0124fd0bb9ead1ec33e1a8e41e90b2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;在开始开发功能前，小红需要一个独立的分支。使用下面的命令&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-branches#!checkout&quot;&gt;新建一个分支&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git checkout -b marys-feature master&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个命令检出一个基于&lt;code&gt;master&lt;/code&gt;名为&lt;code&gt;marys-feature&lt;/code&gt;的分支，&lt;code&gt;Git&lt;/code&gt;的&lt;code&gt;-b&lt;/code&gt;选项表示如果分支还不存在则新建分支。这个新分支上，小红按老套路编辑、暂存和提交修改，按需要提交以实现功能：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git status&lt;br&gt;
git add&lt;br&gt;
git commit&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;小红要去吃个午饭&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/79fdde599a10a04ceb52f3eb3025a34f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;早上小红为新功能添加一些提交。去吃午饭前，&lt;code&gt;push&lt;/code&gt;功能分支到中央仓库是很好的做法，这样可以方便地备份，如果和其它开发协作，也让他们可以看到小红的提交。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git push -u origin marys-feature&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这条命令&lt;code&gt;push&lt;/code&gt; &lt;code&gt;marys-feature&lt;/code&gt;分支到中央仓库（&lt;code&gt;origin&lt;/code&gt;），&lt;code&gt;-u&lt;/code&gt;选项设置本地分支去跟踪远程对应的分支。设置好跟踪的分支后，小红就可以使用&lt;code&gt;git push&lt;/code&gt;命令省去指定推送分支的参数。&lt;/p&gt;
&lt;h3&gt;小红完成功能开发&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/2fd409cc78827d3c7e3be74f7cf6808f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;小红吃完午饭回来，完成整个功能的开发。&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-branches#!merge&quot;&gt;在合并到&lt;code&gt;master&lt;/code&gt;之前&lt;/a&gt;，她发起一个&lt;code&gt;Pull Request&lt;/code&gt;让团队的其它人知道功能已经完成。但首先，她要确认中央仓库中已经有她最近的提交：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git push&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;然后，在她的&lt;code&gt;Git&lt;/code&gt; &lt;code&gt;GUI&lt;/code&gt;客户端中发起&lt;code&gt;Pull Request&lt;/code&gt;，请求合并&lt;code&gt;marys-feature&lt;/code&gt;到&lt;code&gt;master&lt;/code&gt;，团队成员会自动收到通知。&lt;code&gt;Pull Request&lt;/code&gt;很酷的是可以在相关的提交旁边显示评注，所以你可以很对某个变更集提问。&lt;/p&gt;
&lt;h3&gt;小黑收到&lt;code&gt;Pull Request&lt;/code&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1361eddb171308c4ea79f0eff3e7c4aa.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;小黑收到了&lt;code&gt;Pull Request&lt;/code&gt;后会查看&lt;code&gt;marys-feature&lt;/code&gt;的修改。决定在合并到正式项目前是否要做些修改，且通过&lt;code&gt;Pull Request&lt;/code&gt;和小红来回地讨论。&lt;/p&gt;
&lt;h3&gt;小红再做修改&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a1554c004d66beaf396c45b7a49fd295.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;要再做修改，小红用和功能第一个迭代完全一样的过程。编辑、暂存、提交并&lt;code&gt;push&lt;/code&gt;更新到中央仓库。小红这些活动都会显示在&lt;code&gt;Pull Request&lt;/code&gt;上，小黑可以断续做评注。&lt;/p&gt;
&lt;p&gt;如果小黑有需要，也可以把&lt;code&gt;marys-feature&lt;/code&gt;分支拉到本地，自己来修改，他加的提交也会一样显示在&lt;code&gt;Pull Request&lt;/code&gt;上。&lt;/p&gt;
&lt;h3&gt;小红发布她的功能&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8556146c63b1228b896d49314a5f5785.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;一旦小黑可以的接受&lt;code&gt;Pull Request&lt;/code&gt;，就可以合并功能到稳定项目代码中（可以由小黑或是小红来做这个操作）：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git checkout master&lt;br&gt;
git pull&lt;br&gt;
git pull origin marys-feature&lt;br&gt;
git push&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;无论谁来做合并，首先要检出&lt;code&gt;master&lt;/code&gt;分支并确认是它是最新的。然后执行&lt;code&gt;git pull origin marys-feature&lt;/code&gt;合并&lt;code&gt;marys-feature&lt;/code&gt;分支到和已经和远程一致的本地&lt;code&gt;master&lt;/code&gt;分支。你可以使用简单&lt;code&gt;git merge marys-feature&lt;/code&gt;命令，但前面的命令可以保证总是最新的新功能分支。最后更新的&lt;code&gt;master&lt;/code&gt;分支要重新&lt;code&gt;push&lt;/code&gt;回到&lt;code&gt;origin&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这个过程常常会生成一个合并提交。有些开发者喜欢有合并提交，因为它像一个新功能和原来代码基线的连通符。但如果你偏爱线性的提交历史，可以在执行合并时&lt;code&gt;rebase&lt;/code&gt;新功能到&lt;code&gt;master&lt;/code&gt;分支的顶部，这样生成一个快进（&lt;code&gt;fast-forward&lt;/code&gt;）的合并。&lt;/p&gt;
&lt;p&gt;一些&lt;code&gt;GUI&lt;/code&gt;客户端可以只要点一下『接受』按钮执行好上面的命令来自动化&lt;code&gt;Pull Request&lt;/code&gt;接受过程。如果你的不能这样，至少在功能合并到&lt;code&gt;master&lt;/code&gt;分支后能自动关闭&lt;code&gt;Pull Request&lt;/code&gt;。&lt;/p&gt;
&lt;h3&gt;与此同时，小明在做和小红一样的事&lt;/h3&gt;
&lt;p&gt;当小红和小黑在&lt;code&gt;marys-feature&lt;/code&gt;上工作并讨论她的&lt;code&gt;Pull Request&lt;/code&gt;的时候，小明在自己的功能分支上做完全一样的事。&lt;/p&gt;
&lt;p&gt;通过隔离功能到独立的分支上，每个人都可以自主的工作，当然必要的时候在开发者之间分享变更还是比较繁琐的。&lt;/p&gt;
&lt;h2&gt;下一站&lt;/h2&gt;
&lt;p&gt;到了这里，但愿你发现了功能分支可以很直接地在&lt;a href=&quot;http://blog.jobbole.com/76847/&quot;&gt;集中式工作流&lt;/a&gt;的仅有的&lt;code&gt;master&lt;/code&gt;分支上完成多功能的开发。另外，功能分支还使用了&lt;code&gt;Pull Request&lt;/code&gt;，使得可以在你的版本控制&lt;code&gt;GUI&lt;/code&gt;客户端中讨论某个提交。&lt;/p&gt;
&lt;p&gt;功能分支工作流是开发项目异常灵活的方式。问题是，有时候太灵活了。对于大型团队，常常需要给不同分支分配一个更具体的角色。&lt;code&gt;Gitflow&lt;/code&gt;工作流是管理功能开发、发布准备和维护的常用模式。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/76847/&quot;&gt;« 集中式工作流&lt;/a&gt;　　　　&lt;a href=&quot;http://blog.jobbole.com/76867/&quot;&gt;&lt;code&gt;Gitflow&lt;/code&gt;工作流 »&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;译注&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;
&lt;a href=&quot;http://weibo.com/oldratlee&quot;&gt;自己&lt;/a&gt;理解粗浅，译文源码在&lt;a href=&quot;https://github.com/quickhack/translations/tree/master/git-workflows-and-tutorials&quot;&gt;&lt;code&gt;GitHub&lt;/code&gt;上&lt;/a&gt;，翻译中不足和不对之处，欢迎建议（&lt;a href=&quot;https://github.com/quickhack/translations/issues&quot;&gt;提交Issue&lt;/a&gt;）和指正（&lt;a href=&quot;https://github.com/quickhack/translations/fork&quot;&gt;Fork后提交代码&lt;/a&gt;）！&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Sat, 13 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-13-76857-70092e8dc.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-13-76857-70092e8dc.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>Git工作流指南：Pull Request工作流</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;&lt;code&gt;Pull Requests&lt;/code&gt;是&lt;code&gt;Bitbucket&lt;/code&gt;上方便开发者之间协作的功能。提供了一个用户友好的&lt;code&gt;Web&lt;/code&gt;界面，在集成提交的变更到正式项目前可以对变更进行讨论。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/822e73cdf5fe94dec603412fefcbaab0.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;开发者向团队成员通知功能开发已经完成，&lt;code&gt;Pull Requests&lt;/code&gt;是最简单的用法。开发者完成功能开发后，通过&lt;code&gt;Bitbucket&lt;/code&gt;账号发起一个&lt;code&gt;Pull Request&lt;/code&gt;。这样让涉及这个功能的所有人知道，要去做&lt;code&gt;Code Review&lt;/code&gt;和合并到&lt;code&gt;master&lt;/code&gt;分支。&lt;/p&gt;
&lt;p&gt;但是，&lt;code&gt;Pull Request&lt;/code&gt;远不止一个简单的通知，而是为讨论提交的功能的一个专门论坛。如果变更有任何问题，团队成员反馈在&lt;code&gt;Pull Request&lt;/code&gt;中，甚至&lt;code&gt;push&lt;/code&gt;新的提交微调功能。所有的这些活动都直接跟踪在&lt;code&gt;Pull Request&lt;/code&gt;中。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6ac669e0c773553a2e4486a4811a36e3.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;相比其它的协作模型，这种分享提交的形式有助于打造一个更流畅的工作流。&lt;code&gt;SVN&lt;/code&gt;和&lt;code&gt;Git&lt;/code&gt;都能通过一个简单的脚本收到通知邮件；但是，讨论变更时，开发者通常只能去回复邮件。这样做会变得杂乱，尤其还要涉及后面的几个提交时。&lt;code&gt;Pull Requests&lt;/code&gt;把所有相关功能整合到一个和&lt;code&gt;Bitbucket&lt;/code&gt;仓库界面集成的用户友好&lt;code&gt;Web&lt;/code&gt;界面中。&lt;/p&gt;
&lt;h3&gt;解析&lt;code&gt;Pull Request&lt;/code&gt;
&lt;/h3&gt;
&lt;p&gt;当要发起一个&lt;code&gt;Pull Request&lt;/code&gt;，你所要做的就是请求（&lt;code&gt;Request&lt;/code&gt;）另一个开发者（比如项目的维护者），来&lt;code&gt;pull&lt;/code&gt;你仓库中一个分支到他的仓库中。这意味着你要提供4个信息（源仓库、源分支、目的仓库、目的分支），以发起&lt;code&gt;Pull Request&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/06f1386bbe797449b4e92a8399a65ad9.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这些值多数&lt;code&gt;Bitbucket&lt;/code&gt;都会设置上合适的缺省值。但取决你用的协作工作流，你的团队可能会要指定不同的值。上图显示了一个&lt;code&gt;Pull Request&lt;/code&gt;请求合并一个功能分支到正式的&lt;code&gt;master&lt;/code&gt;分支上，但可以有多种不同的&lt;code&gt;Pull Request&lt;/code&gt;用法。&lt;/p&gt;
&lt;h2&gt;工作方式&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Pull Request&lt;/code&gt;可以和&lt;a href=&quot;http://blog.jobbole.com/76857/&quot;&gt;功能分支工作流&lt;/a&gt;、&lt;a href=&quot;http://blog.jobbole.com/76867/&quot;&gt;&lt;code&gt;Gitflow&lt;/code&gt;工作流&lt;/a&gt;或&lt;a href=&quot;http://blog.jobbole.com/76861/&quot;&gt;&lt;code&gt;Forking&lt;/code&gt;工作流&lt;/a&gt;一起使用。但&lt;code&gt;Pull Request&lt;/code&gt;要求要么分支不同，要么仓库不同，所以不能用于&lt;a href=&quot;http://blog.jobbole.com/76847/&quot;&gt;集中式工作流&lt;/a&gt;。在不同的工作流中使用&lt;code&gt;Pull Request&lt;/code&gt;会有一些不同，但基本的过程是这样的：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;开发者在本地仓库中新建一个专门的分支开发功能。&lt;/li&gt;
&lt;li&gt;开发者&lt;code&gt;push&lt;/code&gt;分支修改到公开的&lt;code&gt;Bitbucket&lt;/code&gt;仓库中。&lt;/li&gt;
&lt;li&gt;开发者通过&lt;code&gt;Bitbucket&lt;/code&gt;发起一个&lt;code&gt;Pull Request&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;团队的其它成员&lt;code&gt;review&lt;/code&gt; &lt;code&gt;code&lt;/code&gt;，讨论并修改。&lt;/li&gt;
&lt;li&gt;项目维护者合并功能到官方仓库中并关闭&lt;code&gt;Pull Request&lt;/code&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文后面内容说明，&lt;code&gt;Pull Request&lt;/code&gt;在不同协作工作流中如何应用。&lt;/p&gt;
&lt;h3&gt;在功能分支工作流中使用&lt;code&gt;Pull Request&lt;/code&gt;
&lt;/h3&gt;
&lt;p&gt;功能分支工作流用一个共享的&lt;code&gt;Bitbucket&lt;/code&gt;仓库来管理协作，开发者在专门的分支上开发功能。但不是立即合并到&lt;code&gt;master&lt;/code&gt;分支上，而是在合并到主代码库之前开发者应该开一个&lt;code&gt;Pull Request&lt;/code&gt;发起功能的讨论。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/25b8a8f9f99c288f204238b3ec94458b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;功能分支工作流只有一个公开的仓库，所以&lt;code&gt;Pull Request&lt;/code&gt;的目的仓库和源仓库总是同一个。通常开发者会指定他的功能分支作为源分支，&lt;code&gt;master&lt;/code&gt;分支作为目的分支。&lt;/p&gt;
&lt;p&gt;收到&lt;code&gt;Pull Request&lt;/code&gt;后，项目维护者要决定如何做。如果功能没问题，就简单地合并到&lt;code&gt;master&lt;/code&gt;分支，关闭&lt;code&gt;Pull Request&lt;/code&gt;。但如果提交的变更有问题，他可以在&lt;code&gt;Pull Request&lt;/code&gt;中反馈。之后新加的提交也会评论之后接着显示出来。&lt;/p&gt;
&lt;p&gt;在功能还没有完全开发完的时候，也可能发起一个&lt;code&gt;Pull Request&lt;/code&gt;。比如开发者在实现某个需求时碰到了麻烦，他可以发一个包含正在进行中工作的&lt;code&gt;Pull Request&lt;/code&gt;。其它的开发者可以在&lt;code&gt;Pull Request&lt;/code&gt;提供建议，或者甚至直接添加提交来解决问题。&lt;/p&gt;
&lt;h3&gt;在&lt;code&gt;Gitflow&lt;/code&gt;工作流中使用&lt;code&gt;Pull Request&lt;/code&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Gitflow&lt;/code&gt;工作流和功能分支工作流类似，但围绕项目发布定义一个严格的分支模型。在&lt;code&gt;Gitflow&lt;/code&gt;工作流中使用&lt;code&gt;Pull Request&lt;/code&gt;让开发者在发布分支或是维护分支上工作时，可以有个方便的地方对关于发布分支或是维护分支的问题进行交流。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3d4db46949437e7ee973b10940c60d78.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Gitflow&lt;/code&gt;工作流中&lt;code&gt;Pull Request&lt;/code&gt;的使用过程和上一节中完全一致：当一个功能、发布或是热修复分支需要&lt;code&gt;Review&lt;/code&gt;时，开发者简单发起一个&lt;code&gt;Pull Request&lt;/code&gt;，团队的其它成员会通过&lt;code&gt;Bitbucket&lt;/code&gt;收到通知。&lt;/p&gt;
&lt;p&gt;新功能一般合并到&lt;code&gt;develop&lt;/code&gt;分支，而发布和热修复则要同时合并到&lt;code&gt;develop&lt;/code&gt;分支和&lt;code&gt;master&lt;/code&gt;分支上。&lt;code&gt;Pull Request&lt;/code&gt;可能用做所有合并的正式管理。&lt;/p&gt;
&lt;h3&gt;在&lt;code&gt;Forking&lt;/code&gt;工作流中使用&lt;code&gt;Pull Request&lt;/code&gt;
&lt;/h3&gt;
&lt;p&gt;在&lt;code&gt;Forking&lt;/code&gt;工作流中，开发者&lt;code&gt;push&lt;/code&gt;完成的功能到他自己的仓库中，而不是共享仓库。然后，他发起一个&lt;code&gt;Pull Request&lt;/code&gt;，让项目维护者知道他的功能已经可以&lt;code&gt;Review&lt;/code&gt;了。&lt;/p&gt;
&lt;p&gt;在这个工作流，&lt;code&gt;Pull Request&lt;/code&gt;的通知功能非常有用，因为项目维护者不可能知道其它开发者在他们自己的仓库添加了提交。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3b5756a74b7ccf1356c1e72d16124be1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;由于各个开发有自己的公开仓库，&lt;code&gt;Pull Request&lt;/code&gt;的源仓库和目标仓库不是同一个。源仓库是开发者的公开仓库，源分支是包含了修改的分支。如果开发者要合并修改到正式代码库中，那么目标仓库是正式仓库，目标分支是&lt;code&gt;master&lt;/code&gt;分支。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Pull Request&lt;/code&gt;也可以用于正式项目之外的其它开发者之间的协作。比如，如果一个开发者和一个团队成员一起开发一个功能，他们可以发起一个&lt;code&gt;Pull Request&lt;/code&gt;，用团队成员的&lt;code&gt;Bitbucket&lt;/code&gt;仓库作为目标，而不是正式项目的仓库。然后使用相同的功能分支作为源和目标分支。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/bf9f6dc2a86fa5650fae825e647880a8.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;2个开发者之间可以在&lt;code&gt;Pull Request&lt;/code&gt;中讨论和开发功能。完成开发后，他们可以发起另一个&lt;code&gt;Pull Request&lt;/code&gt;，请求合并功能到正式的&lt;code&gt;master&lt;/code&gt;分支。在&lt;code&gt;Forking&lt;/code&gt;工作流中，这样的灵活性让&lt;code&gt;Pull Request&lt;/code&gt;成为一个强有力的协作工具。&lt;/p&gt;
&lt;h2&gt;示例&lt;/h2&gt;
&lt;p&gt;下面的示例演示了&lt;code&gt;Pull Request&lt;/code&gt;如何在在&lt;code&gt;Forking&lt;/code&gt;工作流中使用。也同样适用于小团队的开发协作和第三方开发者向开源项目的贡献。&lt;/p&gt;
&lt;p&gt;在示例中，小红是个开发，小明是项目维护者。他们各自有一个公开的&lt;code&gt;Bitbucket&lt;/code&gt;仓库，而小明的仓库包含了正式工程。&lt;/p&gt;
&lt;h3&gt;小红&lt;code&gt;fork&lt;/code&gt;正式项目&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a1ea21b78cc96b4465d0fab7ac7646dd.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;小红先要&lt;code&gt;fork&lt;/code&gt;小明的&lt;code&gt;Bitbucket&lt;/code&gt;仓库，开始项目的开发。她登陆&lt;code&gt;Bitbucket&lt;/code&gt;，浏览到小明的仓库页面，&lt;br&gt;
点&lt;code&gt;Fork&lt;/code&gt;按钮。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/05dc6ac30cc935664e7addd9b4b0788e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后为&lt;code&gt;fork&lt;/code&gt;出来的仓库填写名字和描述，这样小红就有了服务端的项目拷贝了。&lt;/p&gt;
&lt;h3&gt;小红克隆她的&lt;code&gt;Bitbucket&lt;/code&gt;仓库&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c54ea7abdc1dc6358b7a128e72280b99.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;下一步，小红克隆自己刚才&lt;code&gt;fork&lt;/code&gt;出来的&lt;code&gt;Bitbucket&lt;/code&gt;仓库，以在本机上准备出工作拷贝。命令如下：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git clone https://user@bitbucket.org/user/repo.git&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;请记住，&lt;code&gt;git clone&lt;/code&gt;会自动创建&lt;code&gt;origin&lt;/code&gt;远程别名，是指向小红&lt;code&gt;fork&lt;/code&gt;出来的仓库。&lt;/p&gt;
&lt;h3&gt;小红开发新功能&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/12b695c7a96a473935de97869bcb00f5.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;在开始改代码前，小红要为新功能先新建一个新分支。她会用这个分支作为&lt;code&gt;Pull Request&lt;/code&gt;的源分支。&lt;/p&gt;
&lt;p&gt;“`&lt;br&gt;
git checkout -b some-feature&lt;/p&gt;
&lt;h1&gt;编辑代码&lt;/h1&gt;
&lt;p&gt;git commit -a -m “Add first draft of some feature”&lt;br&gt;
“`&lt;/p&gt;
&lt;p&gt;在新功能分支上，小红按需要添加提交。甚至如果小红觉得功能分支上的提交历史太乱了，她可以用&lt;a href=&quot;https://www.atlassian.com/git/tutorial/rewriting-git-history#!rebase-i&quot;&gt;交互式&lt;code&gt;rebase&lt;/code&gt;&lt;/a&gt;来删除或压制提交。对于大型项目，整理功能分支的历史可以让项目维护者更容易看出在&lt;code&gt;Pull Request&lt;/code&gt;中做了什么内容。&lt;/p&gt;
&lt;h3&gt;小红&lt;code&gt;push&lt;/code&gt;功能到她的&lt;code&gt;Bitbucket&lt;/code&gt;仓库中&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9bac817bc7fc7e67101d2add206ed6f9.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;小红完成了功能后，&lt;code&gt;push&lt;/code&gt;功能到她自己的&lt;code&gt;Bitbucket&lt;/code&gt;仓库中（不是正式仓库），用下面简单的命令：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git push origin some-branch&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这时她的变更可以让项目维护者看到了（或者任何想要看的协作者）。&lt;/p&gt;
&lt;h3&gt;小红发起&lt;code&gt;Pull Request&lt;/code&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/cffce813e014b022ffedf5494c9b8917.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Bitbucket&lt;/code&gt;上有了她的功能分支后，小红可以用她的&lt;code&gt;Bitbucket&lt;/code&gt;账号浏览到她的&lt;code&gt;fork&lt;/code&gt;出来的仓库页面，点右上角的【&lt;code&gt;Pull Request&lt;/code&gt;】按钮，发起一个&lt;code&gt;Pull Request&lt;/code&gt;。弹出的表单自动设置小红的仓库为源仓库，询问小红以指定源分支、目标仓库和目标分支。&lt;/p&gt;
&lt;p&gt;小红想要合并功能到正式仓库，所以源分支是她的功能分支，目标仓库是小明的公开仓库，而目标分支是&lt;code&gt;master&lt;/code&gt;分支。另外，小红需要提供&lt;code&gt;Pull Request&lt;/code&gt;的标题和描述信息。如果需要小明以外的人审核批准代码，她可以把这些人填在【Reviewers】文本框中。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b6a90e1e0dc833189d348c7a86a5fcb5.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;创建好了&lt;code&gt;Pull Request&lt;/code&gt;，通知会通过&lt;code&gt;Bitbucket&lt;/code&gt;系统消息或邮件（可选）发给小明。&lt;/p&gt;
&lt;h3&gt;小明review &lt;code&gt;Pull Request&lt;/code&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/30b5e47ff1db8daa65351aed0c92016b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;在小明的&lt;code&gt;Bitbucket&lt;/code&gt;仓库页面的【&lt;code&gt;Pull Request&lt;/code&gt;】Tab可以看到所有人发起的&lt;code&gt;Pull Request&lt;/code&gt;。点击小红的&lt;code&gt;Pull Request&lt;/code&gt;会显示出&lt;code&gt;Pull Request&lt;/code&gt;的描述、功能的提交历史和每个变更的差异（&lt;code&gt;diff&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;如果小明想要合并到项目中，只要点一下【&lt;code&gt;Merge&lt;/code&gt;】按钮，就可以同意&lt;code&gt;Pull Request&lt;/code&gt;并合并到&lt;code&gt;master&lt;/code&gt;分支。&lt;/p&gt;
&lt;p&gt;但如果像这个示例中一样小明发现了在小红的代码中的一个小&lt;code&gt;Bug&lt;/code&gt;，要小红在合并前修复。小明可以在整个&lt;code&gt;Pull Request&lt;/code&gt;上加上评注，或是选择历史中的某个提交加上评注。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/7a4b519888065b3271561f5940a759e1.jpg&quot;&gt;&lt;/p&gt;
&lt;h3&gt;小红补加提交&lt;/h3&gt;
&lt;p&gt;如果小红对反馈有任何疑问，可以在&lt;code&gt;Pull Request&lt;/code&gt;中响应，把&lt;code&gt;Pull Request&lt;/code&gt;当作是她功能讨论的论坛。&lt;/p&gt;
&lt;p&gt;小红在她的功能分支新加提交以解决代码问题，并&lt;code&gt;push&lt;/code&gt;到她的&lt;code&gt;Bitbucket&lt;/code&gt;仓库中，就像前一轮中的做法一样。这些提交会进入的&lt;code&gt;Pull Request&lt;/code&gt;，小明在原来的评注旁边可以再次&lt;code&gt;review&lt;/code&gt;变更。&lt;/p&gt;
&lt;h3&gt;小明接受&lt;code&gt;Pull Request&lt;/code&gt;
&lt;/h3&gt;
&lt;p&gt;最终，小明接受变更，合并功能分支到&lt;code&gt;master&lt;/code&gt;分支，并关闭&lt;code&gt;Pull Request&lt;/code&gt;。至此，功能集成到项目中，其它的项目开发者可以用标准的&lt;code&gt;git pull&lt;/code&gt;命令&lt;code&gt;pull&lt;/code&gt;这些变更到自己的本地仓库中。&lt;/p&gt;
&lt;h2&gt;下一站&lt;/h2&gt;
&lt;p&gt;到了这里，你应该有了所有需要的工具来集成&lt;code&gt;Pull Request&lt;/code&gt;到你自己的工作流。请记住，&lt;code&gt;Pull Request&lt;/code&gt;并不是为了替代任何&lt;a href=&quot;http://blog.jobbole.com/76843/&quot;&gt;基于&lt;code&gt;Git&lt;/code&gt;的协作工作流&lt;/a&gt;，而是它们的一个便利的补充，让团队成员间的协作更轻松方便。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/76861/&quot;&gt;« &lt;code&gt;Forking&lt;/code&gt;工作流&lt;/a&gt;　　　　&lt;a href=&quot;http://blog.jobbole.com/76843/&quot;&gt;概述 »&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;译注&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;
&lt;a href=&quot;http://weibo.com/oldratlee&quot;&gt;自己&lt;/a&gt;理解粗浅，译文源码在&lt;a href=&quot;https://github.com/quickhack/translations/tree/master/git-workflows-and-tutorials&quot;&gt;&lt;code&gt;GitHub&lt;/code&gt;上&lt;/a&gt;，翻译中不足和不对之处，欢迎建议（&lt;a href=&quot;https://github.com/quickhack/translations/issues&quot;&gt;提交Issue&lt;/a&gt;）和指正（&lt;a href=&quot;https://github.com/quickhack/translations/fork&quot;&gt;Fork后提交代码&lt;/a&gt;）！&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Sat, 13 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-13-76854-e3a8274ee.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-13-76854-e3a8274ee.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>Git工作流指南：集中式工作流</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;&lt;img alt=&quot;Git Workflows: SVN-style&quot; src=&quot;/images/jobbole.com/13e406eae8561ee406f34639b631d0fd.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;转到分布式版本控制系统看起来像个令人生畏的任务，但不改变已用的工作流你也可以用上&lt;code&gt;Git&lt;/code&gt;带来的收益。团队可以用和&lt;code&gt;Subversion&lt;/code&gt;完全不变的方式来开发项目。&lt;/p&gt;
&lt;p&gt;但使用&lt;code&gt;Git&lt;/code&gt;加强开发的工作流，&lt;code&gt;Git&lt;/code&gt;比&lt;code&gt;SVN有&lt;/code&gt;几个优势。首先，每个开发可以有属于自己的整个工程的本地拷贝。隔离的环境让各个开发者的工作和项目的其他部分（修改）独立开来 —— 即自由地提交到自己的本地仓库，先完全忽略上游的开发，直到方便的时候再把修改反馈上去。&lt;/p&gt;
&lt;p&gt;其次，&lt;code&gt;Git&lt;/code&gt;提供了强壮的分支和合并模型。不像&lt;code&gt;SVN&lt;/code&gt;，&lt;code&gt;Git&lt;/code&gt;的分支设计成可以做为一种用来在仓库之间集成代码和分享修改的『失败安全』的机制。&lt;/p&gt;
&lt;h2&gt;工作方式&lt;/h2&gt;
&lt;p&gt;像&lt;code&gt;Subversion&lt;/code&gt;一样，集中式工作流以中央仓库作为项目所有修改的单点实体。相比&lt;code&gt;SVN&lt;/code&gt;缺省的开发分支&lt;code&gt;trunk&lt;/code&gt;，&lt;code&gt;Git&lt;/code&gt;叫做&lt;code&gt;master&lt;/code&gt;，所有修改提交到这个分支上。该工作流只用到&lt;code&gt;master&lt;/code&gt;这一个分支。&lt;/p&gt;
&lt;p&gt;开发者开始先克隆中央仓库。在自己的项目拷贝中，像&lt;code&gt;SVN&lt;/code&gt;一样的编辑文件和提交修改；但修改是存在本地的，和中央仓库是完全隔离的。开发者可以把和上游的同步延后到一个方便时间点。&lt;/p&gt;
&lt;p&gt;要发布修改到正式项目中，开发者要把本地&lt;code&gt;master&lt;/code&gt;分支的修改『推（push）』到中央仓库中。这相当于&lt;code&gt;svn commit&lt;/code&gt;操作，但&lt;code&gt;push&lt;/code&gt;操作会把所有还不在中央仓库的本地提交都推上去。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;git-workflow-svn-push-local&quot; src=&quot;/images/jobbole.com/2296698d29eb7c9c0579fc94e709f317.jpg&quot;&gt;&lt;/p&gt;
&lt;h2&gt;冲突解决&lt;/h2&gt;
&lt;p&gt;中央仓库代表了正式项目，所以提交历史应该被尊重且是稳定不变的。如果开发者本地的提交历史和中央仓库有分歧，&lt;code&gt;Git&lt;/code&gt;会拒绝&lt;code&gt;push&lt;/code&gt;提交否则会覆盖已经在中央库的正式提交。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;git-workflow-svn-managingconflicts&quot; src=&quot;/images/jobbole.com/cbca8c77199217c6db700dadc9594938.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;在开发者提交自己功能修改到中央库前，需要先&lt;code&gt;fetch&lt;/code&gt;在中央库的新增提交，&lt;code&gt;rebase&lt;/code&gt;自己提交到中央库提交历史之上。这样做的意思是在说，『我要把自己的修改加到别人已经完成的修改上。』最终的结果是一个完美的线性历史，就像以前的&lt;code&gt;SVN&lt;/code&gt;的工作流中一样。&lt;/p&gt;
&lt;p&gt;如果本地修改和上游提交有冲突，&lt;code&gt;Git&lt;/code&gt;会暂停&lt;code&gt;rebase&lt;/code&gt;过程，给你手动解决冲突的机会。&lt;code&gt;Git&lt;/code&gt;解决合并冲突，用和生成提交一样的&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-basics#!status&quot;&gt;&lt;code&gt;git status&lt;/code&gt;&lt;/a&gt;和&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-basics#!add&quot;&gt;&lt;code&gt;git add&lt;/code&gt;&lt;/a&gt;命令，很一致方便。还有一点，如果解决冲突时遇到麻烦，&lt;code&gt;Git&lt;/code&gt;可以很简单中止整个&lt;code&gt;rebase&lt;/code&gt;操作，重来一次（或者让别人来帮助解决）。&lt;/p&gt;
&lt;h2&gt;示例&lt;/h2&gt;
&lt;p&gt;让我们一起逐步分解来看看一个常见的小团队如何用这个工作流来协作的。有两个开发者小明和小红，看他们是如何开发自己的功能并提交到中央仓库上的。&lt;/p&gt;
&lt;h3&gt;有人先初始化好中央仓库&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/084a5d4d6c932e628ca99826f0b95821.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;第一步，有人在服务器上创建好中央仓库。如果是新项目，你可以初始化一个空仓库；否则你要导入已有的&lt;code&gt;Git&lt;/code&gt;或&lt;code&gt;SVN&lt;/code&gt;仓库。&lt;/p&gt;
&lt;p&gt;中央仓库应该是个裸仓库（&lt;code&gt;bare repository&lt;/code&gt;），即没有工作目录（&lt;code&gt;working directory&lt;/code&gt;）的仓库。可以用下面的命令创建：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ssh user@host&lt;br&gt;
git init --bare /path/to/repo.git&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;确保写上有效的&lt;code&gt;user&lt;/code&gt;（&lt;code&gt;SSH&lt;/code&gt;的用户名），&lt;code&gt;host&lt;/code&gt;（服务器的域名或IP地址），&lt;code&gt;/path/to/repo.git&lt;/code&gt;（你想存放仓库的位置）。注意，为了表示是一个裸仓库，按照约定加上&lt;code&gt;.git&lt;/code&gt;扩展名到仓库名上。&lt;/p&gt;
&lt;h3&gt;所有人克隆中央仓库&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8fb607bd35ac92fefb8ba93a20497960.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;下一步，各个开发者创建整个项目的本地拷贝。通过&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-basics#!clone&quot;&gt;&lt;code&gt;git clone&lt;/code&gt;&lt;/a&gt;命令完成：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git clone ssh://user@host/path/to/repo.git&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;基于你后续会持续和克隆的仓库做交互的假设，克隆仓库时&lt;code&gt;Git&lt;/code&gt;会自动添加远程别名&lt;code&gt;origin&lt;/code&gt;指回『父』仓库。&lt;/p&gt;
&lt;h3&gt;小明开发功能&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5ad46e2f8099a74ecf09654a894e7ba3.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;在小明的本地仓库中，他使用标准的&lt;code&gt;Git&lt;/code&gt;过程开发功能：编辑、暂存（&lt;code&gt;Stage&lt;/code&gt;）和提交。如果你不熟悉暂存区（&lt;code&gt;Staging Area&lt;/code&gt;），这里说明一下：&lt;strong&gt;暂存区&lt;/strong&gt;的用来准备一个提交，但可以不用把工作目录中所有的修改内容都包含进来。这样你可以创建一个高度聚焦的提交，尽管你本地修改很多内容。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git status # 查看本地仓库的修改状态&lt;br&gt;
git add # 暂存文件&lt;br&gt;
git commit # 提交文件&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;请记住，因为这些命令生成的是本地提交，小明可以按自己需求反复操作多次，而不用担心中央仓库上有了什么操作。对需要多个更简单更原子分块的大功能，这个做法是很有用的。&lt;/p&gt;
&lt;h3&gt;小红开发功能&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/afab9f895681239c704510cf9feeddde.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;与此同时，小红在自己的本地仓库中用相同的编辑、暂存和提交过程开发功能。和小明一样，她也不关心中央仓库有没有新提交；当然更不关心小明在他的本地仓库中的操作，因为所有本地仓库都是私有的。&lt;/p&gt;
&lt;h3&gt;小明发布功能&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/709e4a119929681aa72a08e314beda6d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;一旦小明完成了他的功能开发，会发布他的本地提交到中央仓库中，这样其它团队成员可以看到他的修改。他可以用下面的&lt;a href=&quot;https://www.atlassian.com/git/tutorial/remote-repositories#!push&quot;&gt;&lt;code&gt;git push&lt;/code&gt;命令&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git push origin master&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;注意，&lt;code&gt;origin&lt;/code&gt;是在小明克隆仓库时&lt;code&gt;Git&lt;/code&gt;创建的远程中央仓库别名。&lt;code&gt;master&lt;/code&gt;参数告诉&lt;code&gt;Git&lt;/code&gt;推送的分支。由于中央仓库自从小明克隆以来还没有被更新过，所以&lt;code&gt;push&lt;/code&gt;操作不会有冲突，成功完成。&lt;/p&gt;
&lt;h3&gt;小红试着发布功能&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b76cdca7036400bb7580defbd6e794ef.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;一起来看看在小明发布修改后，小红&lt;code&gt;push&lt;/code&gt;修改会怎么样？她使用完全一样的&lt;code&gt;push&lt;/code&gt;命令：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git push origin master&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;但她的本地历史已经和中央仓库有分岐了，&lt;code&gt;Git&lt;/code&gt;拒绝操作并给出下面很长的出错消息：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;error: failed to push some refs to &#39;/path/to/repo.git&#39;&lt;br&gt;
hint: Updates were rejected because the tip of your current branch is behind&lt;br&gt;
hint: its remote counterpart. Merge the remote changes (e.g. &#39;git pull&#39;)&lt;br&gt;
hint: before pushing again.&lt;br&gt;
hint: See the &#39;Note about fast-forwards&#39; in &#39;git push --help&#39; for details.&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这避免了小红覆写正式的提交。她要先&lt;code&gt;pull&lt;/code&gt;小明的更新到她的本地仓库合并上她的本地修改后，再重试。&lt;/p&gt;
&lt;h3&gt;小红在小明的提交之上&lt;code&gt;rebase&lt;/code&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0eb847a52d38c7eceb8b4ac2da401cf7.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;小红用&lt;a href=&quot;https://www.atlassian.com/git/tutorial/remote-repositories#!pull&quot;&gt;&lt;code&gt;git pull&lt;/code&gt;&lt;/a&gt;合并上游的修改到自己的仓库中。这条命令类似&lt;code&gt;svn update&lt;/code&gt;——拉取所有上游提交命令到小红的本地仓库，并尝试和她的本地修改合并：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git pull --rebase origin master&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;--rebase&lt;/code&gt;选项告诉&lt;code&gt;Git&lt;/code&gt;把小红的提交移到同步了中央仓库修改后的&lt;code&gt;master&lt;/code&gt;分支的顶部，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a282fd25ee52a31ca56842232ff7db25.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;如果你忘加了这个选项，&lt;code&gt;pull&lt;/code&gt;操作仍然可以完成，但每次&lt;code&gt;pull&lt;/code&gt;操作要同步中央仓库中别人修改时，提交历史会以一个多余的『合并提交』结尾。对于集中式工作流，最好是使用&lt;code&gt;rebase&lt;/code&gt;而不是生成一个合并提交。&lt;/p&gt;
&lt;h3&gt;小红解决合并冲突&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a91b47c5b4c1af124206df9570488aaa.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;rebase&lt;/code&gt;操作过程是把本地提交一次一个地迁移到更新了的中央仓库&lt;code&gt;master&lt;/code&gt;分支之上。这意味着可能要解决在迁移某个提交时出现的合并冲突，而不是解决包含了所有提交的大型合并时所出现的冲突。这样的方式让你尽可能保持每个提交的聚焦和项目历史的整洁。反过来，简化了哪里引入&lt;code&gt;Bug&lt;/code&gt;的分析，如果有必要，回滚修改也可以做到对项目影响最小。&lt;/p&gt;
&lt;p&gt;如果小红和小明的功能是相关的，不大可能在&lt;code&gt;rebase&lt;/code&gt;过程中有冲突。如果有，&lt;code&gt;Git&lt;/code&gt;在合并有冲突的提交处暂停&lt;code&gt;rebase&lt;/code&gt;过程，输出下面的信息并带上相关的指令：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;CONFLICT (content): Merge conflict in&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1288af0cf84b531f867db162255d241a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Git&lt;/code&gt;很赞的一点是，任何人可以解决他自己的冲突。在这个例子中，小红可以简单的运行&lt;a href=&quot;https://www.atlassian.com/git/tutorial/git-basics#!status&quot;&gt;&lt;code&gt;git status&lt;/code&gt;&lt;/a&gt;命令来查看哪里有问题。冲突文件列在&lt;code&gt;Unmerged paths&lt;/code&gt;（未合并路径）一节中：&lt;/p&gt;
&lt;p&gt;“`&lt;br&gt;
Unmerged paths:&lt;br&gt;
(use “git reset HEAD …” to unstage)&lt;br&gt;
(use “git add/rm …” as appropriate to mark resolution)&lt;/p&gt;
&lt;p&gt;both modified:&lt;br&gt;
“`&lt;/p&gt;
&lt;p&gt;接着小红编辑这些文件。修改完成后，用老套路暂存这些文件，并让&lt;a href=&quot;https://www.atlassian.com/git/tutorial/rewriting-git-history#!rebase&quot;&gt;&lt;code&gt;git rebase&lt;/code&gt;&lt;/a&gt;完成剩下的事：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git add&lt;br&gt;
git rebase --continue&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;要做的就这些了。&lt;code&gt;Git&lt;/code&gt;会继续一个一个地合并后面的提交，如其它的提交有冲突就重复这个过程。&lt;/p&gt;
&lt;p&gt;如果你碰到了冲突，但发现搞不定，不要惊慌。只要执行下面这条命令，就可以回到你执行&lt;a href=&quot;https://www.atlassian.com/git/tutorial/remote-repositories#!pull&quot;&gt;&lt;code&gt;git pull --rebase&lt;/code&gt;&lt;/a&gt;命令前的样子：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git rebase --abort&lt;/code&gt;&lt;/p&gt;
&lt;h3&gt;小红成功发布功能&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/88119127c0a6927a7daf8413b3ac4e0e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;小红完成和中央仓库的同步后，就能成功发布她的修改了：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git push origin master&lt;/code&gt;&lt;/p&gt;
&lt;h2&gt;下一站&lt;/h2&gt;
&lt;p&gt;如你所见，仅使用几个&lt;code&gt;Git&lt;/code&gt;命令我们就可以模拟出传统&lt;code&gt;Subversion&lt;/code&gt;开发环境。对于要从&lt;code&gt;SVN&lt;/code&gt;迁移过来的团队来说这太好了，但没有发挥出&lt;code&gt;Git&lt;/code&gt;分布式本质的优势。&lt;/p&gt;
&lt;p&gt;如果你的团队适应了集中式工作流，但想要更流畅的协作效果，绝对值得探索一下&lt;a href=&quot;http://blog.jobbole.com/76857/&quot;&gt;功能分支工作流&lt;/a&gt;的收益。通过为一个功能分配一个专门的分支，能够做到一个新增功能集成到正式项目之前对新功能进行深入讨论。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/76843/&quot;&gt;« 概述&lt;/a&gt;　　　　&lt;a href=&quot;http://blog.jobbole.com/76857/&quot;&gt;功能分支工作流 »&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;译注&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;
&lt;a href=&quot;http://weibo.com/oldratlee&quot;&gt;自己&lt;/a&gt;理解粗浅，译文源码在&lt;a href=&quot;https://github.com/quickhack/translations/tree/master/git-workflows-and-tutorials&quot;&gt;&lt;code&gt;GitHub&lt;/code&gt;上&lt;/a&gt;，翻译中不足和不对之处，欢迎建议（&lt;a href=&quot;https://github.com/quickhack/translations/issues&quot;&gt;提交Issue&lt;/a&gt;）和指正（&lt;a href=&quot;https://github.com/quickhack/translations/fork&quot;&gt;Fork后提交代码&lt;/a&gt;）！&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Sat, 13 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-13-76847-7fffc6f1d.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-13-76847-7fffc6f1d.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>机器学习算法已能发现艺术历史学家从未注意的画作亮点</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;h2&gt;人工智能揭示伟大艺术家之间从未被认识到的影响&lt;/h2&gt;
&lt;p&gt;鉴别艺术作品的优劣是极端复杂的，在审视一副画作时，艺术专家通常会判断它所属的类型、流派、作者和时代。艺术历史学家更为深入，他们会寻找画家间的影响和联系，这项工作更为棘手。&lt;/p&gt;
&lt;p&gt;因此，使用计算机去鉴别画作，寻找它们之间的联系，乍看起来很可笑。然而，在新泽西州的罗格斯大学，Bahak Saleh和pals已经完成了这项艰巨的工作。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/db5cef8ec5fe7ce8635efe0c22badd87.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这些精英们使用了最新的图像处理和分类技术，完成了对“伟大的艺术家们是如何互相影响”的自动化探索。他们甚至发现了艺术历史学家至今都未发现的一些影响。&lt;/p&gt;
&lt;p&gt;艺术专家解决这类问题的方式，是通过一系列的“高级概念”对艺术作品进行比较，正如画家所使用的空间、结构、样式、形状、以及颜色等等。专家们还会考虑画家在画作中所运用的艺术手法，协调、变化、平衡、对比、比例和模仿等。其他重要的要素还包括创作的题材、笔法、寓意、历史背景等等。很显然，这是一项复杂的工作。&lt;/p&gt;
&lt;p&gt;所以可以想象，计算机对二维图像有限的分析能力不太可能完成对这一工作的自动化处理。然而，Salah和他的团队却做到了。&lt;/p&gt;
&lt;p&gt;他们所使用的方法的核心，是一项由新罕布什尔州的达特茅斯学院和英国剑桥微软研究所开发的新技术，这项技术能够根据画作包含的视觉概念对其进行分类。这些概念被称之为&lt;em&gt;“classemes”&lt;/em&gt;，它包含了几乎所有的东西，从小的物质描述如鸭子、飞盘、人、独轮手推车到颜色变化再到高层面描述如死尸、水体、路面等等。&lt;/p&gt;
&lt;p&gt;由此，比较图像就转变为了比较描述它们的“词汇”，这已经有众多成熟技术提供支持了。&lt;/p&gt;
&lt;p&gt;Salah和他的团队将这种方法应用在1700多幅画作上，这些画作经由66个画家，包含13种风格，总的来说，这些画家跨越了从15世纪早期到20世纪末期的时长。为了最准确的评估他们的成就，专家针对这些艺术家是如何互相影响的意见也被考虑在内。&lt;/p&gt;
&lt;p&gt;对每一幅画作的处理来说，为了达到最佳效率，他们将概念总数和兴趣点限制在3000个以内。这个过程会产生一系列描述性词汇，这些词汇可以被视为一种向量，之后的工作是使用自然语言技术和机器学习算法寻找相似的向量。&lt;/p&gt;
&lt;p&gt;判定影响是很困难的，因为“影响”本身就是一个很难界定的概念。如果一副画作与另一幅极其类似，它的画家能被视为影响了另一个画家吗？还是说需要有一大批类似的画作？如果是，那需要多少呢？&lt;/p&gt;
&lt;p&gt;Salah和他的团队试验了大量不同的指标，最终他们建立了一类二维图像，其中每根轴上都有不同的指标，之后将所有画家的作品都置于一处，观察它们是如何聚合的。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/786bf9519728f54248f857d2fffc656d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;结果非常有趣，在很多案例中，他们的算法都清晰地识别出了艺术专家已经发现的影响。比如说，图像显示奥地利画家&lt;em&gt;Klimt&lt;/em&gt;和&lt;em&gt;Picasso&lt;/em&gt;以及&lt;em&gt;Braque&lt;/em&gt;的风格类似，确实，专家们也普遍认同&lt;em&gt;Klimt&lt;/em&gt;深受后两者的影响。这个算法同样指出了法国浪漫主义画家&lt;em&gt;Delacroix&lt;/em&gt;对法国印象派画家&lt;em&gt;Bazille&lt;/em&gt;的影响，以及挪威画家&lt;em&gt;Munch&lt;/em&gt;对德国画家&lt;em&gt;Beckmann&lt;/em&gt;的影响，还有&lt;em&gt;Degas&lt;/em&gt;对&lt;em&gt;Caillebotte&lt;/em&gt;的影响。&lt;/p&gt;
&lt;p&gt;这个算法也能判断个别画作影响了其他东西，它挑选了1912年绘制的&lt;em&gt;Georges Braque&lt;/em&gt;的&lt;em&gt;Man with a Violin&lt;/em&gt;和&lt;em&gt;Pablo Picasso&lt;/em&gt;的 &lt;em&gt;Spanish Still Life: Sun and Shadow&lt;/em&gt;，它们的联系众所周知，通过它们，人们发现了立体主义运动。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/7bd7b1d6615ca3d9e39b94f6a3c53f2b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;该算法也将&lt;em&gt;Vincent van Gogh&lt;/em&gt;的&lt;em&gt;Old Vineyard with Peasant Woman&lt;/em&gt; (1890)(左上) 和&lt;em&gt;Joan Miro&lt;/em&gt;的&lt;em&gt;The Farm&lt;/em&gt; (1922)联系在了一起，这两幅画作包含相同的物体和布景，但情绪与风格极为不同。&lt;/p&gt;
&lt;p&gt;最令人印象深刻的是它将&lt;em&gt;Frederic Bazille&lt;/em&gt;的&lt;em&gt;Studio 9 Rue de la Condamine&lt;/em&gt; (1870)(左下)和&lt;em&gt;Norman Rockwell&lt;/em&gt;的&lt;em&gt;Shuffleton’s Barber Shop&lt;/em&gt; (1950)联系在了一起。在浏览众多出版物和网站后，我们得出结论，就目前我们掌握的知识，还没有一个艺术历史学家发现这样的相似性。&lt;/p&gt;
&lt;p&gt;然而通过目测我们也能看出其中清晰的联系，下图中的黄圈展示了相似物体，红线展示了构图，蓝色矩形展示了相关联的结构性元素，Saleh和他的团队如是说。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/1cf5c812d74463ca9b01c3648d961971.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这非常有趣，当然，Saleh和他的团队并没有声称这种算法可以替代艺术历史学家，毕竟，通过这种方式找出画作间的联系仅仅是深入研究画家生平的第一步。&lt;/p&gt;
&lt;p&gt;但是，这已经非常激动人心，机器学习技术能够在庞大的主题上提供线索，并深入研究艺术历史。&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Sat, 13 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-13-76226-a05a8a3d2.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-13-76226-a05a8a3d2.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>Linux perf Rides the Rocket</title>
        <description>

&lt;div style=&quot;float:right;padding-left:10px;padding-bottom:5px&quot;&gt;
&lt;img src=&quot;/images/brendangregg.com/4dd4b2e20638a1d4bacfcc0b576f2881.jpg&quot; width=&quot;250&quot; height=&quot;176&quot;&gt;&lt;br&gt;&lt;center&gt;&lt;font size=&quot;-1&quot;&gt;&lt;i&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Rocket_sled&quot;&gt;Riding the rocket&lt;/a&gt;&lt;/i&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;WHAT DOES IT MEAN?? Ubuntu Trusty was dropping packets in our cloud instance, and leaving us with the mysterious system message:&lt;/p&gt;

&lt;pre&gt;
[85290.555808] xen_netfront: xennet: 
 &lt;b&gt;skb rides the rocket: 19 slots&lt;/b&gt;
&lt;/pre&gt;

&lt;p&gt;This led us to ride the rocket of advanced Linux kernel tracing...&lt;/p&gt;

&lt;p&gt;In this post, I&#39;ll demonstrate some fairly unknown features (practically secrets) of Linux kernel tracing using perf_events, which is part of the Linux kernel source (tools/perf).&lt;/p&gt;

&lt;p&gt;Mysterious system messages are better than no system messages, because we have something at least to search for. The message comes from the following function (this is Linux 3.13.6), which transmits a packet from a Xen guest (this is on AWS EC2):&lt;/p&gt;

&lt;pre&gt;
static int xennet_start_xmit(struct sk_buff *skb, struct net_device *dev)
{
[...]
        slots = DIV_ROUND_UP(offset + len, PAGE_SIZE) +
                xennet_count_skb_frag_slots(skb);
        if (unlikely(slots &amp;gt; MAX_SKB_FRAGS + 1)) {
                net_alert_ratelimited(
                        &quot;xennet: &lt;b&gt;skb rides the rocket&lt;/b&gt;: %d slots\n&quot;, slots);
                goto drop;
        }
&lt;/pre&gt;

&lt;p&gt;Yes, goto drop, which bumps a counter and frees the packet. Client problem now! The client will, after a performance-problem-inducing timeout, retransmit the packet. Let&#39;s hope the retransmitted packet doesn&#39;t RIDE THE ROCKET as well! (... I&#39;m serious – this could lead to exponential latency.)&lt;/p&gt;

&lt;p&gt;We know the value of &lt;tt&gt;slots&lt;/tt&gt;, since it&#39;s part of the system message (19). We know what MAX_SKB_FRAGS is from the kernel source: it&#39;s 16, and is related to limiting the number of fragments or pages that can be sent to a device ring buffer. We don&#39;t know &lt;tt&gt;offset&lt;/tt&gt;, &lt;tt&gt;len&lt;/tt&gt;, or the return of &lt;tt&gt;xennet_count_skb_frag_slots(skb)&lt;/tt&gt;.&lt;/p&gt;

&lt;p&gt;I&#39;m a little familiar with this codepath already, and have an idea of the real size of these skbs (eg, by using &quot;perf-stat-hist net:net_dev_xmit len 10&quot; from &lt;a href=&quot;https://github.com/brendangregg/perf-tools&quot;&gt;perf-tools&lt;/a&gt;; see the &lt;a href=&quot;https://github.com/brendangregg/perf-tools/blob/master/examples/perf-stat-hist_example.txt&quot;&gt;example&lt;/a&gt;), and what the offset might be. I&#39;d like to check them directly here, but I&#39;ll start by instrumenting the return of xennet_count_skb_frag_slots() using &lt;a href=&quot;http://www.brendangregg.com/perf.html&quot;&gt;perf_events&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;perf probe &#39;xennet_count_skb_frag_slots%return ret=$retval&#39;&lt;/b&gt;
Return probe must be on the head of a real function.
  Error: Failed to add events. (-22)
# &lt;b&gt;grep xennet_count_skb_frag_slots /proc/kallsyms&lt;/b&gt;
# 
&lt;/pre&gt;

&lt;p&gt;... Really compiler, can&#39;t you inline someone else?&lt;/p&gt;

&lt;p&gt;So this symbol doesn&#39;t even exist. (I wish the compiler would RIDE THE ROCKET!) For most tracers, this is a dead end. Almost.&lt;/p&gt;

&lt;p&gt;Having used a kernel dynamic tracer for a decade, I&#39;ve developed all kinds of tricks and hacks to work around this: maybe there&#39;s a child of xennet_count_skb_frag_slots() function I can trace; maybe I can duplicate the logic from xennet_start_xmit(), where I can observe skb. I began trying such workarounds, but in this case it was becomming onerous. At this point I&#39;d usually start considering editing the kernel and inserting instrumentation just to see this, which involves a compile, test, and deploy cycle.&lt;/p&gt;

&lt;p&gt;But on Linux, &lt;b&gt;with kernel debuginfo&lt;/b&gt;, I can go a lot further directly. Let&#39;s switch to the entry to that function, and use &quot;-nv&quot; to show what perf probe would have done without doing it:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;perf probe -nv xennet_count_skb_frag_slots&lt;/b&gt;
probe-definition(0): xennet_count_skb_frag_slots 
symbol:xennet_count_skb_frag_slots file:(null) line:0 offset:0 return:0 lazy:(null)
0 arguments
Looking at the vmlinux_path (6 entries long)
symsrc__init: cannot get elf header.
Using /lib/modules/3.13.11.6/build/vmlinux for symbols
found inline addr: 0xffffffff8152dae8
Probe point found: xennet_start_xmit+88
find 1 probe_trace_events.
Opening /sys/kernel/debug//tracing/kprobe_events write=1
Added new event:
&lt;b&gt;Writing event: p:probe/xennet_count_skb_frag_slots xennet_start_xmit+88&lt;/b&gt;
  probe:xennet_count_skb_frag_slots (on xennet_count_skb_frag_slots)

You can now use it in all perf tools, such as:

    perf record -e probe:xennet_count_skb_frag_slots -aR sleep 1
&lt;/pre&gt;

&lt;p&gt;Wow, so the beginning of this inlined function can indeed be instrumented, since Linux can trace kernel instructions (or line numbers). Note the offset &quot;+88&quot;.&lt;/p&gt;

&lt;p&gt;Lines inside this function (despite it being inlined) can also be traced. The perf report command will list candidates with -L:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;perf probe -L xennet_count_skb_frag_slots&lt;/b&gt;
&lt;xennet_count_skb_frag_slots&gt;
      0  static int xennet_count_skb_frag_slots(struct sk_buff *skb)
&lt;font color=&quot;blue&quot;&gt;         {&lt;/font&gt;
      2         int i, frags = skb_shinfo(skb)-&amp;gt;nr_frags;
      3         int pages = 0;
         
      5         for (i = 0; i                         skb_frag_t *frag = skb_shinfo(skb)-&amp;gt;frags + i;
      7                 unsigned long size = skb_frag_size(frag);
&lt;font color=&quot;blue&quot;&gt;                        unsigned long offset = frag-&amp;gt;page_offset;
         
                        /* Skip unused frames from start of page */&lt;/font&gt;
     11                 offset &amp;amp;= ~PAGE_MASK;
         
     13                 pages += PFN_UP(offset + size);
&lt;font color=&quot;blue&quot;&gt;                }
         
                return pages;&lt;/font&gt;
&lt;/xennet_count_skb_frag_slots&gt;&lt;/pre&gt;

&lt;p&gt;This is pretty amazing. perf shows line numbers of those that can be instrumented directly, and those that can&#39;t in blue.&lt;/p&gt;

&lt;p&gt;Some local variables can also be inspected. Let&#39;s look at what is available at line 11:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;perf probe -V xennet_count_skb_frag_slots:11&lt;/b&gt;
Available variables at xennet_count_skb_frag_slots:11
        @&amp;lt;xennet_start_xmit+155&amp;gt;
                int     pages
                long unsigned int       size
&lt;/pre&gt;

&lt;p&gt;The &lt;tt&gt;offset&lt;/tt&gt; variable is missing, but I have others to work with, which is pretty useful. I can also include external symbols; add an &quot;--externs&quot; to the end of that one-liner for the list.&lt;/p&gt;

&lt;h2&gt;But don&#39;t you hate kernel debuginfo?&lt;/h2&gt;

&lt;p&gt;Yes, it&#39;s rainbows and ponies with kernel debuginfo, but it&#39;s also over 100 Mbytes. At Netflix, we create and destroy cloud instances frequently (auto-scaling and code deployments), and it&#39;s important to keep the instance size small to reduce creation time, and keep network traffic down.&lt;/p&gt;

&lt;p&gt;I&#39;ve come up with a simple workaround: create one small test instance with kernel debuginfo for each kernel version used, and use it for reference. Let&#39;s say I wanted to trace those local variables on line 11 of xennet_count_skb_frag_slots(). On my reference instance:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;perf probe -nv &#39;xennet_count_skb_frag_slots:11 pages size&#39; 2&amp;gt;&amp;amp;1 | grep Writing&lt;/b&gt;
Writing event: p:probe/xennet_count_skb_frag_slots &lt;b&gt;xennet_start_xmit+155 pages=%si:s32 size=%di:u64&lt;/b&gt;
&lt;/pre&gt;

&lt;p&gt;Now I copy-n-paste, with a mouse, the highlighted details for use in perf probe (or my kprobe from &lt;a href=&quot;https://github.com/brendangregg/perf-tools&quot;&gt;perf-tools&lt;/a&gt;, if it&#39;s a real function entry) on the system without debuginfo. Eg:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;perf probe &#39;xennet_count_skb_frag_slots:11 pages size&#39;&lt;/b&gt;
Failed to find path of kernel module.
Failed to open debuginfo file.
  Error: Failed to add events. (-2)
# &lt;b&gt;perf probe &#39;xennet_start_xmit+155 pages=%si:s32 size=%di:u64&#39;&lt;/b&gt;
Failed to find path of kernel module.
Added new event:
  probe:xennet_start_xmit (on xennet_start_xmit+155 with pages=%si:s32 size=%di:u64)

You can now use it in all perf tools, such as:

    perf record -e probe:xennet_start_xmit -aR sleep 1
&lt;/pre&gt;

&lt;p&gt;Awesome!&lt;/p&gt;

&lt;p&gt;I began by showing that this system really doesn&#39;t have kernel debuginfo. The second try, with the register details from the reference system, worked. Note that this approach will only create a valid probe if the kernel versions are identical. If you try this on a different kernel, it may appear to work, but provide invalid results. &lt;/p&gt;

&lt;p&gt;SystemTap can automate the use of reference systems, although when I tried I had issues with firewalling and port forwarding due to our environment. As for other ways: I met Masami Hiramatsu at LinuxCon North America, and he came up with a way to build a simple text database of functions and variables – stripping debuginfo down to just what I needed. I&#39;ll blog about that when I get a chance.&lt;/p&gt;

&lt;p&gt;These reference systems are also useful for testing tracing invocations, before using them in production.&lt;/p&gt;

&lt;h2&gt;Some output&lt;/h2&gt;

&lt;p&gt;Enabling this probe:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;perf record -e probe:xennet_start_xmit -aR sleep 10&lt;/b&gt;
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 1.466 MB perf.data (~64033 samples) ]
# &lt;b&gt;perf script&lt;/b&gt;
[...]
  sshd 92592 [009] 87585.288990: probe:xennet_start_xmit: (ffffffff8152e6bb) pages=0 size=280
  sshd 92592 [009] 87585.295461: probe:xennet_start_xmit: (ffffffff8152e6bb) pages=0 size=3058
  sshd 92592 [009] 87585.295472: probe:xennet_start_xmit: (ffffffff8152e6bb) pages=0 size=4f8
  sshd 92592 [009] 87585.296417: probe:xennet_start_xmit: (ffffffff8152e6bb) pages=0 size=538
  sshd 92592 [009] 87585.296426: probe:xennet_start_xmit: (ffffffff8152e6bb) pages=0 size=1c8
  sshd 92592 [009] 87585.304101: probe:xennet_start_xmit: (ffffffff8152e6bb) pages=0 size=29e0
  sshd 92592 [009] 87585.304102: probe:xennet_start_xmit: (ffffffff8152e6bb) pages=3 size=bdc
  sshd 92592 [009] 87585.304111: probe:xennet_start_xmit: (ffffffff8152e6bb) pages=0 size=4d4
[...]
&lt;/pre&gt;

&lt;p&gt;Great. The sizes are larger than the expected MTU, because of TCP send offload (TSO).
Warning: any network packet tracing can cost significant overheads, especially for 10 GbE speeds and beyond, so be careful on the network path and look for other solutions first.&lt;/p&gt;

&lt;h2&gt;What about the rocket?&lt;/h2&gt;

&lt;p&gt;It&#39;s a driver bug with TSO. A very large skb can span too many pages (more than 16) to be put in the driver ring buffer. One workaround is &quot;sudo ethtool -K eth0 tso off&quot;, for your interface. There&#39;s plenty of articles about this on the Internet, and they are easy to find thanks to our mysterious message. :-)&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I don&#39;t always need Linux kernel line number tracing, but sometimes it is very handy. Local variables at given line numbers can also be inspected. This is useful for both performance analysis and debugging, such as the analysis of our &quot;skb rides the rocket&quot; issue.&lt;/p&gt;

&lt;p&gt;To use this feature without kernel debuginfo on all cloud instances, I used a reference system approach. This reference system also serves as places to test specific tracing, before using it in production.&lt;/p&gt;

&lt;p&gt;As with all kernel tracing: be careful, as there have been panics and freezes in the past, and know what you are doing before use. For more about perf, see my &lt;a href=&quot;http://www.brendangregg.com/perf.html&quot;&gt;perf_events&lt;/a&gt; page and the &lt;a href=&quot;https://perf.wiki.kernel.org/index.php/Main_Page&quot;&gt;perf wiki&lt;/a&gt;.&lt;/p&gt;


</description>
        <pubDate>Thu, 11 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-11-perf-kernel-line-tracing.html-34d140960.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-11-perf-kernel-line-tracing.html-34d140960.html</guid>
        
        
        <category>brendangregg</category>
        
      </item>
    
      <item>
        <title>图解 KMP 算法（JavaScript 实现）</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;没碰算法久了大脑生锈得好快，看着 KMP 居然大脑一片空白，死活想不出当初怎么求 next 数组。google 一下，急躁地参考了一堆博客后终于想起来了。为了避免以后忘了又要浪费时间搜一遍，不如自己总结一篇吧！希望我的表述能帮更多人理解这个巧(qi)妙(pa)的算法。&lt;/p&gt;
&lt;p&gt;本文的完整源码（JavaScript）以及图片的 PSD 源文件都在&lt;a href=&quot;https://github.com/Crimx/Lab/tree/master/Algorithm/Searching/KMP&quot;&gt;[这里]&lt;/a&gt;，有需要跟踪更新的可以 star，也可以 fork 个屌炸天的实现然后尽情嘲笑我。&lt;/p&gt;
&lt;p&gt;领悟好的建议跳着读，只想看 next 数组求法可以跳到&lt;a href=&quot;http://www.crimx.com/2014/09/07/kmp-algorithm/#next_array&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;有什么问题尽管&lt;a href=&quot;http://www.crimx.com/2014/09/07/kmp-algorithm/#ds-thread&quot;&gt;评论&lt;/a&gt;，但我很害羞的，表喷我。&lt;/p&gt;
&lt;h2 id=&quot;kmp-&quot;&gt;KMP 算法是什么？&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;KMP 代表三个作者的名字，看维基去吧。&lt;/li&gt;
&lt;li&gt;这是一个字符串查找算法，可以在一个字符串（S）中查找一个词（W）出现的位置。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;kmp&quot;&gt;KMP 算法怎么查找？&lt;/h2&gt;
&lt;p&gt;说起字符串查找，大家肯定能理解朴素的查法，就是以 S 每个字符为开头与 W 比较。O(m*n)&lt;/p&gt;
&lt;p&gt;这时，一群热(xian)爱(de)思(dan)考(teng)的人就想，我觉得不够快，能不能再优化成 O(m+n) 啊？别说还真可以。&lt;/p&gt;
&lt;p&gt;看下图，现在字符串查找过程中出现了不匹配：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/09/1b7054ddb129fcedaf42f5247cdca1aa.png&quot; rel=&quot;lightbox[76611]&quot; title=&quot;图解 KMP 算法（JavaScript 实现）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-76688&quot; alt=&quot;kmp1&quot; src=&quot;/images/jobbole.com/a9e832ab8155ecbdfba67fc318105c36.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;按朴素算法，这里 W 应该右移一位然后重新匹配。但是，你有没有发现，目前为止，绿色部分在两个字符串中都是已知的。于是就有人想，如果出现下图这样的情况就好了：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/09/3b2bf0cc9650e186658572da7f5c149c.png&quot; rel=&quot;lightbox[76611]&quot; title=&quot;图解 KMP 算法（JavaScript 实现）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-76689&quot; alt=&quot;kmp2&quot; src=&quot;/images/jobbole.com/32eae95d4389d034abf841275fd9394b.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;如果是这样的话，我们就不用一个个比较了，直接&lt;code&gt;滑动&lt;/code&gt;，跳过不匹配的就好：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/09/c35602cd47e698fb1f4fe2e221e916c3.png&quot; rel=&quot;lightbox[76611]&quot; title=&quot;图解 KMP 算法（JavaScript 实现）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-76690&quot; alt=&quot;kmp3&quot; src=&quot;/images/jobbole.com/67fd40e57fbcc08c499f915c3d837370.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;以上就是 KMP 算法的思想啦，就是找到最长的滑动区间，是不是很简单！&lt;/p&gt;
&lt;h2 id=&quot;section&quot;&gt;怎么确定滑动区间？&lt;/h2&gt;
&lt;p&gt;我们可以建立一个数组，叫 next ，它跟 W 串一样长，next[ j ] 表示当 W[ j ] 与 S[ i ] 不匹配时，W 应该滑到哪个位置上。&lt;/p&gt;
&lt;p&gt;所以一但不匹配时，查一下 next 值，让 S[ i ] 跟 W[next[ j ]] 继续比较就行啦。&lt;/p&gt;
&lt;p&gt;现在的问题就变为：怎么计算 next 数组？&lt;/p&gt;
&lt;p&gt;先看回上面的图二，要求 next 数组必须先知道蓝色部分才行。这就头大了，我们是要先求 next 数组再做匹配啊，那求 next 的时候肯定不能碰 S 串，不然就相当于没优化了。&lt;/p&gt;
&lt;p&gt;但是不看 S 串又怎么知道蓝色部分相等了！你坑爹啊！&lt;/p&gt;
&lt;p&gt;有没有开始烦了……稍安勿躁！（我最近刚尝试了画一了一幅 &lt;a href=&quot;http://www.crimx.com/2014/09/02/low-poly/&quot;&gt;Low Poly&lt;/a&gt;，结果现在眼睛那个累啊！打心底佩服设计师们！）&lt;/p&gt;
&lt;p&gt;再看回上面图二，由于绿色部分都是&lt;strong&gt;已经匹配的&lt;/strong&gt;！所以就有了下面的关系：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/09/d8a86b5dc8b4c02f06a72b5732e92adf.png&quot; rel=&quot;lightbox[76611]&quot; title=&quot;图解 KMP 算法（JavaScript 实现）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-76691&quot; alt=&quot;kmp4&quot; src=&quot;/images/jobbole.com/1ab2187ba8918b1e783e6d5ac45fb3b3.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;之前我们假设了 2 和 3 是匹配的，现在看出了什么蹊跷没有？有没有豁然开朗的感觉？&lt;/p&gt;
&lt;p&gt;没错，既然 2 与 3 是匹配的，2 与 4 是匹配的，那么 3 与 4 是不是一定是匹配的！有了这个传递关系我们现在只用 W 串就可以求出 next 数组啦！是不是省了很多时间！&lt;/p&gt;
&lt;h2 id=&quot;next-&quot;&gt;准备求 next 数组&lt;/h2&gt;
&lt;p&gt;这节是求 next 数组前的一些热身概念，如果你有信心，可以直接跳到&lt;a href=&quot;http://www.crimx.com/2014/09/07/kmp-algorithm/#next_array&quot;&gt;下一节&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/09/d00518fcfc79be7850bc5ad5ff33c5cd.png&quot; rel=&quot;lightbox[76611]&quot; title=&quot;图解 KMP 算法（JavaScript 实现）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-76692&quot; alt=&quot;kmp6&quot; src=&quot;/images/jobbole.com/47b4ea96610e79a8a67b8b3f96b0f1bc.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;1、对于 next[ 1 ]，请看灰色部分，在第二组中，因为 W[ 1 ]（图中的 &lt;code&gt;a&lt;/code&gt;）前面只有一个字符（&lt;code&gt;b&lt;/code&gt;），所以只要 W[ 1 ] 不匹配，不管 W[ 0 ] 是不是蓝色，W 总是会滑到开头的（图第三组）。好好理解这句话。&lt;br&gt;
所以 next[ 1 ] == 0 总是成立的，这是一种特殊情况。你可以&lt;strong&gt;顺着灰色条看上去&lt;/strong&gt;（注意是灰色部分哦），图第二组中 &lt;code&gt;c&lt;/code&gt; 对应 W 的位置 &lt;code&gt;1&lt;/code&gt; 在第三组是不是变成对应 &lt;code&gt;0&lt;/code&gt; 了。&lt;/p&gt;
&lt;p&gt;2、对于 next[ 0 ]，继续看图灰色部分，在第三组中，W[ 0 ]（&lt;code&gt;b&lt;/code&gt;）就与 &lt;code&gt;c&lt;/code&gt; 不匹配了，且 W[ 0 ] 左边已经没有字符了，这表示 S[ i ]（图中 &lt;code&gt;c&lt;/code&gt;）肯定没戏了，所以要将 W 滑到 &lt;code&gt;c&lt;/code&gt; 下一个字符的位置重新开始（图第四组），灰色部分的 &lt;code&gt;0&lt;/code&gt; 现在是不是变成 &lt;code&gt;-1&lt;/code&gt; 了。所以 next[ 0 ] = -1。这也是一种特殊情况。&lt;/p&gt;
&lt;p&gt;3、最后再讲一下求 next 的核心思想，看下图中间的 W 。跟前面一样蓝色部分代表相等，于是有 W[ i ] == W[ j ]（j &amp;lt; i）。可以想象如果在 W 和 S 匹配过程中 W[ i+1 ] 不匹配了（与上面 S 的红色部分），那么 W 就要滑动且 W[ j+1 ] 将覆盖在 W[ i+1 ] 上（看最下面的 W）。所以 W[ i ] == W[ j ] 可以得出 next[ i+1 ] = j+1。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/09/691e6c75f86230ac7124ec7bb00937fc.png&quot; rel=&quot;lightbox[76611]&quot; title=&quot;图解 KMP 算法（JavaScript 实现）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-76693&quot; alt=&quot;kmp7&quot; src=&quot;/images/jobbole.com/4363f540d4f136719d5f09db80fa2f9b.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;next_array&quot;&gt;求解 next 数组&lt;/h2&gt;
&lt;p&gt;说了这么多，终于可以开始求解 next 数组啦！&lt;/p&gt;
&lt;p&gt;先看下图：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/09/69931b29c9d230abf8c0b94f712717c6.png&quot; rel=&quot;lightbox[76611]&quot; title=&quot;图解 KMP 算法（JavaScript 实现）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-76694&quot; alt=&quot;kmp9&quot; src=&quot;/images/jobbole.com/9e3bc6ed7d2a5f5d452b3bf79b801493.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;假设求 next 数组过程到达了上面的阶段，即刚利用 i-1 求完 next[ i ]，现在利用 i 求 next[ i+1 ]。我们可以知道蓝色部分是相等的，因为刚刚求完 next[ i ] = j。现在对于 W[ i ] 和 W[ j ] 有两种情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;W[ i ] 和 W[ j ] 相等。这好办，参照上一节第 3 点，next[ i+1 ] = j + 1，然后 W[ i ] 和 W[ j ] 都向前继续看下一个字符（i += 1、j += 1）。（相当于把 W[ i ] 和 W[ j ] 合并到各自的蓝色部分中去）。&lt;/li&gt;
&lt;li&gt;W[ i ] 和 W[ j ] 不等。这时就要试图找下图的关系咯：&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;试图在 j 里找到一个 k，满足 W[ k ] == W[ i ] 且绿色部分相等。（虽然比 j 短一点，但有总比没有爽嘛。）&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/09/b4ab45cca939de44a49720c92f3bcef5.png&quot; rel=&quot;lightbox[76611]&quot; title=&quot;图解 KMP 算法（JavaScript 实现）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-76695&quot; alt=&quot;kmp10&quot; src=&quot;/images/jobbole.com/6a50e39f01afb8fc32890474faac818a.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;怎么确定 k 的位置？再仔细看一下上图，前面用过的一个策略，现在又要用上咯：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/09/e3d71023336e03e59894dc1b39ed42ab.png&quot; rel=&quot;lightbox[76611]&quot; title=&quot;图解 KMP 算法（JavaScript 实现）&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-76696&quot; alt=&quot;kmp11&quot; src=&quot;/images/jobbole.com/9c579ff557a6ba2e67cfe7e1aa9827b2.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;因为 1 和 2 相等，2 和 3 相等，所以 1 和 3 相等。所以现在变成了跟前面一模一样的问题 —— 只是规模变小了。嗅出动态规划的味道没有？假设你不知道动态规划，我们继续分析。&lt;/p&gt;
&lt;p&gt;有了上面的传递关系，我们可以知道 k = next[ j ]，可以理解不？把上图左边一半单独看，假设在 W 和 S 匹配过程中 W[ j ] 不匹配了，那肯定是要滑到 next[ j ] 对不对？按照 next 数组的含义我们知道 next[ j ] 表示绿色部分是最长的咯，我们正好要为 k 找这样的值，所以 k = next[ j ]。&lt;/p&gt;
&lt;p&gt;但如果 W[ k ] 和 W[ i ] 也是不相等呢？没关系，对 k 进行同样的查找（k = next[ k ]），再看有没有短一点的……一直找直到 -1 。&lt;/p&gt;
&lt;p&gt;再次总结一下刚才的两种情况，对于 W[ i ] 和 W[ j ]：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;W[ i ] 和 W[ j ] 相等。next[ i+1 ] = j + 1，i += 1，j += 1。&lt;/li&gt;
&lt;li&gt;W[ i ] 和 W[ j ] 不等。j = next[ j ]。再次重复进行比较。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;代码片段：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;if (w.charAt(i) === w.charAt(j)) {
  // 匹配成功之后两者都跳到下一字符继续匹配
  next[++i] = ++j;
} else {
  // 滑动 j 继续匹配（短了一点还是可以接受嘛）
  j = next[ j ];
}&lt;/pre&gt;
&lt;p&gt;再看一下边界的问题，从前面一节的图可以知道，滑动最多滑到 -1，代表最左侧的空位咯，所以 j 滑动的最坏情况是滑到了 -1 。从前面一节我们也知道 j == -1 时, &lt;code style=&quot;font-style: inherit;&quot;&gt;next[ i+1 ] == 0 == j + 1&lt;/code&gt;，所以：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;if (j === -1 || w.charAt(i) === w.charAt(j)) {
  next[++i] = ++j;
} else {
  j = next[ j ];
}&lt;/pre&gt;
&lt;p&gt;现在考虑循环的问题，求 next 数组只需利用 i 遍历一遍。而对于 j ，因为 next[ 0 ] == -1，所以 j 初值为 -1 。再回想前面一节的第三点，我们是以 i 位置去算 next[ i+1 ] 的，所以 i 在 W1（即 W）倒数第二个位置就可以停止了。&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;var next = []
, i = 0
, j = -1
;

while (i &amp;lt; w.length-1) {
  if (j === -1 || w.charAt(i) === w.charAt(j)) {
    next[++i] = ++j;
  } else {
    j = next[j];
  }
}&lt;/pre&gt;
&lt;p&gt;就这样求完 next 数组啦！是不是超简单啊！&lt;/p&gt;
&lt;p&gt;这里看不懂的话可以继续&lt;a href=&quot;http://www.crimx.com/2014/09/07/kmp-algorithm/#ds-thread&quot;&gt;讨论&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&quot;section-1&quot;&gt;小优化&lt;/h2&gt;
&lt;p&gt;对于 &lt;code&gt;aaaab&lt;/code&gt; 这类的串，按上面的求法得出的 next 数组是 &lt;code&gt;[-1,0,1,2,3]&lt;/code&gt;。其实对于中间的几个 a 来说，当其不匹配的时候，滑动到前面一位的 a 肯定也是不匹配了。所以应该直接滑到最前的一个 a 那里 &lt;code&gt;[-1,-1,-1,-1,3]&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;怎么实现呢？自己想吧！&lt;/p&gt;
&lt;p&gt;弱弱的还是写一下吧，免得被人喷。&lt;/p&gt;
&lt;p&gt;因为是以 i 求 next[ i+1 ]，那么只需判断一下 W[ i ] 是否等于 W[ i+1 ] 不就得了。&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;while (i &amp;lt; w.length-1) {
  if (j === -1 || w.charAt(i) === w.charAt(j)) {
    if (w.charAt(++i) !== w.charAt(++j)) {
      next[i] = j;
    } else {
      next[i] = next[j];
    }
  } else {
    j = next[j];
  }
}&lt;/pre&gt;
&lt;p&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;KMP 算法实现&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;得到了 next 数组后就开始实现 KMP 匹配算法咯。其实跟求 next 数组大同小异。按照&lt;a href=&quot;http://www.crimx.com/2014/09/07/kmp-algorithm/#kmp&quot;&gt;前面&lt;/a&gt;讲过的思路实现就行。最后如果 j 达到了 W 的长度，说明 W 字符全部匹配成功了。&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;i = j = 0;
while (i &amp;lt; s.length &amp;amp;&amp;amp; j &amp;lt; w.length) {
  if (j === -1 || s.charAt(i) === w.charAt(j)) {
    i += 1;
    j += 1;
  } else {
    j = next[j];
  }
}
if (j &amp;gt;= w.length) {
  return (i - w.length);
} else {
  return 0;
}&lt;/pre&gt;
&lt;p&gt;以上就是 KMP 算法啦，希望你以后都能记起来，写完这篇我是忘不了的啦。&lt;/p&gt;
&lt;p&gt;有什么问题可以&lt;a href=&quot;http://www.crimx.com/2014/09/07/kmp-algorithm/#ds-thread&quot;&gt;评论&lt;/a&gt;，本文的完整源码（JavaScript）以及图片的 PSD 源文件都在&lt;a href=&quot;https://github.com/Crimx/Lab/tree/master/Algorithm/Searching/KMP&quot;&gt;[这里]&lt;/a&gt;，有需要的可以 star。就这样，么么扎~&lt;/p&gt;
&lt;h2 id=&quot;section-2&quot;&gt;参考资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html&quot;&gt;字符串匹配的KMP算法 – 阮一峰&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://jakeboxer.com/blog/2009/12/13/the-knuth-morris-pratt-algorithm-in-my-own-words/&quot;&gt;The Knuth Morris Pratt Algorithm In My Own Words – Jake Boxer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm&quot;&gt;Knuth–Morris–Pratt Algorithm – Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;（完）&lt;/p&gt;
&lt;p&gt;// 【注】：本文先发在了作者的&lt;a href=&quot;http://www.crimx.com/2014/09/07/kmp-algorithm/&quot; target=&quot;_blank&quot;&gt;个人博客&lt;/a&gt;。&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Thu, 11 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-11-76611-1cb0b3fb6.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-11-76611-1cb0b3fb6.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>ZIP压缩算法详细分析及解压实例解释</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;最近自己实现了一个ZIP压缩数据的解压程序，觉得有必要把ZIP压缩格式进行一下详细总结，数据压缩是一门通信原理和计算机科学都会涉及到的学科，在通信原理中，一般称为信源编码，在计算机科学里，一般称为数据压缩，两者本质上没啥区别，在数学家看来，都是映射。&lt;/p&gt;
&lt;p&gt;一方面在进行通信的时候，有必要将待传输的数据进行压缩，以减少带宽需求；另一方面，计算机存储数据的时候，为了减少磁盘容量需求，也会将文件进行压缩，尽管现在的网络带宽越来越高，压缩已经不像90年代初那个时候那么迫切，但在很多场合下仍然需要，其中一个原因是压缩后的数据容量减小后，磁盘访问IO的时间也缩短，尽管压缩和解压缩过程会消耗CPU资源，但是CPU计算资源增长得很快，但是磁盘IO资源却变化得很慢，比如目前主流的SATA硬盘仍然是7200转，如果把磁盘的IO压力转化到CPU上，总体上能够提升系统运行速度。&lt;/p&gt;
&lt;p&gt;压缩作为一种非常典型的技术，会应用到很多很多场合下，比如文件系统、数据库、消息传输、网页传输等等各类场合。尽管压缩里面会涉及到很多术语和技术，但无需担心，博主尽量将其描述得通俗易懂。另外，本文涉及的压缩算法非常主流并且十分精巧，理解了ZIP的压缩过程，对理解其它相关的压缩算法应该就比较容易了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、引子&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;压缩可以分为无损压缩和有损压缩，有损，指的是压缩之后就无法完整还原原始信息，但是压缩率可以很高，主要应用于视频、话音等数据的压缩，因为损失了一点信息，人是很难察觉的，或者说，也没必要那么清晰照样可以看可以听；无损压缩则用于文件等等必须完整还原信息的场合，ZIP自然就是一种无损压缩，在通信原理中介绍数据压缩的时候，往往是从信息论的角度出发，引出香农所定义的熵的概念，这方面的介绍实在太多，这里换一种思路，从最原始的思想出发，为了达到压缩的目的，需要怎么去设计算法。而ZIP为我们提供了相当好的案例。&lt;/p&gt;
&lt;p&gt;尽管我们不去探讨信息论里面那些复杂的概念，不过我们首先还是要从两位信息论大牛谈起。因为是他们奠基了今天大多数无损数据压缩的核心，包括ZIP、RAR、GZIP、GIF、PNG等等大部分无损压缩格式。这两位大牛的名字分别是Jacob Ziv和Abraham Lempel，是两位以色列人，在1977年的时候发表了一篇论文《A Universal Algorithm for Sequential Data Compression》，从名字可以看出，这是一种通用压缩算法，所谓通用压缩算法，指的是这种压缩算法没有对数据的类型有什么限定。不过论文我觉得不用仔细看了，因为博主作为一名通信专业的PHD，看起来也焦头烂额，不过我们后面可以看到，它的思想还是很简单的，之所以看起来复杂，主要是因为IEEE的某些杂志就是这个特点，需要从数学上去证明，这种压缩算法到底有多优，比如针对一个各态历经的随机序列（不用追究什么叫各态历经随机序列），经过这样的压缩算法后，是否可以接近信息论里面的极限（也就是前面说的熵的概念）等等，不过在理解其思想之前，个人认为没必要深究这些东西，除非你要发论文。这两位大牛提出的这个算法称为LZ77，两位大牛过了一年又提了一个类似的算法，称为LZ78，思想类似，ZIP这个算法就是基于LZ77的思想演变过来的，但ZIP对LZ77编码之后的结果又继续进行压缩，直到难以压缩为止。除了LZ77、LZ78，还有很多变种的算法，基本都以LZ开头，如LZW、LZO、LZMA、LZSS、LZR、LZB、LZH、LZC、LZT、LZMW、LZJ、LZFG等等，非常多，LZW也比较流行，GIF那个动画格式记得用了LZW。我也写过解码程序，以后有时间可以再写一篇，但感觉跟LZ77这些类似，写的必要性不大。&lt;/p&gt;
&lt;p&gt;ZIP的作者是一个叫Phil Katz的人，这个人算是开源界的一个具有悲剧色彩的传奇人物。虽然二三十年前，开源这个词还没有现在这样风起云涌，但是总有一些具有黑客精神的牛人，内心里面充满了自由，无论他处于哪个时代。Phil Katz这个人是个牛逼程序员，成名于DOS时代，我个人也没有经历过那个时代，我是从Windows98开始接触电脑的，只是从书籍中得知，那个时代网速很慢，拨号使用的是只有几十Kb（比特不是字节）的猫，56Kb实际上是这种猫的最高速度，在ADSL出现之后，这种技术被迅速淘汰。当时记录文件的也是硬盘，但是在电脑之间拷贝文件的是软盘，这个东西我大一还用过，最高容量记得是1.44MB，这还是200X年的软盘，以前的软盘容量具体多大就不知道了，Phil Katz上网的时候还不到1990年，WWW实际上就没出现，浏览器当然是没有的，当时上网干嘛呢？基本就是类似于网管敲各种命令，这样实际上也可以聊天、上论坛不是吗，传个文件不压缩的话肯定死慢死慢的，所以压缩在那个时代很重要。当时有个商业公司提供了一种称为ARC的压缩软件，可以让你在那个时代聊天更快，当然是要付费的，Phil Katz就感觉到不爽，于是写了一个PKARC，免费的，看名字知道是兼容ARC的，于是网友都用PKARC了，ARC那个公司自然就不爽，把哥们告上了法庭，说牵涉了知识产权等等，结果Phil Katz坐牢了。。。牛人就是牛人， 在牢里面冥思苦想，决定整一个超越ARC的牛逼算法出来，牢里面就是适合思考，用了两周就整出来的，称为PKZIP，不仅免费，而且这次还开源了，直接公布源代码，因为算法都不一样了，也就不涉及到知识产权了，于是ZIP流行开来，不过Phil Katz这个人没有从里面赚到一分钱，还是穷困潦倒，因为喝酒过多等众多原因，2000年的时候死在一个汽车旅馆里。英雄逝去，精神永存，现在我们用UE打开ZIP文件，我们能看到开头的两个字节就是PK两个字符的ASCII码。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、一个案例的入门思考&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;好了，Phil Katz在牢里面到底思考了什么？用什么样的算法来压缩数据呢？我们想一个简单的例子：&lt;/p&gt;
&lt;p&gt;生，容易。活，容易。生活，不容易。&lt;/p&gt;
&lt;p&gt;上面这句话假如不压缩，如果使用Unicode编码，每个字会用2个字节表示。为什么是两个字节呢？Unicode是一种国际标准，把常见各国的字符，比如英文字符、日文字符、韩文字符、中文字符、拉丁字符等等全部制定了一个标准，显然，用2个字节可以最多表示2^16=65536个字符，那么65536就够了吗？生僻字其实是很多的，比如光康熙字典里面收录的汉字就好几万，所以实际上是不够的，那么是不是扩到4个字节？也可以，这样空间倒是变大了，可以收录更多字符，但一方面扩到4个字节就一定保证够吗？另一方面，4个字节是不是太浪费空间了，就为了那些一般情况都不会出现的生僻字？所以，一般情况下，使用2个字节表示，当出现生僻字的时候，再使用4个字节表示。这实际上就体现了信息论中数据压缩基本思想，出现频繁的那些字符，表示得短一些；出现稀少的，可以表示得长些（反正一般情况下也不会出现），这样整体长度就会减小。除了Unicode，ASCII编码是针对英文字符的编码方案，用1个字节即可，除了这两种编码方案，还有很多地区性的编码方案，比如GB2312可以对中文简体字进行编码，Big5可以对中文繁体字进行编码。两个文件如果都使用一种编码方案，那是没有问题的，不过考虑到国际化，还是尽量使用Unicode这种国际标准吧。不过这个跟ZIP没啥关系，纯属背景介绍。&lt;/p&gt;
&lt;p&gt;好了，回到我们前面说的例子，一共有17个字符（包括标点符号），如果用普通Unicode表示，一共是17*2=34字节。可不可以压缩呢？所有人一眼都可以看出里面出现了很多重复的字符，比如里面出现了好多次容易（实际上是容易加句号三个字符）这个词，第一次出现的时候用普通的Unicode，第二次出现的“容易。”则可以用（距离、长度）表示，距离的意思是接下来的字符离前面重复的字符隔了几个，长度则表示有几个重复字符，上面的例子的第二个“容易。”就表示为（5,3），就是距离为5个字符，长度是3，在解压缩的时候，解到这个地方的时候，往前跳5个字符，把这个位置的连续3个字符拷贝过来就完成了解压缩，这实际上不就是指针的概念？没有错，跟指针很类似，不过在数据压缩领域，一般称为字典编码，为什么叫字典呢，当我们去查一个字的时候，我们总是先去目录查找这个字在哪一页，再翻到那一页去看，指针不也是这样，指针不就是内存的地址，要对一个内存进行操作，我们先拿到指针，然后去那块内存去操作。所谓的指针、字典、索引、目录等等术语，不同的背景可能称呼不同，但我们要理解他们的本质。如果使用（5,3）这种表示方法，原来需要用6个字节表示，现在只需要记录5和3即可。那么，5和3怎么记录呢？一种方法自然还是可以用Unicode，那么就相当于节省了2个字节，但是有两个问题，第一个问题是解压缩的时候怎么知道是正常的5和3这两个字符，还是这只是一个特殊标记呢？所以前面还得加一个标志来区分一下，到底接下来的Unicode码是指普通字符，还是指距离和长度，如果是普通Unicode，则直接查Unicode码表，如果是距离和长度，则往前面移动一段距离，拷贝即可。第二个问题，还是压缩程度不行，这么一弄，感觉压缩不了多少，如果重复字符比较长那倒是比较划算，因为反正“距离+长度”就够了，但比如这个例子，如果5和3前面加一个特殊字节，岂不是又是3个字节，那还不如不压缩。咋办呢？能不能对（5,3）这种整数进行再次压缩？这里就利用了我们前面说的一个基本原则：出现的少的整数多编一些比特，出现的多的整数少编一些比特。那么，比如3、4、5、6、7、8、9这些距离谁出现得多？谁出现的少呢？谁知道？&lt;/p&gt;
&lt;p&gt;压缩之前当然不知道，不过扫描一遍不就知道了？比如，后面那个重复的字符串“容易。”按照前面的规则可以表示为（7,3）,即离前面重复的字符串距离为7，长度为3。（7,3）指着前面跟自己一样那个字符串。那么，为什么不指着第一个“容易。”要指着第二个“容易。”呢？如果指着第一个，那就不是（7,3）了，就是（12，3）了。当然，表示为（12,3）也可以解压缩，但是有一个问题，就是12这个值比7大，大了又怎么了？我们在生活中会发现一些普遍规律，重复现象往往具有局部性。比如，你跟一个人说话，你说了一句话以后，往往很快会重复一遍，但是你不会隔了5个小时又重复这句话，这种特点在文件里面也存在着，到处都是这种例子，比如你在编程的时候，你定义了一个变量int nCount，这个nCount一般你很快就会用到，不会离得很远。我们前面所说的距离代表了你隔了多久再说这句话，这个距离一般不大，既然如此，应该以离当前字符串距离最近的那个作为记录的依据（也就是指向离自己最近那个重复字符串），这样的话，所有的标记都是一些短距离，比如都是3、4、5、6、7而不会是3、5、78、965等等，如果大多数都是一些短距离，那么这些短距离就可以用短一些的比特表示，长一些的距离不太常见，则用一些长一些的比特表示。这样， 总体的表示长度就会减少。好了，我们前面得到了（5,3）、（7、3）这种记录重复的表示，距离有两种：5、7；长度只有1种：3。咋编码？越短越好。&lt;/p&gt;
&lt;p&gt;既然表示的比特越短越好，3表示为0、5表示为10、7表示为11，行不行？这样（5,3）,（7,3）就只需要表示为100、110，这样岂不是很短？貌似可以，貌似很高效。&lt;/p&gt;
&lt;p&gt;但解压缩遇到10这两个比特的时候，怎么知道10表示5呢？这种表示方法是一个映射表，称为码表。我们设计的上面这个例子的码表如下：&lt;/p&gt;
&lt;p&gt;3–&amp;gt;0&lt;/p&gt;
&lt;p&gt;5–&amp;gt;10&lt;/p&gt;
&lt;p&gt;7–&amp;gt;11&lt;/p&gt;
&lt;p&gt;这个码表也得传过去或者记录在压缩文件里才行啊，否则无法解压缩，但会不会记录了码表以后整体空间又变大了，会不会起不到压缩的作用？而且一个码表怎么记录？码表记录下来也是一堆数据，是不是也需要编码？码表是否可以继续压缩？那岂不是又需要新的码表？压缩会不会是一个永无止境的过程？作为一个入门级的同学，大概想到这儿就不容易想下去了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、ZIP中的LZ编码思想&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上面我们说的重复字符串用指针标记记录下来，这种方法就是LZ这两个人提出来的，理解起来比较简单。后面分析（5,3）这种指针标记应该怎么编码的时候，就涉及到一种非常广泛的编码方式，Huffman编码，Huffman大致和香农是一个时代的人，这种编码方式是他在MIT读书的时候提出来的。接下来，我们来看看ZIP是怎么做的。&lt;/p&gt;
&lt;p&gt;以上面的例子，一个很简单的示意图如下：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a35a6bf1bc4ead9d42ff2b56dcf3f1bc.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看出，ZIP中使用的LZ77算法和前面分析的类似，当然，如果仔细对比的话，ZIP中使用的算法和LZ提出来的LZ77算法其实还是有差异的，不过我建议不用仔细去扣里面的差异，思想基本是相同的，我们后面会简要分析一下两者的差异。LZ77算法一般称为“滑动窗口压缩”，我们前面说过，该算法的核心是在前面的历史数据中寻找重复字符串，但如果要压缩的文件有100MB，是不是从文件头开始找？不是，这里就涉及前面提过的一个规律，重复现象是具有局部性的，它的基本假设是，如果一个字符串要重复，那么也是在附近重复，远的地方就不用找了，因此设置了一个滑动窗口，ZIP中设置的滑动窗口是32KB，那么就是往前面32KB的数据中去找，这个32KB随着编码不断进行而往前滑动。当然，理论上讲，把滑动窗口设置得很大，那样就有更大的概率找到重复的字符串，压缩率不就更高了？初看起来如此，找的范围越大，重复概率越大，不过仔细想想，可能会有问题，一方面，找的范围越大，计算量会增大，不顾一切地增大滑动窗口，甚至不设置滑动窗口，那样的软件可能不可用，你想想，现在这种方式，我们在压缩一个大文件的时候，速度都已经很慢了，如果增大滑动窗口，速度就更慢，从工程实现角度来说，设置滑动窗口是必须的；另一方面，找的范围越大，距离越远，出现的距离很多，也不利于对距离进行进一步压缩吧，我们前面说过，距离和长度最好出现的值越少越好，那样更好压缩，如果出现的很多，如何记录距离和长度可能也存在问题。不过，我相信滑动窗口设置得越大，最终的结果应该越好一些，不过应该不会起到特别大的作用，比如压缩率提高了5%，但计算量增加了10倍，这显然有些得不偿失。&lt;/p&gt;
&lt;p&gt;在第一个图中，“容易。”是一个重复字符串，距离distance=5，字符串长度length=3。当对这三个字符压缩完毕后，接下来滑动窗口向前移动3个字符，要压缩的是“我…”这个字符串，但这个串在滑动窗口内没找到，所以无法使用distance+length的方式记录。这种结果称为literal。literal的中文含义是原义的意思，表示没有使用distance+length的方式记录的那些普通字符。literal是不是就用原始的编码方式，比如Unicode方式表示？ZIP里不是这么做的，ZIP把literal认为也是一个数，尽管不能用distance+length表示，但不代表不可以继续压缩。另外，如果“我”出现在了滑动窗口内，是不是就可以用distance+length的方式表示？也不是，因为一个字出现重复，不值得用这种方式表示，两个字呢？distance+length就是两个整数，看起来也不一定值得，ZIP中确实认为2个字节如果在滑动窗口内找到重复，也不管，只有3个字节以上的重复字符串，才会用distance+length表示，重复字符串的长度越长越好，因为不管多长，都用distance+length表示就行了。&lt;/p&gt;
&lt;p&gt;这样的话，一段字符串最终就可以表示成literal、distance+length这两种形式了。LZ系列算法的作用到此为止，下面，Phil Katz考虑使用Huffman对上面的这些LZ压缩后的结果进行二次压缩。个人认为接下来的过程才是ZIP的核心，所以我们要熟悉一下Huffman编码。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4、ZIP中的Huffman编码思想&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上面LZ压缩结果有三类（literal、distance、length），我们拿出distance一类来举例。distance代表重复字符串离前一个一模一样的字符串之间的距离，是一个大于0的整数。如何对一个整数进行编码呢？一种方法是直接用固定长度表示，比如采用计算机里面描述一个4字节整数那样去记录，这也是可以的，主要问题当然是浪费存储空间，在ZIP中，distance这个数表示的是重复字符串之间的距离，显然，一般而言，越小的距离，出现的数量可能越多，而越大的距离，出现的数量可能越少，那么，按照我们前面所说的原则，小的值就用较少比特表示，大的值就用较多比特表示，在我们这个场景里，distance当然也不会无限大，比如不会超过滑动窗口的最大长度，假如对一个文件进行LZ压缩后，得到的distance值为：&lt;/p&gt;
&lt;p&gt;3、6、4、3、4、3、4、3、5&lt;/p&gt;
&lt;p&gt;这个例子里，3出现了4次，4出现了3次，5出现了1次，6出现了1次。当然，不同的文件得到的结果不同，这里只是举一个典型的例子，因为只有4种值，所以我们没有必要对其它整数编码。只需要对这4个整数进行编码即可。&lt;/p&gt;
&lt;p&gt;那么，怎么设计一个算法，符合3的编码长度最短？6的编码长度最长这种直观上可行的原则（我们并没有说这是理论上最优的方式）呢？&lt;/p&gt;
&lt;p&gt;看起来似乎很难想出来。我们先来简化一下，用固定长度表示。这里有4个整数，只要使用2个比特表示即可。于是这样表示就很简单：&lt;/p&gt;
&lt;p&gt;00–&amp;gt;3； 01–&amp;gt;4； 10–&amp;gt;5;  11–&amp;gt;6。&lt;/p&gt;
&lt;p&gt;00、01这种编码结果称为码字，码字的平均长度是2。上面这个对应关系即为码表，在压缩时，需要将码表放在最前面，后面的数字就用码字表示，解码时，先把码表记录在内存里，比如用一个哈希表记录下来，解压缩时，遇到00，就解码为3等等。&lt;/p&gt;
&lt;p&gt;因为出现了9个数，所以全部码字总长度为18个比特。（我们暂时不考虑记录码表到底要占多少空间）&lt;/p&gt;
&lt;p&gt;想要编码结果更短，因为3出现的最多，所以考虑把3的码字缩短点，比如3是不是可以用1个比特表示，这样才算缩短吧，因为0和1只是二进制的一个标志，所以用0还是1没有本质区别，那么，我们暂定把3用比特0表示。那么，4、5、6还能用0开头的码字表示呢？&lt;/p&gt;
&lt;p&gt;这样会存在问题，因为4、5、6的编码结果如果以0开头，那么，在解压缩的时候，遇到比特0，就不知道是表示3还是表示4、5、6了，就无法解码，当然，似乎理论上也不是不可以，比如可以往后解解看，比如假定0表示3的条件下往后解，如果无效则说明这个假设不对，但这种方式很容易出现两个字符串的编码结果是一样的，这个谁来保证？所以，4、5、6都得以1开头才行，那么，按照这个原则，4用1个比特也不行，因为5、6要么以0开头，要么以1开头，就无法编码了，所以我们将4的码字增加至2个比特，比如10，于是我们得到了部分码表:&lt;/p&gt;
&lt;p&gt;0–&amp;gt;3；10–&amp;gt;4。&lt;/p&gt;
&lt;p&gt;按照这个道理，5、6既不能以0开头，也不能以10开头了，因为同样存在无法解码的问题，所以5应该以11开头，就定为11行不行呢？也不行，因为6就不知道怎么编码了，6也不能以0开头，也不能以10、11开头，那就无法表示了，所以，迫不得已，我们必须把5扩展一位，比如110，那么，6显然就可以用111表示了，反正也没有其他数了。于是我们得到了最终的码表：&lt;/p&gt;
&lt;p&gt;0–&amp;gt;3；10–&amp;gt;4；110–&amp;gt;5；111–&amp;gt;6。&lt;/p&gt;
&lt;p&gt;看起来，编码结果只能是这样了，我们来算一下，码字的总长度减少了没有，原来的9个数是3、6、4、3、4、3、4、3、5，分别对应的码字是：&lt;/p&gt;
&lt;p&gt;0、111、10、0、10、0、10、0、110&lt;/p&gt;
&lt;p&gt;算一下，总共16个比特，果然比前面那种方式变短了。我们在前面的设计过程中，是按照这些值出现次数由高到底的顺序去找码字的，比如先确定3，再确定4、5、6等等。按照一个码字不能是另一个码字的前缀这一规则，逐步获得所有的码字。这种编码规则有一个专用术语，称为前缀码。Huffman编码基本上就是这么做的，把出现频率排个序，然后逐个去找，这个逐个去找的过程，就引入了二叉树。不过Huffman的算法一般是从频率由低到高排序，从树的下面依次往上合并，不过本质上没区别，理解思想即可。上面的结果可以用一颗二叉树表示为下图：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/863e337f5fea5a7ceff50e21f7206fef.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这棵树也称为码树，其实就是码表的一种形式化描述，每个节点（除了叶子节点）都会分出两个分支，左分支代表比特0，右边分支代表1，从根节点到叶子节点的一个比特序列就是码字。因为只有叶子节点可以是码字，所以这样也符合一个码字不能是另一个码字的前缀这一原则。说到这里，可以说一下另一个话题，就是一个映射表map在内存中怎么存储，没有相关经验的可以跳过，map实现的是key–&amp;gt;value这样的一个表，map的存储一般有哈希表和树形存储两类，树形存储就可以采用上面这棵树，树的中间节点并没有什么含义，叶子节点的值表示value，从根节点到叶子节点上分支的值就是key，这样比较适合存储那些key由多个不等长字符组成的场合，比如key如果是字符串，那么把二叉树的分支扩展很多，成为多叉树，每个分支就是a,b,c,d这种字符，这棵树也就是Trie树，是一种很好使的数据结构。利用树的遍历算法，就实现了一个有序Map。&lt;/p&gt;
&lt;p&gt;好了，我们理解了Huffman编码的思想，我们来看看distance的实际情况。ZIP中滑动窗口大小固定为32KB，也就是说，distance的值范围是1-32768。那么，通过上面的方式，统计频率后，就得到32768个码字，按照上面这种方式可以构建出来。于是我们会遇到一个最大的问题，那就是这棵树太大了，怎么记录呢？&lt;/p&gt;
&lt;p&gt;好了，个人认为到了ZIP的核心了，那就是码树应该怎么缩小，以及码树怎么记录的问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5、ZIP中Huffman码树的记录方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;分析上面的例子，看看这个码表：&lt;/p&gt;
&lt;p&gt;0–&amp;gt;3；10–&amp;gt;4；110–&amp;gt;5；111–&amp;gt;6。&lt;/p&gt;
&lt;p&gt;我们之前提过，0和1就是二进制的一个标志，互换一下其实根本不影响编码长度，所以，下面的码表其实是一样的：&lt;/p&gt;
&lt;p&gt;1–&amp;gt;3；00–&amp;gt;4；010–&amp;gt;5；011–&amp;gt;6。&lt;/p&gt;
&lt;p&gt;1–&amp;gt;3；01–&amp;gt;4；000–&amp;gt;5；001–&amp;gt;6。&lt;/p&gt;
&lt;p&gt;0–&amp;gt;3；11–&amp;gt;4；100–&amp;gt;5；101–&amp;gt;6。&lt;/p&gt;
&lt;p&gt;。。。。。&lt;/p&gt;
&lt;p&gt;这些都可以，而且编码长度完全一样，只是码字不同而已。&lt;/p&gt;
&lt;p&gt;对比一下第一个和第二个例子，对应的码树是这个样子：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/df583cc070a2cd35e2a3282c5f62a936.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;也就是说，我们把码树的任意节点的左右分支旋转（0、1互换），也可以称为树的左右互换，其实不影响编码长度，也就是说，这些码表其实都是一样好的，使用哪个都可以。&lt;/p&gt;
&lt;p&gt;这个规律暗示了什么信息呢？暗示了码表可以怎么记录呢？Phil Katz当年在牢里也深深地思考了这一问题。&lt;/p&gt;
&lt;p&gt;为了体会Phil Katz当时的心情，我们有必要盯着这两棵树思考几分钟：怎么把一颗树用最少的比特记录下来？&lt;/p&gt;
&lt;p&gt;Phil Katz当时思考的逻辑我猜是这样的，既然这些树的压缩程度都一样，那干脆使用最特殊的那棵树，反正压缩程度都一样，只要ZIP规定了这棵树的特殊性，那么我记录的信息就可以最少，这种特殊化的思想在后面还会看到。不同的树当然有不同的特点，比如数据结构里面常见的平衡树也是一类特殊的树，他选的树就是左边那棵，这棵树有一个特点，越靠左边越浅，越往右边越深，是这些树中最不平衡的树。ZIP里的压缩算法称为Deflate算法，这棵树也称为Deflate树，对应的解压缩算法称为Inflate，Deflate的大致意思是把轮胎放气了，意为压缩；Inflate是给轮胎打气的意思，意为解压。那么，Deflate树的特殊性又带来什么了？&lt;/p&gt;
&lt;p&gt;揭晓答案吧，Phil Katz认为换来换去只有码字长度不变，如果规定了一类特殊的树，那么就只需要记录码字长度即可。比如，一个有效的码表是0–&amp;gt;3；10–&amp;gt;4；110–&amp;gt;5；111–&amp;gt;6。但只需要记录这个对应关系即可：&lt;/p&gt;
&lt;p&gt;3　　4　　5　　6&lt;/p&gt;
&lt;p&gt;1　　2　　3　　3&lt;/p&gt;
&lt;p&gt;也就是说，把1、2、3、3记录下来，解压一边照着左边那棵树的形状构造一颗树，然后只需要1、2、3、3这个信息自然就知道是0、10、110、111。这就是Phil Katz想出来的ZIP最核心的一点：这棵码树用码字长度序列记录下来即可。&lt;/p&gt;
&lt;p&gt;当然，只把1、2、3、3这个序列记录下来还不行，比如不知道111对应5还是对应6？&lt;/p&gt;
&lt;p&gt;所以，构造出树来只是知道了有哪些码字了，但是这些码字到底对应哪些整数还是不知道。&lt;/p&gt;
&lt;p&gt;Phil Katz于是又出现了一个想法：记录1、2、3、3还是记录1、3、2、3，或者3、3、2、1，其实都能构造出这棵树来，那么，为什么不按照一个特殊的顺序记录呢？这个顺序就是整数的大小顺序，比如上面的3、4、5、6是整数大小顺序排列的，那么，记录的顺序就是1、2、3、3。而不是2、3、3、1。&lt;/p&gt;
&lt;p&gt;好了，根据1、2、3、3这个信息构造出了码字，这些码字对应的整数一个比一个大，假如我们知道编码前的整数就是3、4、5、6这四个数，那就能对应起来了，不过到底是哪四个还是不知道啊？这个整数可以表示距离啊，距离不知道怎么去解码LZ？&lt;/p&gt;
&lt;p&gt;Phil Katz又想了，既然distance的范围是1-32768，那么就按照这个顺序记录。上面的例子1和2没有，那就记录长度0。所以记录下来的码字长度序列为：&lt;/p&gt;
&lt;p&gt;0、0、1、2、3、3、0、0、0、0、0、。。。。。。。。。。。。&lt;/p&gt;
&lt;p&gt;这样就知道构造出来的码字对应哪个整数了吧，但因为distance可能的值很多（32768个），但实际出现的往往不多，中间会出现很多0（也就是根本就没出现这个距离），不过这个问题倒是可以对连续的0做个特殊标记，这样是不是就行了呢？还有什么问题？&lt;/p&gt;
&lt;p&gt;我们还是要站在时代的高度来看待这个问题。我们明白，每个distance肯定对应唯一一个码字，使用Huffman编码可以得到所有码字，但是因为distance可能非常多，虽然一般不会有32768这么多，但对一个大些的文件进行LZ编码，distance上千还是很正常的，所以这棵树很大，计算量、消耗的内存都容易超越了那个时代的硬件条件，那么怎么办呢？这里再次体现了Phil Katz对Huffman编码掌握的深度，他把distance划分成多个区间，每个区间当做一个整数来看，这个整数称为Distance Code。当一个distance落到某个区间，则相当于是出现了那个Code，多个distance对应于一个Distance Code，Distance虽然很多，但Distance Code可以划分得很少，只要我们对Code进行Huffman编码，得到Code的编码后，Distance Code再根据一定规则扩展出来。那么，划分多少个区间？怎么划分区间呢？我们分析过，越小的距离，出现的越多；越大的距离，出现的越少，所以这种区间划分不是等间隔的，而是越来越稀疏的，类似于下面的划分：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/aed9417c727ee2973c9961a4aabc27ae.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;1、2、3、4这四个特殊distance不划分，或者说1个Distance就是1个区间；5,6作为一个区间；7、8作为一个区间等等，基本上，区间的大小都是1、2、4、8、16、32这么递增的，越往后，涵盖的距离越多。为什么这么分呢？首先自然是距离越小出现频率越高，所以距离值小的时候，划分密一些，这样相当于一个放大镜，可以对小的距离进行更精细地编码，使得其编码长度与其出现次数尽量匹配；对于距离较大那些，因为出现频率低，所以可以适当放宽一些。另一个原因是，只要知道这个区间Code的码字，那么对于这个区间里面的所有distance，后面追加相应的多个比特即可，比如，17-24这个区间的Huffman码字是110，因为17-24这个区间有8个整数，于是按照下面的规则即可获得其distance对应的码字：&lt;/p&gt;
&lt;p&gt;17–&amp;gt;110 000&lt;/p&gt;
&lt;p&gt;18–&amp;gt;110 001&lt;/p&gt;
&lt;p&gt;19–&amp;gt;110 010&lt;/p&gt;
&lt;p&gt;20–&amp;gt;110 011&lt;/p&gt;
&lt;p&gt;21–&amp;gt;110 100&lt;/p&gt;
&lt;p&gt;22–&amp;gt;110 101&lt;/p&gt;
&lt;p&gt;23–&amp;gt;110 110&lt;/p&gt;
&lt;p&gt;24–&amp;gt;110 111&lt;/p&gt;
&lt;p&gt;这样计算复杂度和内存消耗是不是很小了，因为需要进行Huffman编码的整数一下字变少了，这棵树不会多大，计算起来时间和空间复杂度降低，扩展起来也比较简单。当然，从理论上来说，这样的编码方式实际上将编码过程分为了两级，并不是理论上最优的，把所有distance当作一个大空间去编码才可能得到最优结果，不过还是那句话，工程实现的限制，在压缩软件实现上，我们不能用压缩率作为衡量一个算法优劣的唯一指标，其实耗费的时间和空间同样是指标，所以需要看综合指标。很多其他软件也一样，扩展性、时间空间复杂度、稳定性、移植性、维护的方便性等等是工程上很重要的东西。我没有看过RAR是如何压缩的，有可能是在类似的地方进行了改进，如果如此，那也是站在巨人的肩膀上，而且硬件条件不同，进行一些改进也并不奇怪。&lt;/p&gt;
&lt;p&gt;具体来说，Phil Katz把distance划分为30个区间，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8ac98d03afca5bbbd88b401d5ba15fe9.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个图是我从David Salomon的《Data Compression The Complete Reference》这本书（第四版）中拷贝出来的，下面的有些图也是，如果需要对数据压缩进行全面的了解，这本书几乎是最全的了，强烈推荐。&lt;/p&gt;
&lt;p&gt;当然，你要问为什么是30个区间，我也没分析过，也许是复杂度和压缩率经过试验之后的一种折中吧。&lt;/p&gt;
&lt;p&gt;其中，左边的Code表示区间的编号，是0-29，共30个区间，这只是个编号，没有特别的含义，但Huffman就是对0-29这30个Code进行编码的，得到区间的码字；&lt;/p&gt;
&lt;p&gt;bits表示distance的码字需要在Code的码字基础上扩展几位，比如0就表示不扩展，最大的13表示要扩展13位，因此，最大的区间包含的distance数量为8192个。&lt;/p&gt;
&lt;p&gt;Distance一列则表示这个区间涵盖的distance范围。&lt;/p&gt;
&lt;p&gt;理解了码树如何有效记录，以及如何缩小码树的过程，我觉得就理解了ZIP的精髓。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6、ZIP中literal和length的压缩方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;说完了distance，LZ编码结果还有两类：literal和length。这两类也利用了类似于distance的方式进行压缩。&lt;/p&gt;
&lt;p&gt;前面分析过，literal表示未匹配的字符，我们前面之所以拿汉字来举例，完全是为了便于理解，ZIP之所以是通用压缩，它实际上是针对字节作为基本字符来编码的，所以一个literal至多有256种可能。&lt;/p&gt;
&lt;p&gt;length表示重复字符串长度，length=1当然不会出现，因为一个字符不值得用distance+length去记录，重复字符串当然越长越好，Phil Katz（下面还是简称PK了，拷贝太麻烦）认为，length=2也不值得用这种方式记录，还是太短了，所以PK把length最小值认为是3，必须3个以上字符的字符串出现重复才用distance+length记录。那么，最大的length是多少呢？理论上当然可以很长很长，比如一个文件就是连续的0，这个重复字符串长度其实接近于这个文件的实际长度。但是PK把length的范围做了限制，限定length的个数跟literal一样，也只有256个，因为PK认为，一个重复字符串达到了256个已经很长了，概率非常小；另外，其实哪怕超过了256，我还是认为是一段256再加上另外一段，增加一个distance+length就行了嘛，并不影响结果。而且这样做，我想同样也考虑了硬件条件吧。&lt;/p&gt;
&lt;p&gt;初看有点奇怪的在于，将literal和length二者合二为一，什么意思呢？就是对这两种整数（literal本质上是一个字节）共用一个Huffman码表，一会儿解释为什么。PK对Huffman的理解我觉得达到了炉火纯青的地步，前面已经看到，后面还会看到。他认为Huffman编码的输入反正说白了就是一个集合的元素就行，无论这个元素是啥，所以多个集合看做一个集合当作Huffman编码的输入没啥问题。literal用整数0-255表示，256是一个结束标志，解码以后结果是256表示解码结束；从257开始表示length，所以257这个数表示length=3，258这个数表示length=4等等，但PK也不是一直这么一一对应，和distance一样，也是把length（总共256个值）划分为29个区间，其结果如下图：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/e04c89d2af7ffd0a9f0bc92a1e6eb82c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;其中的含义和distance类似，不再赘述，所以literal/length这个Huffman编码的输入元素一共285个，其中256表示解码结束标志。为什么要把二者合二为一呢？因为当解码器接收到一个比特流的时候，首先可以按照literal/length这个码表来解码，如果解出来是0-255，就表示未匹配字符，如果是256，那自然就结束，如果是257-285之间，则表示length，把后面扩展比特加上形成length后，后面的比特流肯定就表示distance，因此，实际上通过一个Huffman码表，对各类情况进行了统一，而不是通过加一个什么标志来区分到底是literal还是重复字符串。&lt;/p&gt;
&lt;p&gt;好了，理解了上面的过程，就理解了ZIP压缩的第二步，第一步是LZ编码，第二步是对LZ编码后结果（literal、distance、length）进行的再编码，因为literal/length是一个码表，我称其为Huffman码表1，distance那个码表称为Huffman码表2。前面我们已经分析了，Huffman码树用一个码字长度序列表示，称为CL（Code Length），记录两个码表的码字长度序列分别记为CL1、CL2。码树记录下来，对literal/length的编码比特流称为LIT比特流；对distance的编码比特流称为DIST比特流。&lt;/p&gt;
&lt;p&gt;按照上面的方法，LZ的编码结果就变成四块：CL1、CL2、LIT比特流、DIST比特流。CL1、CL2是码字长度的序列，这个序列说白了就是一堆正整数，因此，PK继续深挖，认为这个序列还应该继续压缩，也就是说，对码表进行压缩。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7、ZIP中对CL进行再次压缩的方法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这里仍然沿用Huffman的想法，因为CL也是一堆整数，那么当然可以再次应用Huffman编码。不过在这之前，PK对CL序列进行了一点处理。这个处理也是很精巧的。&lt;/p&gt;
&lt;p&gt;CL序列表示一系列整数对应的码字长度，对于literal/length来说，总共有0-285这么多符号，所以这个序列长度为286，每个符号都有一个码字长度，当然，这里面可能会出现大段连续的0，因为某些字符或长度不存在，尤其是对英文文本编码的时候，非ASCII字符就根本不会出现，length较大的值出现概率也很小，所以出现大段的0是很正常的；对于distance也类似，也可能出现大段的0。PK于是先进行了一下游程编码。在说什么是游程编码之前，我们谈谈PK对CL序列的认识。&lt;/p&gt;
&lt;p&gt;literal/length的编码符号总共286个（回忆：256个Literal+1个结束标志+29个length区间），distance的编码符号总共30个（回忆：30个区间），所以这颗码树不会特别深，Huffman编码后的码字长度不会特别长，PK认为最长不会超过15，也就是树的深度不会超过15，这个是否是理论证明我还没有分析，有兴趣的同学可以分析一下。因此，CL1和CL2这两个序列的任意整数值的范围是0-15。0表示某个整数没有出现（比如literal=0×12, length Code=8, distance Code=15等等）。&lt;/p&gt;
&lt;p&gt;什么叫游程呢？就是一段完全相同的数的序列。什么叫游程编码呢？说起来原理更简单，就是对一段连续相同的数，记录这个数一次，紧接着记录出现了多少个即可。David的书中举了这个例子，比如CL序列如下：&lt;/p&gt;
&lt;p&gt;4, 4, 4, 4, 4, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2&lt;br&gt;
那么，游程编码的结果为：&lt;/p&gt;
&lt;p&gt;4, 16, 01（二进制）, 3, 3, 3, 6, 16, 11（二进制）, 16, 00（二进制）, 17,011（二进制）, 2, 16, 00（二进制）&lt;br&gt;
这是什么意思呢？因为CL的范围是0-15，PK认为重复出现2次太短就不用游程编码了，所以游程长度从3开始。用16这个特殊的数表示重复出现3、4、5、6个这样一个游程，分别后面跟着00、01、10、11表示（实际存储的时候需要低比特优先存储，需要把比特倒序来存，博文的一些例子有时候会忽略这点，实际写程序的时候一定要注意，否则会得到错误结果）。于是4,4,4,4,4,这段游程记录为4,16,01，也就是说，4这个数，后面还会连续出现了4次。6,16,11,16,00表示6后面还连续跟着6个6，再跟着3个6；因为连续的0出现的可能很多，所以用17、18这两个特殊的数专门表示0游程，17后面跟着3个比特分别记录长度为3-10（总共8种可能）的游程；18后面跟着7个比特表示11-138（总共128种可能）的游程。17,011（二进制）表示连续出现6个0；18,0111110（二进制）表示连续出现62个0。总之记住，0-15是CL可能出现的值，16表示除了0以外的其它游程；17、18表示0游程。因为二进制实际上也是个整数，所以上面的序列用整数表示为：&lt;/p&gt;
&lt;p&gt;4, 16, 1, 3, 3, 3, 6, 16, 3, 16, 0, 17, 3, 2, 16, 0&lt;/p&gt;
&lt;p&gt;我们又看到了一串整数，这串整数的值的范围是0-18。这个序列称为SQ（Sequence的意思）。因为有两个CL1、CL2，所以对应的有两个SQ1、SQ2。&lt;/p&gt;
&lt;p&gt;针对SQ1、SQ2，PK用了第三个Huffman码表来对这两个序列进行编码。通过统计各个整数（0-18范围内）的出现次数，按照相同的思路，对SQ1和SQ2进行了Huffman编码，得到的码流记为SQ1 bits和SQ2 bits。同时，这里又需要记录第三个码表，称为Huffman码表3。同理，这个码表也用相同的方法记录，也等效为一个码长序列，称为CCL，因为至多有0-18个，PK认为树的深度至多为7，于是CCL的范围是0-7。&lt;/p&gt;
&lt;p&gt;当得到了CCL序列后，PK决定不再折腾，对这个序列用普通的3比特定长编码记录下来即可，即000代表0,111代表7。但实际上还有一点小折腾，就是最后这个序列如果全部记录，那就需要19*3=57个比特，PK认为CL序列里面CL范围为0-15，特殊的几个值是16、17、18，如果把CCL序列位置置换一下，把16、17、18这些放前面，那么这个CCL序列就很可能最后面跟着一串0（因为CL=14,15这些很可能没有），所以最后还引入了一个置换，其示意图如下，分别表示置换前的CCL序列和置换后的CCL。可以看出，16、17、18对应的CCL被放到了前面，这样如果尾部出现了一些0，就只需要记录CCL长度即可，后面的0不记录。可以继续节省一些比特，不过这个例子尾部置换后只有1个0：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/122722c8c4fe04fbf02d43bb3de3edd2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;不过粗看起来，这个置换效果并不好，我一开始接触这个置换的时候，我觉得应该按照16、17、18、0、1、2、3、。。。这样的顺序来存储，如果按照我理解的，那么置换后的结果如下：&lt;/p&gt;
&lt;p&gt;2、4、0、4、5、5、1、5、0、6、0、0、0、0、0、0、0、0、0&lt;/p&gt;
&lt;p&gt;这样后面的一大串0直接截断，比PK的方法更短。但PK却按照上面的顺序。我总是认为，我觉得牛人可能出错了的时候，往往是我自己错了，所以我又仔细想了一下，上面的顺序特点比较明显，直观上看，PK认为CL为0和中间的值出现得比较多（放在了前面），但CL比较小的和比较大的出现得比较少（1、15、2、14这些放在了后面，你看，后面交叉着放），在文件比较小的时候，这种方法效果不算好，上面就是一个典型的例子，但文件比较大了以后，CL1、CL2码树比较大，码字长度普遍比较长，大部分很可能接近于中间值，那么这个时候PK的方法可能就体现出优势了。不得不说，对一个算法或者数据结构的优化程度，简直完全取决于程序员对那个东西细节的理解的深度。当我仔细研究了ZIP压缩算法的过程之后，我对PK这种深夜埋头冥思苦想的大牛佩服得五体投地。&lt;/p&gt;
&lt;p&gt;到此为止，ZIP压缩算法的结果已经完毕。这个算法命名为Deflate算法。总结一下其编码流程为：&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/7e2d9cb3c7e30c2383c6fcd6e192c837.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8、Deflate压缩数据格式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ZIP的格式实际上就是Deflate压缩码流外面套了一层文件相关的信息，这里先介绍Deflate压缩码流格式。其格式为：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/401ab474f8d16a4bd37a965cb9251d2e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;Header：3个比特，第一个比特如果是1，表示此部分为最后一个压缩数据块；否则表示这是.ZIP文件的某个中间压缩数据块，但后面还有其他数据块。这是ZIP中使用分块压缩的标志之一；第2、3比特表示3个选择：压缩数据中没有使用Huffman、使用静态Huffman、使用动态Huffman，这是对LZ77编码后的literal/length/distance进行进一步编码的标志。我们前面分析的都是动态Huffman，其实Deflate也支持静态Huffman编码，静态Huffman编码原理更为简单，无需记录码表（因为PK自己定义了一个固定的码表），但压缩率不高，所以大多数情况下都是动态Huffman。&lt;/p&gt;
&lt;p&gt;HLIT：5比特，记录literal/length码树中码长序列（CL1）个数的一个变量。后面CL1个数等于HLIT+257（因为至少有0-255总共256个literal，还有一个256表示解码结束，但length的个数不定）。&lt;/p&gt;
&lt;p&gt;HDIST：5比特，记录distance码树中码长序列（CL2）个数的一个变量。后面CL2个数等于HDIST+1。哪怕没有1个重复字符串，distance都为0也是一个CL。&lt;/p&gt;
&lt;p&gt;HCLEN：4比特，记录Huffman码表3中码长序列（CCL）个数的一个变量。后面CCL个数等于HCLEN+4。PK认为CCL个数不会低于4个，即使对于整个文件只有1个字符的情况。&lt;/p&gt;
&lt;p&gt;接下来是3比特编码的CCL，一共HCLEN+4个，用以构造Huffman码表3；&lt;/p&gt;
&lt;p&gt;接下来是对CL1（码长）序列经过游程编码（SQ1：缩短的整数序列）后，并对SQ1继续用Huffman编码后的比特流。包含HLIT+257个CL1，其解码码表为Huffman码表3，用以构造Huffman码表1；&lt;/p&gt;
&lt;p&gt;接下来是对CL2（码长）序列经过游程编码（SQ2：缩短的整数序列）后，并对SQ2继续用Huffman编码后的比特流。包含HDIST+1个CL2，其解码码表为Huffman码表3，用于构造Huffman码表2；&lt;/p&gt;
&lt;p&gt;总之，上面的数据都是为了构造LZ解码需要的2个Huffman码表。&lt;/p&gt;
&lt;p&gt;接下来才是经过Huffman编码的压缩数据，解码码表为Huffman码表1和码表2。&lt;br&gt;
最后是数据块结束标志，即literal/length这个码表输入符号位256的编码比特。&lt;br&gt;
对倒数第1、2内容块进行解码时，首先利用Huffman码表1进行解码，如果解码所得整数位于0-255之间，表示literal未匹配字符，接下来仍然利用Huffman码表1解码；如果位于257-285之间，表示length匹配长度，之后需要利用Huffman码表2进行解码得到distance偏移距离；如果等于256，表示数据块解码结束。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9、ZIP文件格式解析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上面各节对ZIP的原理进行了分析，这一节我们来看一个实际的例子，为了更好地描述，我们尽量把这个例子举得简单一些。下面是我随便从一本书拷贝出来的一段较短的待压缩的英文文本数据：&lt;/p&gt;
&lt;p&gt;As mentioned above,there are many kinds of wireless systems other than cellular.&lt;/p&gt;
&lt;p&gt;这段英文文本长度为80字节。经过ZIP压缩后，其内容如下：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0b188984a5cf3f5679b36fecc9156d50.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看到，第1、2字节就是PK。看着怎么比原文还长，这怎么叫压缩？实际上，这里面大部分内容是ZIP的文件标记开销，真正压缩的内容（也就是我们前面提到的Deflate数据，划线部分都是ZIP文件开销）其实肯定要比原文短（否则ZIP不会启用压缩），我们这个例子是个短文本，但对于更长的文本而言，那ZIP文件总体长度肯定是要短于原始文本的。上面的这个ZIP文件，可以看到好几个以PK开头的区域，也就是不同颜色的划线区域，这些其实都是ZIP文件本身的开销。&lt;/p&gt;
&lt;p&gt;所以，我们首先来看一看ZIP的格式，其格式定义为：&lt;/p&gt;
&lt;p&gt;[local file header 1]&lt;br&gt;
[file data 1]&lt;br&gt;
[data descriptor 1]&lt;br&gt;
……….&lt;br&gt;
[local file header n]&lt;br&gt;
[file data n]&lt;br&gt;
[data descriptor n]&lt;br&gt;
[archive decryption header]&lt;br&gt;
[archive extra data record]&lt;br&gt;
[central directory]&lt;br&gt;
[zip64 end of central directory record]&lt;br&gt;
[zip64 end of central directory locator]&lt;br&gt;
[end of central directory record]&lt;br&gt;
local file header+file data+data descriptor这是一段ZIP压缩数据，在一个ZIP文件里，至少有一段，至多那就不好说了，假如你要压缩的文件一共有10个，那这个地方至少会有10段，ZIP对每个文件进行了独立压缩，RAR在此进行了改进，将多个文件联合起来进行压缩，提高了压缩率。local file header的格式如下：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ce6fd139ff69b9b37b5e5c9c3fd1278f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;可见，起始的4个字节就是0×50（P）、0x4B（K）、0×03、0×04，因为是低字节优先，所以Signature=0x03044B50.接下来的内容按照上面的格式解析，十分简单，这个区域在上面ZIP数据的那个图里面是红色划线区域，之后则是压缩后的Deflate数据。在文件的尾部，还有ZIP尾部数据，上面这个例子包含了central directory和end of central directory record，一般这两部分也是必须的。central directory以0×50、0x4B、0×01、0×02开头；end of central directory record以0×50、0x4B、0×05、0×06开头，其含义比较简单，分别对应于上面ZIP数据那个图的蓝色和绿色部分，下面是两者的格式：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d8f0632867273d55816b5e6e84ffdcba.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;end of central directory record格式：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fa06aee528647baf2005197a1c311249.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这几张图是我从网上找的，写得比较清晰。对于其中的含义，解释起来也比较简单，我分析的结果如下：注意ZIP采用的低字节优先，在一个字节里面低位优先，需要反过来看。&lt;/p&gt;
&lt;p&gt;Local File Header: (38B,304b)&lt;br&gt;
00001010110100101100000000100000 (signature)&lt;br&gt;
0000000000010100 (version:20)&lt;br&gt;
0000000000000000 (generalBitFlag)&lt;br&gt;
0000000000001000 (compressionMethod:8)&lt;br&gt;
0100110110001110 (lastModTime:19854)&lt;br&gt;
0100010100100101 (lastModDate:17701)&lt;br&gt;
01010100101011010100001100111100 (CRC32)&lt;br&gt;
00000000000000000000000001001000 (compressedSize:72)&lt;br&gt;
00000000000000000000000001010000 (uncompressedSize:80)&lt;br&gt;
0000000000001000 (filenameLength:8)&lt;br&gt;
0000000000000000 (extraFieldLength:0)&lt;br&gt;
0010101010100110110011100010111001110100001011100001111000101110 (fileName:Test.txt)&lt;br&gt;
(extraField)&lt;/p&gt;
&lt;p&gt;Central File Header: (54B,432b)&lt;br&gt;
00001010110100101000000001000000 (signature)&lt;br&gt;
0000000000010100 (versionMadeBy:20)&lt;br&gt;
0000000000010100 (versionNeeded:20)&lt;br&gt;
0000000000000000 (generalBitFlag)&lt;br&gt;
0000000000001000 (compressionMethod:8)&lt;br&gt;
0100110110001110 (lastModTime:19854)&lt;br&gt;
0100010100100101 (lastModDate:17701)&lt;br&gt;
01010100101011010100001100111100 (CRC32)&lt;br&gt;
00000000000000000000000001001000 (compressedSize:72)&lt;br&gt;
00000000000000000000000001010000 (uncompressedSize:80)&lt;br&gt;
0000000000001000 (filenameLength:8)&lt;br&gt;
0000000000000000 (extraFieldLength:0)&lt;br&gt;
0000000000000000 (fileCommenLength:0)&lt;br&gt;
0000000000000000 (diskNumberStart)&lt;br&gt;
0000000000000001 (internalFileAttr)&lt;br&gt;
10000001100000000000000000100000 (externalFileAttr)&lt;br&gt;
00000000000000000000000000000000 (relativeOffsetLocalHeader)&lt;br&gt;
0010101010100110110011100010111001110100001011100001111000101110 (fileName:Test.txt)&lt;br&gt;
(extraField)&lt;br&gt;
(fileComment)&lt;/p&gt;
&lt;p&gt;end of Central Directory Record: (22B,176b)&lt;br&gt;
00001010110100101010000001100000 (signature)&lt;br&gt;
0000000000000000 (numberOfThisDisk:0)&lt;br&gt;
0000000000000000 (numberDiskCentralDirectory:0)&lt;br&gt;
0000000000000001 (EntriesCentralDirectDisk:1)&lt;br&gt;
0000000000000001 (EntriesCentralDirect:1)&lt;br&gt;
00000000000000000000000000110110 (sizeCentralDirectory:54)&lt;br&gt;
00000000000000000000000001101110 (offsetStartCentralDirectory:110)&lt;br&gt;
0000000000000000 (fileCommentLength:0)&lt;br&gt;
(fileComment)&lt;/p&gt;
&lt;p&gt;Local File Header Length:304&lt;br&gt;
Central File Header Length:432&lt;br&gt;
End Central Directory Record Length:176&lt;/p&gt;
&lt;p&gt;可见，开销总的长度为38+54+22=114字节，整个文件长度为186字节，因此Deflate压缩数据长度为72字节（576比特）。尽管这里看起来只是从80字节压缩到72字节，那是因为这是一段短文本，重复字符串出现较少，但如果文本较长，那压缩率就会增加，这里只是举个例子。&lt;/p&gt;
&lt;p&gt;下面对其中的关键部分，也就是Deflate压缩数据进行解析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10、Deflate解码过程实例分析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们按照ZIP格式把Deflate压缩数据（72字节）提取出来，如下（每行8字节）：&lt;/p&gt;
&lt;p&gt;1010100001010011100010111011000000000001000001000011000010100010&lt;br&gt;
1000101110101010011110110000000001100011101110000011100010100101&lt;br&gt;
0101001111001100000010001101001010010010000101101010101100001101&lt;br&gt;
1011110100011111100011101111111001110010011101110110011100010101&lt;br&gt;
0010110100010100101100110001100100000100110111101101111000011101&lt;br&gt;
0010001001100110111001000010011001101010101000110110000001110101&lt;br&gt;
0100011010010011100010110111001000111101101001011100101010010111&lt;br&gt;
0111000011111000011110000011010111001011011111111100100010001001&lt;br&gt;
1010001100001110000010101010111101101010100101111101011111100000&lt;/p&gt;
&lt;p&gt;Deflate格式除了上面的介绍，也可以参考RFC1951，解析如下：&lt;/p&gt;
&lt;p&gt;Header:101, 第一个比特是1，表示此部分为最后一个压缩数据块；后面的两个比特01表示采用动态哈夫曼、静态哈夫曼、或者没有编码的标志，01表示采用动态Huffman；在RFC1951里面是这么说明的：&lt;/p&gt;
&lt;p&gt;00 – no compression&lt;/p&gt;
&lt;p&gt;01 – compressed with fixed Huffman codes&lt;/p&gt;
&lt;p&gt;10 – compressed with dynamic Huffman codes&lt;/p&gt;
&lt;p&gt;11 – reserved (error)&lt;/p&gt;
&lt;p&gt;注意，这里需要按照低比特在先的方式去看，否则会误以为是静态Huffman。&lt;/p&gt;
&lt;p&gt;接下来：&lt;br&gt;
HLIT:01000,记录literal/length码树中码长序列个数的一个变量，表示HLIT=2（低位在前），说明后面存在HLIT + 257=259个CL1，CL1即0-258被编码后的长度，其中0-255表示Literal，256表示无效符号，257、258分别表示Length=3、4（length从3开始）。因此，这里实际上只出现了两种重复字符串的长度，即3和4。回顾这个图可以更清楚：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0fe32fd35ada370c12c83df70a8bfaf1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;继续：&lt;br&gt;
HDIST:01010,记录distance码树中码长序列个数的一个变量，表示HDIST=10，说明后面存在HDIST+1=11个CL2，CL2即Distance Code=0-10被编码的长度。&lt;/p&gt;
&lt;p&gt;继续：&lt;/p&gt;
&lt;p&gt;HCLEN:0111,记录Huffman码树3中码长序列个数的一个变量，表示HCLEN=14（1110二进制），即说明紧接着跟着HCLEN+4=18个CCL，前面已经分析过，CCL记录了一个Huffman码表，这个码表可以用一个码长序列表示，根据这个码长序列可以得到码表。于是接下来我们把后面的18*3=54个比特拷贝出来，上面的码流目前解析为下面的结果：&lt;/p&gt;
&lt;p&gt;101(Header) 01000(HLIT) 01010(HDIST) 0111(HCLEN)&lt;br&gt;
000 101 110 110 000 000 000 010 000 010 000 110 000 101 000 101 000 101 (CCL)&lt;br&gt;
110101010011110110000000001100011101110000011100010100101&lt;br&gt;
0101001111001100000010001101001010010010000101101010101100001101&lt;br&gt;
1011110100011111100011101111111001110010011101110110011100010101&lt;br&gt;
0010110100010100101100110001100100000100110111101101111000011101&lt;br&gt;
0010001001100110111001000010011001101010101000110110000001110101&lt;br&gt;
0100011010010011100010110111001000111101101001011100101010010111&lt;br&gt;
0111000011111000011110000011010111001011011111111100100010001001&lt;br&gt;
1010001100001110000010101010111101101010100101111101011111100000&lt;/p&gt;
&lt;p&gt;标准的CCL长度为19（回忆一下：CCL范围为0-18，按照整数大小排序记录各自的码字长度），因此最后一个补0。得到序列：&lt;/p&gt;
&lt;p&gt;000 101 110 110 000 000 000 010 000 010 000 110 000 101 000 101 000 101 000&lt;/p&gt;
&lt;p&gt;其长度分别为（低位在前）：&lt;br&gt;
0、5、3、3、0、0、0、2、0、2、0、3、0、5、0、5、0、5、0&lt;br&gt;
前面已经分析过，这个CCL序列实际上是经过一次置换操作得到的，需要进行相反的置换，置换后为：&lt;/p&gt;
&lt;p&gt;3、5、5、5、3、2、2、0、0、0、0、0、0、0、0、0、0、5、3&lt;br&gt;
这个就是对应于0-18的码字长度序列。&lt;br&gt;
根据Deflate树的构造方式，得到下面的码表（Huffman码表3）：&lt;/p&gt;
&lt;p&gt;00      &amp;lt;–&amp;gt;   5&lt;br&gt;
01      &amp;lt;–&amp;gt;   6&lt;br&gt;
100     &amp;lt;–&amp;gt;  0&lt;br&gt;
101     &amp;lt;–&amp;gt;  4&lt;br&gt;
110     &amp;lt;–&amp;gt;  18&lt;br&gt;
11100   &amp;lt;–&amp;gt;1&lt;br&gt;
11101   &amp;lt;–&amp;gt;2&lt;br&gt;
11110   &amp;lt;–&amp;gt;3&lt;br&gt;
11111   &amp;lt;–&amp;gt;17&lt;/p&gt;
&lt;p&gt;接下来就是CL1序列，按照前面的指示，一共有259个，分别对应于literal/length：0-258对应的码字长度序列，我们队跟着CCL后面的比特按照上面获得的码表进行逐步解码，在解码之前，实际上并不知道CL1的比特流长度有多少，需要根据259这个数字来判定，解完了259个整数，表明解析CL1完毕：&lt;/p&gt;
&lt;p&gt;101(Header) 01000(HLIT) 01010(HDIST) 0111(HCLEN)&lt;br&gt;
000 101 110 110 000 000 000 010 000 010 000 110 000 101 000 101 000 101 (CCL)&lt;/p&gt;
&lt;p&gt;110（18）1010100（7比特，记录连续的11-138个0，此处一共0010101b=21，即记录21+11=32个0）&lt;/p&gt;
&lt;p&gt;11110（3）110（18）0000000（7比特，记录连续的11-138个0，此处为全0，即记录0+11=11个0）&lt;/p&gt;
&lt;p&gt;01（6）100（0）01（6）110（18）1110000（7比特，记录连续的11-138个0，此处为111b=7，即记录7+11=18个0）&lt;/p&gt;
&lt;p&gt;01（6）110（18）0010100（7比特，记录连续的11-138个0，此处为10100b=20，即记录20+11=31个0）&lt;/p&gt;
&lt;p&gt;101（4）01（6）01（6）00（5）11110（3）01（6）100（0）00（5）00（5）100（0）01（6）101（4）&lt;/p&gt;
&lt;p&gt;00（5）101（4）00（5）100（0）100（0）00（5）101（4）101（4）01（6）01（6）01（6）100（0）&lt;/p&gt;
&lt;p&gt;00（5）110（18）1101111（7比特，记录连续的11-138个0，此处为1111011b=123，即记录123+11=134个0）&lt;/p&gt;
&lt;p&gt;统计一下，上面已经解了32+11+18+31+134+30=256个数了，因为总共259个，还差三个：&lt;/p&gt;
&lt;p&gt;01（6）00（5）01（6）&lt;/p&gt;
&lt;p&gt;好了，CL1比特流解析完毕了，得到的CL1码长序列为：&lt;/p&gt;
&lt;p&gt;0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 &lt;strong&gt;3&lt;/strong&gt; 0 0 0 0 0 0 0&lt;br&gt;
0 0 0 0 6 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0&lt;br&gt;
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 6 6 5 3 6 0 5 5 0 6 4 5 4 5 0 0 5 4 4 6 6 6&lt;br&gt;
0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0&lt;br&gt;
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0&lt;br&gt;
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0&lt;br&gt;
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0&lt;strong&gt; 6 5 6&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;总共259个，每行40个。根据这个序列，同样按照Deflate树构造方法，得到literal/length码表（Huffman码表1）为：&lt;/p&gt;
&lt;p&gt;000     –&amp;gt; (System.Char)（看前面的CL1序列，空格对应的ASCII为0×20=32，码字长度3，即上面序列中第一个3）&lt;br&gt;
001     –&amp;gt;e(System.Char)&lt;br&gt;
0100    –&amp;gt;a(System.Char)&lt;br&gt;
0101    –&amp;gt;l(System.Char)&lt;br&gt;
0110    –&amp;gt;n(System.Char)&lt;br&gt;
0111    –&amp;gt;s(System.Char)&lt;br&gt;
1000    –&amp;gt;t(System.Char)&lt;br&gt;
10010   –&amp;gt;d(System.Char)&lt;br&gt;
10011   –&amp;gt;h(System.Char)&lt;br&gt;
10100   –&amp;gt;i(System.Char)&lt;br&gt;
10101   –&amp;gt;m(System.Char)&lt;br&gt;
10110   –&amp;gt;o(System.Char)&lt;br&gt;
10111   –&amp;gt;r(System.Char)&lt;br&gt;
11000   –&amp;gt;y(System.Char)&lt;br&gt;
&lt;strong&gt;11001   –&amp;gt;3(System.Int32)（看前面的CL1序列，对应257，码字长度5）&lt;/strong&gt;&lt;br&gt;
110100  –&amp;gt;,(System.Char)&lt;br&gt;
110101  –&amp;gt;.(System.Char)&lt;br&gt;
110110  –&amp;gt;A(System.Char)&lt;br&gt;
110111  –&amp;gt;b(System.Char)&lt;br&gt;
111000  –&amp;gt;c(System.Char)&lt;br&gt;
111001  –&amp;gt;f(System.Char)&lt;br&gt;
111010  –&amp;gt;k(System.Char)&lt;br&gt;
111011  –&amp;gt;u(System.Char)&lt;br&gt;
111100  –&amp;gt;v(System.Char)&lt;br&gt;
111101  –&amp;gt;w(System.Char)&lt;br&gt;
&lt;strong&gt;111110  –&amp;gt;-1(System.Int32)（看前面的CL1序列，对应256，码字长度6）&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;111111  –&amp;gt;4(System.Int32)（看前面的CL1序列，对应258，码字长度6）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;可以看出，码表里存在两个重复字符串长度3和4，当解码结果为-1（上面进行了处理，即256），或者说遇到111110的时候，表示Deflate码流结束。&lt;/p&gt;
&lt;p&gt;按照同样的道理，对CL2序列进行解析，前面已经知道HDIST=10，即有11个CL2整数序列：&lt;/p&gt;
&lt;p&gt;11111（17）000（3比特，记录连续的3-10个0，此处为0，即记录3个0）&lt;/p&gt;
&lt;p&gt;11101（2）11111（17）100（3比特，记录连续的3-10个0，此处为001b=1，即记录4个0）&lt;/p&gt;
&lt;p&gt;11100（1）100（0）11101（2）&lt;/p&gt;
&lt;p&gt;已经结束，总共11个。&lt;/p&gt;
&lt;p&gt;于是CL2序列为：&lt;/p&gt;
&lt;p&gt;0 0 0 2 0 0 0 0 1 0 2&lt;/p&gt;
&lt;p&gt;分别记录的是distance码为0-10的码字长度，根据下面的对应关系，需要进行扩展：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1827f952b7cd6dad38f4843cef1c4559.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;比如，第1个码长2记录的是Code=3的长度，即Distance=4对应的码字为：&lt;/p&gt;
&lt;p&gt;10      –&amp;gt;4(System.Int32)&lt;/p&gt;
&lt;p&gt;第1个码长1记录的是Code=8的长度（码字为0，扩展三位000-111），即Distance=17-24对应的码字为（注意，低比特优先）：&lt;/p&gt;
&lt;p&gt;0 000    –&amp;gt;17(System.Int32)&lt;br&gt;
0 100    –&amp;gt;18(System.Int32)&lt;br&gt;
0 010    –&amp;gt;19(System.Int32)&lt;br&gt;
0 110    –&amp;gt;20(System.Int32)&lt;br&gt;
0 001    –&amp;gt;21(System.Int32)&lt;br&gt;
0 101    –&amp;gt;22(System.Int32)&lt;br&gt;
0 011    –&amp;gt;23(System.Int32)&lt;br&gt;
0 111    –&amp;gt;24(System.Int32)&lt;/p&gt;
&lt;p&gt;注意，扩展的时候还是低比特优先。&lt;/p&gt;
&lt;p&gt;最后1个码长2记录的是Code=10的长度（其实是码字：11，扩展四位0000-1111），即Distance=33-48对应的码字为：&lt;/p&gt;
&lt;p&gt;11 0000  –&amp;gt;33(System.Int32)&lt;br&gt;
11 1000  –&amp;gt;34(System.Int32)&lt;br&gt;
11 0100  –&amp;gt;35(System.Int32)&lt;br&gt;
11 1100  –&amp;gt;36(System.Int32)&lt;br&gt;
11 0010  –&amp;gt;37(System.Int32)&lt;br&gt;
11 1010  –&amp;gt;38(System.Int32)&lt;br&gt;
11 0110  –&amp;gt;39(System.Int32)&lt;br&gt;
11 1110  –&amp;gt;40(System.Int32)&lt;br&gt;
11 0001  –&amp;gt;41(System.Int32)&lt;br&gt;
11 1001  –&amp;gt;42(System.Int32)&lt;br&gt;
11 0101  –&amp;gt;43(System.Int32)&lt;br&gt;
11 1101  –&amp;gt;44(System.Int32)&lt;br&gt;
11 0011  –&amp;gt;45(System.Int32)&lt;br&gt;
11 1011  –&amp;gt;46(System.Int32)&lt;br&gt;
11 0111  –&amp;gt;47(System.Int32)&lt;br&gt;
11 1111  –&amp;gt;48(System.Int32)&lt;/p&gt;
&lt;p&gt;至此为止，Huffman码表1、Huffman码表2已经还原出来，接下来是对LZ压缩所得到的literal、distance、length进行解码，目前剩余的比特流如下，先按照Huffman码表1解码，如果解码结果是长度（&amp;gt;256），则接下来按照Huffman码表2解码，逐步解码即可：&lt;/p&gt;
&lt;p&gt;[As ]：110110（A）0111（s）000（空格）&lt;/p&gt;
&lt;p&gt;[mentioned ]：10101（m）001（e）0110（n）1000（t）10100（i）10110（o）0110（n）001（e）10010（d）000（空格）&lt;/p&gt;
&lt;p&gt;[above,]：0100（a）110111（b）10110（o）111100（v）001（e）110100（,）&lt;/p&gt;
&lt;p&gt;[there ]：1000（t）10011（h）001（e）10111（r）001（e）000（空格）&lt;/p&gt;
&lt;p&gt;[are ]：0100（a）11001（长度3，表示下一个需要用Huffman解码）10（Distance=4，即重复字符串为re空格）&lt;/p&gt;
&lt;p&gt;[many ]：10101（m）0100（a）0110（n）11000（y）000（空格）&lt;/p&gt;
&lt;p&gt;[kinds ]：111010（k）10100（i）0110（n）10010（d）0111（s）000（空格）&lt;/p&gt;
&lt;p&gt;[of ]：10110（o）111001（f）000（空格）&lt;/p&gt;
&lt;p&gt;[wireless ]：111101（w）10100（i）10111（r）001（e）0101（l）001（e）0111（s）0111（s）000（空格）&lt;/p&gt;
&lt;p&gt;[systems o]：0111（s）11000（y）0111（s）1000（t）001（e）10101（m）11001（长度指示=3，接下来根据distance解码）0110（Distance=20,即重复字符串为s o）&lt;/p&gt;
&lt;p&gt;[ther ]：111111（长度指示=4，接下来根据distance解码）111001（Distance=42,即重复字符串为ther）000（空格）&lt;/p&gt;
&lt;p&gt;[than ]：1000（t）10011（h）0100（a）0110（n）000（空格）&lt;/p&gt;
&lt;p&gt;[cellular.]：111000（c）001（e）0101（l）0101（l）111011（u）0101（l）0100（a）10111（r）110101（.）&lt;/p&gt;
&lt;p&gt;[256，结束标志]111110（结束标志）0000（字节补齐的0）&lt;/p&gt;
&lt;p&gt;于是解压缩结果为：&lt;/p&gt;
&lt;p&gt;As mentioned above,there are many kinds of wireless systems other than cellular.&lt;/p&gt;
&lt;p&gt;再来回顾我们的解码过程：&lt;/p&gt;
&lt;p&gt;译码过程：&lt;br&gt;
1、根据HCLEN得到截尾信息，并参照固定置换表，根据CCL比特流得到CCL整数序列；&lt;br&gt;
2、根据CCL整数序列构造出等价于CCL的二级Huffman码表3；&lt;br&gt;
3、根据二级Huffman码表3对CL1、CL2比特流进行解码，得到SQ1整数序列,SQ2整数序列；&lt;br&gt;
4、根据SQ1整数序列,SQ2整数序列,利用游程编码规则得到等价的CL1整数序列、CL2整数序列；&lt;br&gt;
5、根据CL1整数序列、CL2整数序列分别构造两个一级Huffman码表：literal/length码表、distance码表；&lt;br&gt;
6、根据两个一级Huffman码表对后面的LZ压缩数据进行解码得到literal/length/distance流；&lt;br&gt;
7、根据literal/length/distance流按照LZ规则进行解码。&lt;/p&gt;
&lt;p&gt;Deflate码流长度总共为72字节=576比特，其中：&lt;/p&gt;
&lt;p&gt;3比特Header；&lt;/p&gt;
&lt;p&gt;5比特HLIT；&lt;/p&gt;
&lt;p&gt;5比特HDIST；&lt;/p&gt;
&lt;p&gt;4比特HCLEN；&lt;/p&gt;
&lt;p&gt;54比特CCL序列码流；&lt;/p&gt;
&lt;p&gt;133比特CL1序列码流；&lt;/p&gt;
&lt;p&gt;34比特CL2序列码流；&lt;/p&gt;
&lt;p&gt;338比特LZ压缩后的literal/length/distance码流。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;11、ZIP的其它说明&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上面各个环节已经详细分析了ZIP压缩的过程以及解码流程，通过对一个实例的解压缩过程分析，可以彻底地掌握ZIP压缩和解压缩的原理和过程。还有一些情况需要说明：&lt;/p&gt;
&lt;p&gt;（1）上面的算法复杂度主要在于压缩一端，因为需要统计literal/length/distance，创建动态Huffman码表，相反解压只需要还原码表后，逐比特解析即可，这也是压缩软件的一个典型特点，解压速度远快于压缩速度。&lt;/p&gt;
&lt;p&gt;（2）上面我们分析了动态Huffman，对于LZ压缩后的literal/length/distance，也可以采用静态Huffman编码，这主要取决于ZIP在压缩中看哪种方式更节省空间，静态Huffman编码不需要记录码表，因为这个码表是固定的，在RFC1951里面也有说明。对于literal/length码表来说，需要对0-285进行编码，其码表为：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d59cb18c6ea3d62aec30fb977660adb3.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;对于Distance来说，需要对Code=0-29的数进行编码，则直接采用5比特表示。Distance和动态Huffman一样，在此基础上进行扩展。&lt;/p&gt;
&lt;p&gt;（3）ZIP中使用的LZ77算法是一种改进的LZ77。主要区别有两点：&lt;/p&gt;
&lt;p&gt;1）标准LZ77在找到重复字符串时输出三元组(length, distance, 下一个未匹配的字符)（有兴趣可以关注LZ77那篇论文）；Deflate在找到重复字符串时仅输出双元组(length, distance)。&lt;br&gt;
2）标准LZ77使用”贪婪“的方式解析，寻找的都是最长匹配字符串。Deflate中不完全如此。David Salomon的书里给了一个例子：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/34e889641a6f29dc9be906efdd34437f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;对于上面这个例子，标准LZ77在滑动窗口中查找最长匹配字符串，找到的是”the”与前面的there的前三个字符匹配，这种贪婪解析方式逻辑简单，但编码效率不一定最高。Deflate则不急于输出，跳过t继续往后查看，发现”th ne”这5个字符存在重复字符串，因此，Deflate算法会选择将t作为未匹配字符输出，而对后面的匹配字符串用(length, distance)编码输出。显然，这样就提高了压缩效率，因为标准的LZ77找到的重复字符串长度为3，而Deflate找到的是5。换句话说，Deflate算法并不是简单的寻找最长匹配后输出，而是会权衡几种可行的编码方式，用其中最高效的方式输出。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;12、总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本篇博文对ZIP中使用的压缩算法进行了详细分析，从一个简单地例子出发，一步步地分析了PK设计Deflate算法的思路。最后，通过一个实际例子，分析了其解压缩流程。总的来看，ZIP的核心在于如何对LZ压缩后的literal、length、distance进行Huffman编码，以及如何以最小空间记录Huffman码表。整个过程充满了对数据结构尤其是树的深入优化利用。按照上面的分析，如果要对ZIP进行进一步改进，可以考虑的地方也有不少，典型的有：&lt;/p&gt;
&lt;p&gt;（1）扩大LZ编码的滑动窗口的大小；&lt;/p&gt;
&lt;p&gt;（2）将Huffman编码改进为算术编码等压缩率更高的方法，毕竟，Huffman的码字长度必须为整数，这就从理论上限制了它的压缩率只能接近于理论极限，但难以达到。我记得在JPEG图像编码领域，以前的JPEG采用了DCT变换编码+Huffman的方式，现在JPEG2000将其改为小波变换+算数编码，所以数据压缩也可以尝试类似的思路；&lt;/p&gt;
&lt;p&gt;（3）将多个文件进行合并压缩，ZIP中，不同的文件压缩过程没有关系，独立进行，如果将它们合并起来一起进行压缩，压缩率可以得到进一步提高。&lt;/p&gt;
&lt;p&gt;描述分析有误的地方，敬请指正。针对数据压缩相关的话题，后续会对HBase列压缩等等进行分析，看看ZIP这种文件压缩和HBase这种数据库数据压缩的区别和联系。&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Wed, 10 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-10-76676-e71c7d494.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-10-76676-e71c7d494.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>由“香蕉”引出的字符串匹配算法的问题</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;这周的早些时候我注意到&lt;a href=&quot;http://static.rust-lang.org/doc/master/std/str/trait.StrSlice.html&quot; target=&quot;_blank&quot;&gt;String slices in Rust&lt;/a&gt;上的一些方法在文档里没有例子，所以我想试着写一些。第一个我打算为之写一个例子的方法是contains，contians可以测试一个字符串是否是另一个的子字符串。思索了一下我决定写一个像这样的例子：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;“bananas”.contains(“nana”)&lt;/pre&gt;
&lt;p&gt;由于我从没有用过这个方法，我想确认这个方法是按照我预想的方式运行，所以我在http://play.rust-lang.org上试运行这个例子。&lt;/p&gt;
&lt;p&gt;返回的结果是false。&lt;/p&gt;
&lt;p&gt;在复核这个文档并尝试了其他例子（都运行正常）以后，我怀疑play.rust-lang.org的这个方法有一些奇怪的问题。我决定要在本地测试一下这个方法。结果一模一样。我下载了最新的Rust nightly并再次运行这个例子。Rust再一次通知我”bananas”不包含”nana”。&lt;/p&gt;
&lt;p&gt;我决定用”bananas”的每一个子字符串去检验contains，以证明事实上不是我在现实生活中突然忘了字母是如何工作的：&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt;fn main() {
    let b = &quot;bananas&quot;;
    for i in range(0, b.len()) {
        for j in range(i, b.len() + 1) {
            let curr = b.slice(i, j);
            println!(&quot;{} - {}&quot;, b.contains(curr), curr);
        }
    }
}&lt;/pre&gt;
&lt;p&gt;运行的结果是：&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt;true - 
true - b
true - ba
true - ban
true - bana
true - banan
true - banana
true - bananas
true - 
true - a
true - an
true - ana
true - anan
true - anana
true - ananas
true - 
true - n
true - na
true - nan
false - nana
true - nanas
true - 
true - a
true - an
true - ana
true - anas
true - 
true - n
true - na
true - nas
true - 
true - a
true - as
true - 
true - s&lt;/pre&gt;
&lt;p&gt;“nana”是唯一”bananas”调用contains方法返回值为false的子字符串。&lt;/p&gt;
&lt;p&gt;我感到高兴起来，我发现了Rust字符串匹配的实现的bug。因为我那时在Hacker School，我也没有比花费一整天去捕获那些预发行的编程语言的标准库的隐藏的bug更好的事了。于是我决定修正这个bug。&lt;/p&gt;
&lt;p&gt;这个独特的问题是由两个独立的bugs导致的结果。包含&lt;a href=&quot;https://github.com/rust-lang/rust/blob/c88feffde4f5043adf07a6837026f228e20b67e6/src/libcore/str.rs#L562-L576&quot; target=&quot;_blank&quot;&gt;第一个bug的代码&lt;/a&gt;：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;impl Searcher {
    fn new(haystack: &amp;amp;[u8], needle: &amp;amp;[u8]) -&amp;gt; Searcher {
        // FIXME: Tune this.
        if needle.len() &amp;gt; haystack.len() - 20 {
            Naive(NaiveSearcher::new())
        } else {
            let searcher = TwoWaySearcher::new(needle);
            if searcher.memory == uint::MAX { // If the period is long
                TwoWayLong(searcher)
            } else {
                TwoWay(searcher)
            }
        }
    }
}&lt;/pre&gt;
&lt;p&gt;这是一个Searcher的构造函数，用于执行字符串的匹配。这段代码的意图是当haystack（我们在这个字符串里搜索）的长度和needle（我们搜索的目标字符串）的长度之间的差距小于20的时候使用NaiveSearcher，否则使用TwoWaySearcher。（NaiveSearcher是一个简单字符串匹配算法的实现，）&lt;/p&gt;
&lt;p&gt;然而，当haystack.len()小于20的时候，haystack.len() – 20会变成一个很大的数，我们碰到了一个下溢的错误。当haystack的长度小于20的时候这个bug致使这段代码错误的调用了TwoWaySearcher，但是在”bananas”.contains(“nana”)这样特殊的情况下，解决方法是needle增加20上而不是haystack减去20：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;if needle.len() + 20 &amp;gt; haystack.len() {&lt;/pre&gt;
&lt;p&gt;我对第一个bug的修改请求&lt;a href=&quot;https://github.com/rust-lang/rust/pull/16590&quot; target=&quot;_blank&quot;&gt;在这里&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;如此上述修改仅仅通过这个方法调用一个不同的简单没有问题的字符串匹配算法就修正了我在”bananas”的例子发现的问题。但是在别的字符串匹配算法TwoWaySearcher上依然还有一个问题。如在例子”012345678901234567890anana”.contains(“nana”) 中的haystack大到足以调用TwoWaySearcher，但是任然返回false。&lt;/p&gt;
&lt;p&gt;这个问题证明更难精确度定位，我也不十分肯定我提交的修改是正确的，所以我就简略的说明一下吧。TwoWaySearcher是“Type-way algorithm“的实现的一种，最早的介绍在这篇论文里。通过阅读该论文和有精彩评论的glibc implementation of Two way algorithm。我注意到有一部分Rust的代码没有准确的匹配该论文提到的东西。你可以在这篇论文的p.670明确找到这个函数：&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/8568d1238972a2aa2781ff5e17e52b73.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;Small-Period函数的伪代码&lt;/p&gt;
&lt;p&gt;Two-Way算法需要两个字符串作为输入，一个是“haystack“，一个是”needle“，并试图在提供的haystack中找到needle第一次出现的起始位置。在这个特定算法中，第一步是以一种遵守确定规律的方式把”needle“变成两部分（就像，发现一对字符串(u,v),比如needle=u+v）。&lt;/p&gt;
&lt;p&gt;现在比较上面的伪代码和在Rust实现中的TwoWaySearcher Constructor的代码。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;fn new(needle: &amp;amp;[u8]) -&amp;gt; TwoWaySearcher {
    let (critPos1, period1) = TwoWaySearcher::maximal_suffix(needle, false);
    let (critPos2, period2) = TwoWaySearcher::maximal_suffix(needle, true);

    let critPos;
    let period;
    if critPos1 &amp;gt; critPos2 {
        critPos = critPos1;
        period = period1;
    } else {
        critPos = critPos2;
        period = period2;
    }

    let byteset = needle.iter()
                        .fold(0, |a, &amp;amp;b| (1 &amp;lt;&amp;lt; ((b &amp;amp; 0x3f) as uint)) | a);

    if needle.slice_to(critPos) == needle.slice_from(needle.len() - critPos) {
        TwoWaySearcher {
            critPos: critPos,
            period: period,
            byteset: byteset,

            position: 0,
            memory: 0
        }
    } else {
        TwoWaySearcher {
            critPos: critPos,
            period: cmp::max(critPos, needle.len() - critPos) + 1,
            byteset: byteset,

            position: 0,
            memory: uint::MAX // Dummy value to signify that the period is long
        }
    }
}&lt;/pre&gt;
&lt;p&gt;特别注意在TwoWaySearcher::new()结尾处的if语句。第一分支使用period，第二分支使用max(critPos, needle.len() – critPos) + 1.这两行相当于上面伪代码的第5行和第6行。剩下的都匹配的相当好，if语句条件检查的异常：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;needle.slice_to(critPos)==needle.slice_from(needl e.len() - critPos)&lt;/pre&gt;
&lt;p&gt;在类Python的伪代码中，这行代码是在检查if needle[:1] == needle[(n - 1):],我使用了1代替cirtPos，n代替needle的长度。与论文的代码相比较，论文代码规定我们需要检查needle[:1]是否是needle[1: (p+1)]的后缀，p是needle的后缀的period，这两个检查不是一样的。我严重怀疑是这段代码的问题。&lt;/p&gt;
&lt;p&gt;一个等价的检查是通过检查if needle[: 1] == needle[p: (p+1)]needle[:1]是否是needle[1: (p + 1)]的后缀。所以我猜我们需要在Rust中把if条件改成这样：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;needle.slice_to(critPos) == needle.slice(period, period + critPos)&lt;/pre&gt;
&lt;p&gt;这个新的逻辑好像也与glibc实现匹配，因为two_way_long_needle函数有像下面的if语句：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;/* Perform the search. Each iteration compares the right half
     first. */
  if (CMP_FUNC (needle, needle + period, suffix) == 0)
    {
      /* Entire needle is periodic; a mismatch can only advance by the
     period, so use memory to avoid rescanning known occurrences
     of the period.  */

      ...

    }
  else
    {
      /* The two halves of needle are distinct; no extra memory is
     required, and any mismatch results in a maximal shift.  */

      ...

    }&lt;/pre&gt;
&lt;p&gt;（你需要检查CMP_FUNC宏以便看看为什么它是一样的）。还有，在做完上述修改以后，所有上面失败的例子现在都正常运行了。&lt;/p&gt;
&lt;p&gt;我给这些修改做了一个open PR，由于我没有花时间完全理解这些算法所以我不能完全肯定它是正确的。&lt;/p&gt;
&lt;p&gt;有趣的是如果我没有注意到第一个bug，我也不会发现第二个。&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Wed, 10 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-10-76509-ac5839beb.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-10-76509-ac5839beb.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>Swift Has Reached 1.0</title>
        <description>

						
						

						&lt;p&gt;On June 2, 2014 at WWDC, the Swift team finally showed you what we had been working on for years. That was a  big day with lots of excitement, for us and for developers around the world. Today, we’ve reached the second giant milestone:&lt;/p&gt;
&lt;p&gt;Swift version 1.0 is now GM.&lt;/p&gt;
&lt;p&gt;You can now submit your apps that use Swift to the App Store. Whether your app uses Swift for a small feature or a complete application, now is the time to share your app with the world. It’s your turn to excite everyone with your new creations.&lt;/p&gt;
&lt;h3&gt;Swift for OS X&lt;/h3&gt;
&lt;p&gt;Today is the GM date for Swift on iOS. We have one more GM date to go for Mac. Swift for OS X currently requires the SDK for OS X Yosemite, and when Yosemite ships later this fall, Swift will also be GM on the Mac. In the meantime, you can keep developing your Mac apps with Swift by downloading the beta of &lt;a href=&quot;http://developer.apple.com/xcode/downloads/&quot;&gt;Xcode 6.1&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;The Road Ahead&lt;/h3&gt;
&lt;p&gt;You’ll notice we’re using the word “GM”, not “final”. That’s because Swift will continue to advance with new features, improved performance, and refined syntax. In fact, you can expect a few improvements to come in Xcode 6.1 in time for the Yosemite launch. Because your apps today embed a version of the Swift GM runtime, they will continue to run well into the future.&lt;/p&gt;

						
												
											

</description>
        <pubDate>Tue, 09 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-09--id=14-50ea6b53d.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-09--id=14-50ea6b53d.html</guid>
        
        
        <category>apple_swift</category>
        
      </item>
    
      <item>
        <title>Git 2.1 有哪些新特性？</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;在&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.0.0&lt;/code&gt;发布2个半月后，作为小版本更新迎来了&lt;code&gt;2.1.0&lt;/code&gt;，带来了一大波令人兴奋的新特性。&lt;/p&gt;
&lt;p&gt;完整的发布说明文档可以在&lt;a href=&quot;https://raw.githubusercontent.com/git/git/master/Documentation/RelNotes/2.1.0.txt&quot;&gt;这里&lt;/a&gt;查看，但如果你不怎么接触&lt;code&gt;git&lt;/code&gt;社区，会觉得发布说明文档有些太简明了。这篇文章是我对这次发布在&lt;code&gt;Atlassian&lt;/code&gt;使用中令我们兴奋的方面所做的评注。&lt;/p&gt;
&lt;h2&gt;更好的分页程序缺省设置&lt;/h2&gt;
&lt;p&gt;本文引文都是直接摘自发布说明文档，其中会加上自己的评注。&lt;/p&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;如果你还没有覆盖过&lt;code&gt;git&lt;/code&gt;分页程序的缺省值，这个变化意味着&lt;code&gt;git&lt;/code&gt;命令的分页输出会在终端宽度的地方折行而不是截断行。下面是&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.1.0&lt;/code&gt;（折行，左图）和&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.0.3&lt;/code&gt;（截断，右图）显示的例子：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/09/525e421fe930a64ec2ad58a4a10dfcfd.png&quot; rel=&quot;lightbox[76550]&quot; title=&quot;Git 2.1 有哪些新特性？&quot;&gt;&lt;img src=&quot;/images/jobbole.com/066545cc928354a57b6baed4a1c05170.jpg&quot; alt=&quot;git210leftvsgit200right-600x293&quot; class=&quot;alignnone size-full wp-image-76560&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这个只会影响你日志的输出，如果你用的是一个窄的终端，或者在提交消息中有长行。一般&lt;code&gt;git&lt;/code&gt;推荐提交日志信息的&lt;a href=&quot;http://stackoverflow.com/questions/2290016/git-commit-messages-50-72-formatting&quot;&gt;宽度不要超过72字符&lt;/a&gt;，但如果觉得折行很烦，可以通过恢复原来的行为来禁用：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ git config core.pager &quot;less -S&quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;当然，分页程序也会用于其它的输出，比如&lt;code&gt;git blame&lt;/code&gt;，这种情况下由于作者名的长度和代码风格，可以能会有很长的行。&lt;code&gt;2.1.0&lt;/code&gt;的发布说明文档也指出了可以只在&lt;code&gt;blame&lt;/code&gt;的分页程序中启用&lt;code&gt;-S&lt;/code&gt;选项：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ git config pager.blame &quot;less -S&quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如果你对&lt;code&gt;git&lt;/code&gt;还在使用的缺省&lt;code&gt;less&lt;/code&gt;选项很好奇，说明如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;code&gt;-F&lt;/code&gt;：让&lt;code&gt;less&lt;/code&gt;进程自动退出，如果输出少于一页。&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;-R&lt;/code&gt;：保证只有&lt;code&gt;ANSI&lt;/code&gt;颜色转义序列按原始形式输出，这样&lt;code&gt;git&lt;/code&gt;控制台颜色才能生效。&lt;/li&gt;
&lt;li&gt;
&lt;code&gt;-X&lt;/code&gt;：避免屏幕在&lt;code&gt;less&lt;/code&gt;启动时被清空。这个也是在&lt;code&gt;less&lt;/code&gt;输出少于一页时才有用。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;更好的&lt;code&gt;Bash&lt;/code&gt;补全&lt;/h2&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;这个&lt;strong&gt;超酷&lt;/strong&gt;！我是一个自定义&lt;code&gt;git&lt;/code&gt;别名的大粉丝。能够在复杂的别名上用上&lt;code&gt;git&lt;/code&gt;的&lt;code&gt;Bash&lt;/code&gt;自动补全，让这些别名在命令行上使用起来更强大和方便。举个例子，我定义一个可以从日志中&lt;code&gt;grep&lt;/code&gt;出&lt;code&gt;JIRA&lt;/code&gt;风格的&lt;code&gt;issue&lt;/code&gt;主键（如&lt;code&gt;STASH-123&lt;/code&gt;）的别名：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;issues = !sh -c &#39;git log --oneline $@ | egrep -o [A-Z]+-[0-9]+ | sort | uniq&#39; -&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;所有的命令行参数传给&lt;code&gt;git log&lt;/code&gt;命令，这样可以限制提交的范围用于返回&lt;code&gt;issue&lt;/code&gt;主键。比如，&lt;code&gt;git issues -n 1&lt;/code&gt;只会显示我的分支最近一次提交所关联的&lt;code&gt;issue&lt;/code&gt;主键。在&lt;code&gt;2.1.0&lt;/code&gt;中，&lt;code&gt;git&lt;/code&gt;的&lt;code&gt;Bash&lt;/code&gt;补全让我可以像&lt;code&gt;git log&lt;/code&gt;命令一样去补全&lt;code&gt;git&lt;/code&gt;的&lt;code&gt;issue&lt;/code&gt;别名。&lt;/p&gt;
&lt;p&gt;在&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.0.3&lt;/code&gt;下，键入&lt;code&gt;git issues m&lt;/code&gt;会退化成缺省的&lt;code&gt;Bash&lt;/code&gt;补全行为，列出当前目录下&lt;code&gt;m&lt;/code&gt;开头的文件。在&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.1.0&lt;/code&gt;下，正确地补全成&lt;code&gt;master&lt;/code&gt;，就和&lt;code&gt;git log&lt;/code&gt;命令下补全动作一样。通过在别名加上空命令前缀&lt;code&gt;:&lt;/code&gt;，可以用于提示&lt;code&gt;Bash&lt;/code&gt;补全行为。如果要补全的不是别名中的第一个命令，这个很有用。举个例子：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;issues = &quot;!f() { echo &#39;Printing issue keys&#39;; git log --oneline $@ | egrep -o [A-Z]+-[0-9]+ | sort | uniq; }; f&quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这个别名不能正常补全，因为&lt;code&gt;git&lt;/code&gt;不能把&lt;code&gt;echo&lt;/code&gt;命令识别为补全目标。但如果加上前缀成&lt;code&gt;: git log;&lt;/code&gt;，补全就正确了：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;issues = &quot;!f() { : git log ; echo &#39;Printing issue keys&#39;; git log --oneline $@ | egrep -o [A-Z]+-[0-9]+ | sort | uniq; }; f&quot;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如果你喜欢编写复杂的别名脚本，这是个可用性的巨大改进！请记住，补全功能的脚本在&lt;code&gt;contrib/&lt;/code&gt;目录下，不是&lt;code&gt;git&lt;/code&gt;核心的一部分，所以如果你要使用这个功能，不要忘了更新&lt;code&gt;Bash profile&lt;/code&gt;指向新版本的&lt;code&gt;contrib/completion/git-completion.bash&lt;/code&gt;。&lt;/p&gt;
&lt;h2&gt;
&lt;code&gt;git commit&lt;/code&gt;命令使用&lt;code&gt;approxidate&lt;/code&gt;
&lt;/h2&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;当严格的&lt;code&gt;parse_date()&lt;/code&gt;函数不能解析给的日期字符串时，&lt;code&gt;git&lt;/code&gt;提交的&lt;code&gt;--date&lt;/code&gt;选项现在会回退到&lt;code&gt;git&lt;/code&gt;酷炫的（也有些古怪的）&lt;code&gt;approxidate&lt;/code&gt;（大概日期）解析器。&lt;code&gt;approxidate&lt;/code&gt;可以处理显而易见的值，像&lt;code&gt;--date=now&lt;/code&gt;，也允许一些略复杂格式，像&lt;code&gt;--date=&quot;midnight the 12th of october, anno domini 1979&quot;&lt;/code&gt;或是&lt;code&gt;--date=teatime&lt;/code&gt;。如果你想了解更多，Alex Peattie有一篇优秀的&lt;a href=&quot;http://alexpeattie.com/blog/working-with-dates-in-git/&quot;&gt;关于&lt;code&gt;git&lt;/code&gt;酷炫日期处理的博文&lt;/a&gt;。&lt;/p&gt;
&lt;h2&gt;更好的路径显示方式&lt;code&gt;grep.fullname&lt;/code&gt;
&lt;/h2&gt;
&lt;blockquote&gt;

&lt;/blockquote&gt;
&lt;p&gt;省得你去翻&lt;code&gt;git-grep&lt;/code&gt;的&lt;code&gt;man&lt;/code&gt;，下面是&lt;code&gt;--full-name&lt;/code&gt;选项的文档说明：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
&lt;code&gt;--full-name&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;非常贴心！这个缺省行为非常符合我的工作方式，我常常会运行&lt;code&gt;git grep&lt;/code&gt;找出一个文件的路径，拷贝粘贴到一个&lt;code&gt;XML&lt;/code&gt;文件中（这样的做法可能出卖了我是个&lt;code&gt;Java&lt;/code&gt;开发）。如果你也觉得有用，只要简单运行：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ git config --global grep.fullname true&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;在你的配置文件开启这个选项。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;--global&lt;/code&gt;选项把配置应用到&lt;code&gt;$HOME/.gitconfig&lt;/code&gt;文件中，这样配置值就会成为我系统上所有&lt;code&gt;git&lt;/code&gt;仓库的缺省行为。如果有必要，你可以也只在仓库级别覆盖配置值。&lt;/p&gt;
&lt;h2&gt;更聪明的&lt;code&gt;git replace&lt;/code&gt;
&lt;/h2&gt;
&lt;p&gt;停一会儿！先看看&lt;code&gt;git replace&lt;/code&gt;能做什么？&lt;/p&gt;
&lt;p&gt;简单地说，&lt;code&gt;git replace&lt;/code&gt;重写&lt;code&gt;git&lt;/code&gt;仓库中的某个对象并且不保持对应树或是提交的&lt;code&gt;SHA&lt;/code&gt;不变。如果你是第一次听到&lt;code&gt;git replace&lt;/code&gt;并且知道&lt;code&gt;git&lt;/code&gt;的数据模型，会觉得这样的做法听起来很逆天！我就是这么觉得。我有另一篇正在写的博文讨论什么时候和为什么要使用这样的功能。如果现在你想了解更多，看&lt;a href=&quot;http://git-scm.com/blog/2010/03/17/replace.html&quot;&gt;这篇文章&lt;/a&gt;比看&lt;code&gt;man&lt;/code&gt;手册好得多，手册中只有很少且有些牵强的用例说明。&lt;/p&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;--edit&lt;/code&gt;选项会&lt;code&gt;dump&lt;/code&gt;一个对象的内容到一个临时文件，启动你喜欢的编辑器，这样就可以方便地拷贝和替换这个对象。要替换&lt;code&gt;master&lt;/code&gt;分支的最近那次提交，可以简单运行命令：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ git replace --edit master&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;或者编辑最近那次提交的&lt;code&gt;blob&lt;/code&gt;，假设是文件&lt;code&gt;jira-components/pom.xml&lt;/code&gt;，可以运行命令：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ git replace --edit master:jira-components/pom.xml&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;应该这么做？基本上不会 :) 大部分情况应该用&lt;code&gt;git rebase&lt;/code&gt;重写对象，这样会正确的重写提交的&lt;code&gt;SHA&lt;/code&gt;，保证历史是健全的（&lt;code&gt;sane history&lt;/code&gt;）。&lt;/p&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;--graft&lt;/code&gt;选项是替换一个提交有相同的内容但用不同的父提交的快捷操作。这可以方便地完成一个稍微正常一点的&lt;code&gt;git replace&lt;/code&gt;的用例，&lt;a href=&quot;http://git-scm.com/blog/2010/03/17/replace.html&quot;&gt;缩短&lt;code&gt;git&lt;/code&gt;历史&lt;/a&gt;。要替换&lt;code&gt;master&lt;/code&gt;分支的最近那次提交的父，可以简单运行命令：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ git replace master --graft [new parent]..&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;或者要砍掉某个点之后的历史，可以忽略所有父提交让这个提交成为孤儿提交：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ git replace master --graft&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;再次说明，如果没有好的理由基本上不应该这么做。通常重写历史的首选方法是用明智的&lt;code&gt;git rebase&lt;/code&gt;。&lt;/p&gt;
&lt;h2&gt;更合理的&lt;code&gt;tag&lt;/code&gt;排序通过&lt;code&gt;tag.sort&lt;/code&gt;
&lt;/h2&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;如果你在&lt;code&gt;tag&lt;/code&gt;名中使用版本号（我想99.9%你就是这么做的），这真是好消息。一旦你发布的版本号中有一段多于一个数字（比如 &lt;code&gt;v10&lt;/code&gt;或&lt;code&gt;v1.10&lt;/code&gt;），&lt;code&gt;git&lt;/code&gt;缺省的字典排序就不好用了。举个例子，看看&lt;code&gt;Atlassian Stash&lt;/code&gt;的&lt;code&gt;git&lt;/code&gt;仓库的缺省&lt;code&gt;tag&lt;/code&gt;排序：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;src/stash $ git tag -l *.*.0&lt;br&gt;
..&lt;br&gt;
stash-parent-2.0.0&lt;br&gt;
stash-parent-2.1.0&lt;br&gt;
stash-parent-2.10.0&lt;br&gt;
stash-parent-2.11.0&lt;br&gt;
stash-parent-2.12.0&lt;br&gt;
stash-parent-2.2.0&lt;br&gt;
stash-parent-2.3.0&lt;br&gt;
stash-parent-2.4.0&lt;br&gt;
stash-parent-2.5.0&lt;br&gt;
stash-parent-2.6.0&lt;br&gt;
stash-parent-2.7.0&lt;br&gt;
stash-parent-2.8.0&lt;br&gt;
stash-parent-2.9.0&lt;br&gt;
stash-parent-3.0.0&lt;br&gt;
..&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;有问题啊！&lt;code&gt;2.10.0&lt;/code&gt;是&lt;code&gt;2.3.0&lt;/code&gt;之后发的，所以缺省的&lt;code&gt;tag&lt;/code&gt;排序不对的。从&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.0.0&lt;/code&gt;开始，可以用&lt;code&gt;--sort&lt;/code&gt;选项可以正确按数值做版本排序：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;src/stash $ git tag --sort=&quot;version:refname&quot; -l *.*.0&lt;br&gt;
..&lt;br&gt;
stash-parent-2.0.0&lt;br&gt;
stash-parent-2.1.0&lt;br&gt;
stash-parent-2.2.0&lt;br&gt;
stash-parent-2.3.0&lt;br&gt;
stash-parent-2.4.0&lt;br&gt;
stash-parent-2.5.0&lt;br&gt;
stash-parent-2.6.0&lt;br&gt;
stash-parent-2.7.0&lt;br&gt;
stash-parent-2.8.0&lt;br&gt;
stash-parent-2.9.0&lt;br&gt;
stash-parent-2.10.0&lt;br&gt;
stash-parent-2.11.0&lt;br&gt;
stash-parent-2.12.0&lt;br&gt;
stash-parent-3.0.0&lt;br&gt;
..&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这好多了。在&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.1.0&lt;/code&gt;中，可以设定这种排序成缺省方式，运行命令：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ git config --global tag.sort version:refname&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;顺便说一下，上面的示例&lt;code&gt;git tag&lt;/code&gt;命令中使用了方便的&lt;code&gt;-l&lt;/code&gt;选项，限制了只显示符合指定模式的&lt;code&gt;tag&lt;/code&gt;名。&lt;code&gt;-l *.*.0&lt;/code&gt;用于只显示大版本（&lt;code&gt;major&lt;/code&gt;）和小版本（&lt;code&gt;minor&lt;/code&gt;）的&lt;code&gt;Stash&lt;/code&gt;的发布。&lt;/p&gt;
&lt;h2&gt;更简单地验证有签名的提交&lt;/h2&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;如果你要用提交签名来认证提交的作者，&lt;code&gt;verify-commit&lt;/code&gt;命令大大简化了验证签名的操作。不再需要自己写个脚本去分析&lt;code&gt;git log --show-signature&lt;/code&gt;，只要简单把要验证签名的那些提交传给&lt;code&gt;git verify-commit&lt;/code&gt;。有可能你没有用签名提交（在&lt;code&gt;Atlassian&lt;/code&gt;我们没有用），因为这么做需要管理&lt;code&gt;Key&lt;/code&gt;和开发额外麻烦的操作。对于多数项目，一般情况下签名的&lt;code&gt;Tag&lt;/code&gt;是在方便性和安全性之间一个更好的平衡。如果你想知道为什么有项目要使用签名提交，Mike Gerwitz讲了一个在假设场景下&lt;a href=&quot;http://mikegerwitz.com/papers/git-horror-story&quot;&gt;&lt;code&gt;git&lt;/code&gt;的恐怖故事&lt;/a&gt;，这个场景下签名提交是非常有用的。所以如果你在特别敏感的企业工作，可能要把它加入到工作流中。&lt;/p&gt;
&lt;h2&gt;更多的性能加速&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.1.0&lt;/code&gt;也带来了一些不错的性能提升。&lt;/p&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;复述一下意思就是：如果你的提交有大量文件修改时，运行&lt;code&gt;git add&lt;/code&gt;可能会更快。我本地的任何增量操作，&lt;code&gt;git add&lt;/code&gt;已经像闪电一样快了，所以我看不出和测试的&lt;code&gt;git&lt;/code&gt;版本之间有什么大的性能变化。有意思的是，大量文件的第一次&lt;code&gt;add&lt;/code&gt;好像快了一点。做了个快糙猛的性能测试，我试着暂存所有在&lt;code&gt;JIRA&lt;/code&gt;代码库从&lt;code&gt;JIRA 5&lt;/code&gt;到&lt;code&gt;JIRA 6&lt;/code&gt;的修改。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ git checkout jira-v6.0&lt;br&gt;
$ git reset jira-v5.0&lt;br&gt;
$ time git add --all&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.0.3&lt;/code&gt;平均使用2.44秒。而&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.1.0&lt;/code&gt;平均使用2.18秒 —— 节省超过10%的时间！注意，由于实验条件这是个很不准确的测试，添加14500+个文件到索引中节省了1/4秒，所以在日常&lt;code&gt;git&lt;/code&gt;使用中不会看到大的变化。关于新索引格式可以在&lt;a href=&quot;https://code.google.com/p/git-core/source/browse/Documentation/technical/index-format.txt&quot;&gt;索引格式文档&lt;/a&gt;中了解更多。&lt;/p&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;不错！之前我没有开启这个功能，但升级到&lt;code&gt;2.1.0&lt;/code&gt;后性能变化很显著。再做一个快糙猛的测试，运行&lt;code&gt;git status&lt;/code&gt;显示之前我用的从&lt;code&gt;JIRA 5&lt;/code&gt;到&lt;code&gt;JIRA 6&lt;/code&gt;的暂存修改。显示暂存的14500+个文件，&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.0.3&lt;/code&gt;平均使用4.94秒。而&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.1.0&lt;/code&gt;平均使用3.99秒 —— 节省了多达～19%的时间。如果你使用了自定义的&lt;code&gt;shell&lt;/code&gt;提示符，在每次提示符显示时检查工作拷贝中是否有未提交的修改，这个性能就非常有用！当索引很大时，我明显觉得&lt;code&gt;bash&lt;/code&gt;反应快了一些。&lt;/p&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;在分析出谁提交某行（搞坏项目的）代码，&lt;code&gt;git blame&lt;/code&gt;更快了。我很高兴看到这个改进，就是说&lt;code&gt;git-guilt&lt;/code&gt;（我写的一个小工具，用于研究&lt;a href=&quot;https://blogs.atlassian.com/2014/07/git-guilt-blame-code-review/&quot;&gt;如何&lt;code&gt;blame&lt;/code&gt;提交的修改&lt;/a&gt;）可以有相当的性能提高，因为它重度依赖于&lt;code&gt;blame&lt;/code&gt;到函数的输出。&lt;/p&gt;
&lt;p&gt;又来一个快糙猛的测试，看一下算出&lt;code&gt;git&lt;/code&gt;源码仓库从&lt;code&gt;2.0.0&lt;/code&gt;到&lt;code&gt;2.1.0&lt;/code&gt;的『罪行证据』（&lt;code&gt;guilt transfer&lt;/code&gt;）要花多长时间。这个操作&lt;code&gt;git-guilt&lt;/code&gt;要在&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.0.0&lt;/code&gt;到&lt;code&gt;2.1.0&lt;/code&gt;修改过的不同大小的文件上调用886次&lt;code&gt;git blame&lt;/code&gt;命令。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;$ git guilt v2.0.0 v2.1.0&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.0.3&lt;/code&gt;平均使用72.1秒。而&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.1.0&lt;/code&gt;平均使用66.7秒，提升了7.5%！如果有兴趣，你可以看看&lt;a href=&quot;http://pastie.org/9492426&quot;&gt;&lt;code&gt;git-guilt transfer&lt;/code&gt;&lt;/a&gt;的实际代码（Karsten Blees的66 LOC行的实现，以微弱优势胜出Junio C Hamano）。&lt;/p&gt;
&lt;p&gt;上面的性能测试都有些随意，但我们正在进行&lt;code&gt;Bitbucket&lt;/code&gt;的&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.1.0&lt;/code&gt;升级。线上会监控升级前后的功能，可以确定新版本对这些操作的性能影响，特别是&lt;code&gt;blame&lt;/code&gt;和&lt;code&gt;diff&lt;/code&gt;操作。过几周我会发出结果让大家知道。&lt;/p&gt;
&lt;h2&gt;等等，还有还有！&lt;/h2&gt;
&lt;p&gt;在&lt;code&gt;git&lt;/code&gt; &lt;code&gt;2.1.0&lt;/code&gt;中还有其它很好的内容我没有在一篇文章中涉及到，所以有兴趣可以看看&lt;a href=&quot;https://raw.githubusercontent.com/git/git/master/Documentation/RelNotes/2.1.0.txt&quot;&gt;完整的发布说明文档&lt;/a&gt;。由衷地感谢&lt;code&gt;git&lt;/code&gt;团队又提供了一个高质量和丰富新功能的版本。如果你有兴趣了解更多有关于&lt;code&gt;git&lt;/code&gt;的实用小建议和花边新闻，欢迎在Twitter上关注我（&lt;a href=&quot;https://twitter.com/kannonboy&quot;&gt;@kannonboy&lt;/a&gt;）和Atlassian开发工具（&lt;a href=&quot;https://twitter.com/atldevtools&quot;&gt;@atldevtools&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;译注&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;
译文的源码在&lt;code&gt;GitHub&lt;/code&gt;的&lt;a href=&quot;https://github.com/quickhack/translations/tree/master/whats-new-git-2-1&quot;&gt;Git 2.1新特性&lt;/a&gt;。&lt;a href=&quot;http://weibo.com/oldratlee&quot;&gt;自己&lt;/a&gt;理解粗浅，翻译中不足和不对之处，欢迎建议（&lt;a href=&quot;https://github.com/quickhack/translations/issues&quot;&gt;提交Issue&lt;/a&gt;）和指正（&lt;a href=&quot;https://github.com/quickhack/translations/fork&quot;&gt;Fork后提交代码&lt;/a&gt;）！&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Mon, 08 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-08-76550-e3ab70ead.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-08-76550-e3ab70ead.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>移动开发需要知道的像素知识『多图』</title>
        <description>

	
	

	&lt;p&gt;&lt;img src=&quot;/images/weizhifeng.net/9d2907cfc7bdb7c48ea701cb214293f5.jpg&quot; title=&quot;title&quot; alt=&quot;title&quot;&gt;&lt;/p&gt;

&lt;p&gt;像素（Pixel）对于WEB开发者来说很是熟悉，在PC互联网时代没少与其打交道。进入移动互联网之后，随着移动设备屏幕的解析度越来越高，衍生了一些关于屏幕和像素的一些新概念，比如DPI，DP，PT，Retina，4K等等，本文对这些概念做一个简单的介绍。&lt;/p&gt;

&lt;h2&gt;DPI与PPI&lt;/h2&gt;

&lt;p&gt;DPI（Dots Per Inch）是印刷行业中用来度量空间点密度用的，这个值是打印机每英寸可以喷的墨汁点数。计算机显示设备从打印机中借鉴了DPI的概念，由于计算机显示设备中的原子单位不是墨汁点而是像素，所以就创造了PPI（Pixels Per Inch），这个值是屏幕每英寸的像素数量，即像素密度（Screen density）。由于各种原因，目前PPI(主要是iOS)和DPI(比如在&lt;a href=&quot;http://developer.android.com/guide/practices/screens_support.html#terms&quot;&gt;Android&lt;/a&gt;中)都会用在计算机显示设备的参数描述中，不过二者的意思是一样的，都是代表像素密度。&lt;/p&gt;

&lt;p&gt;高PPI屏幕显示的元素会比较精细（看起来会比较小），低PPI屏幕显示的元素相对来说就比粗糙（看起来会比较大），我们通过一幅图来看看在不同PPI下元素显示的区别：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/weizhifeng.net/375817a6231b35a39aedcc389785cd4c.jpg&quot; title=&quot;PPI&quot; alt=&quot;PPI&quot;&gt;&lt;/p&gt;

&lt;h2&gt;HD与4K&lt;/h2&gt;

&lt;p&gt;现在移动设备、智能电视宣传最多的两个关键词估计就是HD、4K，这二者都是用来描述显示设备分辨率的标准，到底二者之间有什么区别？&lt;/p&gt;

&lt;p&gt;HD(High-Definition)的分辨率要高于1280x720px或者720p。&lt;/p&gt;

&lt;p&gt;Full HD的分辨率要高于1920x1080px，目前是主流电视以及高端手机（比如Galaxy SIV, HTC one, Sony Xperia Z, Nexus5等）采用的是这个分辨率。&lt;/p&gt;

&lt;p&gt;4K（也叫做Quad HD或者Ultra HD）的分辨率从3840x2160起步，主要是现在高端电视的分辨率；其还有一个更高的4096x2160的标准，主要用于电影放映机或者专业相机。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/weizhifeng.net/9f67b75af71b33a442d121fad67b556f.jpg&quot; title=&quot;4k&quot; alt=&quot;4k&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Retina&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Retina_Display&quot;&gt;Retina display&lt;/a&gt;即视网膜屏幕，是苹果发布iPhone 4时候提出的，之所以叫做视网膜屏幕，是因为屏幕的PPI太高，人的视网膜无法分辨出屏幕上的像素点。iPhone 4/S的PPI为326，是iPhone 3G/S的两倍，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/weizhifeng.net/1989ea1cbdc4b76f42d17d7882d4d334.jpg&quot; title=&quot;retina-01&quot; alt=&quot;retina-01&quot;&gt;&lt;/p&gt;

&lt;p&gt;由于屏幕在宽和高的像素数量提高了整整一倍，所以之前非Retina屏幕上的一个像素渲染的内容在Retina屏幕上会用4个像素去渲染：&lt;code&gt;1x1px(non Retina) = 2x2px(Retina)&lt;/code&gt;，这样元素的内容就会变得精细，比如：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/weizhifeng.net/829faa674075ffdb240ca9fdd3797009.jpg&quot; title=&quot;retina-02&quot; alt=&quot;retina-02&quot;&gt;&lt;/p&gt;

&lt;p&gt;注意，&lt;code&gt;Retina display&lt;/code&gt;是苹果注册的命名方式，其他厂商只能使用&lt;code&gt;HI-DPI&lt;/code&gt;或者其他的命名方式，不过意思都是一样的，就是屏幕的PPI非常高。&lt;/p&gt;

&lt;h2&gt;DP/PT/SP&lt;/h2&gt;

&lt;p&gt;随着移动设备屏幕PPI的不断提高，对于开发者来说以前用物理像素(Physical Pixel)来度量显示元素的方法已经不奏效了。为了解决这个问题，两大平台都提出了抽象像素的概念：iOS叫做PT（Point，显示点），Android中叫做DP/DiP（Device independent Pixel，设备无关像素），如果没有特殊说明，以下统一用DP来进行描述。&lt;/p&gt;

&lt;p&gt;举个例子，44x44dp的元素在非Retina屏幕中等于44x44px，在Retina屏幕中等于88x88px（变为4倍）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/weizhifeng.net/e66891fc599472cb5703bf0019c725e6.jpg&quot; title=&quot;dp-01&quot; alt=&quot;dp-01&quot;&gt;&lt;/p&gt;

&lt;p&gt;SP（Scale-independent pixel）是缩放无关的像素，与DP和PT一样都是抽象像素，只不过用于描述字体的大小。&lt;/p&gt;

&lt;h2&gt;iOS中处理PPI&lt;/h2&gt;

&lt;p&gt;iOS中处理不同PPI显示的方法很简单：首先规定在多高的PPI下1DP等于1px，并以这个PPI作为基准（1x multiplier），如果显示设备的PPI是基准PPI的2倍，那么1DP等于2px（2x multiplier），其实就是简单的小学乘法。&lt;/p&gt;

&lt;p&gt;在iPhone系列中，3G/S为1x multiplier，其他为2x multiplier：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/weizhifeng.net/def49637d8580bb9fe6afc53b08eea2f.jpg&quot; title=&quot;ios-01&quot; alt=&quot;ios-01&quot;&gt;&lt;/p&gt;

&lt;p&gt;在iPad系列中，iPad 1代和2代为1x multiplier，其他为2x multiplier：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/weizhifeng.net/d3d4a647836cee38f924d5c93c5de251.jpg&quot; title=&quot;ios-02&quot; alt=&quot;ios-02&quot;&gt;&lt;/p&gt;

&lt;p&gt;在iPad Mini系列中，iPad Mini一代为1x multiplier，其他为2x multiplier：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/weizhifeng.net/2ff23f64e1a8a0a50851272789323945.jpg&quot; title=&quot;ios-03&quot; alt=&quot;ios-03&quot;&gt;&lt;/p&gt;

&lt;p&gt;在iOS中，同一个应用在非Retina屏幕和Retina屏幕显示的资源是不同的，其规则是：
&lt;code&gt;name.png&lt;/code&gt;为非Retina资源，&lt;code&gt;name@2x.png&lt;/code&gt;为Retina资源，所以对于设计人员来说，在你设计的时候需要考虑到Retina屏幕和非Retina屏幕，看下面这个例子：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/weizhifeng.net/dcb816243d9005a2f96181d42775d9d1.jpg&quot; title=&quot;ios-04&quot; alt=&quot;ios-04&quot;&gt;&lt;/p&gt;

&lt;h2&gt;Android中处理PPI&lt;/h2&gt;

&lt;p&gt;由于Android系统是开放的系统，要适配的PPI非常多，所以它对PPI划分的非常细：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ldpi (low) ~120dpi&lt;/li&gt;
&lt;li&gt;mdpi (medium) ~160dpi&lt;/li&gt;
&lt;li&gt;hdpi (high) ~240dpi&lt;/li&gt;
&lt;li&gt;xhdpi (extra-high) ~320dpi&lt;/li&gt;
&lt;li&gt;xxhdpi (extra-extra-high) ~480dpi&lt;/li&gt;
&lt;li&gt;xxxhdpi (extra-extra-extra-high) ~640dpi&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;你需要把对应dpi的资源放到对应的目录就可以了，Android会根据dpi自动选择资源，目录规则如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;drawable-mdpi/asset.png&lt;/li&gt;
&lt;li&gt;drawable-hdpi/asset.png&lt;/li&gt;
&lt;li&gt;drawable-xhdpi/asset.png&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;/ul&gt;


&lt;p&gt;可以看出Android中mdpi与iOS中的1x multiplier所代表的PPI是一样的，xhdpi与iOS的2x multiplier所代表的PPI一样，如图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/weizhifeng.net/21c329be0d1b37bb0944a2f24be2a2e8.jpg&quot; title=&quot;android-01&quot; alt=&quot;android-01&quot;&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/weizhifeng.net/6ee5509c9e80c3ae42290e742e353e6b.jpg&quot; title=&quot;android-02&quot; alt=&quot;android-02&quot;&gt;&lt;/p&gt;

&lt;h2&gt;参考&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://sebastien-gabriel.com/designers-guide-to-dpi/home&quot;&gt;http://sebastien-gabriel.com/designers-guide-to-dpi/home&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://developer.android.com/guide/practices/screens_support.html&quot;&gt;http://developer.android.com/guide/practices/screens_support.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


	(完)

	&lt;div class=&quot;post-info&quot;&gt;
		07 Sep 2014  
	
		
	
		
	&lt;/div&gt;
	
	&lt;!-- disqus start --&gt;
	
	
	
	
	&lt;!-- disqus end --&gt;

	&lt;!-- related start --&gt;
	
	&lt;!-- related end --&gt;

</description>
        <pubDate>Sun, 07 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-07-you-should-know-about-dpi.html-e3405bc14.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-07-you-should-know-about-dpi.html-e3405bc14.html</guid>
        
        
        <category>weizhifeng</category>
        
      </item>
    
      <item>
        <title>Linux ftrace TCP Retransmit Tracing</title>
        <description>

&lt;p&gt;Why is my Linux system doing TCP retransmits? Lets see packet details and kernel state:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;./tcpretrans&lt;/b&gt;
TIME     PID    LADDR:LPORT          -- RADDR:RPORT          STATE
05:16:44 3375   10.150.18.225:53874  R&amp;gt; 10.105.152.3:6001    ESTABLISHED
05:16:44 3375   10.150.18.225:53874  R&amp;gt; 10.105.152.3:6001    ESTABLISHED
05:16:54 4028   10.150.18.225:6002   R&amp;gt; 10.150.30.249:1710   ESTABLISHED
05:16:54 4028   10.150.18.225:6002   R&amp;gt; 10.150.30.249:1710   ESTABLISHED
05:16:54 4028   10.150.18.225:6002   R&amp;gt; 10.150.30.249:1710   ESTABLISHED
05:16:55 0      10.150.18.225:47115  R&amp;gt; 10.71.171.158:6001   ESTABLISHED
05:16:58 0      10.150.18.225:44388  R&amp;gt; 10.103.130.120:6001  ESTABLISHED
^C
Ending tracing...
&lt;/pre&gt;

&lt;p&gt;Awesome!&lt;/p&gt;

&lt;p&gt;tcpretrans is a script from my &lt;a href=&quot;https://github.com/brendangregg/perf-tools&quot;&gt;perf-tools&lt;/a&gt; collection, and uses &lt;a href=&quot;/blog/2014-08-30/ftrace-the-hidden-light-switch.html&quot;&gt;ftrace&lt;/a&gt; to dynamically instrument the tcp_retransmit_skb() kernel function. One reason this is awesome is that the overhead is negligible: it only adds instrumentation to the retransmit path. It&#39;s also using existing Linux kernel features, ftrace and kprobes, and doesn&#39;t even need kernel debuginfo.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This does not trace every packet and then filter&lt;/strong&gt;, such as if I had used any tcpdump/libpcap/kernel-packet-filter approach, which can become painful for high packet rates. (I think it would also be lazy to trace every packet when you can just trace the kernel retransmit code path.)&lt;/p&gt;

&lt;p&gt;Using a tracer like ftrace means I can also dig out kernel state, which is invisible to on-the-wire tracers like tcpdump. I only included the kernel STATE column, but anything kernel-side could be included.&lt;/p&gt;

&lt;p&gt;The -s option will include the kernel stack trace that led to the TCP retransmit:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;./tcpretrans -s&lt;/b&gt;
TIME     PID    LADDR:LPORT          -- RADDR:RPORT          STATE
06:21:10 19516  10.144.107.151:22    R&amp;gt; 10.13.106.251:32167  ESTABLISHED
 =&amp;gt; tcp_fastretrans_alert
 =&amp;gt; tcp_ack
 =&amp;gt; tcp_rcv_established
 =&amp;gt; tcp_v4_do_rcv
 =&amp;gt; tcp_v4_rcv
 =&amp;gt; ip_local_deliver_finish
 =&amp;gt; ip_local_deliver
 =&amp;gt; ip_rcv_finish
 =&amp;gt; ip_rcv
 =&amp;gt; __netif_receive_skb
 =&amp;gt; netif_receive_skb
 =&amp;gt; handle_incoming_queue
 =&amp;gt; xennet_poll
 =&amp;gt; net_rx_action
 =&amp;gt; __do_softirq
 =&amp;gt; call_softirq
 =&amp;gt; do_softirq
 =&amp;gt; irq_exit
 =&amp;gt; xen_evtchn_do_upcall
 =&amp;gt; xen_do_hypervisor_callback
[...]
&lt;/pre&gt;

&lt;p&gt;In this case, the retransmit was sent after receiving a packet (ip_rcv()), processing a TCP ACK (tcp_ack()), and then by tcp_fastretrans_alert(). This is a TCP fast retransmit. Ie, these:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;netstat -s | grep -i retr&lt;/b&gt;
    242 segments retransmited
    &lt;b&gt;46 fast retransmits&lt;/b&gt;
    2 forward retransmits
    3 retransmits in slow start
&lt;/pre&gt;

&lt;p&gt;Here are a couple of timer-based retransmits for comparison:&lt;/p&gt;

&lt;pre&gt;
06:38:45 0      10.11.172.162:7102   R&amp;gt; 10.10.153.60:47538   ESTABLISHED
 =&amp;gt; tcp_write_timer_handler
 =&amp;gt; tcp_write_timer
 =&amp;gt; call_timer_fn
 =&amp;gt; run_timer_softirq
 =&amp;gt; __do_softirq
 =&amp;gt; irq_exit
 =&amp;gt; xen_evtchn_do_upcall
 =&amp;gt; xen_hvm_callback_vector
 =&amp;gt; default_idle
 =&amp;gt; arch_cpu_idle
 =&amp;gt; cpu_startup_entry
 =&amp;gt; start_secondary
06:38:45 0      10.11.172.162:7102   R&amp;gt; 10.10.153.60:47539   ESTABLISHED
 =&amp;gt; tcp_write_timer_handler
 =&amp;gt; tcp_write_timer
 =&amp;gt; call_timer_fn
 =&amp;gt; run_timer_softirq
 =&amp;gt; __do_softirq
 =&amp;gt; irq_exit
 =&amp;gt; xen_evtchn_do_upcall
 =&amp;gt; xen_hvm_callback_vector
 =&amp;gt; default_idle
 =&amp;gt; arch_cpu_idle
 =&amp;gt; cpu_startup_entry
 =&amp;gt; rest_init
 =&amp;gt; start_kernel
 =&amp;gt; x86_64_start_reservations
 =&amp;gt; x86_64_start_kernel
&lt;/pre&gt;

&lt;p&gt;These come from a callback, and tcp_write_timer_handler(). Timer-based retransmits are worse than fast retransmits, as they add timer-based latency to application requests. This is usually 1000 ms in Linux.&lt;/p&gt;

&lt;p&gt;My tcpretrans ftrace-based tool is a hack, and may not work on some systems without alterations (it also doesn&#39;t support IPv6 yet). To dig out custom details like IP addresses as dotted quad strings, I really should be using a programmable tracer like SystemTap. However, I wanted to see if this was possible with just ftrace, as it would make it easier to use in my production environment (Netflix cloud).&lt;/p&gt;

&lt;p&gt;It works like this:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Dynamically instrument tcp_retransmit_skb() using kprobes, and capture the %di register.&lt;/li&gt;
&lt;li&gt;Assume the skb pointer is in register %di (to know for certain would require kernel debuginfo, which I don&#39;t normally have on production systems). On non-x86 systems, this may well be in another register, and this script will need editing.&lt;/li&gt;
&lt;li&gt;Wait one second.&lt;/li&gt;
&lt;li&gt;Read the kernel buffer of tcp_retransmit_skb() events, with skb pointers.&lt;/li&gt;
&lt;li&gt;Read /proc/net/tcp, and cache socket details by skb.&lt;/li&gt;
&lt;li&gt;Assume retransmits happen for long-lived sessions (&amp;gt; 1 second), and the session details would still have been in /proc/net/tcp when it was read.&lt;/li&gt;
&lt;li&gt;Parse the kernel buffer of tcp_retransmit_skb() events and print retransmit events with session details from the /proc/net/tcp data we read earlier.&lt;/li&gt;
&lt;li&gt;Goto 3.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;On an earlier version, I read /proc/net/tcp synchronously when retransmits occurred, but on production systems with frequent retransmits and tens of thousands of open connections (making for a very large /proc/net/tcp), the CPU overhead of that approach was too high. The approach above only reads /proc/net/tcp once per second.&lt;/p&gt;

&lt;p&gt;So, it was a gift to have socket details in /proc/net/tcp, and not need to dig them out using ftrace. That would be possible, but the script would become much more brittle without kernel debuginfo, as there would then be several assumptions about registers and struct offsets, rather than just skb being in %di. Without /proc/net/tcp, I&#39;d only really attempt this &lt;em&gt;with&lt;/em&gt; kernel debuginfo, where I could make it reasonbly reliable.&lt;/p&gt;

&lt;p&gt;So far tcpretrans has proved quite useful to quickly get some details on TCP retransmits: not just source and destionation addresses and ports, but kernel state and stack traces.&lt;/p&gt;


</description>
        <pubDate>Sat, 06 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-06-linux-ftrace-tcp-retransmit-tracing.html-85fa9c336.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-06-linux-ftrace-tcp-retransmit-tracing.html-85fa9c336.html</guid>
        
        
        <category>brendangregg</category>
        
      </item>
    
      <item>
        <title>用 Spark 处理数据导入 Elasticsearch</title>
        <description>

  
  &lt;div style=&quot;background-color: #FFF;&quot;&gt;
    &lt;p&gt;Logstash 说了这么多。其实运用 Kibana 和 Elasticsearch 不一定需要 logstash，其他各种工具导入的数据都可以。今天就演示一个特别的~用 Spark 来处理导入数据。&lt;/p&gt;
&lt;p&gt;首先分别下载 spark 和 elasticsearch-hadoop 的软件包。注意 elasticsearch-hadoop 从最新的 2.1 版开始才带有 spark 支持，所以要下新版：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;wget http://d3kbcqa49mib13.cloudfront.net/spark-1.0.2-bin-cdh4.tgz
wget http://download.elasticsearch.org/hadoop/elasticsearch-hadoop-2.1.0.Beta1.zip&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;分别解压开后，运行 spark 交互命令行 &lt;code&gt;ADD_JARS=../elasticsearch-hadoop-2.1.0.Beta1/dist/elasticsearch-spark_2.10-2.1.0.Beta1.jar ./bin/spark-shell&lt;/code&gt; 就可以逐行输入 scala 语句测试了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意 elasticsearch 不支持 1.6 版本的 java，所以在 MacBook 上还设置了一下 &lt;code&gt;JAVA_HOME=&quot;/Library/Internet Plug-Ins/JavaAppletPlugin.plugin/Contents/Home&quot;&lt;/code&gt; 启用自己从 Oracle 下载安装的 1.7 版本的 Java。&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;section&quot;&gt;基础示例&lt;/h1&gt;
&lt;p&gt;首先来个最简单的测试，可以展示写入 ES 的用法：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.SparkConf&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.elasticsearch.spark._&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// 更多 ES 设置，见&amp;lt;http://www.elasticsearch.org/guide/en/elasticsearch/hadoop/2.1.Beta/configuration.html&amp;gt;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;SparkConf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;es.index.auto.create&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;es.nodes&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;127.0.0.1&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// 在spark-shell下默认已建立&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// import org.apache.spark.SparkContext    &lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// import org.apache.spark.SparkContext._&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// val sc = new SparkContext(conf)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numbers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;one&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;two&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;three&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;airports&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;OTP&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Otopeni&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;SFO&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;San Fran&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;makeRDD&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Seq&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;numbers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;airports&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;saveToEs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark/docs&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这就 OK 了。尝试访问一下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ curl &#39;127.0.0.1:9200/spark/docs/_search?q=*&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;返回结果如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;took&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;66&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;timed_out&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;_shards&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;total&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;successful&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;failed&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;hits&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;total&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;max_score&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;hits&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:[{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;_index&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;spark&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;_type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;docs&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;BwNJi8l2TmSRTp42GhDmww&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;_score&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;&quot;_source&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;one&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;two&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;three&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}},{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;_index&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;spark&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;_type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;docs&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;_id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;7f7ar-9kSb6WEiLS8ROUCg&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;_score&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;&quot;_source&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;OTP&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Otopeni&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;SFO&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;San Fran&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}}]}}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h1 id=&quot;section-1&quot;&gt;文件处理&lt;/h1&gt;
&lt;p&gt;下一步，我们看如何读取文件和截取字段。scala 也提供了正则和捕获的方法：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;textFile&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/var/log/system.log&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Pattern&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;(\w{3}\s+\d{1,2} \d{2}:\d{2}:\d{2}) (\S+) (\S+)\[(\d+)\]: (.+)&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;r&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entries&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;Pattern&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timestamp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;program&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;timestamp&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;timestamp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;host&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;program&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;program&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;pid&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pid&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;message&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;message&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Map&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;message&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;entries&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;saveToEs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;spark/docs&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里示例写了两个 &lt;code&gt;case&lt;/code&gt; ，因为 Mac 上的 “system.log” 不知道用的什么 syslog 协议，有些在 &lt;code&gt;[pid]&lt;/code&gt; 后面居然还有一个 &lt;code&gt;(***)&lt;/code&gt; 才是 &lt;code&gt;:&lt;/code&gt;。正好就可以用这个来示例如果匹配失败的情况如何处理。不加这个默认 &lt;code&gt;case&lt;/code&gt; 的话，匹配失败的就直接报错不会存进 &lt;code&gt;entries&lt;/code&gt; 对象了。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;code&gt;.textFile&lt;/code&gt; 不是 scala 标准的读取文件函数，而是 sparkContext 对象的方法，返回的是 RDD 对象(包括后面的 &lt;code&gt;.map&lt;/code&gt; 返回的也是新的 RDD 对象)。所以后面就不用再 &lt;code&gt;.makeRDD&lt;/code&gt; 了。&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&quot;section-2&quot;&gt;网络数据&lt;/h1&gt;
&lt;p&gt;Spark 还有 Spark streaming 子项目，用于从其他网络协议读取数据，比如 flume，kafka，zeromq 等。官网上有一个配合 &lt;code&gt;nc -l&lt;/code&gt; 命令的示例程序。&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;org.apache.spark.streaming._&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;StreamingContext&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Seconds&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;val&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lines&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;socketTextStream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;localhost&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9999&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ssc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;awaitTermination&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;有时间我会继续尝试 Spark 其他功能。&lt;/p&gt;
    &lt;hr&gt;
    
    &lt;hr&gt;
  &lt;!-- UY BEGIN --&gt;


&lt;!-- UY END --&gt;
  &lt;/div&gt;

</description>
        <pubDate>Thu, 04 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-04-spark-to-elasticsearch-b436fd476.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-04-spark-to-elasticsearch-b436fd476.html</guid>
        
        
        <category>chenlinux</category>
        
      </item>
    
      <item>
        <title>【调侃】IOC前世今生</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;前些天，参与了公司内部小组的一次技术交流，主要是针对《IOC与AOP》，本着学而时习之的态度及积极分享的精神，我就结合一个小故事来初浅地剖析一下我眼中的“IOC前世今生”，以方便初学者能更直观的来学习与理解IOC！也作抛砖引玉之用。&lt;/p&gt;
&lt;p&gt;（虽说故事中的需求有点小，但看客可在脑海中尽量把他放大，想象成一个很大的应用系统）&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、&lt;/strong&gt;&lt;strong&gt;IOC&lt;/strong&gt;&lt;strong&gt;雏形&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;strong&gt;、程序V1.0&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;话说，多年以前UT公司提出一个需求，要提供一个系统，其中有个功能可以在新春佳节之际给公司员工发送一封邮件。邮件中给大家以新春祝福，并告知发放一定数额的过节费。&lt;/p&gt;
&lt;p&gt;经分析，决定由张三、李四和王五来负责此系统的开发。&lt;/p&gt;
&lt;p&gt;其中：由张三负责业逻辑控制模块 LogicController的开发,此处简化为UT.LogicController.exe ；由李四负责祝福消息管理类（GreetMessageService），并集成到组件 UT.MessageService.dll中；由王五负责邮件功能帮助类（EmailHelper），并提供组件 UT.Email.dll。&lt;/p&gt;
&lt;p&gt;类依赖关系如下：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/09/0bcf61cc8c03df25dfd2c236c039267c.png&quot; rel=&quot;lightbox[76510]&quot; title=&quot;【调侃】IOC前世今生&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-76511&quot; alt=&quot;021118402663083&quot; src=&quot;/images/jobbole.com/0889dac3881de5b9dfa5c457ee0e7baa.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public class EmailHelper
{
    public void Send(string message)
    {
        Console.Write(&quot;Frome email: &quot; + message);            
    }
}&lt;/pre&gt;
&lt;p&gt;李四消息管理模块核心代码如下：&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public class GreetMessageService
{
    EmailHelper greetTool;

    public GreetMessageService()
    {
        greetTool = new EmailHelper();
    }

    public void Greet(string message)
    {
        greetTool.Send(message);
    }
}&lt;/pre&gt;
&lt;p&gt;张三业务集成模块核心代码如下：&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;string message = &quot;新年快乐！过节费5000.&quot;;
MessageService.GreetMessageService service = new MessageService.GreetMessageService();
service.Greet(message);&lt;/pre&gt;
&lt;p&gt;三人经过一个月的艰苦奋战，终于大功告成，系统也在春节其间成功发出问候信。企业如此关怀，给员工带来无比的温暖，因此深受全体员工好评！&lt;/p&gt;
&lt;p&gt;春节过后，相应的功能也移植到了与“UT公司”相关的“UT编辑部”和“UT房产”类似的应用当中，并在后继的“元宵”、“端午”、“中秋”等节日中得以广泛应用。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;strong&gt;、程序V2.0&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;又是一个年关将至……&lt;/p&gt;
&lt;p&gt;说真的，过节费的多少，有时可能直接影响整个假日的行程安排、从而影响假日的整体质量，因此部门领导高度重视。而邮件通知的方式，在边远山区常常因为受网络环境的影响而无法正常收取，许多在外过年的同事对此颇有微词。后经多方考证，决得采用当下非常主流的电话语言播报的方式进行通知。&lt;/p&gt;
&lt;p&gt;于是乎，张三、李四、王五又忙起来了。但李四，却有点头疼了，因为他的模块现在不仅在“UT公司”内部使用，而且还在“UT编辑部”和“UT房产”也都有独立运行。如何让此处变化影响最小，就得费点脑筋。为了达到较好的效果，李四决定按以下方式进行整改。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;    ①&lt;/strong&gt;&lt;strong&gt;、初始设计方案如下：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/09/0d4418f6c0eb1d14e440ce959f16aa6c.png&quot; rel=&quot;lightbox[76510]&quot; title=&quot;【调侃】IOC前世今生&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-76512&quot; alt=&quot;021120182039995&quot; src=&quot;/images/jobbole.com/3e307f19c586bfd2289dc320c2bfbb7e.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;首先为了能让不同“祝福方式”能有效替换，决定以“面向接口”的方式来进行分离。同时，让EmailHelper的邮件通知类和TelephoneHelper的语音播报类都实现此接口。核心代码如下：&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public interface ISendable
{
    void Send(string message);
}&lt;/pre&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public class EmailHelper : ISendable
{
    public void Send(string message)
    {
        Console.Write(&quot;Frome email: &quot; + message);
    }
}&lt;/pre&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public class TelephoneHelper : ISendable
{
    public void Send(string message)
    {
        Console.Write(&quot;Frome telephone: &quot; + message);
    }
}&lt;/pre&gt;
&lt;p&gt;再者，为了方便兼容新旧产品，要求Controller决定当前采用什么方式进行通信，并以参数方式传给消息管理模块，核心代码如下：&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public enum SendToolType
{
    Email,
    Telephone,
}&lt;/pre&gt;
&lt;p&gt;【备注】:上述代码，并不是一个优秀的设计，在后继的优化方案当中将被去除。&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public class GreetMessageService
{
    ISendable greetTool;

    public GreetMessageService(SendToolType sendToolType)
    {
        if (sendToolType == SendToolType.Email)
        {
            greetTool = new UT.EmailV20.EmailHelper();
        }
        else if (sendToolType == SendToolType.Telephone)
        {
            greetTool = new UT.TelephoneV20.TelephoneHelper();
        }
    }

    public void Greet(string message)
    {
        greetTool.Send(message);
    }
}&lt;/pre&gt;
&lt;p&gt;【备注】:上述代码，并不是一个优秀的设计，在后继的优化方案当中将被优化。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;最后，业务集成模块结合具体业务需求进行适当的调整，核心代码如下：&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;string message = &quot;新年快乐！过节费5000.&quot;;
GreetMessageService service = new GreetMessageService(SendTool.Telephone);
service.Greet(message);&lt;/pre&gt;
&lt;p&gt;眼看即将完工，但李四却越看越不顺眼，因为考虑到以后可能再添加新的祝福方式，这种未来的不确定性，一定会让李四现有的枚举SendToolType和 GreetMessageService中的构造函数不断的进行更改，这将会是一个没完没了工作。&lt;/p&gt;
&lt;p&gt;再说了，既然张三要传SendToolType给我，也就是说在具体产品应用时，张三的模块肯定是知道要采用什么方式进行祝福，那么何不让他直接把祝福方式的实例而不是简单的方式类型给我呢？这样，我不就省事了吗，于是乎把设计进行了优化。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;   ②&lt;/strong&gt;&lt;strong&gt;、优化后设计方案：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/09/eed2a807894bc5e1f4c312dc1a7f298d.png&quot; rel=&quot;lightbox[76510]&quot; title=&quot;【调侃】IOC前世今生&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-76513&quot; alt=&quot;021120417194179&quot; src=&quot;/images/jobbole.com/42e5a24214105dcf35ce2d0266fae888.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;又是一个月的苦战……&lt;/p&gt;
&lt;p&gt;王五的代码不受影响。&lt;/p&gt;
&lt;p&gt;李四删除 SendToolType枚举，同进把GreetMessageService改成如下：&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public class GreetMessageService
{
    ISendable greetTool;

    public GreetMessageService(ISendable sendtool)
    {
        greetTool = sendtool;
    }

    public void Greet(string message)
    {
        greetTool.Send(message);
    }
}&lt;/pre&gt;
&lt;p&gt;张三，也把业务逻辑控制部分改成如下：&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;string message = &quot;新年快乐！ 过节费5000.&quot;;
ISendable greetTool = new TelephoneHelper();
GreetMessageService service = new GreetMessageService(greetTool);
service.Greet(message);&lt;/pre&gt;
&lt;p&gt;最终：张三更新UT.LogicController.exe中的实现；李四更新了UT.MessageSevice.dll,王五提供新的组件：UT.Telephone.dll，并把接口集成到一个叫UT.Core.dll的库中。经多方集成测试后系统运行良好！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【点评】：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;    &lt;/em&gt;李四此处成功的利用“接口分离”、并结合“依赖倒置”的方式，使得自己负责的模块初步具备了应对新增祝福方式的扩展要求。同时由于其采用的“依赖注入”方式要求李四的业务逻辑控制模块对其所需的 &lt;/strong&gt;&lt;strong&gt;“ISendable&lt;/strong&gt;&lt;strong&gt;”实例进行注入，理论上已经初步具体了“IOC&lt;/strong&gt;&lt;strong&gt;反转控制”的雏形。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;    对“IOC&lt;/strong&gt;&lt;strong&gt;反转控制”此时带来的优势就是：确保了“红色框”内的模块是具有应对变化的能力，在后继新增新祝福方式时，UT.MessageService.dll&lt;/strong&gt;&lt;strong&gt;组件可以完全不做任何修改。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;strong&gt;、V2.1&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于电话语言播报必须接听、过后不便留底查询等不足也常被人们诟病，因此短信通知的方式被提上议程。&lt;/p&gt;
&lt;p&gt;在此要求下，王五提供了新的组件：UT.GSN.dll。核心代码如下：&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public class SMSHelper : ISendable
{
    public void Send(string message)
    {
        Console.WriteLine(&quot;Frome SMS: &quot; + message);
    }
}&lt;/pre&gt;
&lt;p&gt;张三也把代码改成了如下，&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;string message = &quot;新年快乐！ 过节费5000.&quot;;
ISendable greetTool = new SMSHelper();
GreetMessageService service = new GreetMessageService(greetTool);
service.Greet(message);&lt;/pre&gt;
&lt;p&gt;李四坐享其成！&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;strong&gt;、V2.2&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;祝福方式日新月异人们的要求也是不断发展，没过多久短信方式太呆板、信息量不足等缺陷也暴露出来，微信深受大伙青睐。&lt;/p&gt;
&lt;p&gt;在此要求下，王五提供了新的组件：UT.Wechat.dll。核心代码如下：&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public class WechatHelper : ISendable
{
    public void Send(string message)
    {
        Console.WriteLine(&quot;Frome wechat: &quot; + message);
    }
}&lt;/pre&gt;
&lt;p&gt;张三也把代码改成了如下：&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;string message = &quot;新年快乐！ 过节费5000.&quot;;
ISendable greetTool = new WechatHelper();
GreetMessageService service = new GreetMessageService(greetTool);
service.Greet(message);&lt;/pre&gt;
&lt;p&gt;李四再次坐享其成！！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二、IOC&lt;/strong&gt;&lt;strong&gt;扩展&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;strong&gt;、李四的逍遥自在与张三的焦头烂额&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;由于采用了IOC反转控制的思想，现在不管系统如何变化，李四负责的模块总的来说还是相当稳定，因此这些年李四过的可谓逍遥自在。然而，相比之下张三却因为产品在UT公司、UT编辑部、UT房产等都有独立应用，且各自使用的版本又不尽相同，因此要同时维护三个版本，可谓是焦头烂额。&lt;/p&gt;
&lt;p&gt;当然张三曾经也想统一各个版本，从而实现代码的统一维护。为此还专门与各相关主管沟通过、协调过，然而由为UT编辑部与电信服务商早有合作所有短信免费，因此短信方式最得人心；而UT房产基于对信息接收者身份的特殊性考虑，邮件通知被认为是不二选择。因此，张三统一版本的梦想最终还是无果而终。&lt;/p&gt;
&lt;p&gt;我们来看看此时的张三同时维护着三个系统，其中各自核心代码基本如下：&lt;/p&gt;
&lt;p&gt;UT公司（微信方式）&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;string message = &quot;新年快乐！ 过节费5000.&quot;;
ISendable greetTool = new WechatHelper();
GreetMessageService service = new GreetMessageService(greetTool);
service.Greet(message);&lt;/pre&gt;
&lt;p&gt;UT编辑部（短信方式）&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;string message = &quot;新年快乐！ 过节费5000.&quot;;
ISendable greetTool = new SMSHelper();
GreetMessageService service = new GreetMessageService(greetTool);
service.Greet(message);&lt;/pre&gt;
&lt;p&gt;UT房产(邮件方式)&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;string message = &quot;新年快乐！ 过节费5000.&quot;;
ISendable greetTool = new EmailHelper();
GreetMessageService service = new GreetMessageService(greetTool);
service.Greet(message);&lt;/pre&gt;
&lt;p&gt;这些年，本着对工作和客户的认真负责，张三长时间在这些“版本维护”、“产品兼容”等脏活累活中摸爬滚打，现在是心力憔悴……&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;strong&gt;、张三的出路&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;某日张三与李四觥筹交错、把酒言欢……&lt;/p&gt;
&lt;p&gt;酒过三巡，张三对李四说：当年你的模块因“IOC反转控制”而脱身，却把“变化点”反转到我模块，由我来生成特定的对象，然后再向你注入。这样你是轻松了，但我却深陷泥潭……&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;面对张三的吐槽，李四只能给张三进行细心分析：&lt;/p&gt;
&lt;p&gt;首先、MessageService消息管理模块作为一个消息专用服务，其实对“是采用邮件还是微信方式进行祝福”这样的功能性把控本身是不具主动权，由这个模块来负责实在是有点鞭长莫及，即便强扭到一起，这瓜也铁定甜不了。&lt;/p&gt;
&lt;p&gt;还有，本着单一职责的原则本消息服务其实是不方便过多地去处理本应该是业务逻辑处理的类似“选择祝福方式”这种事情。理论上，作为业务集成方的“LogicController”负责处理这类业务应该是责无傍代。&lt;/p&gt;
&lt;p&gt;再者，作为新增需求，王五为此而新增组件（dll）那是必不可少；张三作为业务的总集成方也是难以脱身；由于新增需求而引起的变化，对张三和王五产生影响也是情理之中。即便退一万步来说，就算没有“反转控制”张三也是要面对变化的（就像V2.0初始方案中的传入SendToolType参数），因此有无“反转控制”对张三而言该变的始终还是要变化。那么现在采用“IOC反转控制”而成全了李四的稳定，对张三来说这是个“利人不损已”的买卖。&lt;/p&gt;
&lt;p&gt;最后，不管从架构设计还是开发效率上来说，“IOC反转控制”虽说把变化点从李四的“MessageService”模块反转到了张三的“LogicController”模块当中，但这符合“SOLID面向对象设计”的原则，可以说是一个好的设计，本无可厚非！&lt;/p&gt;
&lt;p&gt;听完李四的论述，张三觉得甚是有理，酒不免醒了三分！由于两人都是这个行业打拼多年的老鸟，争论也是点到即止。马上把交流的重点转移到“如何解决张三同时维护三个产品”的尴尬处境上来。&lt;/p&gt;
&lt;p&gt;经过深入分析，两人觉得要脱困必须解决好如下两个问题：&lt;/p&gt;
&lt;p&gt;①：如何有效创建“ISendable”实例，减少由于新增祝福方式对实例创建的影响？&lt;/p&gt;
&lt;p&gt;②：如何减少新增祝福方式而对“LogicController”模块的冲击，以减少维护成本？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【备注】&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;     SOLID&lt;/strong&gt;&lt;strong&gt;面向对象的五个设计原则对于开发人员非常重要，其身影在任何大中型软件项目中随处可见，建议必须掌握并灵活应用。此五原则分别为：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;    单一职责原则（Single Resposibility Principle&lt;/strong&gt;&lt;strong&gt;）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;    开放封闭原则（Open Closed principle&lt;/strong&gt;&lt;strong&gt;）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;    里氏替换原则（&lt;/strong&gt;&lt;strong&gt;Liskov Substitution Principle&lt;/strong&gt;&lt;strong&gt;）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;    接口分离原则（&lt;/strong&gt;&lt;strong&gt;Interface Segregation Principle&lt;/strong&gt;&lt;strong&gt;）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;    依赖倒置原则 （Dependency Inversion Principle&lt;/strong&gt;&lt;strong&gt;）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;strong&gt;、解决方案&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了实现“如何有效创建ISendable实例”的问题，张三引入了“工厂模式”，由于不同的祝福方式而产生的变化，封装在一个独立的“&lt;strong&gt;SendToolFactory&lt;/strong&gt;”类中，这样就算以后再有变化，只要更改此类中部分代码即可，而不影响程序中其他所有用到ISendable的地方。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;【点评】：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;以工厂模式来实现“ISendable&lt;/strong&gt;&lt;strong&gt;”对象实例的创建，是一种典型的“高内聚”与“松耦合”的设计方式，它有效的使得应用程序核心部分并不用去关心系统到底采用了什么样的“祝福方式”，而具体的“祝福方式”则在工厂模式内部进行创建。如果以后需求有变动，那也只需在工厂做少许修改即可，程序其他代码都将不受影响。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当成功解决完第一个问题后，我们立即拉开针对“如何能实现在新增祝福方式之后，有效的控制对“LogicController”模块的冲击”这们问题上来。从目前程序的结构来看，在新增祝福方式之后的主要冲击有两方面：首先是更改工厂类中的代码用以创建新的实例；再者是引入新的动态库。&lt;/p&gt;
&lt;p&gt;最后我们决定采用“工厂模式+反射机制”的方式来解决上述难题，并在工厂模式中依靠配置文件的节点信息，然后采用“反射机制”来动态创建相应的实例；如此一来，以后就算再有新的祝福方式采用，也只需把王五新增的动态库拷贝过来，然后再更改一下配置文件中的节点信息就行，不再需要更改任何程序源代码，也不再需要重新编译生成程序。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;strong&gt;、程序V3.0&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;采用工厂模式创建实例&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;string message = &quot;新年快乐！ 过节费5000.&quot;;
ISendable greetTool = SendToolFactory.GetInstance();
GreetMessageService service = new GreetMessageService(greetTool);
service.Greet(message);&lt;/pre&gt;
&lt;p&gt;工厂中的实现&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;public abstract class SendToolFactory
    {
        public static ISendable GetInstance()
        {
            try
            {
                Assembly assembly = Assembly.LoadFile(GetAssembly()); // 加载程序集
                object obj = assembly.CreateInstance(GetObjectType()); // 创建类的实例 
                return obj as ISendable;
            }
            catch
            {
                return null;
            }
        }

        static string GetAssembly()
        {
            return Path.Combine(AppDomain.CurrentDomain.BaseDirectory, ConfigurationManager.AppSettings[&quot;AssemblyString&quot;]);            
        }

        static string GetObjectType()
        {
            return ConfigurationManager.AppSettings[&quot;TypeString&quot;];
      }
}&lt;/pre&gt;
&lt;p&gt;配置文件节点信息&lt;/p&gt;
&lt;pre class=&quot;brush: csharp; gutter: true&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&amp;gt;
&amp;lt;configuration&amp;gt;
  &amp;lt;appSettings&amp;gt;
    &amp;lt;!--&amp;lt;add key=&quot;AssemblyString&quot; value=&quot;UT.EmailV20.dll&quot; /&amp;gt;
    &amp;lt;add key=&quot;TypeString&quot; value=&quot;UT.EmailV20.EmailHelper&quot; /&amp;gt;--&amp;gt;
    
    &amp;lt;!--&amp;lt;add key=&quot;AssemblyString&quot; value=&quot;UT.SMSV21.dll&quot; /&amp;gt;
    &amp;lt;add key=&quot;TypeString&quot; value=&quot;UT.SMSV21.SMSHelper&quot; /&amp;gt;--&amp;gt;

    &amp;lt;add key=&quot;AssemblyString&quot; value=&quot;UT.WechatV22.dll&quot; /&amp;gt;
    &amp;lt;add key=&quot;TypeString&quot; value=&quot;UT.WechatV22.WechatHelper&quot; /&amp;gt;
  &amp;lt;/appSettings&amp;gt;      
&amp;lt;/configuration&amp;gt;&lt;/pre&gt;
&lt;p&gt;自从V3.0推出后，基于“IOC反转控制”的思想也算小有收获，多年来产品运行良好，就算不断有新的“祝福方式”出现，张三和李四也都不必再为之操心，同时也能适用“UT公司”、“UT编辑部”和“UT房产”等不同的场景要求，可谓皆大欢喜。&lt;/p&gt;
&lt;p&gt;【&lt;strong&gt;点评&lt;/strong&gt;】：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;①&lt;/strong&gt;&lt;strong&gt;：IOC&lt;/strong&gt;&lt;strong&gt;反转控制常见的实现手段之一就是DI&lt;/strong&gt;&lt;strong&gt;依赖注入，而依赖注入的方式通常有：接口注入、Setter&lt;/strong&gt;&lt;strong&gt;注入和构造函数注入。本次示例给出的代码具备“接口注入”的特征，并通过构造函数来实现。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;    &lt;/strong&gt;&lt;strong&gt;②&lt;/strong&gt;&lt;strong&gt;：IOC&lt;/strong&gt;&lt;strong&gt;反转控制还有一种手段就是依赖查找，这种方式一般先进行类型注册，使用时进行查找；对这种方式有兴趣的朋友可以参考微软企业库中Microsoft.Practices.Unity.dll&lt;/strong&gt;&lt;strong&gt;中的源码（&lt;a href=&quot;https://entlib.codeplex.com/&quot;&gt;https://entlib.codeplex.com/&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;）和详细的示例说明整理（如：Enterprise Library 4.1 HOL&lt;/strong&gt;&lt;strong&gt;）。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;     &lt;/strong&gt;&lt;strong&gt;③&lt;/strong&gt;&lt;strong&gt;:&lt;/strong&gt;&lt;strong&gt;依赖注入一般由调用者（LogicController&lt;/strong&gt;&lt;strong&gt;）依赖IOC&lt;/strong&gt;&lt;strong&gt;框架生成好实例对象，然后直接注入到被调用者（GreetMessageService&lt;/strong&gt;&lt;strong&gt;）当中，被者用者内部直接使用此实例，代码流程清晰明了；而依赖查找一般由调用者（LogicController&lt;/strong&gt;&lt;strong&gt;）前期进行类型注册，被调用者（GreetMessageService&lt;/strong&gt;&lt;strong&gt;）内部依赖IOC&lt;/strong&gt;&lt;strong&gt;框架获取到想要的对象实例，然后再使用此实例。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;    ④&lt;/strong&gt;&lt;strong&gt;：两者生成实例的目的都是为了能动态创建实例，只不过创建的时机不一样。我个人认为依赖注入分离了逻辑控制相对来说层次性更清晰明了，但在需要注入多个对象时，却不及查找注入方式方便简洁。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三、IOC&lt;/strong&gt;&lt;strong&gt;框架&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;strong&gt;、模式的复用&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;自从张三在上述产品开发过程中成功地总结出“IOC思想”后，在后继的其他产品中进行了推广与实践。在使用的过程中，张三发现这样的模式是可以很好的在模块间、产品间进行有效的复用，不仅大大提高了开发效率，对产品后继的扩展和维护都带来不少方便。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;strong&gt;、对象容器&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当然，在对“IOC思想”的实践中，张三还发现有些地方需要完善。比如，有时我们可能要创建单一对象实例，有时却要要创建多个对象的实例，甚至有时要创建一系列实例；有时要创建一个本地的对象实例，有时却要创建一个远端的服务对象实例；等等…..&lt;/p&gt;
&lt;p&gt;为了应对复杂的对象应用，张三把原来的“对象工厂”这样的小作坊升级成了一个功能强大的、具有一定智能水平的“IOC对象容器”，这个容器可以动态的依据参数设定或配置文件来进行有策略性的对象创建与管理，使得整个框架对对象集的管理上升到了一个更高的层次。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;strong&gt;、IOC&lt;/strong&gt;&lt;strong&gt;基础框架&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;张三通过前期的“接口分离”及“依赖倒置”达到了“反转控制”的效果，并结合有效的“依赖注入”方式，实现了系统的“松耦合”架构；再通过“工厂模式 + 反射机制”有效实现了对象的动态创建，并在后期升级成“对象容器”，大大减少新增需求对程序带来的冲击。通过以上方式，张三成功地摸索出一套行这有效且复用性高的“IOC基础框架”。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;strong&gt;、IOC&lt;/strong&gt;&lt;strong&gt;思想&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;后来，张三把摸索总结出的“IOC基础框架”在公司各产品中进行了广泛实践，得到一致好评，并且被作为一个公共组件集成在一个叫“UT企业库”的组件集中。从此，在张三的朋友圈中，IOC思想广为流传。&lt;/p&gt;
&lt;p&gt;若干年后，我们发现EJB、Spring、Struts、Asp.netMVC等框架中都能看到IOC思想的影子，这些框架都对张三最初IOC的思想作了进一步的发扬、光大。&lt;/p&gt;
&lt;p&gt;现在，IOC的思想在软件设计与系统架构中大放异彩，然而非常遗憾中国人口中的那个神秘的张三至今也不知到底是谁。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;四：源代码&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;strong&gt;、开发环境为：VS2010 + NET4.0 + Windos7&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;strong&gt;、下载示例源代码（&lt;a href=&quot;http://files.cnblogs.com/showjan/IOCDemo.rar&quot; target=&quot;_blank&quot;&gt;IOCDemo&lt;/a&gt;&lt;/strong&gt;&lt;strong&gt;），代码很简单都没写注释。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Thu, 04 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-04-76510-fd2920382.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-04-76510-fd2920382.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>MogileFS 根据不同网段使用不同 IP</title>
        <description>

							&lt;p&gt;前些日子使用 Lua 写了一个, 给请求的外网转换成内网 IP 的 MogileFS 模块, 后来发现自己傻了…其实 MogileFS 也有这个功能. 前二天调 MogileFS 的时候, 发现 HOST 的配置中直接有这个选项.&lt;/p&gt;
&lt;pre class=&quot;brush:perl;first-line:1;pad-line-numbers:true;highlight:null;collapse:false;&quot;&gt;
# mogadm host add

ERROR: Missing argument &#39;hostname&#39;

Help for &#39;host-add&#39; command:

  mogadm host add &amp;lt;hostname&amp;gt; [opts]                  Add a host to MogileFS.

      &amp;lt;hostname&amp;gt;           Hostname of machine
      --altip=s            Alternate IP that is machine is reachable from
      --altmask=s          Netmask which, when matches client, uses alt IP
      --getport=i          Alternate HTTP port serving readonly traffic
      --ip=s               IP address of machine.
      --port=i             HTTP port of mogstored
      --status=s           One of {alive,down}.  Default &#39;down&#39;.

&lt;/pre&gt;
&lt;p&gt;
上面的选项, 正常我们只使用 –ip 来配置复制和工作所使用的 IP . 但我们还可以配置一个 –altip , 这个在请求过来的 –altmask 的网络的查询请求时(不同网段的 MogileFS 客户端, 如 Nginx 中的 MogileFS 模块), 会使用这个 IP .&lt;/p&gt;
&lt;p&gt;这个非常实现, 比如实现内网复制, 多机房的数据同步. 就非常需要这个功能, 不然本地同步和复制数据都是使用的公网. 配置很简单&lt;/p&gt;
&lt;pre class=&quot;brush:perl;first-line:1;pad-line-numbers:true;highlight:null;collapse:false;&quot;&gt;
# mogadm host modify CT-ZH-1CV1172 --ip=ip1 --altip=ip2 --getport=7500 --altmask=使用altip的来源网段

&lt;/pre&gt;

			&lt;!--[syntaxhighlighter]--&gt;
			&lt;!--代码高亮，请勿编辑--&gt;
			

			&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;http://www.php-oa.com/wp-content/plugins/ck-and-syntaxhighlighter/syntaxhighlighter/styles/shCoreDefault.css&quot;&gt;
			&lt;link type=&quot;text/css&quot; rel=&quot;stylesheet&quot; href=&quot;http://www.php-oa.com/wp-content/plugins/ck-and-syntaxhighlighter/syntaxhighlighter/styles/shThemeDefault.css&quot;&gt;
			
			&lt;!--[/syntaxhighlighter]--&gt;						

</description>
        <pubDate>Tue, 02 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-02-mogilefs-%25e6%25a0%25b9%25e6%258d%25ae%25e4%25b8%258d%25e5%2590%258c%25e7%25bd%2591%25e6%25ae%25b5%25e4%25bd%25bf%25e7%2594%25a8%25e4%25b8%258d%25e5%2590%258c-ip.html-dce2d9923.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-02-mogilefs-%25e6%25a0%25b9%25e6%258d%25ae%25e4%25b8%258d%25e5%2590%258c%25e7%25bd%2591%25e6%25ae%25b5%25e4%25bd%25bf%25e7%2594%25a8%25e4%25b8%258d%25e5%2590%258c-ip.html-dce2d9923.html</guid>
        
        
        <category>php-oa</category>
        
      </item>
    
      <item>
        <title>字符编码常识及问题解析</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;在面试的笔试题里出了一道开放性的题：请简述Unicode与UTF-8之间的关系。一道看似简单的题，能给出满意答案的却寥寥无几 ，确实挺失望的。所以今天就结合我以前做过的一个关于字符编码的分享，总结一些与字符编码相关的知识和问题。如果你这方面的知识已经掌握的足够了，可以忽略这篇文字。但如果你没法很好的回答我上面的面试题，或经常被乱码的问题所困扰，还是不妨一读。&lt;/p&gt;
&lt;h2&gt;基本常识&lt;/h2&gt;
&lt;h3&gt;1.位和字节&lt;/h3&gt;
&lt;p&gt;说起编码，我们必须从最基础的说起，&lt;strong&gt;位和字节&lt;/strong&gt;(别觉得这个过于简单不值一说，我还真见过很多个不能区分这两者的程序员)。位（bit）是指计算机里存放的二进制值(0/1)，而8个位组合成的“位串”称为一个字节，容易算出，8个位的组合有256（ 2&lt;sup&gt;8&lt;/sup&gt; ）个组合方式，其取值范围是“00000000-11111111”，常用十六进制来表示。比如“01000001”就是一个字节，其对应的十六进制值为“0×41”。&lt;/p&gt;
&lt;p&gt;而我们通常所讲的字符编码，就是指&lt;strong&gt;定义一套规则&lt;/strong&gt;，将真实世界里的字母/字符与计算机的二进制序列进行相互转化。如我们可以针对上面的字节定义如下的转换规则：&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt;01000001（0x41）&amp;lt;-&amp;gt; 65 &amp;lt;-&amp;gt; &#39;A&#39;&lt;/pre&gt;
&lt;p&gt;即用字位序“01000001”来表示字母’A’。&lt;/p&gt;
&lt;h3&gt;2.拉丁字符&lt;/h3&gt;
&lt;p&gt;拉丁字符是当今世界使用最广泛的符号了。通常我们说的拉丁字母，指的的是&lt;strong&gt;基础拉丁字母&lt;/strong&gt;,即指常见的”ABCD“等26个英文字母，这些字母与英语中一些常见的符号（如数字，标点符号）称为&lt;strong&gt;基础拉丁字符&lt;/strong&gt;，这些基础拉丁字符在使用英语的国家广为流行，当然在中国，也被用来当作汉语拼音使用。在欧洲其它一些非英语国家，为满足其语言需要，在基础拉丁字符的基础上，加上一些连字符，变音字符(如’Á’)，形成了&lt;strong&gt;派生拉丁字母&lt;/strong&gt;，其表示的字符范围在各种语言有所不同，而&lt;strong&gt;完整意义上的拉丁字符是指这些变体字符与基础拉丁字符的全集&lt;/strong&gt;。是比基础拉丁字符集大很多的一个集合。&lt;/p&gt;
&lt;h2&gt;编码标准&lt;/h2&gt;
&lt;p&gt;前文提到，字符编码是一套规则。既然是规则，就必须有标准。下面我就仔细说说常见的字符编码标准。&lt;/p&gt;
&lt;h3&gt;1.拉丁编码&lt;/h3&gt;
&lt;p&gt;ASCII的全称是American Standard Code for Information Interchange（美国信息交换标准代码）。顾名思义，这是现代计算机的发明国美国人设计的标准，而美国是一个英语国家，他们设定的&lt;strong&gt;ASCII编码也只支持基础拉丁字符&lt;/strong&gt;。ASCII的设计也很简单，&lt;strong&gt;用一个字节（8个位）来表示一个字符，并保证最高位的取值永远为’0’&lt;/strong&gt;。即表示字符含义的位数为7位，不难算出其可表达字符数为2&lt;sup&gt;7&lt;/sup&gt; =128个。这128个字符包括95个可打印的字符（涵盖了26个英文字母的大小写以及英文标点符号能）与33个控制字符（不可打印字符）。例如下表，就是几个简单的规则对应：&lt;/p&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;th&gt;字符类型&lt;/th&gt;
&lt;th&gt;字符&lt;/th&gt;
&lt;th&gt;二进制&lt;/th&gt;
&lt;th&gt;16进制&lt;/th&gt;
&lt;th&gt;10进制&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;可打印字符&lt;/td&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;01000001&lt;/td&gt;
&lt;td&gt;0×41&lt;/td&gt;
&lt;td&gt;65&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;可打印字符&lt;/td&gt;
&lt;td&gt;a&lt;/td&gt;
&lt;td&gt;01100001&lt;/td&gt;
&lt;td&gt;0×61&lt;/td&gt;
&lt;td&gt;97&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;控制字符&lt;/td&gt;
&lt;td&gt;\r&lt;/td&gt;
&lt;td&gt;00001101&lt;/td&gt;
&lt;td&gt;0x0D&lt;/td&gt;
&lt;td&gt;13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;控制字符&lt;/td&gt;
&lt;td&gt;\n&lt;/td&gt;
&lt;td&gt;00001010&lt;/td&gt;
&lt;td&gt;0xA&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;前面说到了，ASCII是美国人设计的，只能支持基础拉丁字符，而当计算机发展到欧洲，欧洲其它不只是用的基础拉丁字符的国家（即用更大的派生拉丁字符集）该怎么办呢？&lt;/p&gt;
&lt;p&gt;当然，最简单的办法就是将美国人没有用到的&lt;strong&gt;第8位也用上&lt;/strong&gt;就好了，这样能表达的字符个数就达到了2&lt;sup&gt;8&lt;/sup&gt; =256个，相比较原来，增长了一倍， 这个编码规则也常被称为&lt;strong&gt;EASCII&lt;/strong&gt;。EASCII基本解决了整个西欧的字符编码问题。但是对于欧洲其它地方如北欧，东欧地区，256个字符还是不够用，如是出现了&lt;strong&gt;ISO 8859&lt;/strong&gt;,为解决256个字符不够用的问题，&lt;strong&gt;ISO 8859采取的不再是单个独立的编码规则，而是由一系列的字符集（共15个）所组成&lt;/strong&gt;，分别称为ISO 8859-n(n=1,2,3…11,13…16,没有12)。其每个字符集对应不同的语言,如ISO 8859-1对应西欧语言，ISO 8859-2对应中欧语言等。其中大家所熟悉的&lt;strong&gt;Latin-1就是ISO 8859-1的别名,它表示整个西欧的字符集范围&lt;/strong&gt;。 &lt;strong&gt;需要注意的一点的是，ISO 8859-n与ASCII是兼容的，即其0000000(0×00)-01111111(0x7f)范围段与ASCII保持一致，而10000000（0×80）-11111111(0xFF)范围段被扩展用到不同的字符集。&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;2.中文编码&lt;/h3&gt;
&lt;p&gt;以上我们接触到的拉丁编码，都是单字节编码，即用一个字节来对应一个字符。但这一规则对于其它字符集更大的语言来说，并不适应，比如中文，而是出现了用多个字节表示一个字符的编码规则。常见的中文GB2312（国家简体中文字符集）就是用两个字节来表示一个汉字（注意是表示一个汉字，对于拉丁字母，GB2312还是是用一个字节来表示以兼容ASCII）。我们用下表来说明各中文编码之间的规则和兼容性。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/86b97cded768a8e92bf409765901c5b3.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;对于中文编码，其规则实现上是很简单的，一般都是简单的&lt;strong&gt;字符查表&lt;/strong&gt;即可，重要的是要注意其相互之间的&lt;strong&gt;兼容性&lt;/strong&gt;问题。如如果选择BIG5字符集编码，就不能很好的兼容GB2312，当做繁转简时有可能导致个别字的冲突与不一致，但是GBK与GB2312之间就不存在这样的问题。&lt;/p&gt;
&lt;h3&gt;3.Unicode&lt;/h3&gt;
&lt;p&gt;以上可以看到，针对不同的语言采用不同的编码，有可能导致冲突与不兼容性，如果我们打开一份字节序文件，如果不知道其编码规则，就无法正确解析其语义，这也是产生乱码的根本原因。有没有一种规则是全世界字符统一的呢？当然有，Unicode就是一种。为了能独立表示世界上所有的字符，Unicode采用&lt;strong&gt;4个字节表示一个字符&lt;/strong&gt;,这样理论上Unicode能表示的字符数就达到了2&lt;sup&gt;31&lt;/sup&gt; = 2147483648 = 21 亿左右个字符，完全可以涵盖世界上一切语言所用的符号。我们以汉字”微信“两字举例说明：&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span style=&quot;font-family: Monaco, Consolas, &#39;Andale Mono&#39;, &#39;DejaVu Sans Mono&#39;, monospace; font-style: normal;&quot;&gt;微 &amp;amp;lt;-&amp;amp;gt; \u5fae &amp;amp;lt;-&amp;amp;gt; 00000000 00000000 01011111 10101110&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span style=&quot;font-family: Monaco, Consolas, &#39;Andale Mono&#39;, &#39;DejaVu Sans Mono&#39;, monospace; font-style: normal;&quot;&gt;信 &amp;amp;lt;-&amp;amp;gt; \u4fe1 &amp;amp;lt;-&amp;amp;gt; 00000000 00000000 01001111 11100001&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;容易从上面的例子里看出，Unicode对所有的字符编码均需要四个字节，而这对于拉丁字母或汉字来说是浪费的，其前面三个或两个字节均是0,这对信息存储来说是极大的浪费。另外一个问题就是，如何区分Unicode与其它编码这也是一个问题，比如计算机怎么知道四个字节表示一个Unicode中的字符，还是分别表示四个ASCII的字符呢？&lt;/p&gt;
&lt;p&gt;以上两个问题，困扰着Unicode，让Unicode的推广上一直面临着困难。直至UTF-8作为Unicode的一种实现后，部分问题得到解决，才得以完成推广使用。说到此，我们可以回答文章一开始提出的问题了，&lt;strong&gt;UTF-8是Unicode的一种实现方式，而Unicode是一个统一标准规范，Unicode的实现方式除了UTF-8还有其它的，比如UTF-16等。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;话说当初大牛Ben Thomson吃饭时，在一张餐巾纸上，设计出了UTF-8，然后回到房间，实现了第一版的UTF-8。关于UTF-8的基本规则，其实简单来说就两条（来自阮一峰老师的总结）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span style=&quot;font-family: Monaco, Consolas, &#39;Andale Mono&#39;, &#39;DejaVu Sans Mono&#39;, monospace; font-style: normal;&quot;&gt;规则1：对于单字节字符，字节的第一位为0，后7位为这个符号的Unicode码，所以对于拉丁字母，UTF-8与ASCII码是一致的。&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;span style=&quot;font-family: Monaco, Consolas, &#39;Andale Mono&#39;, &#39;DejaVu Sans Mono&#39;, monospace; font-style: normal;&quot;&gt;规则2：对于n字节(n&amp;amp;gt;1)的字符，第一个字节前n位都设为1，第n+1位为0，后面字节的前两位一律设为10，&lt;/span&gt;剩下没有提及的位，全部为这个符号的Unicode编码。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过，根据以上规则，可以建立一个Unicode取值范围与UTF-8字节序表示的对应关系，如下表，&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f04574df32a4070acf5b9442af0082c8.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;举例来说，’微’的Unicode是’\u5fae’，二进制表示是”00000000 00000000 01011111 10101110“，其取值就位于’0000 0800-0000 FFFF’之间，所以其UTF-8编码为’&lt;strong&gt;111&lt;/strong&gt;00101 &lt;strong&gt;10&lt;/strong&gt;111110 &lt;strong&gt;10&lt;/strong&gt;101110’ （加粗部分为固定编码内容）。&lt;/p&gt;
&lt;p&gt;通过以上简单规则，UTF-8采取变字节的方式，解决了我们前文提到的关于Unicode的两大问题。同时，作为中文使用者需要注意的一点是&lt;strong&gt;Unicode(UTF-8)与GBK，GB2312这些汉字编码规则是完全不兼容的，也就是说这两者之间不能通过任何算法来进行转换,如需转换，一般通过GBK查表的方式来进行&lt;/strong&gt;。&lt;/p&gt;
&lt;h2&gt;常见问题及解答&lt;/h2&gt;
&lt;h3&gt;1.windows Notepad中的编码ANSI保存选项，代表什么含义？&lt;/h3&gt;
&lt;p&gt;ANSI是windows的默认的编码方式，对于英文文件是ASCII编码，对于简体中文文件是GB2312编码（只针对Windows简体中文版，如果是繁体中文版会采用Big5码）。所以，&lt;strong&gt;如果将一个UTF-8编码的文件，另存为ANSI的方式，对于中文部分会产生乱码&lt;/strong&gt;。&lt;/p&gt;
&lt;h3&gt;2.什么是UTF-8的BOM？&lt;/h3&gt;
&lt;p&gt;BOM的全称是Byte Order Mark，BOM是微软给UTF-8编码加上的，用于标识文件使用的是UTF-8编码，即在UTF-8编码的文件起始位置，加入三个字节“EE BB BF”。这是微软特有的，标准并不推荐包含BOM的方式。采用加BOM的UTF-8编码文件，对于一些只支持标准UTF-8编码的环境，可能导致问题。比如，在Go语言编程中，对于包含BOM的代码文件，会导致编译出错。详细可见我的&lt;a href=&quot;http://sharecore.info/blog/2013/04/05/parse-csv-to-sql-for-insert/&quot;&gt;这篇文章&lt;/a&gt;。&lt;/p&gt;
&lt;h3&gt;3.为什么数据库Latin1字符集（单字节）可以存储中文呢？&lt;/h3&gt;
&lt;p&gt;其实不管需要使用几个字节来表示一个字符，但最小的存储单位都是字节,所以，&lt;strong&gt;只要能保证传输和存储的字节顺序不会乱即可&lt;/strong&gt;。作为数据库，只是作为存储的使用的话，只要能保证存储的顺序与写入的顺序一致，然后再按相同的字节顺序读出即可，翻译成语义字符的任务交给应用程序。比如’微’的UTF-8编码是’0xE5 0xBE 0xAE’，那数据库也存储’0xE5 0xBE 0xAE’三个字节，其它应用按顺序从数据库读取，再按UTF-8编码进行展现。这当然是一个看似完美的方案，但是只要写入，存储，读取过程中岔出任何别的编码，都可能导致乱码。&lt;/p&gt;
&lt;h3&gt;4.Mysql数据库中多个字符集变量（其它数据库其实也类似），它们之间分别是什么关系？&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f7f395dfa765754b84ae0aeed1f6561f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们分别解释：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;character_set_client&lt;/strong&gt;：客户端来源的数据使用的字符集，用于客户端显式告诉客户端所发送的语句中的的字符编码。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;character_set_connection&lt;/strong&gt;：连接层的字符编码，mysql一般用character_set_connection将客户端的字符转换为连接层表示的字符。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;character_set_results&lt;/strong&gt;:查询结果从数据库读出后，将转换为character_set_results返回给前端。&lt;/p&gt;
&lt;p&gt;而我们常见的解决乱码问题的操作：&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;mysql_query(&#39;SET NAMES GBK&#39;)&lt;/pre&gt;
&lt;p&gt;其相当于将以上三个字符集统一全部设置为GBK，这三者一致时，一般就解决了乱码问题。&lt;/p&gt;
&lt;p&gt;character_set_database:当前选中数据库的默认字符集，如当create table时没有指定字符集，将默认选择该字符集。&lt;/p&gt;
&lt;p&gt;character_set_database已经character_set_system，一般用于数据库系统内部的一些字符编码，处理数据乱码问题时，我们基本可以忽略。&lt;/p&gt;
&lt;h3&gt;5.什么情况下，表示信息丢失？&lt;/h3&gt;
&lt;p&gt;对于mysql数据库，我们可以通过&lt;strong&gt;hex(colname)&lt;/strong&gt;函数（其它数据库也有类似的函数，一些文本文件编辑器也具有这个功能），查看实际存储的字节内容，如：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f56d707f3c3dd94fb25ca6e9275643f4.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;通过查看存储的字节序，我们可以从根本上了解存储的内容是什么编码了。而当发现&lt;strong&gt;存储的内容全部是’3F’时，就表明存储的内容由于编码问题，信息已经丢失了，无法再找回&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;之所以出现这种信息丢失的情况，一般是将不能相互转换的字符集之间做了转换，比如我们在前文说到，UTF-8只能一个个字节地变成Latin-1，但是根本不能转换的，因为两者之间没有转换规则，Unicode的字符对应范围也根本不在Latin-1范围内，所以只能用’?(0x3F)’代替了。&lt;/p&gt;
&lt;h2&gt;总结：&lt;/h2&gt;
&lt;p&gt;本文从基础知识与实际中碰到的问题上，解析了字符编码相关内容。而之所以要从头介绍字符编码的基础知识，是为了更好的从原理上了解与解决日常碰到的编码问题，只有从根本上了解了不同字符集的规则及其之间的关系与兼容性，才能更好的解决碰到的乱码问题，也能避免由于程序中不正确的编码转换导致的信息丢失问题。&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Tue, 02 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-02-76376-a2d2cc672.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-02-76376-a2d2cc672.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>常用排序算法之JavaScript实现</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;笔试面试经常涉及各种算法，本文简要介绍常用的一些算法，并用JavaScript实现。&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;1、插入排序&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;1）算法简介&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;插入排序（Insertion-Sort）的算法描述是一种简单直观的排序算法。它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常采用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;2）算法描述和实现&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;从第一个元素开始，该元素可以认为已经被排序；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;取出下一个元素，在已经排序的元素序列中从后向前扫描；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;如果该元素（已排序）大于新元素，将该元素移到下一位置；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;重复步骤3，直到找到已排序的元素小于或者等于新元素的位置；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;将新元素插入到该位置后；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;重复步骤2~5。&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;JavaScript代码实现：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;function insertionSort(array) {
    if (Object.prototype.toString.call(array).slice(8, -1) === &#39;Array&#39;) {
        for (var i = 1; i &amp;lt; array.length; i++) {
            var key = array[i];
            var j = i - 1;
            while (j &amp;gt;= 0 &amp;amp;&amp;amp; array[j] &amp;gt; key) {
                array[j + 1] = array[j];
                j--;
            }
            array[j + 1] = key;
        }
        return array;
    } else {
        return &#39;array is not an Array!&#39;;
    }
}&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;3）算法分析&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最佳情况：输入数组按升序排列。T(n) = O(n)&lt;/li&gt;
&lt;li&gt;最坏情况：输入数组按降序排列。T(n) = O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/li&gt;
&lt;li&gt;平均情况：T(n) = O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3&gt;二、二分插入排序&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;1）算法简介&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;二分插入（Binary-insert-sort)排序是一种在直接插入排序算法上进行小改动的排序算法。其与直接插入排序算法最大的区别在于查找插入位置时使用的是二分查找的方式，在速度上有一定提升。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;2）算法描述和实现&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;一般来说，插入排序都采用in-place在数组上实现。具体算法描述如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;从第一个元素开始，该元素可以认为已经被排序；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;取出下一个元素，在已经排序的元素序列中二分查找到第一个比它大的数的位置；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;将新元素插入到该位置后；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;重复上述两步。&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;JavaScript代码实现：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;function binaryInsertionSort(array) {
    if (Object.prototype.toString.call(array).slice(8, -1) === &#39;Array&#39;) {
        for (var i = 1; i &amp;lt; array.length; i++) {
            var key = array[i], left = 0, right = i - 1;
            while (left &amp;lt;= right) {
                var middle = parseInt((left + right) / 2);
                if (key &amp;lt; array[middle]) {
                    right = middle - 1;
                } else {
                    left = middle + 1;
                }
            }
            for (var j = i - 1; j &amp;gt;= left; j--) {
                array[j + 1] = array[j];
            }
            array[left] = key;
        }
        return array;
    } else {
        return &#39;array is not an Array!&#39;;
    }
}&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;3）算法分析&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最佳情况：T(n) = O(nlogn)&lt;/li&gt;
&lt;li&gt;最差情况：T(n) = O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/li&gt;
&lt;li&gt;平均情况：T(n) = O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3&gt;三、选择排序&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;1）算法简介&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;选择排序(Selection-sort)是一种简单直观的排序算法。它的工作原理：首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;2）算法描述和实现&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;n个记录的直接选择排序可经过n-1趟直接选择排序得到有序结果。具体算法描述如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;初始状态：无序区为R[1..n]，有序区为空；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;第i趟排序(i=1,2,3…n-1)开始时，当前有序区和无序区分别为R[1..i-1]和R(i..n）。该趟排序从当前无序区中选出关键字最小的记录 R[k]，将它与无序区的第1个记录R交换，使R[1..i]和R[i+1..n)分别变为记录个数增加1个的新有序区和记录个数减少1个的新无序区；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;n-1趟结束，数组有序化了。&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;JavaScript代码实现：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;function selectionSort(array) {
    if (Object.prototype.toString.call(array).slice(8, -1) === &#39;Array&#39;) {
        var len = array.length, temp;
        for (var i = 0; i &amp;lt; len - 1; i++) {
            var min = array[i];
            for (var j = i + 1; j &amp;lt; len; j++) {
                if (array[j] &amp;lt; min) {
                    temp = min;
                    min = array[j];
                    array[j] = temp;
                }
            }
            array[i] = min;
        }
        return array;
    } else {
        return &#39;array is not an Array!&#39;;
    }
}&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;3）算法分析&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最佳情况：T(n) = O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/li&gt;
&lt;li&gt;最差情况：T(n) = O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/li&gt;
&lt;li&gt;平均情况：T(n) = O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3&gt;四、冒泡排序&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;1）算法简介&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;冒泡排序是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果它们的顺序错误就把它们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;2）算法描述和实现&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;具体算法描述如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;比较相邻的元素。如果第一个比第二个大，就交换它们两个；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对，&lt;em&gt;这样&lt;/em&gt;在最后的元素应该会是最大的数；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;针对所有的元素重复以上的步骤，除了最后一个；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;重复步骤1~3，直到排序完成。&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;JavaScript代码实现：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;function bubbleSort(array) {
    if (Object.prototype.toString.call(array).slice(8, -1) === &#39;Array&#39;) {
        var len = array.length, temp;
        for (var i = 0; i &amp;lt; len - 1; i++) {
            for (var j = len - 1; j &amp;gt;= i; j--) {
                if (array[j] &amp;lt; array[j - 1]) {
                    temp = array[j];
                    array[j] = array[j - 1];
                    array[j - 1] = temp;
                }
            }
        }
        return array;
    } else {
        return &#39;array is not an Array!&#39;;
    }
}&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;3）算法分析&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最佳情况：T(n) = O(n)&lt;/li&gt;
&lt;li&gt;最差情况：T(n) = O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/li&gt;
&lt;li&gt;平均情况：T(n) = O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3&gt;五、快速排序&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;1）算法简介&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;快速排序的基本思想：通过一趟排序将待排记录分隔成独立的两部分，其中一部分记录的关键字均比另一部分的关键字小，则可分别对这两部分记录继续进行排序，以达到整个序列有序。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;2）算法描述和实现&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;快速排序使用分治法来把一个串（list）分为两个子串（sub-lists）。具体算法描述如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;从数列中挑出一个元素，称为 &quot;基准&quot;（pivot）；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序。&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;JavaScript代码实现：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;//方法一
function quickSort(array, left, right) {
    if (Object.prototype.toString.call(array).slice(8, -1) === &#39;Array&#39; &amp;amp;&amp;amp; typeof left === &#39;number&#39; &amp;amp;&amp;amp; typeof right === &#39;number&#39;) {
        if (left &amp;lt; right) {
            var x = array[right], i = left - 1, temp;
            for (var j = left; j &amp;lt;= right; j++) {
                if (array[j] &amp;lt;= x) {
                    i++;
                    temp = array[i];
                    array[i] = array[j];
                    array[j] = temp;
                }
            }
            quickSort(array, left, i - 1);
            quickSort(array, i + 1, right);
        };
    } else {
        return &#39;array is not an Array or left or right is not a number!&#39;;
    }
}  
var aaa = [3, 5, 2, 9, 1];
quickSort(aaa, 0, aaa.length - 1);
console.log(aaa);

//方法二
var quickSort = function(arr) {
　　if (arr.length &amp;lt;= 1) { return arr; }
　　var pivotIndex = Math.floor(arr.length / 2);
　　var pivot = arr.splice(pivotIndex, 1)[0];
　　var left = [];
　　var right = [];
　　for (var i = 0; i &amp;lt; arr.length; i++){
　　　　if (arr[i] &amp;lt; pivot) {
　　　　　　left.push(arr[i]);
　　　　} else {
　　　　　　right.push(arr[i]);
　　　　}
　　}
　　return quickSort(left).concat([pivot], quickSort(right));
};&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;3）算法分析&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最佳情况：T(n) = O(nlogn)&lt;/li&gt;
&lt;li&gt;最差情况：T(n) = O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/li&gt;
&lt;li&gt;平均情况：T(n) = O(nlogn)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3&gt;六、堆排序&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;1）算法简介&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;2）算法描述和实现&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;具体算法描述如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;将初始待排序关键字序列(R1,R2....Rn)构建成大顶堆，此堆为初始的无序区；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;将堆顶元素R[1]与最后一个元素R[n]交换，此时得到新的无序区(R1,R2,......Rn-1)和新的有序区(Rn),且满足R[1,2...n-1]&amp;lt;=R[n]；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;由于交换后新的堆顶R[1]可能违反堆的性质，因此需要对当前无序区(R1,R2,......Rn-1)调整为新堆，然后再次将R[1]与无序区最后一个元素交换，得到新的无序区(R1,R2....Rn-2)和新的有序区(Rn-1,Rn)。不断重复此过程直到有序区的元素个数为n-1，则整个排序过程完成。&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;JavaScript代码实现：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;/*方法说明：堆排序
@param  array 待排序数组*/            
function heapSort(array) {
    if (Object.prototype.toString.call(array).slice(8, -1) === &#39;Array&#39;) {
        //建堆
        var heapSize = array.length, temp;
        for (var i = Math.floor(heapSize / 2); i &amp;gt;= 0; i--) {
            heapify(array, i, heapSize);
        }

        //堆排序
        for (var j = heapSize - 1; j &amp;gt;= 1; j--) {
            temp = array[0];
            array[0] = array[j];
            array[j] = temp;
            heapify(array, 0, --heapSize);
        }
    } else {
        return &#39;array is not an Array!&#39;;
    }
}
/*方法说明：维护堆的性质
@param  arr 数组
@param  x   数组下标
@param  len 堆大小*/
function heapify(arr, x, len) {
    if (Object.prototype.toString.call(arr).slice(8, -1) === &#39;Array&#39; &amp;amp;&amp;amp; typeof x === &#39;number&#39;) {
        var l = 2 * x, r = 2 * x + 1, largest = x, temp;
        if (l &amp;lt; len &amp;amp;&amp;amp; arr[l] &amp;gt; arr[largest]) {
            largest = l;
        }
        if (r &amp;lt; len &amp;amp;&amp;amp; arr[r] &amp;gt; arr[largest]) {
            largest = r;
        }
        if (largest != x) {
            temp = arr[x];
            arr[x] = arr[largest];
            arr[largest] = temp;
            heapify(arr, largest, len);
        }
    } else {
        return &#39;arr is not an Array or x is not a number!&#39;;
    }
}&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;3）算法分析&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最佳情况：T(n) = O(nlogn)&lt;/li&gt;
&lt;li&gt;最差情况：T(n) = O(nlogn)&lt;/li&gt;
&lt;li&gt;平均情况：T(n) = O(nlogn)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3&gt;七、归并排序&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;1）算法简介&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。归并排序是一种稳定的排序方法。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;2）算法描述和实现&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;具体算法描述如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;把长度为n的输入序列分成两个长度为n/2的子序列；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;对这两个子序列分别采用归并排序；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;将两个排序好的子序列合并成一个最终的排序序列。&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;JavaScript代码实现：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;function mergeSort(array, p, r) {
    if (p &amp;lt; r) {
        var q = Math.floor((p + r) / 2);
        mergeSort(array, p, q);
        mergeSort(array, q + 1, r);
        merge(array, p, q, r);
    }
}
function merge(array, p, q, r) {
    var n1 = q - p + 1, n2 = r - q, left = [], right = [], m = n = 0;
    for (var i = 0; i &amp;lt; n1; i++) {
        left[i] = array[p + i];
    }
    for (var j = 0; j &amp;lt; n2; j++) {
        right[j] = array[q + 1 + j];
    }
    left[n1] = right[n2] = Number.MAX_VALUE;
    for (var k = p; k &amp;lt;= r; k++) {
        if (left[m] &amp;lt;= right[n]) {
            array[k] = left[m];
            m++;
        } else {
            array[k] = right[n];
            n++;
        }
    }
}&lt;/pre&gt;
&lt;p&gt;3）算法分析&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;最佳情况：T(n) = O(n)&lt;/li&gt;
&lt;li&gt;最差情况：T(n) = O(nlogn)&lt;/li&gt;
&lt;li&gt;平均情况：T(n) = O(nlogn)&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3&gt;八、桶排序&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;1）算法简介&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;桶排序 (Bucket sort)的工作的原理：假设输入数据服从均匀分布，将数据分到有限数量的桶里，每个桶再分别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;2）算法描述和实现&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;具体算法描述如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;设置一个定量的数组当作空桶；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;遍历输入数据，并且把数据一个一个放到对应的桶里去；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;对每个不是空的桶进行排序；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;从不是空的桶里把排好序的数据拼接起来。&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;JavaScript代码实现：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;/*方法说明：桶排序
@param  array 数组
@param  num   桶的数量*/
function bucketSort(array, num) {
    if (array.length &amp;lt;= 1) {
        return array;
    }
    var len = array.length, buckets = [], result = [], min = max = array[0], regex = &#39;/^[1-9]+[0-9]*$/&#39;, space, n = 0;
    num = num || ((num &amp;gt; 1 &amp;amp;&amp;amp; regex.test(num)) ? num : 10);
    for (var i = 1; i &amp;lt; len; i++) {
        min = min &amp;lt;= array[i] ? min : array[i];
        max = max &amp;gt;= array[i] ? max : array[i];
    }
    space = (max - min + 1) / num;
    for (var j = 0; j &amp;lt; len; j++) {
        var index = Math.floor((array[j] - min) / space);
        if (buckets[index]) {   //  非空桶，插入排序
            var k = buckets[index].length - 1;
            while (k &amp;gt;= 0 &amp;amp;&amp;amp; buckets[index][k] &amp;gt; array[j]) {
                buckets[index][k + 1] = buckets[index][k];
                k--;
            }
            buckets[index][k + 1] = array[j];
        } else {    //空桶，初始化
            buckets[index] = [];
            buckets[index].push(array[j]);
        }
    }
    while (n &amp;lt; num) {
        result = result.concat(buckets[n]);
        n++;
    }
    return result;
}&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;3）算法分析&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;桶排序最好情况下使用线性时间O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为O(n)。很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。&lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;九、计数排序&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;1）算法简介&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;计数排序(Counting sort)是一种稳定的排序算法。计数排序使用一个额外的数组C，其中第i个元素是待排序数组A中值等于i的元素的个数。然后根据数组C来将A中的元素排到正确的位置。它只能对整数进行排序。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;2）算法描述和实现&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;具体算法描述如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;找出待排序的数组中最大和最小的元素；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;统计数组中每个值为i的元素出现的次数，存入数组C的第i项；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）；&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;反向填充目标数组：将每个元素i放在新数组的第C(i)项，每放一个元素就将C(i)减去1。&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;JavaScript代码实现：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;function countingSort(array) {
    var len = array.length, B = [], C = [], min = max = array[0];
    for (var i = 0; i &amp;lt; len; i++) {
        min = min &amp;lt;= array[i] ? min : array[i];
        max = max &amp;gt;= array[i] ? max : array[i];
        C[array[i]] = C[array[i]] ? C[array[i]] + 1 : 1;
    }
    for (var j = min; j &amp;lt; max; j++) {
        C[j + 1] = (C[j + 1] || 0) + (C[j] || 0);
    }
    for (var k = len - 1; k &amp;gt;=0; k--) {
        B[C[array[k]] - 1] = array[k];
        C[array[k]]--;
    }
    return B;
}&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;3）算法分析&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当输入的元素是n 个0到k之间的整数时，它的运行时间是 O(n + k)。计数排序不是比较排序，排序的速度快于任何比较排序算法。由于用来计数的数组C的长度取决于待排序数组中数据的范围（等于待排序数组的最大值与最小值的差加上1），这使得计数排序对于数据范围很大的数组，需要大量时间和内存。&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Mon, 01 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-01-76339-ce9e2dee1.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-01-76339-ce9e2dee1.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>制作自己的嵌入式 Linux 电脑</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;当今所有最好的集成电路都大规模的使用BGA封装法来焊接。因为BGA封装法连接在芯片底下，焊接更紧，需要使用回流焊箱或者热印版。另一个问题是设计PCB（印刷电路板）时，过孔和引线之间的焊接球需要足够小，主板上通常需要更多层来为紧挨的引线来腾出空间，这意味着一个廉价的中国产的两层主板没有足够的空间，所以需要更多的层。附加层则会显著提高主板的成本 ，就算只多了几个拷贝。&lt;/p&gt;
&lt;p&gt;我想设计一款内置BGA芯片的主板来体验下焊接它们究竟是有多难。于是我决定设计一个可运行Linux的小型ARM嵌入式系统，使用的ARM处理器是在一个217球的LFBGA包中的&lt;a href=&quot;http://www.digikey.fi/product-detail/en/AT91SAM9N12-CU/AT91SAM9N12-CU-ND/3128657&quot; target=&quot;_blank&quot;&gt;AT91SAM9N12&lt;/a&gt;，只是因为在带有运行Linux必需的内存管理单元的ARM处理器中，它是最便宜的。起初我只想用一块BGA芯片，但是BGA包中的RAM比其他包里要便宜很多，所以我就决定在BGA包也增加一块DDR2（Double Data Rate 2）的内存。&lt;/p&gt;
&lt;p&gt;&lt;img style=&quot;border: 2px solid black;&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/5d98dca7ba6a5b5637f1ae3aee1a31af.jpg&quot; width=&quot;75%&quot; border=&quot;2&quot;&gt;&lt;br&gt;
为最大化可用空间定位过孔。&lt;/p&gt;
&lt;p&gt;结果寻找主板生产商还颇费了一番周折。两层的空间是还不够的，至少需要4层。217-LFBGA包的球直径是0.4mm，临接球的距离是0.8mm。为了给过孔多留些空间，球的焊盘布局做的要比焊球要稍小一些。我用的0.36mm的焊盘。在4个球之间放置过孔会最大程度的利用可用空间。厂商要能制造可以放进0.8mm宽度的过孔。几乎所有厂商都可以制造这种直径大小的过孔，但问题是：这个距离包括了过孔的钻孔直径，两倍的过孔绕环的宽度 ，两倍的过孔和引线之间的最小距离。比如，iTead的4层主板最小的过孔钻孔直径是0.3mm， 最小环宽度是0.15mm，过孔和引线的最小距离是0.15mm，加起来是0.9 mm，这意味着最小尺寸的过孔不能放在BGA球之间。我发现的唯一一家可以实现这一要求而且价钱相对合理的生厂商是&lt;a href=&quot;http://oshpark.com/&quot; target=&quot;_blank&quot;&gt;OSH parks&lt;/a&gt;。他们的四层主板有更小的限制，过孔刚刚可以放进BGA球里面。额外的好处是，对于小主板而言，它要比iTead更便宜一些。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/dc0afdb02de100885a8e664ef7b4ce90.jpg&quot;&gt;&lt;br&gt;
在OSH park设计原则下最小的过孔，刚刚能放下。&lt;/p&gt;
&lt;p&gt;即使过孔可以放进BGA 球中间，仍然有一些问题：过孔中间没有足够的空间走线。这意味着要让每一个焊盘都有一个过孔的标准布线通道是不可能了。这就是说主板需要有足够的未经连接的焊盘，所以过线需要从里面进行布置。幸运的是，处理器还有很多通用的未连接的I/O引脚。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/fbe598dbba6d04d297be110cd28b653b.jpg&quot;&gt;&lt;br&gt;
… 如果不违反设计原则的话，过线就不能正好在两个过孔之间穿过。CAS 过线没有足够的空间来放入DQM0 和 D15过孔。&lt;/p&gt;
&lt;p&gt;生产问题解决了，是时候开始想想主板上该放哪些部件了。我并不很在乎这块主板的实际用处，相对于用处而言，整个项目更是一个学习的过程。为了降低成本，主板的尺寸要小。这意味着不会为其他额外的接口预留空间，比如：以太网，串口或者SD卡。&lt;/p&gt;
&lt;p&gt;除了处理器和RAM外，其他必需的部件是：大内存，电压调整器，以及处理芯片重置的监控电路。处理器可以从NAND启动，但是以防万一我决定为引导装载程序加入Dataflash（数据闪存），虽然最终会很少被用到。对于大内存而言，NAND是一个很好的选择因为他容量大又便宜。在BGA包中加入会更便宜些，但我已经被两个BGA包折腾的够呛了，所以我决定在一个48引脚的TSOP（薄型小尺寸封装）包里面使用4GB的NAND。连接各个组件在处理器的清单表中已经解释的很好了，但是在上千页的文档中要找到全部的细节还是很难的。Atmel 也发布了一个试用板的原理图，在设计主板时会很有帮助。&lt;/p&gt;
&lt;p&gt;DDR2 引线空间应该有一定的自由度。正常的引线应该长度合适，有可控的阻抗和可以终止或者串联电阻。在开发板的参考设计中，所有DDR2的信号使用了串联电阻。我没有足够的空间放置他们，所以我决定暂且放着不管。阻抗也不是50欧姆，因为我必须使用小一些的引线来填充其他的空间。我希望的是，因为RAM更靠近处理器，就算缺少串联电阻箱或者阻抗不匹配，关系也不大。所有从CPU到RAM的连线大约是25mm长。通常的经验是：如果引线的长度要超过信号波长的10%时，转换线的影响应该被考虑进去。这种情况意味着频率大约在1 GHz以上。RAM的时钟频率只有133 MHz， 甚至头几个谐波还在1 GHz以下，这预示着应该会正常工作。为了保证可行，我几乎完全匹配了引线的长度，但这也许不是必须的。&lt;/p&gt;
&lt;p&gt;供电有些复杂。处理器核心的电压是1伏特，RAM需要1.8伏特， NAND需要3.3 伏特。因为从USB输入电压是5伏特，主板需要有三种不同的电压适配器。正常情况下比较好的做法是：在主板上为电力供应保留一层并且保持它与信号脱离，来降低电力供应的阻抗，但是主板只有4层，而且其中一层要用于做底板。这意味着只有两层留给做信号处理，这显示不够。所以我没有单独拿出一层来供电，而是在不同的层里为不同的供电做了一些挡板。&lt;/p&gt;
&lt;p&gt;对于USB供电的应用，线形调整器的电力损失在最坏的情况下太大了些，所以我决定用3.3伏特的调整器作为一个更有效的可切换开关的调整器。1.0伏特和1.8伏特的调整期是一个以3.3伏特作为输入电压的线性调整器。因为线形调整器的损失决定于输入和输出电压的差，所以使用3.3伏特的电压比5伏特的电压提高了效率。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5478d0b1479f1f201577c844429e7aa3.jpg&quot;&gt;&lt;br&gt;
电路图。&lt;a href=&quot;http://hforsten.com/static/img/diy-bga/schematic.pdf&quot; target=&quot;_blank&quot;&gt;PDF&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6412ca9485b8a602888f7a053df7a985.jpg&quot;&gt;&lt;br&gt;
PCB布局，尚未焊锡。&lt;/p&gt;
&lt;h2&gt;焊接&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d1ac1012730b0c42e7feeb03bcfcc523.jpg&quot;&gt;&lt;br&gt;
空的电路板。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0d2bce250eaf4931c08eb5201e1bbd01.jpg&quot;&gt;&lt;br&gt;
焊锡和部件被固定到背面。焊锡是用牙签手动固定的。这儿的部件都是1mm（0.04英寸）长。我只拿上一些做下试验，先看下他们如何回流的。如果情况不太好，我会换另外一块板子。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6b9149bc1dd0366d621bdb9bd05354d9.jpg&quot;&gt;&lt;br&gt;
使用一个烤箱和自制的控制器来控制回流。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c23ae3d9050563d2a8d8793ce87eb3a6.jpg&quot;&gt;&lt;br&gt;
回流之后。三个部件被焊接到一个错误的地方。我最后还是把它们拿出来了，在主板上有足够的解耦的电容器，即使丢了一小部分，也不过有什么影响。我还错误的把一个电容器放在左上的位置，但那儿其实应该是一个电阻。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1c62019d6abec832791517be33162dee.jpg&quot;&gt;&lt;br&gt;
对于上层，我有一个OSH的模板，所以我不必手动把焊锡弄到BGA板上。直接按到桌子上，我就把主板和模具焊牢了。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/65135369be14ee66d4eebe8d3dc6fc83.jpg&quot;&gt;&lt;br&gt;
模板队形排列很整齐。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/04119877455b5ab01b9a3e75b9226b13.jpg&quot;&gt;&lt;br&gt;
这看起来有些过了，但是几乎所有的焊锡都可以用了。还需要一些额外的焊锡来让模具平整一些。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/92c492bb244b4de66373f0a7cf87c563.jpg&quot;&gt;&lt;br&gt;
把焊锡铺开，然后挪掉模具。比我自己手动弄的背面要好的多。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/7bbb65587ae6582311f403f6dd1e445f.jpg&quot;&gt;&lt;br&gt;
我从一个非BGA的部件开始。它们是用一双沉稳的手用钳子固定的。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c0ac579e85d5eaba696816a2655aec5d.jpg&quot;&gt;&lt;br&gt;
CPU 和我的指尖。球间距是0.8mm。许多新的BGA甚至使用小于0.5mm的间距。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9fc5f8f5fd2d1217ed66d42f8bbaf09a.jpg&quot;&gt;&lt;br&gt;
BGA固定在板上。部件放置的位置误差需要小于0.4mm，否则可能和一个行间隔焊接，而且因为焊球在芯片下面，不能检查。没有丝网印刷的边界，几乎不可能按照要求的精度放置。有了丝网印刷，只需沿着丝网印刷边沿对齐即可，很容易。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b55a05c1ae178b71f6131e59811e75c1.jpg&quot;&gt;&lt;br&gt;
回焊正面，抬高PCB，这样底面的部件也不会触到其他地方。焊接表面的拉力会保持底面不倒下。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0d4bd5ea93c449f7ee16f4d98923db93.jpg&quot;&gt;&lt;br&gt;
过烤箱后。焊接口看上去很好看，所有部件仍然在他们应该的位置上。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f727a52a06a21069f1893b624030325f.jpg&quot;&gt;&lt;br&gt;
焊接NAND Flash。我的焊接铁片要比引脚大一些。一次焊接一个引脚太困难了。简单些的办法是灌锡后，用吸锡带把多余的吸出来。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/bf6c76d28ac1e27b04986dd1c8dfb4f2.jpg&quot;&gt;&lt;br&gt;
在移除多余焊锡后，焊接口现在质量很高了。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3a56812eab8afb007a59bebb973e9b16.jpg&quot;&gt;&lt;br&gt;
在加入供电头和调试串口后，主板焊接完毕。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/09314c78e30ceed6c4c629cb7b703275.jpg&quot;&gt;&lt;br&gt;
最终的成品。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ec86a30541cf1ba0bdc98c7345c16570.jpg&quot;&gt;&lt;br&gt;
另一面，空着的位置是位Dataflash准备的。&lt;/p&gt;
&lt;p&gt;在把USB缆线接到USB设备口上，没有出现什么意外，而且我看到了一个新的串口 /dev/ttyACM0 出现。再用SAM-BA程序（用来对启动加载程序和内核编程）打开，一切都能用了。许多人说焊接BGA很难，但是从这次经验来看，我觉得还好。也许只是幸运吧，但是我的确没出什么问题就搞定了。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/40db8efe9cffb8730220f2a90dc9ad26.jpg&quot;&gt;&lt;br&gt;
打开SAM-BA。At91sam9n12ek是Atmel针对这款处理器提供的开发工具，他的配置同样适用于这块板。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a81587b9b5c1b63c2eadc51533e362a1.jpg&quot;&gt;&lt;br&gt;
DDR2 也可以工作，执行程序，并且可以写回NAND。一切都OK。&lt;/p&gt;
&lt;h2&gt;软件&lt;/h2&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/00a120df2bee0e2e41f6117f95959070.jpg&quot;&gt;&lt;/p&gt;
&lt;h3&gt;软件启动加载程序&lt;/h3&gt;
&lt;p&gt;启动进程开始工作时，内部的ROM加载器尝试在不同的内存区域发现一个合法的程序。他会扫描SPI （串行外设接口）缓存，SD卡，NAND flash，二级SPI flash 还有I2C EEPROM 对于一个合法的程序。一旦发现一个，马上就启动它，否则就会进入SAM-BA监控器，也就是进入调试模式，此时处理器会监听来自串口和USB端口的指令。这种模式下可以对bootloader进行编程。&lt;/p&gt;
&lt;p&gt;ROM 启动不能直接启动linux内核，所以需要一个二级的启动加载器。它会初始化RAM和时钟，然后开始加载linux内核。&lt;a href=&quot;http://www.at91.com/linux4sam/bin/view/Linux4SAM/AT91Bootstrap&quot; target=&quot;_blank&quot;&gt;AT91 Bootstrap&lt;/a&gt; 是一个现成的启动加载器，可以完成这一系列操作。它被放在NAND flash开始的地方，或者如果我填充这些位置，它可能被放到Dataflash。即使AT91 bootstrap 可以直接启动linux，对于调试而言，之后启动U-boot的bootloader 对调试更有用。U-boot是它自带的基于命令行的微操作系统，可以读取USB棒，使用以太网，读写NAND，当然可以启动linux。例如使用U-boot 可以清除NAND或者改变linux 启动参数。&lt;/p&gt;
&lt;p&gt;为编译bootloader，需要一个ARM 交叉编译器。我用的是&lt;a href=&quot;http://www.mentor.com/embedded-software/sourcery-tools/sourcery-codebench/editions/lite-edition/&quot; target=&quot;_blank&quot;&gt;Sourcery codebench lite edition&lt;/a&gt;，因为它容易设置，而且效果不错。先加载AT91SAM9N12EK 开发板配置文件是最容易的。和从头开始写新的配置相比，修改文件要省事的多。&lt;/p&gt;
&lt;p&gt;为了让这份定制版同样有效，需要做一些改动：RAM 大小需要设置成64MB，bank的数量改成4，一些试验需要稍微调整一下（试用版有128MB的RAM容量，8个banks）。NAND初始的函数也需要改动，这块板比开发板相比，NAND flash要连接的地方有些不同，因此有必要告诉bootloader。&lt;/p&gt;
&lt;h3&gt;U-boot&lt;/h3&gt;
&lt;p&gt;因为AT91 bootstrap已经初始化了整个硬件，就可以直截了当的配置U-boot。同样有为at91sam9n12ek准备的配置文件，但是默认是从SD卡启动设置的。因为硬件已经配置好了，所以其他需要改动的地方就没多少了。有一些可选项比如在NAND flash上创造和改变分区时启动UBIFS 工具 ，以及为读取ext4格式的USB棒提供支持。USB支持使得从USB棒启动Linux 内核变得可能，这让试验不同的内核配置变得容易了。&lt;/p&gt;
&lt;h3&gt;Linux和根文件系统&lt;/h3&gt;
&lt;p&gt;安装linux不像安装一台常规的x86 pc一般容易。需要配置内核来支持各种需要的设置，而且需要建立根目录的镜像文件。可以手动来做，但是用&lt;a href=&quot;http://buildroot.uclibc.org/&quot; target=&quot;_blank&quot;&gt;buildroot&lt;/a&gt;做起来会很容易些。后者是用来建立根文件系统和内核的一系列工具。整个过程可能会有一些难，因为内核和build root有很多的选项。&lt;/p&gt;
&lt;p&gt;Buildroot 没有为at91sam9n12ek开发板提供配置文件，但有为另一款 Atmel板 at91sam9260ek提供配置文件。使用这个配置文件作为基准文件，配置会更容易些。可以通过“make at91sam9260ek_defconfig”加载。&lt;/p&gt;
&lt;p&gt;开始我们想有一个相对新的内核版本，因为相对于处理器来说，只需要做一些很小的改动，所以我们就使用上周新发布的3.15.1版本吧。&lt;/p&gt;
&lt;p&gt;Linux 被配置成用buildroot 的“make linux-menuconfig” 命令配置。它会打开寻常的Linux菜单配置窗口。内核中大多数重要的配置是系统类型的配置菜单。我们需要检查AT91SAM9N12的支持情况还有“Atmel AT91SAM Evaluation Kits with device-tree support”” 选项。&lt;a href=&quot;http://en.wikipedia.org/wiki/Device_tree&quot; target=&quot;_blank&quot;&gt;设备树&lt;/a&gt;是一个随内核一同加载的外部二进制文件，描述了开发板上各硬件的可用性情况。这使得使用带有不同开发板的同样的内核以及针对不同开发板的设备配置，可以用文本来写，而不是为每块板都写一个只是略有不同的C文件。幸运的是：有一个可以作为基准文件的针对at91sam9n12ek 的设备树文件。需要做得改动只是一些简单的移除不再使用的设备。这块修改过的设备数文件需要被添加到buildroot配置，所以它可以知道如何编译，并且从中构造一个镜像文件。&lt;/p&gt;
&lt;p&gt;内核里面其他值得启动的选项是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;USB 主机支持AT91_USB。&lt;/li&gt;
&lt;li&gt;支持NAND flash还有处理器内部的NAND ECC 控制器支持。&lt;/li&gt;
&lt;li&gt;支持UBIFS，将被用作一个根文件系统。&lt;/li&gt;
&lt;li&gt;读取USB棒的Ext4 支持。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在buildroot 配置过程中，我们需要选择我们想要在根目录上安装哪些程序以及产生根文件系统镜像的选项。这块开发板有不带控制器的原始NAND内存，所以一般的桌面文件系统，比如ext4就不能用了。UBIFS是通常的选择，在这正好也能用。&lt;/p&gt;
&lt;p&gt;UBIFS 有一些依赖NAND flash 类型的选项，如果设置错了，LInux将不能读取最终的文件系统。这些选项可以从NAND FLASH 的数据清单里面得到，但是更容易的方法是从USB 棒启动linux，并且从那创建ubi 分区。或者也可以使用 U-boot的“ubi info”指令，这将会读取NAND 并且输出需要的配置值。&lt;/p&gt;
&lt;p&gt;在键入“make”后， Buildroot 会下载交叉编译器，linux 内核以及所有其他的包，构建并输出内核，设备树，以及根文件系统镜像。然后可以用SAM-BA程序传到开发板上。一些程序需要对 NAND ECC controller 参数编程。一些参数也应该被配置到AT91bootstrap， U-boot 以及linux 内核，否则他们会报告NAND已经损坏。这种情况下NAND有2048个字节，带有512字节的扇区，ECC能够每1个扇区纠正4个字节。存储这些镜像的NAND地址可以在AT91的bootstrap 以及U-boot配置文件中找到。&lt;/p&gt;
&lt;p&gt;在对主板编程以及重置后，ROM 启动加载器应该可以在NAND上找到AT91bootstrap 并且开始启动过程。如果你对更多细节感兴趣，所有硬件和软件的文件都可以在&lt;a href=&quot;https://github.com/Ttl/sam_board&quot; target=&quot;_blank&quot;&gt;这&lt;/a&gt;找到。&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Mon, 01 Sep 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-09-01-75414-21f3a4d3d.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-09-01-75414-21f3a4d3d.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>ftrace: The Hidden Light Switch</title>
        <description>

&lt;p&gt;If you&#39;ve been following my previous posts about Linux ftrace, you&#39;ll want to read my recent &lt;a href=&quot;http://lwn.net/&quot;&gt;lwn.net&lt;/a&gt; article: &lt;a href=&quot;http://lwn.net/Articles/608497/&quot;&gt;Ftrace: The Hidden Light Switch&lt;/a&gt;. This showed how I used ftrace at Netflix to confirm whether a kernel tunable change took affect immediately, and how it was set. It was also a tour of some ftrace capabilities. &lt;/p&gt;

&lt;p&gt;ftrace is particularly useful for us since it is already available in all our Linux systems, and has been for years. The biggest problem is that it&#39;s not very well known. I&#39;ve hopefully helped raise awareness with this article, and I also included ftrace in my &lt;a href=&quot;http://www.brendangregg.com/blog/2014-08-23/linux-perf-tools-linuxcon-na-2014.html&quot;&gt;Linux Performance Tools&lt;/a&gt; talk at LinuxCon.&lt;/p&gt;

&lt;p&gt;I mentioned the following commands, but didn&#39;t include screenshots. Here I&#39;m checking if the deadline or noop I/O schedulers are active, based on counting the function calls:&lt;/p&gt;

&lt;pre&gt;
# &lt;b&gt;./funccount -i 1 &#39;deadline*&#39;&lt;/b&gt;
Tracing &quot;deadline*&quot;... Ctrl-C to end.

FUNC                              COUNT
deadline_add_request                178
deadline_merge                      178
deadline_remove_request.isra.4      178
deadline_dispatch_requests          712

FUNC                              COUNT
deadline_add_request                698
deadline_merge                      698
deadline_remove_request.isra.4      698
deadline_dispatch_requests         2792
^C
FUNC                              COUNT
deadline_add_request                316
deadline_merge                      316
deadline_remove_request.isra.4      316
deadline_dispatch_requests         1264

Ending tracing...
# &lt;b&gt;./funccount -i 1 &#39;noop*&#39;&lt;/b&gt;
Tracing &quot;noop*&quot;... Ctrl-C to end.

FUNC                              COUNT

FUNC                              COUNT
^C
FUNC                              COUNT

Ending tracing...
&lt;/pre&gt;

&lt;p&gt;So, deadline is active right now...&lt;/p&gt;

&lt;p&gt;These and the other ftrace capabilities have been invaluable so far, which we&#39;ve been using via my &lt;a href=&quot;https://github.com/brendangregg/perf-tools&quot;&gt;perf-tools&lt;/a&gt; wrappers. If you want to do more with ftrace, see &lt;a href=&quot;http://git.kernel.org/cgit/linux/kernel/git/rostedt/trace-cmd.git&quot;&gt;trace-cmd&lt;/a&gt; by Steven Rostedt, which is a more powerful multi-tool.&lt;/p&gt;

&lt;p&gt;ftrace can&#39;t yet do everything that I want from a kernel tracer. For example, I can&#39;t yet do custom in-kernel aggregations. But it can do a lot more than I previously thought possible.&lt;/p&gt;

&lt;p&gt;Thanks to &lt;a href=&quot;http://www.beginningwithi.com/&quot;&gt;Deirdré Straughan&lt;/a&gt; and Jonathan Corbet for editing help with the article. For more about ftrace, see the resources I linked to at the end (many also on lwn.net), and my previous posts on &lt;a href=&quot;http://www.brendangregg.com/linuxperf.html#Documentation&quot;&gt;ftrace&lt;/a&gt;.&lt;/p&gt;


</description>
        <pubDate>Sat, 30 Aug 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-08-30-ftrace-the-hidden-light-switch.html-2c60798c9.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-08-30-ftrace-the-hidden-light-switch.html-2c60798c9.html</guid>
        
        
        <category>brendangregg</category>
        
      </item>
    
      <item>
        <title>如何用正确姿势调戏蹭网者？</title>
        <description>

					
		
&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
google_ad_client = &quot;ca-pub-7056282119617872&quot;;
google_ad_slot = &quot;6645040531&quot;;
google_ad_width = 300;
google_ad_height = 250;
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;
src=&quot;http://pagead2.googlesyndication.com/pagead/show_ads.js&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;br/ --&gt;

&lt;p&gt;&lt;strong&gt;这篇文章本来是知乎回答的一个问题，但是由于本人五行缺勤奋，所以一直没写（其实是忘了=。=），下面是我的一个实验，如何通过squid调戏那些蹭网的人。没什么技术含量，请大牛不要笑话～&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;声明：本实验仅作为技术分享，一把刀用来砍什么，由你决定。&lt;/p&gt;
&lt;p&gt;先上效果：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/cfaef72ecb87cef5876a20751cd3c623.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/2153548858f89ac433b395872ee28828.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;是不是有点意思？&lt;br&gt;
这里还需要说明一件事情&lt;br&gt;
本文目的在于分享，采用的方式是国外的Pete大大的一种做法，效果不错，&lt;a title=&quot;&quot; href=&quot;http://www.ex-parrot.com/pete/upside-down-ternet.html&quot; target=&quot;_blank&quot;&gt;http://www.ex-parrot.com/pete/upside-down-ternet.html&lt;/a&gt; 但是这里不是重复造轮子，实在是Pete先僧写得过于简略，作为事件主角的squid居然被一笔带过，squid表示相当不爽(╯‵□′)╯︵┻━┻ 。如果可以通过上面的描述实现这个效果的，就不用往下看我的废话连篇了～如果你和我一样开始遇到过问题，那就跟着我走吧～&lt;br&gt;
先说一下大体的思路。既然是要对网页中的图片进行操作，那么我们首先需要把图片下载到本地，然后进行变换之后再输出到客户端机器上面，就实现了图片的翻转，水印，模糊等各种捉弄人的效果。当然功能绝不仅仅是这样就算了，更多功能，大家看完之后不妨多挖掘一下，我就不多废话了～&lt;br&gt;
好的，那么下面我们正式开始！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0×01    实验环境&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我先说一下我的实验环境：&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;主机：ubuntu
虚拟机：windowsXP（vbox）
软件：squid、apache&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;拓扑环境就不多废话了，我这边是host通过wlan0上网，虚拟机选择Host-Only模式，连接到主机的vboxnet0接口（默认的，我没修改）。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0×02  系统配置&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这里，我们首先要把系统的网络转发功能打开，可以使用&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt;echo 1 &amp;gt; /proc/sys/net/ipv4/ip_forward&lt;/pre&gt;
&lt;p&gt;暂时启用，当然也可以修改sysctl.conf永久转发。&lt;br&gt;
然后，对虚拟机进行ip设定，我这里设置为192.168.56.21，子网掩码255.255.255.0&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0×03  软件设置&lt;/strong&gt;&lt;br&gt;
下面我们进行软件的设置。&lt;br&gt;
apache不多说了，你可以指定一个本地路径作为网络分享的地址，作用主要是发布修改后的图片，我这里的路径选择是/mydoc/test/&lt;br&gt;
接着是squid。&lt;br&gt;
关于squid的安装这里不是重点，网上有很多的教程，我们着重说配置。Squid的配置文件是在/etc/squid(3)下面的squid.conf。为了看起来能凸显得我的高冷气质（楼主自恋程度已经逆天…( ＿ ＿)ノ｜壁 ），着重配置的点我都已经写在上传的文件里面了，文末我会给出地址，大家可以看一下。&lt;br&gt;
这里之所以说squid是关键，是因为我们主要使用了squid的redircetor的功能，即我们常说的重定向器功能。重定向器可以将收到的url进行改写重定向，而且支持python、perl、C等等语言写的重定向脚本（程序），功能还是很强大的，这里感兴趣的同学不妨玩玩～这里贴上《squid权威指南》中关于squid的详细描述，有问题可以到这里查阅：http://zyan.cc/book/squid/chap11.html&lt;br&gt;
然后，我们把脚本文件放在配置文件中指定的位置，我这里是放在了/etc/squid3/下面，这里需要注意的是文件的权限问题，因为squid默认运行权限是squid用户，隶属于squid组（squid3是proxy用户，proxy组），所以如果squid没有权限执行脚本文件的时候是会报错的。这里的脚本文件我直接使用了Pete大大给出的perl脚本进行了一点点修改，可能是因为Pete直接从本地测试的，所以脚本有一点点的小问题，大家也可以从我给出的网址上下载。&lt;br&gt;
然后我们配置虚拟机的代理。因为这里我没有用iptables进行流量转发，为了方便，直接配置了浏览器的代理配置，这里代理IP 192.168.56.1：8080，当然大家也可以使用iptables进行转发，这样就可以了。&lt;br&gt;
最后我们重启squid。&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt;sudo service squid restart&lt;/pre&gt;
&lt;p&gt;(squid3的服务名称是squid3)，这里注意对于squid的任何操作一定要记得用sudo执行，否则会报错。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0×04  检验效果&lt;/strong&gt;&lt;br&gt;
这个时候，我们打开虚拟机，输入http://www.baidu.com，就应该可以看到baidu的logo是反向的了，打开更多网页试试吧～是不是很好玩？23333。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/bd7c6718738f55e8afa7b764dce1cbb5.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;当然，脚本只是使用了flip选项，当然这里不建议使用过于复杂的命令，会使浏览器响应过于慢。关于imagemagic的更多的效果可以从网上查阅，是一个相当强大的命令行图片控制软件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0×05  更多猜想&lt;/strong&gt;&lt;br&gt;
实验已经成功，那么我们说回到我们今天的MITM主题上面。有的同学或许会问：你得得得得说这么多，怎么应用啊？我这里提供一个小的方式，抛砖引玉：&lt;br&gt;
可以买一树莓派，买一个usb上网卡，一张中国联通或者中国电信的卡，再买一个无线网卡，用airport建个无线信号，买个电源，装上linux配置好squid，当然还可以打开sniff，配好接收数据的服务器。。&lt;/p&gt;
&lt;p&gt;剩下的就是：背好你的背包，默默走到斯达巴克斯，点一杯咖啡，用吸管慢慢品尝这份苦茗，望向窗外花坛那朵玫瑰，心里静静地想着那个TA。。。&lt;br&gt;
说道这里，大家可能会想到菠萝，其实因为菠萝使用的是openwrt的精简系统，很多东西不可以使用，而且配置比起树莓派低了一些，大批量的图片操作很容易让CPU狂飙，自带的MITM最近貌似也不能用了？不过还是推荐Geek们自行动手～&lt;/p&gt;
&lt;p&gt;如果有更多的想法，我们一起交流。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0×06  注意事项&lt;/strong&gt;&lt;br&gt;
因为我在做实验的过程中也遇到了很多问题，这里贴出一些常见的问题，大牛略过吧～:)&lt;br&gt;
1、注意接收图片文件夹的权限和隶属于的用户，最好是能与squid用户相同的用户组。如果不是，可以使用chown进行修改。例：chown proxy.proxy xxx&lt;br&gt;
2、注意脚本文件的权限。脚本文件必须是可以被squid用户执行的。&lt;br&gt;
3、注意log文件的权限，关于log文件一共有三个，位于/var/log/squid3/下，分别是cache.log、store.log、access.log，这三个文件必须是可写的，同时也可以直接用chown改变用户所有权限。&lt;br&gt;
4、遇到更多虚拟机打不开网页的问题，大家可以查阅/var/log/squid3/cache.log，这里会给出很详细的说明。&lt;br&gt;
这里我能想到的暂时就这么多了，再有什么其他问题我们可以一起交流，我这里有一把肥皂。。。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0×07  写在最后&lt;/strong&gt;&lt;br&gt;
最后，也没什么好说的了，附上链接：&lt;a title=&quot;&quot; href=&quot;https://github.com/linvex/MITM-squid/tree/master&quot; target=&quot;_blank&quot;&gt;https://github.com/linvex/MITM-squid/tree/master&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;上几张图吧～&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/260428ff963e739e0603d70fd7e67abc.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/18dfceaf669d5cf3e2ce5acfdd9fe2d6.jpg&quot;&gt;&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Sat, 30 Aug 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-08-30-76247-c5cb03f35.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-08-30-76247-c5cb03f35.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
  </channel>
</rss>
