<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>IT技术干货</title>
    <description>[IT技术干货iftti.com] @KernelHacks</description>
    <link>http://iftti.com/</link>
    <atom:link href="http://iftti.com/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Thu, 18 Dec 2014 21:18:10 +0800</pubDate>
    <lastBuildDate>Thu, 18 Dec 2014 21:18:10 +0800</lastBuildDate>
    <generator>Jekyll v2.2.0</generator>
    
      <item>
        <title>超酷算法：用四叉树和希尔伯特曲线做空间索引</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;随着越来越多的数据和应用和地理空间相关，空间索引变得愈加重要。然而，有效地查询地理空间数据是相当大的挑战，因为数据是二维的（有时候更高），不能用标准的索引技术来查询位置。空间索引通过各种各样的技术来解决这个问题。在这篇博文中，我将介绍几种：&lt;a href=&quot;http://en.wikipedia.org/wiki/Quadtree&quot; target=&quot;_blank&quot;&gt;四叉树&lt;/a&gt;，&lt;a href=&quot;http://en.wikipedia.org/wiki/Geohash&quot;&gt;geohash&lt;/a&gt;（不要和&lt;a href=&quot;http://wiki.xkcd.com/geohashing/Main_Page&quot;&gt;geohashing&lt;/a&gt;混淆）以及空间填充曲线，并揭示它们是怎样相互关联的。&lt;/p&gt;
&lt;h2&gt;四叉树&lt;/h2&gt;
&lt;p&gt;四叉树是种很直接的空间索引技术。在四叉树中，每个节点表示覆盖了部分进行索引的空间的边界框，根节点覆盖了整个区域。每个节点要么是叶节点，有包含一个或多个索引点的列表，没有孩子。要么是内部节点，有四个孩子，每个孩子对应将区域沿两根轴对半分得到的四个象限中的一个，四叉树也因此得名。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img class=&quot;aligncenter&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/39fecd468ba069854ffe8d28f44f0068.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图1    展示四叉树是怎样划分索引区域的 来源：&lt;a href=&quot;http://en.wikipedia.org/wiki/File:Point_quadtree.svg&quot;&gt;维基百科&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;将数据插入四叉树很简单：从根节点开始，判断你的数据点属于哪个象限。递归到相应的节点，重复步骤，直到到达叶节点，然后将该点加入节点的索引点列表中。如果列表中的元素个数超出了预设的最大数目，则将节点分裂，将其中的索引点移动到相应的子节点中去。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c1f387ac669a9f6a26ab952da6bb8c27.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图2    四叉树的内部结构&lt;/p&gt;
&lt;p&gt;查询四叉树时从根节点开始，检查每个子节点看是否与查询的区域相交。如果是，则递归进入该子节点。当到达叶节点时，检查点列表中的每一个项看是否与查询区域相交，如果是则返回此项。&lt;/p&gt;
&lt;p&gt;注意四叉树是非常规则的，事实上它是一种&lt;a href=&quot;http://en.wikipedia.org/wiki/Trie&quot;&gt;字典树&lt;/a&gt;，因为树节点的值不依赖于插入的数据。因此我们可以用直接的方式给节点编号：用二进制给每个象限编号（左上是00，右上是10等等 &lt;span style=&quot;color: #808080;&quot;&gt;译者注：第一个比特位为0表示在左半平面，为1在右半平面。第二个比特位为0表示在上半平面，为1在下半平面&lt;/span&gt;），任一节点的编号是由从根开始，它的各祖先的象限号码串接而成的。在这个编号系统中，图2中右下角节点的编号是1101。&lt;/p&gt;
&lt;p&gt;如果我们定义了树的最大深度，不需通过树就可以计算数据点所在节点的编号：只要把节点的坐标标准化到适当的整数区间中（比如32位整数），然后把转化后x, y坐标的比特位交错组合。每对比特指定了假想的四叉树中的一个象限。（&lt;span style=&quot;color: #808080;&quot;&gt;译者注：不了解的读者可看看&lt;/span&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Z-order_curve&quot;&gt;Z-order&lt;/a&gt;，&lt;span style=&quot;color: #808080;&quot;&gt;它和下文的希尔伯特曲线都是将二维的点映射到一维的方法&lt;/span&gt;）&lt;/p&gt;
&lt;h3&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;Geohash&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;上述编号系统可能看起来有些熟悉，没错，就是&lt;a href=&quot;http://en.wikipedia.org/wiki/Geohash&quot;&gt;geohash&lt;/a&gt;！此刻，你可以把四叉树扔掉了。节点编号，或者说geohash，包含了对于节点在树中位置我们需要的全部信息。全高树中的每个叶节点是个完整的geohash，每个内部节点代表从它最小的叶节点到最大的叶节点的区间。因此，通过查询所需的节点覆盖的数值区间中的一切（在geohash上索引），你可以有效地定位任意内部节点下的所有数据点。&lt;/p&gt;
&lt;p&gt;一旦我们丢掉了四叉树，查询就变得复杂一点了。我们需要事先构建搜索集合而不是在树中递归地精炼搜索集合。首先，找到完全覆盖查询区域的最小前缀（或者说四叉树节点  &lt;span style=&quot;color: #808080;&quot;&gt;译者注：注意在我们的编号系统中节点由比特串表示&lt;/span&gt;）。在最坏情况下，这可能远大于实际的查询区域，比如对于在索引区域中心、和四个象限都相交的小块地方，查询将要从根节点开始。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;现在的目标是构建一组完全包含查询区域的前缀，并且尽可能少包含区域外的部分。如果没有其他约束，我们可以简单地选择与查询区域相交的叶节点，但这会造成大量的查询。所以要加一个约束：使得要查询的不同区间最少。&lt;/p&gt;
&lt;p&gt;一种达到这个目的的方法是先设置我们愿意承受的查询区间的最大数目。构建一组区间，最开始都设为我们之前指定的前缀。从中选择可以再分裂而不超出最大区间数并将从查询区域删除最不受欢迎区域的节点。重复这个过程直到集合中再没有区间可以细分。最后，检查得到的集合，如果可能的话合并相邻的区间。下面的图说明了这对于查询一个圆形区域且限制最大5个查询区间是如何工作的。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b1120ce5106afa2e05d2960a503b4e62.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图3    一个对区域的查询是怎样分解成一连串geohash前缀/区间的&lt;/p&gt;
&lt;p&gt;这个方法工作地很好，它使我们避免了递归查找。我们执行的一整套区间查找都可以并行完成。由于每次查找都预期要一次硬盘搜索，将查询并行化大大减少了返回结果需要的时间。&lt;/p&gt;
&lt;p&gt;然而，我们还可以做得更好。你可能注意到上图中我们要查询的所有区域都是相邻的，但我们却只能将其中两个合并（选择区域的右下角的两个）成一个单独的查询，进而只要4次单独查询。&lt;span style=&quot;color: #808080;&quot;&gt;（译者注：这两个区域可以合并是因为它们在geohash以Z字形遍历区域的路径上是相邻的）&lt;/span&gt;这个后果部分是由于geohash访问子区域的顺序，在每个象限中从左到右，从上到下。从右上角象限到左下角象限的不连续性使得我们不得不将本可以使之连续的区间分裂。如果以不同的顺序访问区域，可能我们就可以最小化或者消除这些不连续性，使得更多的区域可以被看做是相邻的，一次查询就可得到结果。通过这样效率上的提升，对于同样的覆盖区域，我们可以做更少的查询，或者相反地，同样的查询次数的情况下包含更少的无关区域。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a8453f1a894f9e8d97f9130bdb1b465c.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图4    geohash访问象限的顺序&lt;/p&gt;
&lt;h3&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;希尔伯特曲线&lt;/span&gt;&lt;/h3&gt;
&lt;p align=&quot;left&quot;&gt;现在假设我们以U字形来访问区域。在每个象限中，我们同样以U字形来访问子象限，但是要调整好U字形的朝向使得和相邻的象限衔接起来。如果我们正确地组织了这些U字形的朝向，我们就能完全消除不连续性，不管我们选择了什么分辨率，都能连续地访问整个区域，可以在完全地探访了一个区域后才移动到下一个。这个方案不仅消除了不连续性，而且提高了总体的局域性。按照这个方案得到的图案看起来有些熟悉，没错，就是希尔伯特曲线。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Hilbert_curve&quot;&gt;希尔伯特曲线&lt;/a&gt;属于一类被称为&lt;a href=&quot;http://en.wikipedia.org/wiki/Space-filling_curve&quot;&gt;空间填充曲线&lt;/a&gt;的一维分形，因为它们虽然是一维的线，却可以填充固定区域的所有空间。它们相当有名，部分是由于&lt;a href=&quot;http://blag.xkcd.com/2006/12/11/the-map-of-the-internet/&quot;&gt;XKCD把它们用于互联网地图&lt;/a&gt;。如你所见，对于空间索引它们也是有用的，因为它们展现的正是我们需要的局域性和连续性。再看看之前用一组查询来覆盖圆的例子，我们发现（应用希尔伯特曲线）还可以减少一次查询：左下方的小区域现在和它右边的区域连起来了（减少一次），虽然底部的两块区域不再连续了（增加一次），右下角的区域现在却和它上方的连续了（减少一次）。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot; align=&quot;left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/4f8a19d0cae6c4f480deab72c6f3cf3c.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot; align=&quot;left&quot;&gt;图5    希尔伯特曲线访问象限的顺序&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;到目前为止，我们优雅的系统还缺一样东西：将(x,y)坐标转换为希尔伯特曲线上相应位置的方法。对于geohash，这是简单而明显的–只需将x, y坐标交错，但没有明显的方法修改这个方案使之对希尔伯特曲线也适用。在网上搜索，你很可能遇到很多关于希尔伯特曲线是怎样画出来的描述，但很少有关于找到任意点（在曲线上）位置的。为了搞定它，我们需要更仔细看看希尔伯特曲线是怎么递归构建的。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;首先要注意到虽然大多数关于希尔伯特曲线的文献都关注曲线是怎么画出来的，却容易让我们忽略曲线的本质属性以及其重要性：曲线规定了平面上点的顺序。如果我们用这顺序来表达希尔伯特曲线，画曲线就不值一提了：仅仅是把点连起来。忘记怎么把子曲线连起来吧，把注意力集中在怎么递归地列举点上。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot; align=&quot;left&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/448eac58b45d967edfb3b7f13add636c.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot; align=&quot;left&quot;&gt;图6    希尔伯特曲线规定了二维平面上的点的顺序&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;在根这一层，列举点很简单：选定一个方向和一个起始点，环绕四个象限，用0到3给他们编号。当我们要确定访问子象限的顺序同时维护总体的邻接属性，困难就来了。通过检查我们发现，子象限的曲线是原曲线的简单变换，而且只有四种变换。自然地，这个结论也适用于子子象限，等等。对于一个给定的象限，我们在其中画出的曲线是由象限所在大的方形的曲线以及该象限的位置决定的。只需要费一点力，我们就能构建出如下概况所有情况的表。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot; align=&quot;left&quot;&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/fcce8a2c8572a9bf70d084de7b13e0cc.jpg&quot; width=&quot;668&quot; height=&quot;184&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图7&lt;/p&gt;
&lt;p&gt;假设我们想用这个表来确定某个点在第三层希尔伯特曲线上的位置。在这个例子中，假设点的坐标是(5,2)。&lt;span style=&quot;color: #808080;&quot;&gt;（译者注：请参照图8）&lt;/span&gt;从上图的第一个方形开始，找到你的点所在的象限。在这个例子中，是在右上方的象限。那么点在希尔伯特曲线上的位置的第一部分是3（二进制是11）。接着我们进入象限3里面的方块，在这个例子中，它是（图7中的）第二个方块。重复刚才的过程：我们的点落在哪个子象限？这次是左下角，意味着位置的下一部分是1（二进制01），我们将进入的小方块又是第二个。最后一次重复这个过程，发现点落在右上角的子子象限，因此位置的最后部分是3（二进制11）。把这些位置连接起来，我们得到点在曲线上的位置是二进制的110111，或者十进制的55。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://fanyi.jobbole.com/wp-content/uploads/sites/9/2014/10/hilbert_curve.png&quot; rel=&quot;lightbox[81106]&quot; title=&quot;超酷算法：用四叉树和希尔伯特曲线做空间索引&quot;&gt;&lt;img class=&quot;alignnone size-medium wp-image-1175&quot; alt=&quot;hilbert_curve&quot; src=&quot;/images/jobbole.com/65007f040e43a1e10906ab9ec0263dd8.jpg&quot; width=&quot;300&quot; height=&quot;297&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;图8  三阶希尔伯特曲线&lt;/p&gt;
&lt;p&gt;让我们更系统一些，写出从x, y坐标到希尔伯特曲线位置转换的方法。首先，我们要以计算机看得懂的形式表达图7：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;hilbert_map = { 
&#39;a&#39;: {(0, 0): (0, &#39;d&#39;), (0, 1): (1, &#39;a&#39;), (1, 0): (3, &#39;b&#39;), (1, 1): (2, &#39;a&#39;)}, 
&#39;b&#39;: {(0, 0): (2, &#39;b&#39;), (0, 1): (1, &#39;b&#39;), (1, 0): (3, &#39;a&#39;), (1, 1): (0, &#39;c&#39;)}, 
&#39;c&#39;: {(0, 0): (2, &#39;c&#39;), (0, 1): (3, &#39;d&#39;), (1, 0): (1, &#39;c&#39;), (1, 1): (0, &#39;b&#39;)}, 
&#39;d&#39;: {(0, 0): (0, &#39;a&#39;), (0, 1): (3, &#39;c&#39;), (1, 0): (1, &#39;d&#39;), (1, 1): (2, &#39;d&#39;)}}&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;上面的代码中，每个hilbert_map的元素对应图7四个方形中的一个。为了容易区分，我用一个字母来标识每个方块：’a&#39;是第一个方块，’b&#39;是第二个，等等。每个方块的值是个字典，将(子)象限的x, y坐标映射到曲线上的位置（元组值的第一部分）以及下一个用到的方块（元组值的第二部分）。下面的代码展示了怎么用这个来将x, y坐标转换成希尔伯特曲线上的位置：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;def point_to_hilbert(x, y, order=16):
    current_square = &#39;a&#39;
    position = 0
    for i in range(order - 1, -1, -1):
        position &amp;lt;&amp;lt;= 2
        quad_x = 1 if x &amp;amp; (1 &amp;lt;&amp;lt; i) else 0
        quad_y = 1 if y &amp;amp; (1 &amp;lt;&amp;lt; i) else 0
        quad_position, current_square = hilbert_map[current_square][(quad_x, quad_y)]
        position |= quad_position
    return position&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;函数的输入是为整数的x, y坐标和曲线的阶。一阶曲线填充2×2的格子，二阶曲线填充4×4的格子，等等。我们的x, y坐标应该先标准化到0到2&lt;sup&gt;order&lt;/sup&gt;-1的区间。这个函数从最高位开始，逐步处理x, y坐标的每个比特位。在每个阶段中，通过测试对应的比特位，可以确定坐标处于哪个（子）象限，还可以从我们之前定义的hilbert_map中取得在曲线上的位置以及下一个要用的方块。在这阶段取得的位置，加入到目前总的位置的最低两位。在下一次循环的开头，总的位置左移两位以便给下一个位置腾出地方。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;让我们运行一下之前的例子来检验一下函数写对了没有：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;&amp;gt;&amp;gt;&amp;gt; point_to_hilbert(5,2,3)
55&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;对了！为了进一步测试，我们可以用这个函数生成一条希尔伯特曲线的有序点的完整列表，然后用电子制表软件把它们画出来看我们是否真的得到了一条希尔伯特曲线。在Python交互解释器中输入如下代码：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;&amp;gt;&amp;gt;&amp;gt; points = [(x, y) for x in range(8) for y in range(8)]
&amp;gt;&amp;gt;&amp;gt; sorted_points = sorted(points, key=lambda k: point_to_hilbert(k[0], k[1], 3))
&amp;gt;&amp;gt;&amp;gt; print &#39;n&#39;.join(&#39;%s,%s&#39; % x for x in sorted_points)&lt;/pre&gt;
&lt;p&gt;将输出的文本粘贴到文件中，保存为hilbert.csv，用你最喜欢的电子制表软件打开，将数据画成一个散点图。结果当然是一条漂亮的希尔伯特曲线！&lt;/p&gt;
&lt;p&gt;将hilbert_map做简单的反转就能实现point_to_hilbert的逆向功能（将希尔伯特曲线上的位置转换为x, y坐标），把这个留给读者作为练习吧。&lt;/p&gt;
&lt;h2&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 24px; font-style: normal; font-weight: bold; line-height: 36px;&quot;&gt;结论&lt;/span&gt;&lt;/h2&gt;
&lt;p align=&quot;left&quot;&gt;空间索引，从四叉树到geohash到希尔伯特曲线，到这就结束了。最后一点说明：如果你将一条希尔伯特曲线上的x, y坐标的有序序列写成二进制形式，对于顺序你注意到什么有趣的东西吗？你想到了什么？&lt;/p&gt;
&lt;p&gt;结束前的一点警告：我在这里描述的全部索引方法都只适用于索引点。如果你想索引线、折线或者多边形，这些方法可能就不管用了。据我所知，已知的唯一能有效索引形体的算法是&lt;a href=&quot;http://en.wikipedia.org/wiki/R-tree&quot;&gt;R-tree&lt;/a&gt;，这是一种完全不同且更复杂的方法。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Thu, 18 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-18-81106-2aba1c5c3.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-18-81106-2aba1c5c3.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>图文说明：Linux监控命令全覆盖</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;h2&gt;1.1 top&lt;/h2&gt;
&lt;h4&gt;1.1.1 命令说明&lt;/h4&gt;
&lt;p&gt;Top 命令能够实时监控系统的运行状态，并且可以按照cpu、内存和执行时间进行排序&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.1.2 参数说明&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;命令行启动参数：&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;用法: top -hv | -bcisSHM -d delay -n iterations [-u user | -U user] -p pid [,pid ...]&lt;/li&gt;
&lt;li&gt;-b : 批次模式运行。通常用作来将top的输出的结果传送给其他程式或储存成文件&lt;/li&gt;
&lt;li&gt;-c : 显示执行任务的命令行&lt;/li&gt;
&lt;li&gt;-d : 设定延迟时间&lt;/li&gt;
&lt;li&gt;-h : 帮助&lt;/li&gt;
&lt;li&gt;-H : 显示线程。当这个设定开启时，将显示所有进程产生的线程&lt;/li&gt;
&lt;li&gt;-i : 显示空闲的进程&lt;/li&gt;
&lt;li&gt;-n : 执行次数。一般与-b搭配使用&lt;/li&gt;
&lt;li&gt;-u : 监控指定用户相关进程&lt;/li&gt;
&lt;li&gt;-U : 监控指定用户相关进程&lt;/li&gt;
&lt;li&gt;-p : 监控指定的进程。当监控多个进程时，进程ID以逗号分隔。这个选项只能在命令行下使用&lt;/li&gt;
&lt;li&gt;-s : 安全模式操作&lt;/li&gt;
&lt;li&gt;-S : 累计时间模式&lt;/li&gt;
&lt;li&gt;-v : 显示top版本，然后退出。&lt;/li&gt;
&lt;li&gt;-M : 自动显示内存单位（k/M/G）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt;&lt;strong&gt;全局命令&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;回车、空格 : 刷新显示信息&lt;/li&gt;
&lt;li&gt;?、h : 帮助&lt;/li&gt;
&lt;li&gt;= : 移除所有任务显示的限制&lt;/li&gt;
&lt;li&gt;A : 交替显示模式切换&lt;/li&gt;
&lt;li&gt;B : 粗体显示切换&lt;/li&gt;
&lt;li&gt;d、s : 更改界面刷新时间间隔&lt;/li&gt;
&lt;li&gt;G : 选择其它窗口/栏位组&lt;/li&gt;
&lt;li&gt;I : Irix或Solaris模式切换&lt;/li&gt;
&lt;li&gt;u、U : 监控指定用户相关进程&lt;/li&gt;
&lt;li&gt;k : 结束进程&lt;/li&gt;
&lt;li&gt;q : 退出top&lt;/li&gt;
&lt;li&gt;r : 重新设定进程的nice值&lt;/li&gt;
&lt;li&gt;W : 存储当前设定&lt;/li&gt;
&lt;li&gt;Z : 改变颜色模板&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt;&lt;strong&gt;摘要区命令&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;l : 平均负载及系统运行时间显示开关&lt;/li&gt;
&lt;li&gt;m : 内存及交换空间使用率显示开关&lt;/li&gt;
&lt;li&gt;t : 当前任务及CPU状态显示开关&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1 : 汇总显示CPU状态或分开显示每个CPU状态&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt;&lt;strong&gt;任务区命令&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;外观样式&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;b : 黑体/反色显示高亮的行/列。控制x和y交互命令的显示样式&lt;/li&gt;
&lt;li&gt;x : 高亮显示排序的列&lt;/li&gt;
&lt;li&gt;y : 高亮显示正在运行的任务&lt;/li&gt;
&lt;li&gt;z : 彩色/黑白显示。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;显示内容&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;c : 任务执行的命令行或进程名称&lt;/li&gt;
&lt;li&gt;f、o : 增加和移除进程信息栏位及调整进程信息栏位显示顺序&lt;/li&gt;
&lt;li&gt;H : 显示线程&lt;/li&gt;
&lt;li&gt;S : 时间累计模式&lt;/li&gt;
&lt;li&gt;u : 监控指定用户相关进程&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;任务显示的数量&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;i : 显示空闲的进程&lt;/li&gt;
&lt;li&gt;n或# : 设置任务显示最大数量&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;任务排序（shift+f&lt;/strong&gt;&lt;strong&gt;）&lt;/strong&gt;
&lt;/li&gt;
&lt;li&gt;M : 按内存使用率排序&lt;/li&gt;
&lt;li&gt;N : 按PID排序&lt;/li&gt;
&lt;li&gt;P : 按CPU使用率排序&lt;/li&gt;
&lt;li&gt;T : 按Time+排序&lt;/li&gt;
&lt;li&gt;&amp;lt; : 按当前排序栏位左边相邻栏位排序&lt;/li&gt;
&lt;li&gt;&amp;gt; : 按当前排序栏位右边相邻栏位排序&lt;/li&gt;
&lt;li&gt;F 或 O : 选择排序栏位&lt;/li&gt;
&lt;li&gt;R : 反向排序&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.1.3  结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fc9a0b3650de3198a8de2b9b1d58d8cd.jpg&quot;&gt;&lt;/p&gt;
&lt;h3&gt;1.2 free&lt;/h3&gt;
&lt;h4&gt;1.2.1  命令说明&lt;/h4&gt;
&lt;p&gt;Free命令是监控系统内存最常用的命令&lt;/p&gt;
&lt;h4&gt;1.2.2.参数说明&lt;/h4&gt;
&lt;p&gt;-m：以M为单位查看内存使用情况（默认为kb）&lt;/p&gt;
&lt;p&gt;-b：以字节为单位查看内存使用情况&lt;/p&gt;
&lt;p&gt;-s：可以在指定时间段内不简单监控内存的使用情况&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.2.3 结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/89fedab6983ba6fac4f3213a706fc780.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;total：总计物理内存的大小。&lt;/li&gt;
&lt;li&gt;Used：已使用多大。&lt;/li&gt;
&lt;li&gt;Free：可用有多少。&lt;/li&gt;
&lt;li&gt;shared：多个进程共享的内存总额。&lt;/li&gt;
&lt;li&gt;buffers/cached:磁盘缓存的大小。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.3 vmstat&lt;/h3&gt;
&lt;h4&gt;1.1.1命令说明&lt;/h4&gt;
&lt;p&gt;可以监控操作系统的进程状态、内存、虚拟内存、磁盘IO、上下文、CPU的信息。&lt;/p&gt;
&lt;h4&gt;1.1.2参数说明&lt;/h4&gt;
&lt;p&gt;vmstat [-a] [-n] [-S unit] [delay [ count]]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-a：显示活跃和非活跃内存&lt;/li&gt;
&lt;li&gt;-m：显示slabinfo&lt;/li&gt;
&lt;li&gt;-n：只在开始时显示一次各字段名称。&lt;/li&gt;
&lt;li&gt;-s：显示内存相关统计信息及多种系统活动数量。&lt;/li&gt;
&lt;li&gt;delay：刷新时间间隔。如果不指定，只显示一条结果。&lt;/li&gt;
&lt;li&gt;count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷。&lt;/li&gt;
&lt;li&gt;-d：显示各个磁盘相关统计信息。&lt;/li&gt;
&lt;li&gt;-S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes）&lt;/li&gt;
&lt;li&gt;-V：显示vmstat版本信息。&lt;/li&gt;
&lt;li&gt;-p：显示指定磁盘分区统计信息&lt;/li&gt;
&lt;li&gt;-D：显示磁盘总体信息&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;1.1.3 结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a34977b8ecda13cdccf7d2692d391219.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Procs&lt;/li&gt;
&lt;li&gt;R:等待被执行的进程数，即表示运行和等待CPU时间片的进程数&lt;/li&gt;
&lt;li&gt;B:排队的进程数，即等待资源的进程数&lt;/li&gt;
&lt;li&gt;Memory&lt;/li&gt;
&lt;li&gt;Swap : 虚拟内存，切换到虚拟内存的内存大小&lt;/li&gt;
&lt;li&gt;Free: 空闲的物理内存大小&lt;/li&gt;
&lt;li&gt;Buff: 缓冲区大小&lt;/li&gt;
&lt;li&gt;Cache: 缓存大小&lt;/li&gt;
&lt;li&gt;Swap&lt;/li&gt;
&lt;li&gt;Si:磁盘写入虚拟内存，即由内存进入到虚拟内存的大小。&lt;/li&gt;
&lt;li&gt;So:虚拟内存写入磁盘，即由虚拟内存进入到磁盘的大小。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Io&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Bi:由块设备读入的数据总量，读磁盘&lt;/li&gt;
&lt;li&gt;Bo:由块设备写入的数据总量，写磁盘&lt;/li&gt;
&lt;li&gt;System&lt;/li&gt;
&lt;li&gt;In: 每秒设备中断数&lt;/li&gt;
&lt;li&gt;Cs:每秒上下文切换的次数&lt;/li&gt;
&lt;li&gt;Cpu&lt;/li&gt;
&lt;li&gt;Us:用户进程消耗cpu百分比&lt;/li&gt;
&lt;li&gt;Sy:内核进程消耗cpu百分比&lt;/li&gt;
&lt;li&gt;Id:cpu处于空闲状态的时间百分比&lt;/li&gt;
&lt;li&gt;Wa：Io等待cpu所占时间的百分比&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.4 iostat&lt;/h3&gt;
&lt;h4&gt;1.4.1命令说明&lt;/h4&gt;
&lt;p&gt;Iostat是对系统磁盘IO操作进行监控，它的输出主要显示磁盘的读写操作的统计信息。同时给出cpu的使用情况&lt;/p&gt;
&lt;h4&gt;1.4.2参数说明&lt;/h4&gt;
&lt;p&gt;iostat [ -c | -d ] [ -k | -m ] [ -t ] [ -V ] [ -x ] [ device [ ... ] | ALL ] [ -p [ device | ALL ] ] [ interval [ count ] ]&lt;br&gt;
各选项以及参数含义如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-c： 仅显示CPU统计信息.与-d选项互斥.&lt;/li&gt;
&lt;li&gt;-d ：仅显示磁盘统计信息.与-c选项互斥.&lt;/li&gt;
&lt;li&gt;-k ：以K为单位显示每秒的磁盘请求数,默认单位块.&lt;/li&gt;
&lt;li&gt;-p ：device | ALL&lt;br&gt;
与-x选项互斥,用于显示块设备及系统分区的统计信息.也可以在-p后指定一个设备名,如:&lt;br&gt;
# iostat -p had&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;或显示所有设备&lt;br&gt;
# iostat -p ALL&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-t ：在输出数据时,打印搜集数据的时间.&lt;/li&gt;
&lt;li&gt;-V ：打印版本号和帮助信息.&lt;/li&gt;
&lt;li&gt;-x  device  输出指定要统计的磁盘设备名称，默认为所有磁盘设备.&lt;/li&gt;
&lt;li&gt;- interval ：指两次统计间隔时间&lt;/li&gt;
&lt;li&gt;-  count ：按照interval 指定的时间间隔统计的次数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.4.3结果说明&lt;/h4&gt;
&lt;p&gt;Iostat的简单应用&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f577cded44dfba51f23a0ad91cb5e7c8.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;Iostat磁盘监控&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/74b290084e02eb3ca810612b5900d24e.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rrqm/s：每秒进行 merge 的读操作数目，即 delta(rmerge)/s 。&lt;/li&gt;
&lt;li&gt;wrqm/s：每秒进行 merge 的写操作数目，即 delta(wmerge)/s 。&lt;/li&gt;
&lt;li&gt;r/s：每秒完成的读 I/O 设备次数，即 delta(rio)/s 。&lt;/li&gt;
&lt;li&gt;w/s： 每秒完成的写 I/O 设备次数，即 delta(wio)/s 。&lt;/li&gt;
&lt;li&gt;rsec/s：每秒读扇区数，即 delta(rsect)/s。&lt;/li&gt;
&lt;li&gt;wsec/s：每秒写扇区数，即 delta(wsect)/s&lt;/li&gt;
&lt;li&gt;rkB/s：每秒读K字节数，是 rsect/s 的一半，因为每扇区大小为512字节。&lt;/li&gt;
&lt;li&gt;wkB/s：每秒写K字节数，是 wsect/s 的一半&lt;/li&gt;
&lt;li&gt;avgrq-sz：平均每次设备I/O操作的数据大小 (扇区)，即                                                               delta(rsect+wsect)/delta(rio+wio) 。&lt;/li&gt;
&lt;li&gt;avgqu-sz：平均I/O队列长度，即 delta(aveq)/s/1000 (因为aveq的单位为毫秒)。&lt;/li&gt;
&lt;li&gt;Await：平均每次设备I/O操作的等待时间 (毫秒)，即  delta(ruse+wuse)/delta(rio+wio) 。&lt;/li&gt;
&lt;li&gt;Svctm：平均每次设备I/O操作的服务时间 (毫秒)，即 delta(use)/delta(rio+wio) 。&lt;/li&gt;
&lt;li&gt;%util：一秒中有百分之多少的时间用于 I/O 操作，或者说一秒中有多少时间 I/O 队列是非空的，&lt;br&gt;
即 delta(use)/s/1000 (因为use的单位为毫秒) 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Iostat   cpu 监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/065ea149d47af73faf4a211a65ca6e5f.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;%usr：用户进程消耗的CPU时间百分比。&lt;/li&gt;
&lt;li&gt;%nice:  运行正常进程消耗的CPU时间百分比。&lt;/li&gt;
&lt;li&gt;%system：系统进程消耗的CPU时间百分比。&lt;/li&gt;
&lt;li&gt;%iowait：I/O等待所占CPU时间百分比。&lt;/li&gt;
&lt;li&gt;%steal：在内存紧张环境下，pagein强制对不同的页面进行的steal操作。&lt;/li&gt;
&lt;li&gt;%idle：CPU空闲状态的时间百分比。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.5 mpstat&lt;/h3&gt;
&lt;h4&gt;1.5.1命令说明&lt;/h4&gt;
&lt;p&gt;Mpstat可以监控到cpu的一些统计信息，在多核cpu的系统里不但能够查看所有cpu的平均状况信息，而且能够查看特定的cpu的信息&lt;/p&gt;
&lt;h4&gt;1.5.2参数说明&lt;/h4&gt;
&lt;p&gt;mpstat [-P {|ALL}] [internal [count]]&lt;/p&gt;
&lt;p&gt;参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;（1）-P {|ALL}：表示监控哪个CPU，在[0,cpu个数-1]中取值；&lt;/li&gt;
&lt;li&gt;（2）internal：相邻的两次采样的间隔时间；&lt;/li&gt;
&lt;li&gt;（3）count：采样的次数，count只能和delay一起使用；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;备注：当没有参数时，mpstat则显示系统启动以后所有信息的平均值。有interval时，第一行的信息自系统启动以来的平均信息。从第二行开始，输出为前一个interval时间段的平均信息。&lt;/p&gt;
&lt;h4&gt;1.5.3结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/25ea44eadc7f3c535b3a5d21d5637049.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; （1）user：在internal时间段里，用户态的CPU时间（%），不包含nice值为负进程，值为 (usr/total)*100；&lt;/li&gt;
&lt;li&gt;（2）nice：在internal时间段里，nice值为负进程的CPU时间（%），值为(nice/total)*100；&lt;/li&gt;
&lt;li&gt;（3）system：在internal时间段里，核心时间（%），值为(system/total)*100；&lt;/li&gt;
&lt;li&gt;（4）iowait：在internal时间段里，硬盘IO等待时间（%），值为(iowait/total)*100；&lt;/li&gt;
&lt;li&gt;（5）irq：在internal时间段里，硬中断时间（%），值为(irq/total)*100；&lt;/li&gt;
&lt;li&gt;（6）soft：在internal时间段里，软中断时间（%），值为(softirq/total)*100；&lt;/li&gt;
&lt;li&gt;（7）idle：在internal时间段里，CPU除去等待磁盘IO操作外的因为任何原因而空闲的时间闲置时间（%），值为(idle/total)*100；&lt;/li&gt;
&lt;li&gt;（8）intr/s：在internal时间段里，每秒CPU接收的中断的次数，值为(intr/total)*100；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.6 sar&lt;/h3&gt;
&lt;h4&gt;1.6.1命令说明&lt;/h4&gt;
&lt;p&gt;Sar命令可以全名的获取到cpu 、运行、磁盘IO、虚拟内存、内存、网络等信息。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.6.2参数说明&lt;/h4&gt;
&lt;p&gt;sar 命令行的常用格式：&lt;br&gt;
sar [options] [-A] [-o file] t [n]&lt;br&gt;
在命令行中，n 和t 两个参数组合起来定义采样间隔和次数，t为采样间隔，是必须有的参数，n为采样次数，是可选的，默认值是1，-o file表示将命令结果以二进制格式存放在文件中，file 在此处不是关键字，是文件名。options 为命令行选项，sar命令的选项很多，下面只列出常用选项：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-A：所有报告的总和。&lt;/li&gt;
&lt;li&gt;-u：CPU利用率&lt;/li&gt;
&lt;li&gt;-v：进程、节点、文件和锁表状态。&lt;/li&gt;
&lt;li&gt;-p：像是当前系统中指定CPU使用信息。&lt;/li&gt;
&lt;li&gt;-d：硬盘使用报告。&lt;/li&gt;
&lt;li&gt;-r：显示系统内存的使用情况。&lt;/li&gt;
&lt;li&gt;-n：显示网络运行状态。参数后面可跟DEV、EDEV、SOCK和FULL。DEV显示网络接口信息，EDEV显示网络错误的统计数据，SOCK显示套接字信息，FULL显示前三参数所有信息。&lt;/li&gt;
&lt;li&gt;-q：显示运行队列的大小，它与系统当时的平均负载相同&lt;/li&gt;
&lt;li&gt;-B：内存分页情况&lt;/li&gt;
&lt;li&gt;-R：显示进程在采样时间内的活动情况。&lt;/li&gt;
&lt;li&gt;-g：串口I/O的情况。&lt;/li&gt;
&lt;li&gt;-b：缓冲区使用情况。&lt;/li&gt;
&lt;li&gt;-a：文件读写情况。&lt;/li&gt;
&lt;li&gt;-c：系统调用情况。&lt;/li&gt;
&lt;li&gt;-R：进程的活动情况。&lt;/li&gt;
&lt;li&gt;-y：终端设备活动情况。&lt;/li&gt;
&lt;li&gt;-W：系统交换活动。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.6.3结果说明&lt;/h4&gt;
&lt;p&gt;Cpu资源监控&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9b59f930a06ed273e49e799fb6144cde.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;CPU：all 表示统计信息为所有 CPU 的平均值。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;%user：显示在用户级别(application)运行使用 CPU 总时间的百分比。&lt;/li&gt;
&lt;li&gt;%nice：显示在用户级别，用于nice操作，所占用 CPU 总时间的百分比。&lt;/li&gt;
&lt;li&gt;%system：在核心级别(kernel)运行所使用 CPU 总时间的百分比。&lt;/li&gt;
&lt;li&gt;%iowait：显示用于等待I/O操作占用 CPU 总时间的百分比。&lt;/li&gt;
&lt;li&gt;%steal：管理程序(hypervisor)为另一个虚拟进程提供服务而等待虚拟 CPU 的百分比。&lt;/li&gt;
&lt;li&gt;%idle：显示 CPU 空闲时间占用 CPU 总时间的百分比。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1. 若 %iowait 的值过高，表示硬盘存在I/O瓶颈&lt;/p&gt;
&lt;p&gt;2. 若 %idle 的值高但系统响应慢时，有可能是 CPU 等待分配内存，此时应加大内存容量&lt;/p&gt;
&lt;p&gt;1. 若 %idle 的值持续低于1，则系统的 CPU 处理能力相对较低，表明系统中最需要解决的资源是 CPU 。&lt;/p&gt;
&lt;p&gt;如果要查看二进制文件test中的内容，需键入如下sar命令：&lt;/p&gt;
&lt;p&gt;sar -u -f test&lt;/p&gt;
&lt;p&gt;Inode、文件和其他内核表监控&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/7618312dd4e19c83dbcbfdbc335dc1ba.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; Dentunued: 目录告诉缓存中未被使用的条目数量&lt;/li&gt;
&lt;li&gt;File-nr: 文件句柄的使用数量&lt;/li&gt;
&lt;li&gt;Inode-nr: 索引节点句柄的使用数量&lt;/li&gt;
&lt;li&gt;Pty-nr :使用的pty的数量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;内存和交换空间监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c8242104dbe01003ae60d7b06e662948.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kbmemfree：这个值和free命令中的free值基本一致,所以它不包括buffer和cache的空间.&lt;/li&gt;
&lt;li&gt;kbmemused：这个值和free命令中的used值基本一致,所以它包括buffer和cache的空间.&lt;/li&gt;
&lt;li&gt;%memused：这个值是kbmemused和内存总量(不包括swap)的一个百分比.&lt;/li&gt;
&lt;li&gt;kbbuffers和kbcached：这两个值就是free命令中的buffer和cache.&lt;/li&gt;
&lt;li&gt;kbcommit：保证当前系统所需要的内存,即为了确保不溢出而需要的内存(RAM+swap).&lt;/li&gt;
&lt;li&gt;%commit：这个值是kbcommit与内存总量(包括swap)的一个百分比.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt; 内存分页监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/eeec89d54067a726da3f2aea5e2212fe.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;pgpgin/s：表示每秒从磁盘或SWAP置换到内存的字节数(KB)&lt;/li&gt;
&lt;li&gt;pgpgout/s：表示每秒从内存置换到磁盘或SWAP的字节数(KB)&lt;/li&gt;
&lt;li&gt;fault/s：每秒钟系统产生的缺页数,即主缺页与次缺页之和(major + minor)&lt;/li&gt;
&lt;li&gt;majflt/s：每秒钟产生的主缺页数.&lt;/li&gt;
&lt;li&gt;pgfree/s：每秒被放入空闲队列中的页个数&lt;/li&gt;
&lt;li&gt;pgscank/s：每秒被kswapd扫描的页个数&lt;/li&gt;
&lt;li&gt;pgscand/s：每秒直接被扫描的页个数&lt;/li&gt;
&lt;li&gt;pgsteal/s：每秒钟从cache中被清除来满足内存需要的页个数&lt;/li&gt;
&lt;li&gt;%vmeff：每秒清除的页(pgsteal)占总扫描页(pgscank+pgscand)的百分比&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt; IO和传送速率监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6d976da42d91d87beb830afc2106db84.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; tps：每秒钟物理设备的 I/O 传输总量&lt;/li&gt;
&lt;li&gt;rtps：每秒钟从物理设备读入的数据总量&lt;/li&gt;
&lt;li&gt;wtps：每秒钟向物理设备写入的数据总量&lt;/li&gt;
&lt;li&gt;bread/s：每秒钟从物理设备读入的数据量，单位为 块/s&lt;/li&gt;
&lt;li&gt;bwrtn/s：每秒钟向物理设备写入的数据量，单位为 块/s&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;进程队列长度和平均负载状态监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/322e27cc538370dfc4e973ef13b1df2a.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;runq-sz：运行队列的长度（等待运行的进程数）&lt;/li&gt;
&lt;li&gt;plist-sz：进程列表中进程（processes）和线程（threads）的数量&lt;/li&gt;
&lt;li&gt;ldavg-1：最后1分钟的系统平均负载（System load average）&lt;/li&gt;
&lt;li&gt;ldavg-5：过去5分钟的系统平均负载&lt;/li&gt;
&lt;li&gt;ldavg-15：过去15分钟的系统平均负载&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;系统交换活动信息监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/11e32ec5dd63016c5728d4d0989009d7.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; pswpin/s：每秒系统换入的交换页面（swap page）数量&lt;/li&gt;
&lt;li&gt;pswpout/s：每秒系统换出的交换页面（swap page）数量&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;设备使用情况监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ea9a684b6d475681c1093d973458e10d.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;参数-p可以打印出sda,hdc等磁盘设备名称,如果不用参数-p,设备节点则有可能是dev8-0,dev22-0&lt;/li&gt;
&lt;li&gt; tps:每秒从物理磁盘I/O的次数.多个逻辑请求会被合并为一个I/O磁盘请求,一次传输的大小是不确定的.&lt;/li&gt;
&lt;li&gt;rd_sec/s:每秒读扇区的次数.&lt;/li&gt;
&lt;li&gt;wr_sec/s:每秒写扇区的次数.&lt;/li&gt;
&lt;li&gt;avgrq-sz:平均每次设备I/O操作的数据大小(扇区).&lt;/li&gt;
&lt;li&gt;avgqu-sz:磁盘请求队列的平均长度.&lt;/li&gt;
&lt;li&gt;await:从请求磁盘操作到系统完成处理,每次请求的平均消耗时间,包括请求队列等待时间,单位是毫秒(1秒=1000毫秒).&lt;/li&gt;
&lt;li&gt;svctm:系统处理每次请求的平均时间,不包括在请求队列中消耗的时间.&lt;/li&gt;
&lt;li&gt;%util:I/O请求占CPU的百分比,比率越大,说明越饱和.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1. avgqu-sz 的值较低时，设备的利用率较高。&lt;/p&gt;
&lt;p&gt;2. 当%util的值接近 1% 时，表示设备带宽已经占满。&lt;/p&gt;
&lt;h3&gt;1.7 netstat&lt;/h3&gt;
&lt;h4&gt;1.7.1命令说明&lt;/h4&gt;
&lt;p&gt;Netstat 命令用于显示本机网络链接、运行端口、路由表等信息&lt;/p&gt;
&lt;h4&gt;1.7.2参数说明&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;netstat [&lt;/strong&gt;&lt;strong&gt;选项]&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-a (all)：显示一个所有的有效连接信息列表，包括已建立的连接（ESTABLISHED），也包括监听连接请求（LISTENING）的那些连接，断开连接（CLOSE_WAIT）或者处于联机等待状态的（TIME_WAIT）等&lt;/li&gt;
&lt;li&gt;-t (tcp)：显示tcp相关选项&lt;/li&gt;
&lt;li&gt;-u (udp)：仅显示udp相关选项&lt;/li&gt;
&lt;li&gt;-n ：拒绝显示别名，能显示数字的全部转化成数字。&lt;/li&gt;
&lt;li&gt;-l ：仅列出有在 Listen (监听) 的服务状态&lt;/li&gt;
&lt;li&gt;-p ：显示建立相关链接的程序名&lt;/li&gt;
&lt;li&gt;-r ：显示路由信息，路由表，除了显示有效路由外，还显示当前有效的连接&lt;/li&gt;
&lt;li&gt;-e ：显示扩展信息，例如uid等&lt;/li&gt;
&lt;li&gt;-s ：按各个协议进行统计&lt;/li&gt;
&lt;li&gt;-c ：每隔一个固定时间，执行该netstat命令。&lt;/li&gt;
&lt;li&gt;-v ：显示当前的有效连接，与-n选项类似&lt;/li&gt;
&lt;li&gt;-I ：显示自动匹配接口的信息&lt;/li&gt;
&lt;li&gt;-e ：显示关于以太网的统计数据。它列出的项目包括传送的数据报的总字节数、错误数、删除数、数据报的数量和广播的数量。这些统计数据既有发送的数据报数量，也有接收的数据报数量。这个选项可以用来统计一些基本的网络流量。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.7.3结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6addb3a87100d1ff1b6d8de377906e19.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Iface：表示网络设备的接口名称。&lt;/li&gt;
&lt;li&gt;MTU：表示最大传输单元，单位为字节。&lt;/li&gt;
&lt;li&gt;RX-OK/TX-OK：表示已经准确无误地接收/发送了多少数据包。&lt;/li&gt;
&lt;li&gt;RX-ERR/TX-ERR：表示接收/发送数据包时候产生了多少错误。&lt;/li&gt;
&lt;li&gt;RX-DRP/TX-DRP：表示接收/发送数据包时候丢弃了多少数据包。&lt;/li&gt;
&lt;li&gt;RX-OVR/TX-OVR：表示由于误差而丢失了多少数据包。&lt;/li&gt;
&lt;li&gt;Flg表示接口标记，其中&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;B 已经设置了一个广播地址。&lt;/p&gt;
&lt;p&gt;L 该接口是一个回送设备。&lt;/p&gt;
&lt;p&gt;M 接收所有数据包（混乱模式）。&lt;/p&gt;
&lt;p&gt;N 避免跟踪。&lt;/p&gt;
&lt;p&gt;O 在该接口上，禁用A R P。&lt;/p&gt;
&lt;p&gt;P 这是一个点到点链接。&lt;/p&gt;
&lt;p&gt;R 接口正在运行。&lt;/p&gt;
&lt;p&gt;U 接口处于“活动”状态。&lt;/p&gt;
&lt;p&gt;其中RX-ERR/TX-ERR、 RX-DRP/TX-DRP和RX-OVR/TX-OVR的值应该都为0，如果不为0，并且很大，那么网络质量肯定有问题，网络传输性能也一代会下降。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/eec8735e6b628b9770e5bb6d708f6924.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Recv-Q：表示接收队列。&lt;/li&gt;
&lt;li&gt;Send-Q ：表示发送队列。&lt;/li&gt;
&lt;li&gt;Local Address ：表示本地机器名、端口&lt;/li&gt;
&lt;li&gt;Foreign Address ：表示远程机器名、端口&lt;/li&gt;
&lt;li&gt;State：表示状态，其中&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;LISTEN ：在监听状态中。&lt;br&gt;
ESTABLISHED：已建立联机的联机情况。&lt;br&gt;
TIME_WAIT：该联机在目前已经是等待的状态。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.8 uptime&lt;/h3&gt;
&lt;h4&gt;1.8.1 命令说明&lt;/h4&gt;
&lt;p&gt;Uptime主要是用来统计系统当前的运行状态&lt;/p&gt;
&lt;h4&gt;1.8.2参数说明&lt;/h4&gt;
&lt;p&gt;-V  显示版本&lt;/p&gt;
&lt;h4&gt;1.8.3 结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1cd52079b5fc329ab5af65b9634b4927.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;输出信息依次是：系统现在的时间，系统从上次开机到现在运行了多长时间，系统当前有多少个登录用户，系统在一分钟内、5分钟内、15分钟内的平均负载&lt;/li&gt;
&lt;li&gt;注意点：如果load average值长期大于系统CPU的个数则说明CPU很繁忙，负载很高，可能会影响系统性能&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.9 ps&lt;/h3&gt;
&lt;h4&gt;1.9.1命令说明&lt;/h4&gt;
&lt;p&gt;Ps命令是进程查看命令，使用这个命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、进程有没有僵死、哪些进程占用了过多的资源等。&lt;/p&gt;
&lt;h4&gt;1.9.2参数说明&lt;/h4&gt;
&lt;p&gt;常用参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-A 显示所有进程（等价于-e）(utility)&lt;/li&gt;
&lt;li&gt;-a 显示一个终端的所有进程，除了会话引线&lt;/li&gt;
&lt;li&gt;-N 忽略选择。&lt;/li&gt;
&lt;li&gt;-d 显示所有进程，但省略所有的会话引线(utility)&lt;/li&gt;
&lt;li&gt;-x 显示没有控制终端的进程，同时显示各个命令的具体路径。dx不可合用。（utility）&lt;/li&gt;
&lt;li&gt;-p pid 进程使用cpu的时间&lt;/li&gt;
&lt;li&gt;-u uid or username 选择有效的用户id或者是用户名&lt;/li&gt;
&lt;li&gt;-g gid or groupname 显示组的所有进程。&lt;/li&gt;
&lt;li&gt;U username 显示该用户下的所有进程，且显示各个命令的详细路径。如:ps U zhang;(utility)&lt;/li&gt;
&lt;li&gt;-f 全部列出，通常和其他选项联用。如：ps -fa or ps -fx and so on.&lt;/li&gt;
&lt;li&gt;-l 长格式（有F,wchan,C 等字段）&lt;/li&gt;
&lt;li&gt;-j 作业格式&lt;/li&gt;
&lt;li&gt;-o 用户自定义格式。&lt;/li&gt;
&lt;li&gt;v 以虚拟存储器格式显示&lt;/li&gt;
&lt;li&gt;s 以信号格式显示&lt;/li&gt;
&lt;li&gt;-m 显示所有的线程&lt;/li&gt;
&lt;li&gt;-H 显示进程的层次(和其它的命令合用，如：ps -Ha)（utility）&lt;/li&gt;
&lt;li&gt;e 命令之后显示环境（如：ps -d e; ps -a e）(utility)&lt;/li&gt;
&lt;li&gt;h 不显示第一行&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常用用法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ps a： 显示现行终端机下的所有程序，包括其他用户的程序。&lt;/li&gt;
&lt;li&gt;ps -A ：显示所有程序。&lt;/li&gt;
&lt;li&gt;ps c ：列出程序时，显示每个程序真正的指令名称，而不包含路径，参数或常驻服务的标示。&lt;/li&gt;
&lt;li&gt;ps -e ：此参数的效果和指定”A”参数相同。&lt;/li&gt;
&lt;li&gt;ps e ：列出程序时，显示每个程序所使用的环境变量。&lt;/li&gt;
&lt;li&gt;ps f ：用ASCII字符显示树状结构，表达程序间的相互关系。&lt;/li&gt;
&lt;li&gt;ps -H：显示树状结构，表示程序间的相互关系。&lt;/li&gt;
&lt;li&gt;ps –N：显示所有的程序，除了执行ps指令终端机下的程序之外。&lt;/li&gt;
&lt;li&gt;ps s：采用程序信号的格式显示程序状况。&lt;/li&gt;
&lt;li&gt;ps S ：列出程序时，包括已中断的子程序资料。&lt;/li&gt;
&lt;li&gt;ps -t&amp;lt;终端机编号&amp;gt; ：指定终端机编号，并列出属于该终端机的程序的状况。&lt;/li&gt;
&lt;li&gt;ps u：以用户为主的格式来显示程序状况。&lt;/li&gt;
&lt;li&gt;ps x：显示所有程序，不以终端机来区分。&lt;/li&gt;
&lt;li&gt;Ps -l：较长较详细的显示该pid信息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最常用的方法是ps -aux,然后再利用一个管道符号导向到grep去查找特定的进程,然后再对特定的进程进行操作。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.9.3结果说明&lt;/h4&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d09d684a1f22ecbd69d32c1af7c45bee.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;USER    用户名&lt;/li&gt;
&lt;li&gt;UID    用户ID（User ID）&lt;/li&gt;
&lt;li&gt;PID    进程ID（Process ID）&lt;/li&gt;
&lt;li&gt;PPID    父进程的进程ID（Parent Process id）&lt;/li&gt;
&lt;li&gt;SID    会话ID（Session id）&lt;/li&gt;
&lt;li&gt;%CPU    进程的cpu占用率&lt;/li&gt;
&lt;li&gt;%MEM    进程的内存占用率&lt;/li&gt;
&lt;li&gt;VSZ    进程所使用的虚存的大小（Virtual Size）&lt;/li&gt;
&lt;li&gt;RSS    进程使用的驻留集大小或者是实际内存的大小，Kbytes字节。&lt;/li&gt;
&lt;li&gt;TTY    与进程关联的终端（tty）&lt;/li&gt;
&lt;li&gt;STAT    进程的状态：进程状态使用字符表示的（STAT的状态码）
&lt;ul&gt;
&lt;li&gt;R 运行    Runnable (on run queue)            正在运行或在运行队列中等待。&lt;/li&gt;
&lt;li&gt;S 睡眠    Sleeping                休眠中, 受阻, 在等待某个条件的形成或接受到信号。&lt;/li&gt;
&lt;li&gt;I 空闲    Idle&lt;/li&gt;
&lt;li&gt;Z 僵死    Zombie（a defunct process)        进程已终止, 但进程描述符存在, 直到父进程调用wait4()系统调用后释放。&lt;/li&gt;
&lt;li&gt;D 不可中断    Uninterruptible sleep (ususally IO)    收到信号不唤醒和不可运行, 进程必须等待直到有中断发生。&lt;/li&gt;
&lt;li&gt;T 终止    Terminate                进程收到SIGSTOP, SIGSTP, SIGTIN, SIGTOU信号后停止运行运行。&lt;/li&gt;
&lt;li&gt;P 等待交换页&lt;/li&gt;
&lt;li&gt;W 无驻留页    has no resident pages        没有足够的记忆体分页可分配。&lt;/li&gt;
&lt;li&gt;X 死掉的进程&lt;/li&gt;
&lt;li&gt;&amp;lt; 高优先级进程                    高优先序的进程&lt;/li&gt;
&lt;li&gt;N 低优先    级进程                    低优先序的进程&lt;/li&gt;
&lt;li&gt;L 内存锁页    Lock                有记忆体分页分配并缩在记忆体内&lt;/li&gt;
&lt;li&gt;s 进程的领导者（在它之下有子进程）；&lt;/li&gt;
&lt;li&gt;l 多进程的（使用 CLONE_THREAD, 类似 NPTL pthreads）&lt;/li&gt;
&lt;li&gt;+ 位于后台的进程组&lt;/li&gt;
&lt;li&gt;START    进程启动时间和日期&lt;/li&gt;
&lt;li&gt;TIME    进程使用的总cpu时间&lt;/li&gt;
&lt;li&gt;COMMAND    正在执行的命令行命令&lt;/li&gt;
&lt;li&gt;NI    优先级(Nice)&lt;/li&gt;
&lt;li&gt;PRI    进程优先级编号(Priority)&lt;/li&gt;
&lt;li&gt;WCHAN    进程正在睡眠的内核函数名称；该函数的名称是从/root/system.map文件中获得的。&lt;/li&gt;
&lt;li&gt;FLAGS    与进程相关的数字标识&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;1.10 watch&lt;/h3&gt;
&lt;h4&gt;1.10.1命令说明&lt;/h4&gt;
&lt;p&gt;实时监测命令，还可以检测其他命令运行情况的命令&lt;/p&gt;
&lt;h4&gt;1.10.2参数说明&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;-d 高亮显示变动&lt;/li&gt;
&lt;li&gt; -n 周期（秒）&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;1.10.3结果说明&lt;/h4&gt;
&lt;p&gt;Watch –d –n 1 netstat -ant&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3fd9f157309957b0c4ef4c3ba359a6d2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;每秒监测网络，高亮显示变化。&lt;/p&gt;
&lt;h3&gt;1.11 strace&lt;/h3&gt;
&lt;h4&gt;1.11.1命令说明&lt;/h4&gt;
&lt;p&gt;Strace命令用来跟踪进程执行时的系统调用和所接收的信号。在Linux世界，进程不能直接访问硬件设备，当进程需要访问硬件设备(比如读取磁盘文件，接收网络数据等等)时，必须由用户态模式切换至内核态模式，通过系统调用访问硬件设备。strace可以跟踪到一个进程产生的系统调用,包括参数，返回值，执行消耗的时间&lt;/p&gt;
&lt;h4&gt;1.11.2参数说明&lt;/h4&gt;
&lt;p&gt;strace使用参数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-p：跟踪指定的进程。&lt;/li&gt;
&lt;li&gt;-f：跟踪由fork子进程系统调用。&lt;/li&gt;
&lt;li&gt;-F：尝试跟踪vfork子进程系统调吸入，与-f同时出现时, vfork不被跟踪。&lt;/li&gt;
&lt;li&gt;-o filename：默认strace将结果输出到stdout。通过-o可以将输出写入到filename文件中。&lt;/li&gt;
&lt;li&gt;-ff：常与-o选项一起使用，不同进程(子进程)产生的系统调用输出到filename.PID文&lt;/li&gt;
&lt;li&gt;-r：打印每一个系统调用的相对时间。&lt;/li&gt;
&lt;li&gt;-t：在输出中的每一行前加上时间信息。 -tt 时间确定到微秒级。还可以使用-ttt打印相对时间。&lt;/li&gt;
&lt;li&gt;-v：输出所有系统调用。默认情况下，一些频繁调用的系统调用不会输出。&lt;/li&gt;
&lt;li&gt;-s：指定每一行输出字符串的长度,默认是32。文件名一直全部输出。&lt;/li&gt;
&lt;li&gt;-c：统计每种系统调用所执行的时间，调用次数，出错次数。&lt;/li&gt;
&lt;li&gt;-e expr：输出过滤器，通过表达式，可以过滤出掉你不想要输出。&lt;/li&gt;
&lt;li&gt;-d：输出strace关于标准错误的调试信息。&lt;/li&gt;
&lt;li&gt;-h：输出简要的帮助信息。&lt;/li&gt;
&lt;li&gt;-i：输出系统调用的入口指针。&lt;/li&gt;
&lt;li&gt;-q：禁止输出关于脱离的消息。&lt;/li&gt;
&lt;li&gt;-tt：在输出中的每一行前加上时间信息,微秒级。&lt;/li&gt;
&lt;li&gt;-T：显示每一调用所耗的时间。&lt;/li&gt;
&lt;li&gt;-V ：输出strace的版本信息。&lt;/li&gt;
&lt;li&gt;-x：以十六进制形式输出非标准字符串。&lt;/li&gt;
&lt;li&gt;-xx：所有字符串以十六进制形式输出。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.11.3结果说明&lt;/h4&gt;
&lt;p&gt;strace -ff -F -o ls.log ls –l   跟踪ls –l命令的执行情况&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d76526f14f5cb02e296926e7ebfe1f98.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;当某个函数执行失败时，那么返回值一般为-1&lt;/p&gt;
&lt;h3&gt;1.12  lsof&lt;/h3&gt;
&lt;h4&gt;1.12.1命令说明&lt;/h4&gt;
&lt;p&gt;Lsof的原始功能是列出打开的文件的进程。Linux下一切皆文件。&lt;/p&gt;
&lt;h4&gt;1.12.2参数说明&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;-a ：列出打开文件存在的进程&lt;/li&gt;
&lt;li&gt;-c&amp;lt;进程名&amp;gt; ：列出指定进程所打开的文件&lt;/li&gt;
&lt;li&gt;-g ：列出GID号进程详情&lt;/li&gt;
&lt;li&gt;-d&amp;lt;文件号&amp;gt; ：列出占用该文件号的进程&lt;/li&gt;
&lt;li&gt;+d&amp;lt;目录&amp;gt; ：列出目录下被打开的文件&lt;/li&gt;
&lt;li&gt;+D&amp;lt;目录&amp;gt; ：递归列出目录下被打开的文件&lt;/li&gt;
&lt;li&gt;-n&amp;lt;目录&amp;gt; ：列出使用NFS的文件&lt;/li&gt;
&lt;li&gt;-i&amp;lt;条件&amp;gt; ：列出符合条件的进程。&lt;/li&gt;
&lt;li&gt;-p&amp;lt;进程号&amp;gt;： 列出指定进程号所打开的文件&lt;/li&gt;
&lt;li&gt;-u 后面跟username：列出该用户相关进程所打开文件&lt;/li&gt;
&lt;li&gt;-U ：仅列出系统socket文件类型&lt;/li&gt;
&lt;li&gt;-h：显示帮助信息&lt;/li&gt;
&lt;li&gt;-v：显示版本信息&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;1.12.3结果说明&lt;/h4&gt;
&lt;p&gt;列出所有root用户下的socket文件进程&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/2cd3ebbdca3d1fa68a2ad4b422b72565.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;COMMAND：进程的名称&lt;/li&gt;
&lt;li&gt;PID：进程标识符&lt;/li&gt;
&lt;li&gt;USER：进程所有者&lt;/li&gt;
&lt;li&gt;FD：文件描述符，应用程序通过文件描述符识别该文件。如cwd、txt等&lt;/li&gt;
&lt;li&gt;TYPE：文件类型，如DIR、REG等&lt;/li&gt;
&lt;li&gt;DEVICE：指定磁盘的名称&lt;/li&gt;
&lt;li&gt;SIZE：文件的大小&lt;/li&gt;
&lt;li&gt;NODE：索引节点（文件在磁盘上的标识）&lt;/li&gt;
&lt;li&gt;NAME：打开文件的确切名称&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如有遗漏处，欢迎评论，逐渐补充。&lt;/p&gt;
&lt;div id=&quot;MySignature&quot;&gt;凌风出品，文武兼备&lt;/div&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Wed, 17 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-17-81173-86eab02cd.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-17-81173-86eab02cd.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>为什么社交网络中数据翻页技术复杂</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;为开发者打造的Linux视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;今天讨论了一个传统的问题，问题本身比较简单，就是针对key-list类型的数据，如何优化方案做到性能与成本的tradeoff。Key-list在用户类型的产品中非常普遍，如一个用户的好友关系 {“uid”:{1,2,3,4,5}}，表示uid包含有5个好友；一条微博下面的评论id列表{“weibo_id”: {comment_id1, comment_id2……}}，一个用户发表的微博id列表等。&lt;/p&gt;
&lt;p&gt;在list长度较少时候，我们可以直接的使用数据库的翻页功能，如&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT * FROM LIST_TABLE LIMIT offset, row_count;&lt;/pre&gt;
&lt;p&gt;根据经验，在大部分场景下，单个业务的list数据长度99%在1000条以下，在数据规模较小时候，上面的方法非常适合。但剩下的1%的数据可能多达100万条，在数据规模较大的时候，当访问offset较大的数据，上述方法非常低效（可参看&lt;a href=&quot;http://stackoverflow.com/questions/4481388/why-does-mysql-higher-limit-offset-slow-the-query-down&quot;&gt;Why does MYSQL higher LIMIT offset slow the query down?&lt;/a&gt;），但在实现方案的时候不能忽视这些超大数据集的问题，因此要实现一个适合各种变长list的翻页方案，考虑到数据的长尾问题，并没有简单高效的方案。这也体现了常说的80%+的时间在优化20%-的功能。&lt;/p&gt;
&lt;p&gt;List数据访问模型常见的有两种方式&lt;br&gt;
1. 扶梯方式&lt;br&gt;
扶梯方式在导航上通常只提供上一页/下一页这两种模式，部分产品甚至不提供上一页功能，只提供一种“更多/more”的方式，也有下拉自动加载更多的方式，在技术上都可以归纳成扶梯方式。&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fbabe6705a3ac4e242be3f8339155ec5.jpg&quot;&gt;&lt;br&gt;
（图：blogspot的导航条）&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b34808bdbbbf01345794ff800181aa0e.jpg&quot;&gt;&lt;br&gt;
（图：很多瀑布流式的产品只提供一个more的导航条）&lt;/p&gt;
&lt;p&gt;扶梯方式在技术实现上比较简单及高效，根据当前页最后一条的偏移往后获取一页即可，在MySQL可使用以下方法实现。&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT * FROM LIST_TABLE WHERE id &amp;gt; offset_id LIMIT n;&lt;/pre&gt;
&lt;p&gt;由于where条件中指定了位置，因此算法复杂度是O(log n)&lt;/p&gt;
&lt;p&gt;2. 电梯方式&lt;br&gt;
另外一种数据获取方式在产品上体现成精确的翻页方式，如1,2,3……n，同时在导航上也可以由用户输入直达n页。国内大部分产品经理对电梯方式有特殊的喜好，如图&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5993eadae1c0c142e3c20a03e8d16cfe.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;但电梯方式在技术实现上相对成本较高，当使用以下SQL时&lt;/p&gt;
&lt;pre class=&quot;brush: sql; gutter: true&quot;&gt;SELECT * FROM LIST_TABLE LIMIT offset, row_count;&lt;/pre&gt;
&lt;p&gt;我们可以使用MySQL explain来分析，从下文可以看到，当offset=10000时候，实际上MySQL也扫描了10000行记录。&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/16ff67aeda384a11d50ef19722bad657.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;为什么会这样？在MySQL中，索引通常是b-tree方式（但存储引擎如InnoDB实际是b+tree），如图&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/484d7282d3330a4e0be469741ac96ad4.jpg&quot;&gt;&lt;br&gt;
从图中可以看到，使用电梯方式时候，当用户指定翻到第n页时候，并没有直接方法寻址到该位置，而是需要从第一楼逐个count，scan到count*page时候，获取数据才真正开始，所以导致效率不高。对应的算法复杂度是O(n)，n指offset，也就是page*count。&lt;/p&gt;
&lt;p&gt;另外Offset并不能有效的缓存，这是由于&lt;br&gt;
1、在数据存在新增及删除的情况下，只要有一条变化，原先的楼层可能会全部发生变化。在一个用户并发访问的场景，频繁变化的场景比较常见。&lt;br&gt;
2、电梯使用比较离散，可能一个20万条的list，用户使用了一次电梯直达100楼之后就走了，这样即使缓存100楼之下全部数据也不能得到有效利用。&lt;/p&gt;
&lt;p&gt;以上描述的场景属于单机版本，在数据规模较大时候，互联网系统通常使用分库的方式来保存，实现方法更为复杂。&lt;br&gt;
在面向用户的产品中，数据分片通常会将同一用户的数据存在相同的分区，以便更有效率的获取当前用户的数据。如下图所示&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/337b38dc0f2b712c5c275d8cfc384f2b.jpg&quot;&gt;&lt;br&gt;
（图：数据按用户uid进行hash拆分）&lt;/p&gt;
&lt;p&gt;图中的不同年份的数据的格子是逻辑概念，实际上同一用户的数据是保存在一张表中。因此方案在常见的使用场景中存在很大不足，大部分产品用户只访问最近产生的数据，历史的数据只有极小的概率被访问到，因此同一个区域内部的数据访问是非常不均匀，如图中2014年生成的属于热数据，2012年以前的属于冷数据，只有极低的概率被访问到。但为了承担红色部分的访问，数据库通常需要高速昂贵的设备如SSD，因此上面方案所有的数据都需要存在SSD设备中，即使这些数据已经不被访问。&lt;/p&gt;
&lt;p&gt;简单的解决方案是按时间远近将数据进行进一步分区，如图。&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/4dd567cde869476b9a2dc8a0d6f72812.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;注意在上图中使用时间方式sharding之后，在一个时间分区内，也需要用前一种方案将数据进行sharding，因为一个时间片区通常也无法用一台服务器容纳。&lt;/p&gt;
&lt;p&gt;上面的方案较好的解决了具体场景对于key list访问性能及成本的tradeoff，但是它存在以下不足&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据按时间进行滚动无法全自动，需要较多人为介入或干预&lt;/li&gt;
&lt;li&gt;数据时间维度需要根据访问数据及模型进行精巧的设计，如果希望实现一个公用的key-list服务来存储所有业务的数据，这个公用服务可能很难实现&lt;/li&gt;
&lt;li&gt;为了实现电梯直达功能，需要增加额外的二级索引，比如2013年某用户总共有多少条记录&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;由于以上问题，尤其是二级索引的引入，显然它不是理想中的key list实现，后文继续介绍适合长尾翻页key list设计的一些思路及尝试。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Mon, 15 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-15-81268-fba7bccf7.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-15-81268-fba7bccf7.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>Worktile中百万级实时消息推送服务的实现</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;为开发者打造的Linux视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;本文由 &lt;a href=&quot;https://worktile.com?hmsr=http%3A%2F%2Fblog.jobbole.com%2F&amp;amp;hmmd=%E6%96%87%E5%AD%97&amp;amp;hmpl=&amp;amp;hmkw=&amp;amp;hmci=&quot; target=&quot;_blank&quot;&gt;Worktile&lt;/a&gt; – 研发团队 分享&lt;/p&gt;
&lt;p&gt;在团队协同工具&lt;a href=&quot;https://worktile.com?hmsr=http%3A%2F%2Fblog.jobbole.com%2F&amp;amp;hmmd=%E6%96%87%E5%AD%97&amp;amp;hmpl=&amp;amp;hmkw=&amp;amp;hmci=&quot; target=&quot;_blank&quot;&gt;Worktile&lt;/a&gt;的使用过程中，你会发现无论是右上角的消息通知，还是在任务面板中拖动任务，还有用户的在线状态，都是实时刷新。Worktile中的推送服务是采用的是基于xmpp协议、erlang语言实现的ejabberd，并在其源码基础上，结合我们的业务，对源码作了修改以适配我们自身的需求。另外，基于amqp协议也可以作为实时消息推送的一种选择，踢踢网就是采用 rabbitmq+stomp 协议实现的消息推送服务。本文将结合我在Worktile和踢踢网的项目实践，介绍下消息推送服务的具体实现。&lt;/p&gt;
&lt;h2&gt;实时推送的几种实现方式&lt;/h2&gt;
&lt;p&gt;相较于手机端的消息推送（一般都是以socket方式实现），web端是基于http协议，很难像tcp一样保持长连接。但随着技术的发展，出现了websocket, comet等新的技术可以达到类似长连接的效果，这些技术大体可分为以下几类：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1）短轮询&lt;/strong&gt;。页面端通过js定时异步刷新，这种方式实时效果较差。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2）长轮询&lt;/strong&gt;。页面端通过js异步请求服务端，服务端在接收到请求后，如果该次请求没有数据，则挂起这次请求，直到有数据到达或时间片（服务端设定）到，则返回本次请求，客户端接着下一次请求。示例如下：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter size-full wp-image-81129&quot; alt=&quot;1&quot; src=&quot;/images/jobbole.com/ace2e1f25f23fad6337356424e566791.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3）Websocket&lt;/strong&gt;。浏览器通过websocket协议连接服务端，实现了浏览器和服务器端的全双工通信。需要服务端和浏览器都支持websocket协议。&lt;/p&gt;
&lt;p&gt;以上几种方式中，方式1实现较简单，但效率和实时效果较差。方式2对服务端实现的要求比较高，尤其是并发量大的情况下，对服务端的压力很大。方式3效率较高，但对较低版本的浏览器不支持，另外服务端也需要有支持websocket的实现。Worktile的web端实时消息推送，采用的是xmpp扩展协议xep-0124 BOSH(&lt;a href=&quot;http://xmpp.org/extensions/xep-0124.html&quot; target=&quot;_blank&quot;&gt;http://xmpp.org/extensions/xep-0124.html&lt;/a&gt;)，本质是采用方式2长轮询的方式。踢踢网则采用了websocket连接rabbitmq的方式实现，下面我会具体介绍如何用这两种方式实现Server Push。&lt;/p&gt;
&lt;h2&gt;运行时环境准备&lt;/h2&gt;
&lt;p&gt;服务端的实现中，无论采用ejabberd还是rabbitmq，都是基于erlang语言开发的，所以必须安装erlang运行时环境。Erlang是一种函数式语言，具有容错、高并发的特点，借助OTP的函数库，很容易构建一个健壮的分布式系统。目前，基于erlang开发的产品有，数据库方面：Riak（Dynamo实现）、CouchDB， Webserver方面：Cowboy、Mochiweb， 消息中间件有rabbitmq等。对于服务端程序员来说，erlang提供的高并发、容错、热部署等特性是其他语言无法达到的。无论在实时通信还是在游戏程序中，用erlang可以很容易为每一个上线用户创建一个对应的process，对一台4核8个G的服务器来说，承载上百万个这样的process是非常轻松的事。下图是erlang程序发起process的一般性示意图：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter size-full wp-image-81131&quot; alt=&quot;2&quot; src=&quot;/images/jobbole.com/302f7ea0b47b013067f6b3d7e7a6d3fd.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;如图所示，Session manager(or gateway)负责为每个用户（uid）创建相对应的process， 并把这个对应关系（map）存放到数据表中。每个process则对应用户数据，并且他们之间可以相互发送消息。Erlang的优势就是在内存足够的情况下创建上百万个这样的process，而且它的创建和销毁比java的thread要轻量的多，两者不是一个数量级的。&lt;/p&gt;
&lt;p&gt;好了，我们现在开始着手erlang环境的搭建（实验的系统为ubuntu12.04, 4核8个G内存）：&lt;/p&gt;
&lt;p&gt;1、依赖库安装&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt; sudo apt-get install build-essential
 sudo apt-get install libncurses5-dev
 sudo apt-get install libssl-dev libyaml-dev
 sudo apt-get install m4
 sudo apt-get install unixodbc unixodbc-dev
 sudo apt-get install freeglut3-dev libwxgtk2.8-dev
 sudo apt-get install xsltproc
 sudo apt-get install fop tk8.5 libxml2-utils&lt;/pre&gt;
&lt;p&gt;2、官网下载otp源码包(&lt;a href=&quot;http://www.erlang.org/download.html&quot; target=&quot;_blank&quot;&gt;http://www.erlang.org/download.html&lt;/a&gt;), 解压并安装：&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;tar zxvf otpsrcR16B01.tar.gz
cd otpsrcR16B01
configure
make &amp;amp; make install&lt;/pre&gt;
&lt;p&gt;至此，erlang运行环境就完成了。下面将分别介绍rabbitmq和ejabberd构建实时消息服务。&lt;/p&gt;
&lt;h2&gt;基于RabbitMQ的实时消息服务&lt;/h2&gt;
&lt;p&gt;RabbitMQ是在业界广泛应用的消息中间件，也是对AMQP协议实现最好的一种中间件。AMQP协议中定义了Producer、 Consumer、MessageQueue、Exchange、Binding、Virtual Host等实体，他们的关系如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;3&quot; src=&quot;/images/jobbole.com/8e24adab99b47ccfd977fb75da6c031c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;消息发布者(Producer)连接交换器（Exchange）, 交换器和消息队列（Message Queue）通过key进行Binding，Binding是根据Exchange的类型（分为fanout、direct、topic、header）分别对消息作不同形式的派发。Message Queue又分为durable、temporary、auto-delete三种类型，durable queue是持久化队列，不会因为服务shutdown而消失，temporary queue则服务重启后会消失，auto-delete则是在没有consumer连接时自动删除。另外RabbitMQ有很多第三方插件，可以基于AMQP协议基础之上做出很多扩展的应用。下面我们将介绍web stomp插件构建基于AMQP之上的stomp文本协议，通过浏览器websocket达到实时的消息传输。系统的结构如图：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;aligncenter size-full wp-image-81137&quot; alt=&quot;4&quot; src=&quot;/images/jobbole.com/f67cff5a22bae9cde1ec6054fd986e5b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;如图所示，web端我们使用stomp.js和sockjs.js与rabbitmq的web stomp plugin通信，手机端可以用stompj, gozirra(Android)或者objc-stomp(IOS)通过stomp协议与rabbitmq收发消息。因为我们是实时消息系统通常都是要与已有的用户系统结合，rabbitmq可以通过第三方插件rabbitmq-auth-backend-http来适配已有的用户系统，这个插件可以通过http接口完成用户连接时的认证过程。当然，认证方式还有ldap等其他方式。下面介绍具体步骤：&lt;/p&gt;
&lt;p&gt;从官网（&lt;a href=&quot;http://rabbitmq.com/download.html&quot; target=&quot;_blank&quot;&gt;http://rabbitmq.com/download.html&lt;/a&gt;）下载最新版本的源码包，解压并安装：&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;tar zxf rabbitmq-server-x.x.x.tar.gz
cd rabbitmq-server-x.x.x
make &amp;amp; make install&lt;/pre&gt;
&lt;p&gt;为rabbitmq安装web-stomp插件&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;cd /path/to/your/rabbitmq
./sbin/rabbitmq-plugins enable rabbitmq_web_stomp
./sbin/rabbitmq-plugins enable rabbitmq_web_stomp_examples
./sbin/rabbitmqctl stop
./sbin/rabbitmqctl start
./sbin/rabbitmqctl status&lt;/pre&gt;
&lt;p&gt;将会显示下图所示的运行的插件列表&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/4e44f1ac85cd60e3caa56bfd4afb675e.jpeg&quot; rel=&quot;lightbox[81125]&quot; title=&quot;Worktile中百万级实时消息推送服务的实现&quot;&gt;&lt;img class=&quot;aligncenter size-full wp-image-81140&quot; alt=&quot;4.2&quot; src=&quot;/images/jobbole.com/9ea26bd914523b80adb866b5fcd1cf50.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;安装用户授权插件&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;cd /path/to/your/rabbitmq/plugins
wget http://www.rabbitmq.com/community-plugins/v3.3.x/rabbitmq_auth_backend_http-3.3.x-e7ac6289.ez
cd ..
./sbin/rabbitmq-plugins enable rabbitmq_auth_backend_http&lt;/pre&gt;
&lt;p&gt;编辑rabbitmq.config文件（默认存放于/etc/rabbitmq/下），添加：&lt;/p&gt;
&lt;pre class=&quot;brush: xml; gutter: true&quot;&gt;[
 ...
 {rabbit, [{auth_backends, [rabbit_auth_backend_http]}]},
 ...
 {rabbitmq_auth_backend_http,
 [{user_path, “http://your-server/auth/user”},
 {vhost_path, “http://your-server/auth/vhost”},
 {resource_path, “http://your-server/auth/resource”}
 ]}
 ...
].&lt;/pre&gt;
&lt;p&gt;其中，user_path是根据用户名密码进行校验，vhost_path是校验是否有权限访问vhost， resource_path是校验用户对传入的exchange、queue是否有权限。我下面的代码是用nodejs实现的这三个接口的示例：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;var express = require(&#39;express&#39;);
 var app = express();
 app.get(&#39;/auth/user&#39;, function(req, res){
 var name = req.query.username;
 var pass = req.query.password;
 console.log(&quot;name : &quot; + name + &quot;, pass : &quot; + pass);
 if(name === &#39;guest&#39; &amp;amp;&amp;amp; pass === &quot;guest&quot;){
 console.log(&quot;allow&quot;);
 res.send(&quot;allow&quot;);
 }else{
 res.send(&#39;deny&#39;);
 }
 });
 app.get(&#39;/auth/vhost&#39;, function(req, res){
 console.log(&quot;/auth/vhost&quot;);
 res.send(&quot;allow&quot;);
 });
 app.get(&#39;/auth/resource&#39;, function(req, res){
 console.log(&quot;/auth/resource&quot;);
 res.send(&quot;allow&quot;);
 });
 app.listen(3000);&lt;/pre&gt;
&lt;p&gt;浏览器端js实现，示例代码如下：&lt;/p&gt;
&lt;pre class=&quot;brush: javascript; gutter: true&quot;&gt;......
 var ws = new SockJS(&#39;http://&#39; + window.location.hostname + &#39;:15674/stomp&#39;);
 var client = Stomp.over(ws);
 // SockJS does not support heart-beat: disable heart-beats
 client.heartbeat.outgoing = 0;
 client.heartbeat.incoming = 0;
 client.debug = pipe(&#39;#second&#39;);
 var print_first = pipe(&#39;#first&#39;, function(data) {
 client.send(&#39;/exchange/feed/user_x&#39;, {&quot;content-type&quot;:&quot;text/plain&quot;}, data);
 });
 var on_connect = function(x) {
 id = client.subscribe(&quot;/exchange/feed/user_x&quot;, function(d) {
 print_first(d.body);
 });
 };
 var on_error = function() {
 console.log(&#39;error&#39;);
 };
 client.connect(&#39;guest1&#39;, &#39;guest1&#39;, on_connect, on_error, &#39;/&#39;);
 ......&lt;/pre&gt;
&lt;p&gt;需要说明的时，在这里我们首先要在rabbitmq实例中创建feed这个exchange，我们用stomp.js连接成功后，根据当前登陆用户的id（user_x）绑定到这个exchange，即 subscribe(“/exchange/feed/user_x”, …) 这个操作的行为，这样在向rabbitmq中feed exchange发送消息并指定用户id(user_x)为key，页面端就会通过websocket实时接收到这条消息。&lt;/p&gt;
&lt;p&gt;到目前为止，基于rabbitmq+stomp实现web端消息推送就已经完成，其中很多的细节需要小伙伴们亲自去实践了，这里就不多说了。实践过程中可以参照官方文档：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://rabbitmq.com/stomp.html&quot; target=&quot;_blank&quot;&gt;http://rabbitmq.com/stomp.html&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;http://rabbitmq.com/web-stomp.html&quot; target=&quot;_blank&quot;&gt;http://rabbitmq.com/web-stomp.html&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://github.com/simonmacmullen/rabbitmq-auth-backend-http&quot; target=&quot;_blank&quot;&gt;https://github.com/simonmacmullen/rabbitmq-auth-backend-http&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;以上的实现是我本人在踢踢网时采用的方式，下面接着介绍一下现在在Worktile中如何通过ejabberd实现消息推送。&lt;/p&gt;
&lt;h2&gt;基于ejabberd的实时消息推送&lt;/h2&gt;
&lt;p&gt;与rabbitmq不同，ejabberd是xmpp协议的一种实现，与amqp相比，xmpp广泛应用于即时通信领域。Xmpp协议的实现有很多种，比如java的openfire，但相较其他实现，ejabberd的并发性能无疑使最优秀的。Xmpp协议的前身是jabber协议，早期的jabber协议主要包括在线状态（presence）、好友花名册（roster）、IQ（Info/Query）几个部分。现在jabber已经成为rfc的官方标准，如rfc2799, rfc4622, rfc6121，以及xmpp的扩展协议（xep）。Worktile Web端的消息提醒功能就是基于XEP-0124、XEP-0206定义的BOSH扩展协议。&lt;/p&gt;
&lt;p&gt;由于自身业务的需要，我们对ejabberd的用户认证和好友列表模块的源码进行修改，通过redis保存用户的在线状态，而不是mnesia和mysql。另外好友这块我们是从已有的数据库中（mongodb）中获取项目或团队的成员。Web端通过strophe.js来连接（http-bind），strophe.js可以以长轮询和websocket两种方式来连接，由于ejabberd还没有好的websocket的实现，就采用了BOSH的方式模拟长连接。整个系统的结构如下：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/4e44f1ac85cd60e3caa56bfd4afb675e.jpeg&quot; rel=&quot;lightbox[81125]&quot; title=&quot;Worktile中百万级实时消息推送服务的实现&quot;&gt;&lt;img alt=&quot;5&quot; src=&quot;/images/jobbole.com/2c970cd29b1e2a84a68dc717926f2264.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Web端用strophe.js通过http-bind进行连接nginx代理，nginx反向代理ejabberd cluster。iOS用xmpp-framwork连接, Android可以用smack直接连ejabberd服务器集群。这些都是现有的库，无需对client进行开发。在线状态根据用户uid作为key定义了在线、离线、忙等状态存放于redis中。好友列表从mongodb的project表中获取。用户认证直接修改了ejabberd_auth_internal.erl文件，通过mongodb驱动连接用户库，在线状态等功能是新加了模块，其部分代码如下:&lt;/p&gt;
&lt;pre class=&quot;brush: erlang; gutter: true&quot;&gt;-module(wt_mod_proj).
 -behaviour(gen_mod).
 -behaviour(gen_server).
 -include(&quot;ejabberd.hrl&quot;).
 -include(&quot;logger.hrl&quot;).
 -include(&quot;jlib.hrl&quot;).
 -define(SUPERVISOR, ejabberd_sup).
 ...
 -define(ONLINE, 1).
 -define(OFFLINE, 0).
 -define(BUSY, 2).
 -define(LEAVE, 3).
 ...
 %% API
 -export([start_link/2, get_proj_online_users/2]).
 %% gen_mod callbacks
 -export([start/2, stop/1]).
 %% gen_server callbacks
 -export([init/1, terminate/2, handle_call/3, handle_cast/2, handle_info/2, code_change/3]).
 %% Hook callbacks
 -export([user_available/1, unset_presence/3, set_presence/4]).
 -export([get_redis/1, remove_online_user/3, append_online_user/3]).
 ...
 -record(state,{host = &amp;amp;lt;&amp;amp;lt;&quot;&quot;&amp;amp;gt;&amp;amp;gt;, server_host, rconn, mconn}).
start_link(Host, Opts) -&amp;amp;gt;
 Proc = gen_mod:get_module_proc(Host, ?MODULE),
 gen_server:start_link({local, Proc}, ?MODULE, [Host, Opts], []).
 user_available(New) -&amp;amp;gt;
 LUser = New#jid.luser, LServer = New#jid.lserver,
 Proc = gen_mod:get_module_proc(LServer, ?MODULE),
 gen_server:cast(Proc, {user_available, LUser, LServer}).
append_online_user(Uid, Proj, Host) -&amp;amp;gt;
 Proc = gen_mod:get_module_proc(Host, ?MODULE),
 gen_server:call(Proc, {append_online_user, Uid, Proj}).
 remove_online_user(Uid, Proj, Host) -&amp;amp;gt;
 Proc = gen_mod:get_module_proc(Host, ?MODULE),
 gen_server:call(Proc, {remove_online_user, Uid, Proj}).
 ...
 set_presence(User, Server, Resource, Packet) -&amp;amp;gt;
 Proc = gen_mod:get_module_proc(Server, ?MODULE),
 gen_server:cast(Proc, {set_presence, User, Server, Resource, Packet}).
 ...
start(Host, Opts) -&amp;amp;gt;
 Proc = gen_mod:get_module_proc(Host, ?MODULE),
 ChildSpec = {Proc, {?MODULE, start_link, [Host, Opts]},
 transient, 2000, worker, [?MODULE]},
 supervisor:start_child(?SUPERVISOR, ChildSpec).
stop(Host) -&amp;amp;gt;
 Proc = gen_mod:get_module_proc(Host, ?MODULE),
 gen_server:call(Proc, stop),
 supervisor:delete_child(?SUPERVISOR, Proc).
init([Host, Opts]) -&amp;amp;gt;
 MyHost = gen_mod:get_opt_host(Host, Opts, &amp;amp;lt;&amp;amp;lt;&quot;wtmuc.@HOST@&quot;&amp;amp;gt;&amp;amp;gt;),
 RedisHost = gen_mod:get_opt(redis_host, Opts, fun(B) -&amp;amp;gt; B end,?REDIS_HOST),
 RedisPort = gen_mod:get_opt(redis_port, Opts, fun(I) when is_integer(I), I&amp;amp;gt;0 -&amp;amp;gt; I end, ?REDIS_PORT),
 ejabberd_hooks:add(set_presence_hook, Host, ?MODULE, set_presence, 100),
 ejabberd_hooks:add(user_available_hook, Host, ?MODULE, user_available, 50),
 ejabberd_hooks:add(sm_remove_connection_hook, Host, ?MODULE, unset_presence, 50),
 MongoHost = gen_mod:get_opt(mongo_host, Opts, fun(B) -&amp;amp;gt; binary_to_list(B) end, ?MONGO_HOST),
 MongoPort = gen_mod:get_opt(mongo_port, Opts, fun(I) when is_integer(I), I&amp;amp;gt;0 -&amp;amp;gt; I end, ?MONGO_PORT),
 {ok, Mongo} = mongo_connection:start_link({MongoHost, MongoPort}),
 C = c(RedisHost, RedisPort),
 ejabberd_router:register_route(MyHost), {ok, #state{host = Host, server_host = MyHost, rconn = C, mconn = Mongo}}.
 terminate(_Reason, #state{host = Host, rconn = C, mconn = Mongo}) -&amp;amp;gt;
 ejabberd_hooks:delete(set_presence_hook, Host, ?MODULE, set_presence, 100),
 ejabberd_hooks:delete(user_available_hook, Host, ?MODULE, user_available, 50),
 ejabberd_hooks:delete(unset_presence_hook, Host, ?MODULE, unset_presence, 50),
 eredis:stop(C),
 ok.
 ...
 handle_call({append_online_user, Uid, ProjId}, _From, State) -&amp;amp;gt;
 C = State#state.rconn,
 Key = &amp;amp;lt;&amp;lt;!--?PRE_RPOJ_ONLINE_USERS /binary, ProjId/binary--&amp;gt;&amp;amp;gt;,
 Resp = eredis:q(C, [&quot;SADD&quot;, Key, Uid]),
 {reply, Resp, State};
 handle_call({remove_online_user, Uid, ProjId}, _From, State) -&amp;amp;gt;
 ...
 handle_call({get_proj_online_users, ProjId}, _From, State) -&amp;amp;gt;
 ...
 handle_cast({set_presence, User, Server, Resource, Packet}, #state{mconn = Mongo} = State) -&amp;amp;gt;
 C = State#state.rconn,
 Key = &amp;amp;lt;&amp;lt;!--?USER_PRESENCE /binary, User/binary--&amp;gt;&amp;amp;gt;,
 Pids = get_user_projs(User, Mongo),
 Cmd = get_proj_key(Pids, [&quot;SUNION&quot;]),
 case xml:get_subtag_cdata(Packet, &amp;amp;lt;&amp;amp;lt;&quot;show&quot;&amp;amp;gt;&amp;amp;gt;) of
 &amp;amp;lt;&amp;amp;lt;&quot;away&quot;&amp;amp;gt;&amp;amp;gt; -&amp;amp;gt;
 eredis:q(C, [&quot;SET&quot;, Key, ?LEAVE]);
 &amp;amp;lt;&amp;amp;lt;&quot;offline&quot;&amp;amp;gt;&amp;amp;gt; -&amp;amp;gt;
 ...
 handle_cast(_Msg, State) -&amp;amp;gt; {noreply, State}.
handle_info({route, From, To, Packet}, #state{host = Host, server_host = MyHost, rconn = RedisConn, mconn = Mongo} = State) -&amp;amp;gt;
 case catch do_route(Host, MyHost, From, To, Packet, RedisConn, Mongo) of
 {&#39;EXIT&#39;, Reason} -&amp;amp;gt;
 ?ERROR_MSG(&quot;~p&quot;, [Reason]);
 _ -&amp;amp;gt;
 ok
 end,
 {noreply, State};
handle_info(_Info, State) -&amp;amp;gt; {noreply, State}.
code_change(_OldVsn, State, _Extra) -&amp;amp;gt; {ok, State}.
 ...&lt;/pre&gt;
&lt;p&gt;其中，user\_available\_hook和sm\_remove\_connection\_hook 就是用户上线和用户断开连接触发的事件，ejabberd 中正是由于这些hook，才能很容易扩展功能。&lt;/p&gt;
&lt;p&gt;在用tsung对ejabberd进行压力测试，测试机器为4核心8G内存的普通PC，以3台客户机模拟用户登录、设置在线状态、发送一条文本消息、关闭连接操作，在同时在线达到30w时，CPU占用不到3%，内存大概到3个G左右，随着用户数增多，主要内存的损耗较大。由于压力测试比较耗时，再等到有时间的时候，会在做一些更深入的测试。&lt;/p&gt;
&lt;p&gt;对于ejabberd的安装与集群的搭建，大家可以参照官方文档，这里不再赘述。如果在使用过程中有什么问题，可以加入&lt;a href=&quot;https://worktile.com?hmsr=http%3A%2F%2Fblog.jobbole.com%2F&amp;amp;hmmd=%E6%96%87%E5%AD%97&amp;amp;hmpl=&amp;amp;hmkw=&amp;amp;hmci=&quot; target=&quot;_blank&quot;&gt;Worktile&lt;/a&gt;官方群(110257147)，进行讨论。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Mon, 15 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-15-81125-28848f539.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-15-81125-28848f539.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>一个成功的 Git 分支模型</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69?from=jobboleblog&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181?from=jobboleblog&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;在这篇文章中介绍的开发模型在大约一年前已经在我的私有项目和工作引入的，而且已经被证明是非常成功的。我想写一些关于这个模型的东西已经好一段时间了，但是一直苦于没有时间，不过现在可以了。我不想探讨任何项目细节，只讨论分支策略和发布管理。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/24b04fd5f739b36d90727cfa07aa886d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;这篇文章围绕着Git做为我们所有的源代码版本控制工具而展开的。&lt;/p&gt;
&lt;h2&gt;为什么是Git&lt;/h2&gt;
&lt;p&gt;为了深入探讨git和集中式源码版本控制系统的利弊，&lt;a href=&quot;http://www.whygitisbetterthanx.com/&quot;&gt;参见&lt;/a&gt;这些&lt;a href=&quot;https://git.wiki.kernel.org/index.php/GitSvnComparsion&quot;&gt;文章&lt;/a&gt;。这方面有太多的激烈争论。作为一个开发者，相比其他工具，当前我更喜欢Git。Git的确改变了开发者关于合并与分支的思考方式。在那些经典的CVS/Subversion管理工具的世界中，合并/分支被认为是有些吓人的(“当心合并冲突，它们咬你!”)，而且偶尔你得做些操作解决一些问题。&lt;/p&gt;
&lt;p&gt;但是使用Git，这些操作都变得极度简单，这些操作被认为是你日常工作流程核心部分之一。例如，&lt;a href=&quot;http://svnbook.red-bean.com/&quot;&gt;在CVS/Subversion 这本书中&lt;/a&gt;，分支与合并在很后的章节中才被第一次讨论(针对高级用户)。但是在&lt;a href=&quot;http://git-scm.com/book/en/v2&quot;&gt;每一本&lt;/a&gt;&lt;a href=&quot;pragprog.com/titles/tsgit/pragmatic-version-control-using-git&quot;&gt;Git&lt;/a&gt;&lt;a href=&quot;github.com/progit/progit&quot;&gt;书籍&lt;/a&gt;中，在第三章就讲到了(基础部分)。&lt;/p&gt;
&lt;p&gt;由于它的简单性和操作命令的重复性，分支与合并操作变得不再可怕。版本控制工具被认为在分支/合并方面提供操作便利性比什么都重要&lt;/p&gt;
&lt;p&gt;关于工具本身，已经讨论的足够多了，下面针对开发模型进行展开。我将要介绍的这个模型不会比任何一套流程内容多，每个团队成员都必须遵守，这样便于管理软件开发过程。&lt;/p&gt;
&lt;h2&gt;既分散又集中&lt;/h2&gt;
&lt;p&gt;我们使用的，且与这个分支模型配合的非常好的库，他有一个“真正”的中央仓库。注意，这个库只是被认为是中央仓库(因为Git是一个分布式的版本控制工具，在技术层面没有所谓的中央仓库)。我们将会为这个仓库起名为&lt;code&gt;origin&lt;/code&gt;，因为所有的Git用户对这个名字都比较熟悉。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/96afd39407d6531b1c545913d2e90214.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;每个开发者从origin拉取和推送代码。除了集中式的推送拉取关系，每个开发者也有可能从别的开发者处拉取代码，形成自己的团队。例如当与两个或者更多的人开发一个大的特性时，或者在将代码推送到&lt;code&gt;origin&lt;/code&gt;之前，这种代码管理模式可能有用。在上图中，存在Alice和Bob，Alice和David，Clair 和David三个子团队&lt;/p&gt;
&lt;p&gt;技术上而言，这只不过意味着Alice定义了一个远程Git仓库，起名为bob，实际上指向Bob的版本库，反之亦然(Bob定义了一个远程Git仓库，起名为alice，实际上指向Alice的版本库)。&lt;/p&gt;
&lt;h2&gt;&lt;/h2&gt;
&lt;h2&gt;主分支&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/504f548086e67e6a1147da77a43da6ff.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;老实说，我们讨论的开发模型受到了当前已存在模型的很大启发。集中式的版本库有两个永久存在的主分支：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;master分支&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;develop分支&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;&lt;code&gt;origin&lt;/code&gt;的master&lt;/code&gt;分支每个Git用户都很熟悉。平行的另外一个分支叫做&lt;code&gt;develop&lt;/code&gt;分支。&lt;/p&gt;
&lt;p&gt;我们认为&lt;code&gt;origin/master&lt;/code&gt;这个分支上&lt;code&gt;HEAD&lt;/code&gt;引用所指向的代码都是可发布的。&lt;/p&gt;
&lt;p&gt;我们认为&lt;code&gt;origin/develop&lt;/code&gt;这个分支上&lt;code&gt;HEAD&lt;/code&gt;引用所指向的代码总是反应了下一个版本所要交付特性的最新的代码变更。一些人管它叫“整合分支”。它也是自动构建系统执行构建命令的分支。&lt;/p&gt;
&lt;p&gt;当&lt;code&gt;develop&lt;/code&gt;分支上的代码达到了一个稳定状态，并且准备发布时，所有的代码变更都应该合并到master分支，然后打上发布版本号的tag。具体如何进行这些操作，我们将会讨论&lt;/p&gt;
&lt;p&gt;因此，每次代码合并到master分支时，它就是一个人为定义的新的发布产品。理论上而言，在这我们应该非常严格，当master分支有新的提交时，我们应该使用Git的钩子脚本执行自动构建命令，然后将软件推送到生产环境的服务器中进行发布。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2&gt;辅助性分支&lt;/h2&gt;
&lt;p&gt;紧邻&lt;code&gt;master&lt;/code&gt;和&lt;code&gt;develop&lt;/code&gt;分支，我们的开发模型采用了另外一种辅助性的分支，以帮助团队成员间的并行开发，特性的简单跟踪，产品的发布准备事宜，以及快速的解决线上问题。不同于主分支，这些辅助性分支往往只要有限的生命周期，因为他们最终会被删除。&lt;/p&gt;
&lt;p&gt;我们使用的不同类型分支包括:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;特性分支&lt;/li&gt;
&lt;li&gt;Release分支&lt;/li&gt;
&lt;li&gt;Hotfix 分支&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上述的每一个分支都有其特殊目的，也绑定了严格的规则：哪些分支是自己的拉取分支，哪些分支是自己的目标合并分支。&lt;/p&gt;
&lt;p&gt;从技术角度看，这些分支的特殊性没有更多的含义。只是按照我们的使用方式对这些分支进行了归类。他们依旧是原Git分支的样子。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;特性分支&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c184c28a1551540c859851e640cddccf.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;特性分支可以从develop分支拉取建立，最终必须合并会develop分支。特性分支的命名，除了 &lt;code&gt;master&lt;/code&gt;， &lt;code&gt;develop&lt;/code&gt;， &lt;code&gt;release-*&lt;/code&gt;，或&lt;code&gt;hotfix-*&lt;/code&gt;以外，可以随便起名。&lt;/p&gt;
&lt;p&gt;特性分支(有时候也成主题分支)用于开发未来某个版本新的特性。当开始一个新特性的开发时，这个特性未来将发布于哪个目标版本，此刻我们是不得而知的。特性分支的本质特征就是只要特性还在开发，他就应该存在，但最终这些特性分支会被合并到develop分支(目的是在新版本中添加新的功能)或者被丢弃(它只是一个令人失望的试验)&lt;/p&gt;
&lt;p&gt;特性分支只存在开发者本地版本库，不在远程版本库。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h4&gt;创建特性分支&lt;/h4&gt;
&lt;p&gt;当开始开发一个新特性时，从develop分支中创建特性分支&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout -b myfeature develop
Switched to a new branch &quot;myfeature&quot;&lt;/pre&gt;
&lt;h4&gt;在develop分支整合已经开发完成的特性&lt;/h4&gt;
&lt;p&gt;开发完成的特性必须合并到develop分支，即添加到即将发布的版本中。&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout develop
Switched to branch &#39;develop&#39;
$ git merge --no-ff myfeature
Updating ea1b82a..05e9557
(Summary of changes)
$ git branch -d myfeature
Deleted branch myfeature (was 05e9557).
$ git push origin develop&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;--no-ff&lt;/code&gt;参数的作用是在合并的时候，会创建一个新的提交对象，即使是fast-forward方式的合并。这就避免了丢失特性分支的历史记录信息以及提交记录信息。比较一下&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/4502bb84bffab2acb8fc87b0d86b008a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;在右面的例子中，是不可能从Git历史记录中看到一个已经实现了的特性的所有提交对象-除非你去查看所有的日志信息。要想获取整个特性分支信息，在右面的例子中的确是一个头疼的问题，但是如果使用&lt;code&gt;--no-ff&lt;/code&gt;参数就没有这个问题。&lt;/p&gt;
&lt;p&gt;使用这个参数后，的确创建了一些新的提交对象(那怕是空提交对象)，但是很值得。&lt;/p&gt;
&lt;p&gt;不幸的是，我还没有找到一种方法使Git默认的merge操作带着&lt;code&gt;--no-ff&lt;/code&gt;参数，但的确应该这样。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h3&gt;发布分支&lt;/h3&gt;
&lt;p&gt;从&lt;code&gt;develop&lt;/code&gt;分支去建立Release分支，Release分支必须合并到develop分支和master分支，Release分支名可以这样起名:&lt;code&gt;release-*。&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Release分支用于支持一个新版本的发布。他们允许在最后时刻进行一些小修小改。甚至允许进行一些小bug的修改，为新版本的发布准要一些元数据(版本号，构建时间等)。通过在release分支完成这些工作，&lt;code&gt;develop&lt;/code&gt;分支将会合并这些特性以备下一个大版本的发布。&lt;/p&gt;
&lt;p&gt;从&lt;code&gt;develop&lt;/code&gt;分支拉取新的release分支的时间点是当开发工作已经达到了新版本的期望值。至少在这个时间点，下一版本准备发布的所有目标特性必须已经合并到了&lt;code&gt;develop&lt;/code&gt;分支。更远版本的目标特性不必合并会develop分支。这些特性必须等到个性分支创建后，才能合并回develop分支&lt;/p&gt;
&lt;p&gt;在release分支创建好后，就会获取到一个分配好即将发布的版本号，不能更早，就在这个时间点。在此之前，develop分支代码反应出了下一版本的代码变更，但是到底下一版本是 0.3 还是 1.0，不是很明确，直到release分支被建立后一切都确定了。这些决定在release分支开始建立，项目版本号等项目规则出来后就会做出。&lt;/p&gt;
&lt;h4&gt;创建release分支&lt;/h4&gt;
&lt;p id=&quot;creating-a-release-branch&quot;&gt;从&lt;code&gt;develop&lt;/code&gt;分支创建release分支。例如1.1.5版本是当前产品的发布版本，我们即将发布一个更大的版本。&lt;code&gt;develop&lt;/code&gt;分支此时已经为下一版本准备好了，我们决定下一版的版本号是1.2(1.1.6或者2.0也可以)。所以我们创建release分支，并给分支赋予新的版本号:&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout -b release-1.2 develop
Switched to a new branch &quot;release-1.2&quot;
$ ./bump-version.sh 1.2
Files modified successfully, version bumped to 1.2.
$ git commit -a -m &quot;Bumped version number to 1.2&quot;
[release-1.2 74d9424] Bumped version number to 1.2
1 files changed, 1 insertions(+), 1 deletions(-)&lt;/pre&gt;
&lt;p&gt;创建好分支并切到这个分支后，我们给分支打上版本号。&lt;code&gt;bump-version.sh是一个虚构的shell脚本，它更改了工作空间的&lt;code&gt;某些文件来&lt;/code&gt;反映新版本特征。(当然也可以手动改变这些文件)，然后版本就被提交了。&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;新的分支会存在一段时间，直到新版本最终发布。在这段时间里，bug的解决可以在这个分支进行(不要在&lt;code&gt;develop&lt;/code&gt;分支进行)。此时是严禁添加新的大特性。这些修改必须合并回develop分支，之后就等待新版本的发布。&lt;/p&gt;
&lt;h4&gt;结束一个release分支&lt;/h4&gt;
&lt;p&gt;当release分支的准备成为一个真正的发布版本时，一些操作必须需要执行。首先，将release分支合并回&lt;code&gt;master&lt;/code&gt;分支(因为&lt;code&gt;master&lt;/code&gt;分支的每一次提交都是预先定义好的一个新版本，谨记)。然后为这次提交打tag，为将来去查看历史版本。最后在release分支做的更改也合并到develop分支，这样的话，将来的其他版本也会包含这些已经解决了的bug。&lt;/p&gt;
&lt;p&gt;在Git中需要两步完成:&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout master
Switched to branch &#39;master&#39;
$ git merge --no-ff release-1.2
Merge made by recursive.
(Summary of changes)
$ git tag -a 1.2&lt;/pre&gt;
&lt;p&gt;这样release分支已经完成工作，tag也已经打了。&lt;/p&gt;
&lt;p&gt;备注:你可以使用&lt;code&gt;-s&lt;/code&gt; or &lt;code&gt;-u &amp;lt;key&amp;gt;&lt;/code&gt;参数为你的tag设置标签签名。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;为了保存这些在release分支所做的变更，我们需要将这些变更合并回develop分支。执行如下Git命令:&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout develop
Switched to branch &#39;develop&#39;
$ git merge --no-ff release-1.2
Merge made by recursive.
(Summary of changes)&lt;/pre&gt;
&lt;p&gt;这步有可能会有合并冲突(极有可能，因为我们已经改变了版本号)。如果有冲突，解决掉他，然后提交。&lt;br&gt;
现在我们已经完成了工作，release分支可以删除了，因为我们不在需要他:&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git branch -d release-1.2
Deleted branch release-1.2 (was ff452fe).&lt;/pre&gt;
&lt;h2&gt;Hotfix分支&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/225f93ac35cb4238b4c05ede833d3490.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;Hotfix分支从master分支建立，必须合并回&lt;code&gt;develop&lt;/code&gt;分支和&lt;code&gt;master&lt;/code&gt;分支，为Hotfix分支可以这样起名:&lt;code&gt;hotfix-*&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Hotfix分支在某种程度上非常像release分支，他们都意味着为某个新版本发布做准备，并且都是预先不可知的。Hotfix分支是基于当前生产环境的产品的一个bug急需解决而必须创建的。当某个版本的产品有一个严重bug需要立即解决，Hotfix分支需要从master分支上该版本对应的tag上进行建立，因为这个tag标记了产品版本&lt;/p&gt;
&lt;h4&gt;创建hotfix分支&lt;/h4&gt;
&lt;p&gt;Hotfix分支从&lt;code&gt;master&lt;/code&gt;分支进行创建。例如当前线上1.2版本产品因为server端的一个Bug导致系统有问题。但是在&lt;code&gt;develop分支进行&lt;/code&gt;更改是不靠谱的，所以我们需要建立hotfix分支，然后开始解决问题:&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout -b hotfix-1.2.1 master
Switched to a new branch &quot;hotfix-1.2.1&quot;
$ ./bump-version.sh 1.2.1
Files modified successfully, version bumped to 1.2.1.
$ git commit -a -m &quot;Bumped version number to 1.2.1&quot;
[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.1
1 files changed, 1 insertions(+), 1 deletions(-)&lt;/pre&gt;
&lt;p&gt;千万别忘记在创建分支后修改版本号。&lt;/p&gt;
&lt;p&gt;然后解决掉bug，提交一次或多次。&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git commit -m &quot;Fixed severe production problem&quot;
[hotfix-1.2.1 abbe5d6] Fixed severe production problem
5 files changed, 32 insertions(+), 17 deletions(-)&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;结束hotfix 分支&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;完成工作后，解决掉的bug代码需要合并回master分支，但同时也需要合并到&lt;code&gt;develop&lt;/code&gt;分支，目的是保证在下一版中该bug已经被解决。这多么像release分支啊。&lt;/p&gt;
&lt;p&gt;首先，对master分支进行合并更新，然后打tag&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout master
Switched to branch &#39;master&#39;
$ git merge --no-ff hotfix-1.2.1
Merge made by recursive.
(Summary of changes)
$ git tag -a 1.2.1&lt;/pre&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;备注:你可以使用&lt;code&gt;-s&lt;/code&gt; or &lt;code&gt;-u &amp;lt;key&amp;gt;&lt;/code&gt;参数为你的tag设置标签签名。&lt;/p&gt;
&lt;p&gt;紧接着，在develop分支合并bugfix代码&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git checkout develop
Switched to branch &#39;develop&#39;
$ git merge --no-ff hotfix-1.2.1
Merge made by recursive.
(Summary of changes)&lt;/pre&gt;
&lt;p&gt;这里可能会有一些异常情况，&lt;strong&gt;当一个release分支存在时，hotfix 分支需要合并到release 分支，而不是&lt;code&gt;develop&lt;/code&gt;分支。&lt;/strong&gt;当release分支的使命完成后，合并回release分支的bugfix代码最终也会被合并到develop分支。(当&lt;code&gt;develop&lt;/code&gt;分支急需解决这些bug，而等不到release分支的结束，你可以安全的将这些bugfix代码合并到develop分支，这样做也是可以的)。&lt;/p&gt;
&lt;p&gt;最后删除这些临时分支&lt;/p&gt;
&lt;pre class=&quot;brush: bash; gutter: true&quot;&gt;$ git branch -d hotfix-1.2.1
Deleted branch hotfix-1.2.1 (was abbe5d6).&lt;/pre&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;这个分支模型其实没有什么震撼人心的新东西，这篇文章开始的那个“最大图片”已经证明了他在我们工程项目中的巨大作用。它会形成一种优雅的理想模型，而且很容易理解，该模型也允许团队成员形成一个关于分支和版本发布过程的相同理念。&lt;/p&gt;
&lt;p&gt;这里有提供一个高质量的分支模型图的PDF版本。去吧，把它挂在墙上随时快速参考。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;a href=&quot;http://nvie.com/files/Git-branching-model.pdf&quot;&gt;&lt;img class=&quot;aligncenter&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/61c41705125bfe5e7aede02f6046b8cd.jpg&quot; width=&quot;128&quot;&gt;&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;http://nvie.com/files/Git-branching-model.pdf&quot;&gt; Git-branching-model.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;更新：&lt;/strong&gt;任何需要他的人,这里有一个主图的&lt;a href=&quot;http://github.com/downloads/nvie/gitflow/Git-branching-model-src.key.zip&quot;&gt;gitflow-model.src.key&lt;/a&gt;文件&lt;/p&gt;
&lt;p&gt;如果想和我取得联系，在推特上&lt;a href=&quot;http://twitter.com/nvie&quot;&gt;@nvie&lt;/a&gt;&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81196-6bf51109d.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81196-6bf51109d.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列基础篇（索引运算总结）</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上几篇文章我们介绍了如何&lt;a href=&quot;http://blog.jobbole.com/81176/&quot; target=&quot;_blank&quot;&gt;查看查询计划的方式&lt;/a&gt;、常用运算符（&lt;a href=&quot;http://blog.jobbole.com/81182/&quot; target=&quot;_blank&quot;&gt;连接运算符&lt;/a&gt;、&lt;a href=&quot;http://blog.jobbole.com/81184/&quot; target=&quot;_blank&quot;&gt;联合运算符&lt;/a&gt;）的介绍、并行运算的方式（&lt;a href=&quot;http://blog.jobbole.com/81186/&quot; target=&quot;_blank&quot;&gt;1&lt;/a&gt;、&lt;a href=&quot;http://blog.jobbole.com/81189/&quot; target=&quot;_blank&quot;&gt;2&lt;/a&gt;），有兴趣的可以点击查看。 本篇将分析在SQL Server中，如何利用先有索引项进行查询性能优化，通过了解这些索引项的应用方式可以指导我们如何建立索引、调整我们的查询语句，达到性能优化的目的。 闲言少叙，进入本篇的正题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt; 基于SQL Server2008R2版本，利用微软的一个更简洁的案例库（Northwind）进行解析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;简介&lt;/strong&gt; 所谓的索引应用就是在我们日常写的T-SQL语句中，如何利用现有的索引项，再分析的话就是我们所写的查询条件，其实大部分情况也无非以下几种：&lt;/p&gt;
&lt;p&gt;1、等于谓词：select …where…column=@parameter&lt;/p&gt;
&lt;p&gt;2、比较谓词：select …where…column&amp;gt; or &amp;lt; or  &amp;lt;&amp;gt; or &amp;lt;= or &amp;gt;= @parameter&lt;/p&gt;
&lt;p&gt;3、范围谓词：select …where…column in or not in  or between and @parameter&lt;/p&gt;
&lt;p&gt;4、逻辑谓词：select …where…一个谓词 or、and 其它谓词 or、and 更多谓词…. 我们就依次分析上面几种情况下，如何利用索引进行查询优化的&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、动态索引查找&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所谓的动态索引查找就是SQL Server在执行语句的时候，才格式化查询条件，然后根据查询条件的不同自动的去匹配索引项，达到性能提升的目的。 来举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SET SHOWPLAN_TEXT ON
GO
SELECT OrderID
FROM Orders
WHERE ShipPostalCode IN (N&#39;05022&#39;,N&#39;99362&#39;)&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/959475861d0ef7ebba7b411da09ea32b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;因为我们在表Orders的列ShipPostalCode列中建立了非聚集索引列，所以这里查询的计划利用了索引查找的方式。这也是需要建立索引的地方。 我们来利用文本的方式来查看该语句的详细的执行计划脚本，语句比较长，我用记事本换行，格式化查看 &lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f83962f492e6673824acebcc8893c34a.jpg&quot;&gt;我们知道这张表的该列里存在一个非聚集索引，所以在查询的时候要尽量使用，如果通过索引扫描的方式消耗就比价大了，所以SQL Server尽量想采取索引查找的方式，其实IN关键字和OR关键字逻辑是一样的。&lt;/p&gt;
&lt;p&gt;于是上面的查询条件就转换成了：&lt;/p&gt;
&lt;p&gt;[Northwind].[dbo].[Orders].[ShipPostalCode]=N’05022′&lt;/p&gt;
&lt;p&gt;OR&lt;/p&gt;
&lt;p&gt;[Northwind].[dbo].[Orders].[ShipPostalCode]=N’99362′&lt;/p&gt;
&lt;p&gt;这样就可以采用索引查找了，先查找第一个结果，然后再查找第二个，而这个过程在SQL Server中就被称为：动态索引查找。&lt;/p&gt;
&lt;p&gt;是不是有点智能的感觉了….&lt;/p&gt;
&lt;p&gt;所以有时候我们写语句的时候，尽量要使用SQL Server的这点智能了，让其能自动的查找到索引，提升性能。&lt;/p&gt;
&lt;p&gt;有时候偏偏我们写的语句让SQL Server的智能消失，举个例子：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;--参数化查询条件
DECLARE @Parameter1 NVARCHAR(20),@Parameter2 NVARCHAR(20)
SELECT @Parameter1=N&#39;05022&#39;,@Parameter2=N&#39;99362&#39;
SELECT OrderID
FROM Orders
WHERE ShipPostalCode IN (@Parameter1,@Parameter2)&lt;/pre&gt;
&lt;p&gt;我们将这两个静态的筛序值改成参数，有时候我们写的存储过程灰常喜欢这么做！我们来看这种方式的生成的查询计划 &lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fbc7f2e2425189ed01a993aa2b8cf8f1.jpg&quot;&gt;本来很简单的一个非聚集索引查找搞定的执行计划，我们只是将这两个数值没有直接写入IN关键字中，而是利用了两个变量来代替。&lt;/p&gt;
&lt;p&gt;看看上面SQL Server生成的查询计划！尼玛…这都是些啥？？？还用起来嵌套循环，我就查询了一个Orders表…你嵌套循环个啥….上面动态索引查找的能力去哪了？？？ 好吧，我们用文本查询计划来查看下，这个简单的语句到底在干些啥…&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt; |--Nested Loops(Inner Join, OUTER REFERENCES:([Expr1009], [Expr1010], [Expr1011]))
       |--Merge Interval
       |    |--Sort(TOP 2, ORDER BY:([Expr1012] DESC, [Expr1013] ASC, [Expr1009] ASC, [Expr1014] DESC))
       |         |--Compute Scalar(DEFINE:([Expr1012]=((4)&amp;amp;[Expr1011]) = (4) AND NULL = [Expr1009], [Expr1013]=(4)&amp;amp;[Expr1011], [Expr1014]=(16)&amp;amp;[Expr1011]))
       |              |--Concatenation
       |                   |--Compute Scalar(DEFINE:([Expr1004]=[@Parameter2], [Expr1005]=[@Parameter2], [Expr1003]=(62)))
       |                   |    |--Constant Scan
       |                   |--Compute Scalar(DEFINE:([Expr1007]=[@Parameter1], [Expr1008]=[@Parameter1], [Expr1006]=(62)))
       |                        |--Constant Scan
       |--Index Seek(OBJECT:([Northwind].[dbo].[Orders].[ShipPostalCode]), SEEK:([Northwind].[dbo].[Orders].[ShipPostalCode] &amp;gt; [Expr1009] AND [Northwind].[dbo].[Orders].[ShipPostalCode] &amp;lt; [Expr1010]) ORDERED FORWARD)&lt;/pre&gt;
&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;挺复杂的是吧，其实我分析了一下脚本，关于为什么会生成这个计划脚本的原因，是为了解决如下几个问题：&lt;/p&gt;
&lt;p&gt;1、前面我们写的脚本在IN里面写的是两个常量值，并且是不同的值，所以形成了两个索引值的查找通过OR关键字组合， 这种方式貌似没问题，但是我们将这两个数值变成了参数，这就引来了新的问题，假如这两个参数我们输入的是相等的，那么利用前面的执行计划就会生成如下&lt;/p&gt;
&lt;p&gt;[Northwind].[dbo].[Orders].[ShipPostalCode]=N’05022′&lt;/p&gt;
&lt;p&gt;OR&lt;/p&gt;
&lt;p&gt;[Northwind].[dbo].[Orders].[ShipPostalCode]=N’05022′&lt;/p&gt;
&lt;p&gt;这样执行产生的输出结果就是2条一样的输出值！…但是表里面确实只有1条数据…所以这样输出结果不正确！ 所以变成参数后首先解决的问题就是去重问题，2个一样的变成1个。&lt;/p&gt;
&lt;p&gt;2、上面变成参数，还引入了另外一个问题，加入我们两个值有一个传入的为Null值，或者两个都为Null值，同样输出结果面临着这样的问题。所以这里还要解决的去Null值的问题。   为了解决上面的问题，我们来粗略的分析一下执行计划，看SQL Server如何解决这个问题的 &lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a5932aa87d836f49e0475da3da6cb8e7.jpg&quot;&gt;简单点将就是通过扫描变量中的值，然后将内容进行汇总值，然后在进行排序，再将参数中的重复值去掉，这样获取的值就是一个正确的值，最后拿这些去重后的参数值参与到嵌套循环中，和表Orders进行索引查找。&lt;/p&gt;
&lt;p&gt;但是分析的过程中，有一个问题我也没看明白，就是最好的经过去重之后的常量汇总值，用来嵌套循环连接的时候，在下面的索引查找的时候的过滤条件变成了 and  查找 &lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3e9829cc38b921fe11ddc313ad89106f.jpg&quot;&gt;我将上面的最后的索引查找条件，整理如下：&lt;/p&gt;
&lt;p&gt;|–Index Seek(OBJECT:([Northwind].[dbo].[Orders].[ShipPostalCode]), SEEK:&lt;/p&gt;
&lt;p&gt;(&lt;/p&gt;
&lt;p&gt;[Northwind].[dbo].[Orders].[ShipPostalCode] &amp;gt; [Expr1009]&lt;/p&gt;
&lt;p&gt;AND&lt;/p&gt;
&lt;p&gt;[Northwind].[dbo].[Orders].[ShipPostalCode] &amp;lt; [Expr1010]&lt;/p&gt;
&lt;p&gt;) ORDERED FORWARD)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;这个地方怎么搞的？我也没弄清楚，还望有看明白童鞋的稍加指导下….&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;好了，我们继续&lt;/p&gt;
&lt;p&gt;上面的执行计划中，提到了一个新的运算符：合并间隔（merge interval operator）&lt;/p&gt;
&lt;p&gt;我们来分析下这个运算符的作用，其实在上面我们已经在执行计划的图中标示出该运算符的作用了，去掉重复值。&lt;/p&gt;
&lt;p&gt;其实关于去重的操作有很多的，比如前面文章中我们提到的各种去重操作。&lt;/p&gt;
&lt;p&gt;这里怎么又冒出个合并间隔去重？其实原因很简单，因为我们在使用这个运算符之前已经对结果进行了排序操作，排序后的结果项重复值是紧紧靠在一起的，所以就引入了合并间隔的方式去处理，这样性能是最好的。&lt;/p&gt;
&lt;p&gt;更重要的是合并间隔这种运算符应用场景不仅仅局限于重复值的去除，更重要的是还应用于重复区间的去除。 来看下面的例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;--参数化查询条件
DECLARE @Parameter1 DATETIME,@Parameter2 DATETIME
SELECT @Parameter1=&#39;1998-01-01&#39;,@Parameter2=&#39;1998-01-04&#39;
SELECT OrderID 
FROM ORDERS
WHERE OrderDate BETWEEN @Parameter1 AND DATEADD(DAY,6,@Parameter1)
OR OrderDate BETWEEN @Parameter2 AND DATEADD(DAY,6,@Parameter2)&lt;/pre&gt;
&lt;p&gt;我们看看这个生成的查询计划项 &lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/47c1a3d7eb97048994de1d1ae9ba62d6.jpg&quot;&gt;可以看到，SQL Server为我们生成的查询计划，和前面我们写的语句是一模一样的，当然我们的语句也没做多少改动，改动的地方就是查询条件上。&lt;/p&gt;
&lt;p&gt;我们来分析下这个查询条件：&lt;/p&gt;
&lt;p&gt;WHERE OrderDate BETWEEN @Parameter1 AND DATEADD(DAY,6,@Parameter1)&lt;/p&gt;
&lt;p&gt;OR OrderDate BETWEEN @Parameter2 AND DATEADD(DAY,6,@Parameter2)&lt;/p&gt;
&lt;p&gt;很简单的筛选条件，要获取订单日期在1998-01-01开始到1998-01-07内的值或者1998-01-04开始到1998-01-10内的值（不包含开始日期）&lt;/p&gt;
&lt;p&gt;这里用的逻辑谓词为：OR…其实也就等同于我们前面写的IN&lt;/p&gt;
&lt;p&gt;但是我们这里再分析一下，你会发现这两个时间段是重叠的 &lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/07e07944fc7d7b01be834be7e674b6d1.jpg&quot;&gt;这个重复的区间值，如果用到前面的直接索引查找，在这段区间之内的搜索出来的范围值就是重复的，所以为了避免这种问题，SQL Server又引入了“合并间隔”这个运算符。&lt;/p&gt;
&lt;p&gt;其实，经过上面的分析，我们已经分析出这种动态索引查找的优缺点了，有时候我们为了避免这种复杂的执行计划生成，使用最简单的方式就是直接传值进入语句中（当然这里需要重编译），当然大部分的情况我们写的程序都是只定义的参数，然后进行的运算。可能带来的麻烦就是上面的问题，当然有时候参数多了，为了合并间隔所应用的排序就消耗的内存就会增长。怎么使用，根据场景自己酌情分析。&lt;/p&gt;
&lt;p&gt;二&lt;strong&gt;、索引联合&lt;/strong&gt; 所谓的索引联合，就是根据就是根据筛选条件的不同，拆分成不同的条件，去匹配不同的索引项。 举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT OrderID 
FROM ORDERS
WHERE OrderDate BETWEEN &#39;1998-01-01&#39; AND &#39;1998-01-07&#39;
OR ShippedDate BETWEEN &#39;1998-01-01&#39; AND &#39;1998-01-07&#39;&lt;/pre&gt;
&lt;p&gt;这段代码是查询出订单中的订单日期在1998年1月1日到1998年1月7日的或者发货日期同样在1998年1月1日到1998年1月7日的。&lt;/p&gt;
&lt;p&gt;逻辑很简单，我们知道在这种表里面这两个字段都有索引项。所以这个查询在SQL Server中就有了两个选择：&lt;/p&gt;
&lt;p&gt;1、一次性的来个索引扫描根据匹配结果项输出，这样简单有效，但是如果订单表数据量比较大的话，性能就会很差，因为大部分数据就根本不是我们想要的，还要浪费时间去扫描。&lt;/p&gt;
&lt;p&gt;2、就是通过两列的索引字段直接查找获取这部分数据，这样可以直接减少数据表的扫描量，但是带来的问题就是，如果分开扫描，有一部分数据就是重复的：那些同时在1998年1月1日到1998年1月7日的订单，发货日期也在这段时间内，因为两个扫描项都包含，所以再输出的时候需要将这部分重复数据去掉。&lt;/p&gt;
&lt;p&gt;我们来看SQL Server如何选择&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/cffdc85f7c4eb6f5ff90954bdfc6bdce.jpg&quot;&gt;看来SQL Server经过评估选择了第2中方法。但是上面的方法也不尽完美，采用去重操作耗费了64%的资源。&lt;/p&gt;
&lt;p&gt;其实，上面的方法，我们根据生成的查询计划可以变通的使用以下逻辑，其效果和上面的语句是一样的，并且生成的查询计划也一样&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT OrderID 
FROM ORDERS
WHERE OrderDate BETWEEN &#39;1998-01-01&#39; AND &#39;1998-01-07&#39;
UNION 
SELECT OrderID 
FROM ORDERS
WHERE  ShippedDate BETWEEN &#39;1998-01-01&#39; AND &#39;1998-01-07&#39;&lt;/pre&gt;
&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/e3dd1707e5cac9631f2a430698a7a1a9.jpg&quot;&gt;  我们再来看一个索引联合的例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT OrderID 
FROM ORDERS
WHERE OrderDate = &#39;1998-01-01&#39; 
OR ShippedDate = &#39;1998-01-01&#39;&lt;/pre&gt;
&lt;p&gt;我们将上面的Between and不等式筛选条件改成等式筛选条件，我们来看一下这样形成的执行计划&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/242b70cdee9e76d80a6c2fa6be3982ab.jpg&quot;&gt;基本相同的语句，只是我们改变了不同的查询条件，但是生成的查询计划还是变化蛮大的，有几点不同之处：&lt;/p&gt;
&lt;p&gt;1、前面的用between…and  的筛选条件，通过索引查找返回的值进行组合是用的串联的方式，所谓的串联就是两个数据集拼凑在一起就行，无所谓顺序连接什么的。&lt;/p&gt;
&lt;p&gt;2、前面的用between…and  的筛选条件，通过串联拼凑的结果集去重的方式，是排序去重（Sort Distinct）…并且耗费了大量的资源。这里采用了流聚合来干这个事，基本不消耗&lt;/p&gt;
&lt;p&gt;我们来分析以下产生着两点不同的原因有哪些：&lt;/p&gt;
&lt;p&gt;首先、这里改变了筛选条件为等式连接，所通过索引查找所产生的结果项是排序的，并且按照我们所要查询的OrderID列排序，因此在两个数据集进行汇总的时候，正适合合并连接的条件！需要提前排序。所以这里最优的方式就是采用合并连接！&lt;/p&gt;
&lt;p&gt;那么前面我们用between…and  的筛选条件通过索引查找获取的结果项也是排序的，但是这里它没有按照OrderID排序，它是按照OrderDate或者ShippedDate列排序的，而我们的结果是要OrderID列，所以这里的排序是没用的……所以SQL Server只能选择一个串联操作，将结果汇聚到一起，然后在排序了……我希望这里我已经讲明白了…&lt;/p&gt;
&lt;p&gt;其次、关于去重操作，毫无疑问采用流聚合（Aggregate）这种方式最好，消耗内存少，速度又快…但是前提是要提前排序…前面选用的排序去重（Sort Distinct）纯属无奈之举…&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总结下：我们在写语句的时候能确定为等式连接，最好采用等式连接。还有就是如果能确定输出条件的最好能写入，避免多余的书签查找，还有万恶的SELEECT *….&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;如果写了万恶的SELECT *…那么你所写的语句基本上就可以和非聚集索引查找告别了….顶多就是聚集索引扫描或者RID查找…&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;瞅瞅以下语句&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT * 
FROM ORDERS
WHERE OrderDate = &#39;1998-01-01&#39; 
OR ShippedDate = &#39;1998-01-01&#39;&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3ac389d29ae91913e9790cc1ed0824fd.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;最后，奉上一个AND的一个连接谓词的操作方式，这个方式被称为：索引交叉，意思就是说如果两个或多个筛选条件如果采用的索引是交叉进行的，那么使用一个就可以进行查询。 来看个语句就明白了&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT OrderID 
FROM ORDERS
WHERE OrderDate = &#39;1998-01-01&#39; 
AND ShippedDate = &#39;1998-03-05&#39;&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9bc407cf9b8ab45689330c9cfb764165.jpg&quot;&gt;这里我们采用了的谓词连接方式为AND，所以在实际执行的时候，虽然两列都存在非聚集索引，理论都可以使用，但是我们只要选一个最优的索引进行查找，另外一个直接使用书签查找出来就可以。省去了前面介绍的各种神马排序去重….流聚合去重….等等不人性的操作。 看来AND连接符是一个很帅的运算符…所以很多时候我们在尝试写OR的情况下，不如换个思路改用AND更高效。   &lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微软联机丛书&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/ms191158(SQL.90).aspx&quot; target=&quot;_blank&quot;&gt;逻辑运算符和物理运算符引用&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;参照书籍《SQL.Server.2005.技术内幕》系列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt; 此篇文章主要介绍了索引运算的一些方式，主要是描述了我们平常在写语句的时候所应用的方式，并且举了几个例子，算作抛砖引玉吧，其实我们平常所写的语句中无非也就本篇文章中介绍的各种方式的更改，拼凑。而且根据此，我们该怎样建立索引也作为一个指导项。 下一篇我们介绍子查询一系列的内容，有兴趣可提前关注，关于SQL Server性能调优的内容涉及面很广，后续文章中依次展开分析。 有问题可以留言或者私信，随时恭候有兴趣的童鞋加入SQL SERVER的深入研究。共同学习，一起进步。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81193-13e555725.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81193-13e555725.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列基础篇（并行运算总结篇二）</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/81186/&quot; target=&quot;_blank&quot;&gt;上一篇文章我们介绍了查看查询计划的并行运行方式&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;本篇我们接着分析SQL Server的并行运算。&lt;/p&gt;
&lt;p&gt;闲言少叙，直接进入本篇的正题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;同前几篇一样，基于SQL Server2008R2版本，利用微软的一个更简洁的案例库（Northwind）进行解析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;内容&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;文章开始前，我们先来回顾上一篇中介绍的并行运算，来看文章最后介绍的并行运算语句：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT B1.[KEY],B1.DATA,B2.DATA 
FROM BigTable B1 JOIN BigTable2 B2
ON B1.[KEY]=B2.[KEY]
WHERE B1.DATA&amp;lt;100&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1626f90d3b4dabe350f056ff7212e1ad.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面是详细的执行计划，从右边依次向左执行，上图中有一个地方很有意思，就是在聚集索引扫描后获取的数据，又重新了使用了一次重新分配任务的过程&lt;/p&gt;
&lt;p&gt;（Repartition Streams），就是上图的将获取的100行数据重新分配到并行的各个线程中。&lt;/p&gt;
&lt;p&gt;其实这里本可以直接将索引扫描出来的100行数据直接扔到嵌套循环中执行。它这里又重新分配任务的目的就是为了后面嵌套循环的并行执行，最大限度的利用硬件资源！&lt;/p&gt;
&lt;p&gt;但这样做又带了另一个弊端就是执行完嵌套循环之后，需要将结果重新汇总，就是下面的（Gather Sreams）运算符。&lt;/p&gt;
&lt;p&gt;我们来看看该语句如果不并行的执行计划&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT B1.[KEY],B1.DATA,B2.DATA 
FROM BigTable B1 JOIN BigTable2 B2
ON B1.[KEY]=B2.[KEY]
WHERE B1.DATA&amp;lt;100
option(maxdop 1)&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/2979eea75768313c334555ad258aa585.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这才是正宗的串行执行计划。&lt;/p&gt;
&lt;p&gt;和上面的并行执行计划相比较，你会发现SQL Server充分利用硬件资源而形成的并行计划，是不是很帅！&lt;/p&gt;
&lt;p&gt;如果还没感觉到SQL Server并行执行计划的魅力，我们再来举个例子，看如下语句&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT BIG_TOP.[KEY],BIG_TOP.DATA,B2.DATA
FROM 
(
   SELECT TOP 100 B.[KEY],B.DATA
   FROM BigTable B
   ORDER BY DATA
) BIG_TOP,
BigTable2 B2
WHERE BIG_TOP.[KEY]=B2.[KEY]&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;先来分析下上面的语句，这个语句我们在外表中加入了TOP 100…..ORDER BY DATA关键字，这个关键字是很有意思….&lt;/p&gt;
&lt;p&gt;因为我们知道这个语句是获取根据DATA关键字排序，然后获取出前100行的意思…&lt;/p&gt;
&lt;p&gt;1、根据DATA排序…..丫的多线程我看你怎么排序？每个线程排列自己的？那你排列完了在汇聚在一起…那岂不是还得重新排序！！&lt;/p&gt;
&lt;p&gt;2、获取前100行数据，丫多线程怎么获取？假如我4个线程扫描每个线程获取25条数据？这样出来的结果对嘛？&lt;/p&gt;
&lt;p&gt;3、我们的目标是让外表和上面的100行数据还要并行嵌套循环连接，因为这样才能充分利用资源，这个怎么实现呢？&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;上面的这些问题，我们来看强大的SQL Server将为我们怎样生成强悍的执行计划&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1e79b272b6e8f5452bcc8fac03e5b1b2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面的执行计划已经解决了我们以上所述的三个问题，我们依次来分析下，这几个问题的解决方法&lt;/p&gt;
&lt;p&gt;第一个问题，关于并列排序问题&lt;/p&gt;
&lt;p&gt;首选根据聚集索引扫描的方式采用并列的方式从表中获取出数据&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/487dc679d9ad8caa187844b2dc0115d1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后，在并行的根据各个线程中的数据进行排序，获取前几列值，我们知道，我们的目标获取的是前100行，它这里获取的方式是冗余获取，也就是说每个线程各自排序自己的数据&lt;/p&gt;
&lt;p&gt;然后获取出前面的数据，通过循环赛的方式进行交换，获取出一部分数据&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6ca7f892d188fd3cce023fa3163eee0f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;第二个问题，关于并列获取前100行数据问题&lt;/p&gt;
&lt;p&gt;我们知道要想获取前100行数据，就必须将各个线程的数据汇总到一起，然后通过比较获取前100行数据，这是必须的，于是在这一步里SQL Server又的重新将数据汇总到一起&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6fe31a22e4c6fcf8d318f445f31486c1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;第三个问题，下一步需要将这100行数据和外表进行连接，获取出结果，这里面采用的嵌套循环连接的方式，为了充分利用资源，提升性能，SQL Server又不得不将这100行数据均分到各个线程中去执行，所以这里又采用了一个拆分任务的运算符分发流（Distribute Sreams）任务&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/20cc1cb7827ae5132d5df187b6dfbe95.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;所以经过此步骤又将系统的硬件资源充分利用起来了，然后下一步同样就是讲过嵌套循环进行关联获取结果，然后再重新将结果汇总，然后输出&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1036eb78eb39f30ec963d5eee2a9403d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们可以看到上面的一个流程，SQLServer经过了：先拆分（并行扫描）——》再并行（获取TOP 100….）——》再拆分(为了并行嵌套循环)——》再并行（为了合并结果）&lt;/p&gt;
&lt;p&gt;总之，SQL Server在运行语句的时候，经过各种评估之后，利用各种拆分、各种汇总，目的就是充分的利用硬件资源，达到一个性能最优化的方式！这就是SQL Server并行运算的精髓。&lt;/p&gt;
&lt;p&gt;当然凡事有利就有弊，我们通过这条语句来对比一下串行和并行在SQL Server中的优劣项&lt;/p&gt;
&lt;p&gt;一下是串行执行计划：&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT BIG_TOP.[KEY],BIG_TOP.DATA,B2.DATA
FROM 
(
   SELECT TOP 100 B.[KEY],B.DATA
   FROM BigTable B
   ORDER BY DATA
) BIG_TOP,
BigTable2 B2
WHERE BIG_TOP.[KEY]=B2.[KEY]
option(maxdop 1)&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/bfbca3d3053c9945a90891abf2dcaf2a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;串行执行的执行计划：简单、大气、没有复杂的各种拆分、各种汇总及并行。&lt;/p&gt;
&lt;p&gt;我们来比较下两者的不同项，先比较一个T-SQL语句的各个参数值：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1abd65bdb45130ef3a1e60a5667897e0.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/244b04328ef4be0ca04e591295a715f7.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;前者是串行、后者是并行&lt;/p&gt;
&lt;p&gt;串行编译耗费CPU：2、并行编译耗费CPU:10&lt;/p&gt;
&lt;p&gt;串行编译耗费内存：184、并行编译耗费内存：208&lt;/p&gt;
&lt;p&gt;串行编译耗时：2、并行编译耗时：81&lt;/p&gt;
&lt;p&gt;上面是采取并行的缺点：1、更消耗CPU、2、编译更消耗内存、3、编译时间更久&lt;/p&gt;
&lt;p&gt;我们来看一下并行的优点：&lt;/p&gt;
&lt;p&gt;上图中串行内存使用（1024），并行内存（448）&lt;/p&gt;
&lt;p&gt;优点就是：并行执行消耗内存更小&lt;/p&gt;
&lt;p&gt;当然还有一个更重要的优点：执行速度更快！&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/585e2d4fa48d56d564661000ab8475e0.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9ab8bc0581a6de1ba794097455ec9ab3.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;采用并行的执行方式，执行时间从218毫秒提升到187毫秒！数据量少，我机器性能差所以提升不明显！&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;在并行运算执行过程中，还有一种运算符经常遇到：位图运算符，这里我们顺带也介绍一下&lt;/p&gt;
&lt;p&gt;举个例子：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT B1.[KEY],B1.DATA,B2.[KEY] 
FROM BigTable B1 JOIN BigTable2 B2
ON B1.DATA=B2.DATA
WHERE B1.[KEY]&amp;lt;10000&lt;/pre&gt;
&lt;p&gt;这里我们获取大表中Key列小于10000行的数据。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/536ba709ea5f347994d2ff0bbcb80035.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上述的执行语句，就引入了位图计算。&lt;/p&gt;
&lt;p&gt;其实位图计算的目标很简单：&lt;strong&gt;提前过滤&lt;/strong&gt;，因为我们的语句中要求获取的结果项比较多10000行数据，在我们后面的线程中采用的并行扫描的方式获取出数据。由于数据量比较多的原因，各个线程在执行的过程中获取完数据的时间不同，为了避免因某个线程执行速度缓慢，导致整体堵塞，索引引入了位图运算，先将获取出来的部分结果过滤输出到前面的哈希匹配，完整执行。&lt;/p&gt;
&lt;p&gt;关于位图运算符更多详细可参照：&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/bb510541&quot;&gt;http://msdn.microsoft.com/zh-cn/library/bb510541&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此篇文章先到此吧，本篇主要是上一篇并行运算的一个延续，两篇文章介绍了SQL Server中关于并行运算的原理和使用方式，关于并行运算这块就到这吧，下一篇我们补充SQL Server中关于索引的利用方式和动态索引的内容，关于索引我相信很多了解数据库产品的人都熟悉，但是SQL Server中一些语句利用索引的方式可能还不清楚，我们下一篇分析这块，借此了解索引的建立方式和优化技巧，有兴趣可提前关注，关于SQL Server性能调优的内容涉及面很广，后续文章中依次展开分析。&lt;/p&gt;
&lt;p&gt;有问题可以留言或者私信，随时恭候有兴趣的童鞋加入SQL SERVER的深入研究。共同学习，一起进步。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81189-e246d0739.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81189-e246d0739.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列基础篇（并行运算总结）</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上三篇文章我们介绍了&lt;a href=&quot;http://blog.jobbole.com/81176/&quot; target=&quot;_blank&quot;&gt;查看查询计划的方式&lt;/a&gt;，以及一些&lt;a href=&quot;http://blog.jobbole.com/81182/&quot; target=&quot;_blank&quot;&gt;常用的连接运算符&lt;/a&gt;、&lt;a href=&quot;http://blog.jobbole.com/81184/&quot; target=&quot;_blank&quot;&gt;联合运算符的优化技巧&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;本篇我们分析SQL Server的并行运算，作为多核计算机盛行的今天，SQL Server也会适时调整自己的查询计划，来适应硬件资源的扩展，充分利用硬件资源，最大限度的提高性能。&lt;/p&gt;
&lt;p&gt;闲言少叙，直接进入本篇的正题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;同前几篇一样，基于SQL Server2008R2版本，利用微软的一个更简洁的案例库（Northwind）进行解析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、并行运算符&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在我们日常所写的T-SQL语句，并不是所有的最优执行计划都是一样的，其最优的执行计划的形成需要多方面的评估才可以，大部分根据SQL Server本身所形成的统计信息，然后对形成的多个执行计划进行评估，进而选出最优的执行方式。&lt;/p&gt;
&lt;p&gt;在SQL Server根据库内容形成的统计信息进行评估的同时，还要参照当前运行的硬件资源，有时候它认为最优的方案可能当前硬件资源不支持，比如：内存限制、CPU限制、IO瓶颈等，所以执行计划的优劣还要依赖于底层硬件。&lt;/p&gt;
&lt;p&gt;当SQL Server发现某个处理的数据集比较大，耗费资源比较多时，但此时硬件存在多颗CPU时，SQL Server会尝试使用并行的方法，把数据集拆分成若干个，若干个线程同时处理，来提高整体效率。&lt;/p&gt;
&lt;p&gt;在SQL Server中可以通过如下方法，设置SQL Server可用的CPU个数&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c2f0bdc73b4c0b418cddf36583eae542.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;默认SQL Server会自动选择CPU个数，当然不排除某些情况下，比如高并发的生产环境中，防止SQL Server独占所有CPU，所以提供了该配置的界面。&lt;/p&gt;
&lt;p&gt;还有一个系统参数，就是我们熟知的MAXDOP参数，也可以更改此系统参数配置，该配置也可以控制每个运算符的并行数（记住：这里是每个运算符的，而非全部的），我们来查看该参数&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/bb02def16855f529a1a109601c7301de.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个并行运算符的设置数，指定的是每个运算符的最大并行数，所以有时候我们利用查看系统任务数的DMV视图sys.dm_os_tasks来查看，很可能看到大于并行度的线程数据量，也就是说线程数据可能超过并行度，原因就是两个运算符重新划分了数据，分配到不同的线程中。&lt;/p&gt;
&lt;p&gt;这里如没特殊情况的话，建议采用默认设置最佳。&lt;/p&gt;
&lt;p&gt;我们举一个分组的例子，来理解并行运算&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/15f5fa26bffbcf5469f2e5f3e84b0e8a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;采用并行运算出了提升性能还有如下几个优点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不依赖于线程的数量，在运行时自动的添加或移除线程，在保证系统正常吞吐率的前提下达到一个性能最优值&lt;/li&gt;
&lt;li&gt;能够适应倾斜和负载均衡，比如一个线程运行速度比其它线程慢，这个线程要扫描或者运行的数量会自动减少，而其它跑的快的线程会相应提高任务数，所以总的执行时间就会平稳的减少，而非一个线程阻塞整体性能。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面我们来举个例子，详细的说明一下&lt;/p&gt;
&lt;p&gt;并行计划一般应用于数据量比较大的表，小表采用串行的效率是最高的，所以这里我们新建一个测试的大表，然后插入部分测试数据，我们插入250000行，整体表超过6500页，脚本如下&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;--新建表，建立主键，形成聚集索引
CREATE TABLE BigTable
(
   [KEY] INT,
   DATA INT,
   PAD CHAR(200),
   CONSTRAINT [PK1] PRIMARY KEY ([KEY])
)
GO
--批量插入测试数据250000行
SET NOCOUNT ON 
DECLARE @i INT
BEGIN TRAN
    SET @i=0
    WHILE @i&amp;lt;250000
    BEGIN
       INSERT BigTable VALUES(@i,@i,NULL)
       SET @i=@i+1
       IF @i%1000=0
       BEGIN
          COMMIT TRAN
          BEGIN TRAN
       END
END    
COMMIT TRAN
GO&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;我们来执行一个简单查询的脚本&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT [KEY],[DATA]
FROM BigTable&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8d7127de51524ed8295a0571fa7a9ff7.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里对于这种查询脚本，没有任何筛选条件的情况下，没必要采用并行扫描，因为采用串行扫描的方式得到数据的速度反而比并行扫描获取的快，所以这里采用了clustered scan的方式，我们来加一个筛选条件看看&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT [KEY],[DATA]
FROM BigTable
WHERE DATA&amp;lt;1000&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/efeac598ce77d13a3421d821357576fa.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;对于这个有筛选条件的T-SQL语句，这里SQL Server果断的采用的并行运算的方式，聚集索引也是并行扫描，因为我电脑为4个逻辑CPU(其实是2颗物理CPU，4线程)，所以这里使用的是4线程并行扫描四次表，每个线程扫描一部分数据，然后汇总。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/18bea2d366c1ce1ce047e3fdf9e13610.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里总共用了4个线程，其中线程0为调度线程，负责调度所有的其它线程，所以它不执行扫描，而线程1到线程4执行了这1000行的扫描！当然这里数据量比较少，有的线程分配了0个任务，但是总得扫描次数为4次，所以这4个线程是并行的扫描了这个表。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;可能上面获取的结果比较简单，有的线程任务还没有给分配满，我们来找一个相对稍复杂的语句&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT MIN([DATA])
FROM BigTable&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/49bfae5d5064e6e4c7b77f1537f3e719.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个执行计划挺简单的，我们依次从右边向左分析，依次执行为：&lt;/p&gt;
&lt;p&gt;4个并行聚集索引扫描——&amp;gt;4个线程并行获取出前当前线程的最小数——&amp;gt;执行4个最小数汇总——&amp;gt;执行流聚合获取出4个数中的最小值——&amp;gt;输出结果项。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c6c10f5c90a956c8ffb12e7a799a5335.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后4个线程，每个线程一个流聚合获取当前线程的最小数&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/887a15feab88feb064098e28350e64da.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后，将这个四个最小值经过下一个“并行度”的运算符汇聚成一个表&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1d2e19d10e78e99e0926ff42fde59075.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后下一个就是流聚合，从这个4行数据中获取出最小值，进行输出，关于流聚合我们上一篇文章中已经介绍&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ab028e94471985a779f5b7b5ee102074.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;以上就一个一个标准的多线程并行运算的过程。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;上面的过程中，因为我们使用的并行聚集索引扫描数据，4个线程基本上是平均分摊了任务量，也就是说每个线程扫描的数据量基本相等，下面我们将一个线程使其处于忙碌状态，看看SQL Server会不会将任务动态的平摊到其它几个不忙碌的线程上。&lt;/p&gt;
&lt;p&gt;我们在来添加一个大数据量表，脚本如下&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT [KEY],[DATA],[PAD] 
INTO BigTable2
FROM BigTable&lt;/pre&gt;
&lt;p&gt;我们来写一个大量语句的查询，使其占用一个线程，并且我们这里强制指定只用一个线程运行&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT MIN(B1.[KEY]+B2.[KEY]) 
FROM BigTable B1 CROSS JOIN BigTable2 B2
OPTION(MAXDOP 1)&lt;/pre&gt;
&lt;p&gt;以上代码想跑出结果，就我这个电脑配置估计少说五分钟以上，并且我们还强行串行运算，速度可想而知，&lt;br&gt;
我们接着执行上面的获取最小值的语句，查看执行计划&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT MIN([DATA])
FROM BigTable&lt;/pre&gt;
&lt;p&gt;我们在执行计划中，查看到了聚集索引扫描的线程数量&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c97eacdc3b1747bbaf7d9bec918c9988.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以看到，线程1已经数量减少了近四分之的数据，并且从线程1到线程4，所扫描的数据量是依次增加的。&lt;/p&gt;
&lt;p&gt;我们上面的语句很明确的指定了MAXDOP为1，理论上讲只可能会影响一个线程，为什么这几个线程都影响呢？其实这个原因很简单，我的电脑是物理CPU只有两核，所谓的线程数只是超线程，所以非传统意义上的真正的4核数，所以线程之间是互相影响的。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;我们来看一个并行连接操作的例子，我们查看并行嵌套循环是怎样利用资源的&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT B1.[KEY],B1.DATA,B2.DATA 
FROM BigTable B1 JOIN BigTable2 B2
ON B1.[KEY]=B2.[KEY]
WHERE B1.DATA&amp;lt;100&lt;/pre&gt;
&lt;p&gt;上面的语句中，我们在BigTable中Key列存在聚集索引，而查询条件中DATA列不存在，所以这里肯定为聚集索引扫描，对数据进行查找&lt;/p&gt;
&lt;p&gt;来看执行计划&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/42b6fa34356413c5640274ddd1c68763.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们依次来分析这个流程，结合文本的执行计划分析更为准确，从右边依次向左分析&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/aa1bbf8be5c6e789049bf9672b3d3ab7.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;第一步，就是利用全表通过聚集索引扫描获取出数据，因为这里采用的并行的聚集索引扫描，我们来看并行的线程数和扫描数&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/10bf43a9be037d77d11d2925ef16517e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;四个线程扫描，这里线程3获取出数据100行数据。&lt;/p&gt;
&lt;p&gt;然后将这100行数据，重新分配线程，这里每个线程平均分配到25行数据&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3c082a7f60509cb026af80e202bd4420.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;到此，我们要获取的结果已经均分成4个线程共同执行，每个线程分配了25行数据，下一步就是交给嵌套循环连接了，因为我们上面的语句中需要从BigTable2中获取数据行，所以这里选择了嵌套循环，依次扫描BigTable2获取数据。&lt;/p&gt;
&lt;p&gt;关于嵌套循环连接运算符，可以参照我的第二篇文章。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/527240fbb764e3637717a2ef2e55a13b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们知道这是外表的循环数，也就是说这里会有4个线程并行执行嵌套循环。如果每个线程均分25行，数据那么内部表就要执行&lt;/p&gt;
&lt;p&gt;4*25=100次。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ade88dfef52c75f3dc22799955d7b481.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;然后，执行完，嵌套扫描获取结果后，下一步就是，将各个线程执行的结果通过并行运算符汇总，然后输出&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9111291744a2a80ea310ab4bc1dfca9d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上述过程就是一个并行嵌套循环的执行流程。充分利用了四核的硬件资源。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微软联机丛书&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/ms191158(SQL.90).aspx&quot; target=&quot;_blank&quot;&gt;逻辑运算符和物理运算符引用&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;参照书籍《SQL.Server.2005.技术内幕》系列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此篇文章先到此吧，文章短一点，便于理解掌握，后续关于并行操作还有一部分内容，后续文章补充吧，本篇主要介绍了查询计划中的并行运算符，下一篇我们接着补充一部分SQL Server中的并行运算，然后分析下我们日常所写的增删改这些操作符的优化项，有兴趣可提前关注，关于SQL Server性能调优的内容涉及面很广，后续文章中依次展开分析。&lt;/p&gt;
&lt;p&gt;有问题可以留言或者私信，随时恭候有兴趣的童鞋加入SQL SERVER的深入研究。共同学习，一起进步。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81186-49d084331.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81186-49d084331.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列基础篇（联合运算符总结）</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上两篇文章我们介绍了&lt;a href=&quot;http://blog.jobbole.com/81176/&quot; target=&quot;_blank&quot;&gt;查看查询计划的方式&lt;/a&gt;，以及一些&lt;a href=&quot;http://blog.jobbole.com/81182/&quot; target=&quot;_blank&quot;&gt;常用的连接运算符的优化技巧&lt;/a&gt;，本篇我们总结联合运算符的使用方式和优化技巧。&lt;/p&gt;
&lt;p&gt;废话少说，直接进入本篇的主题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;基于SQL Server2008R2版本，利用微软的一个更简洁的案例库（Northwind）进行解析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、联合运算符&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所谓的联合运算符，其实应用最多的就两种：UNION ALL和UNION。&lt;/p&gt;
&lt;p&gt;这两个运算符用法很简单，前者是将两个数据集结果合并，后者则是合并后进行去重操作，如果有过写T-SQL语句的码农都不会陌生。&lt;/p&gt;
&lt;p&gt;我们来分析下这两个运算符在执行计划中的显示，举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT FirstName+N&#39;&#39;+LastName,City,Country FROM Employees
UNION ALL
SELECT ContactName,City,Country FROM Customers&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a573e1f1c88074e1831001ecce1cbd97.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;就是上面这个图标了，这就是UNION ALL联合运算符的图标。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0d877d98b1c0d32a7df2a9e13bfe632d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这个联合运算符很简单的操作，将两个数据集合扫描完通过联合将结果汇总。&lt;/p&gt;
&lt;p&gt;我们来看一下UNION 这个运算符，例子如下&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;select City,Country from Employees
UNION
SELECT City,Country FROM Customers&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3ad0527989de6b497b6dbc9c1bf06240.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们可以看到，UNION 运算符是在串联运算符之后发生了一个Distinct Sort排序操作，经过这个操作会将结果集合中的重复值去掉。&lt;/p&gt;
&lt;p&gt;我们一直强调：大数据表的排序是一个非常耗资源的动作！&lt;/p&gt;
&lt;p&gt;所以，到这里我们已经找到了可优化的选项，去掉排序，或者更改排序方式。&lt;/p&gt;
&lt;p&gt;替换掉Distinct Sort排序操作的方式就是哈序聚合。Distinct Sort排序操作需要的内存和去除重复之前数据集合的数据量成正比，而哈希聚合需要的内存则是和去除重复之后的结果集成正比！&lt;/p&gt;
&lt;p&gt;所以如果数据行中重复值很多，那么相比而言通过哈希聚合所消耗的内存会少。&lt;/p&gt;
&lt;p&gt;我们来举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;select ShipCountry from Orders
UNION
SELECT ShipCountry FROM Orders&lt;/pre&gt;
&lt;p&gt;这个例子其实没啥用处，这里就是为了演示，我们来看一下结果&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/10a6f9571e62d7962386b8e51325f75e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们知道，这张表里这个ShipCountry是存在大面积重复值的，所以采用了哈希匹配来去重操作是最优的方式。&lt;/p&gt;
&lt;p&gt;其实，相比哈希匹配连接还有一种更轻量级的去重的连接方式：合并连接&lt;/p&gt;
&lt;p&gt;上一篇我已经分析了这个连接方法，用于两个数据集的连接方式，这里其实类似，应用前都必须先将原结果集合排序！&lt;/p&gt;
&lt;p&gt;我们知道优化的方式可以采用建立索引来提高排序速度。&lt;/p&gt;
&lt;p&gt;我们来重现这种去重方式，我们新建一个表，然后建立索引，代码如下&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;--新建表
SELECT EmployeeID,FirstName+N&#39; &#39;+LastName AS ContactName,City,Country
INTO NewEmployees
FROM Employees
GO
--添加索引
ALTER TABLE NewEmployees ADD CONSTRAINT PK_NewEmployees PRIMARY KEY(EmployeeID)
CREATE INDEX ContactName ON NewEmployees(ContactName)
CREATE INDEX ContactName ON CUSTOMERS(ContactName)
GO
--新建查询，这里一定要加上一个显示的Order by才能出现合并连接去重
SELECT ContactName FROM NewEmployees
UNION ALL
SELECT ContactName FROM Customers
ORDER BY ContactName&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/17ddcf5853ea7eb207bab193975799d1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;我们采用索引扫描的方式可以避免显式的排序操作。&lt;/p&gt;
&lt;p&gt;我们将UNION ALL改成UNION，该操作将会对两个数据集进行去重操作。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;--新建查询，这里一定要加上一个显示的Order by才能出现合并连接去重
SELECT ContactName FROM NewEmployees
UNION 
SELECT ContactName FROM Customers
ORDER BY ContactName&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/8be518bdedfb55620994cc6a9257510e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里我们知道UNION操作会对结果进行去重操作，上面应用了流聚合操作，流聚合一般应用于分组操作中，当然这里用它进行了分组去重。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;在我们实际的应用环境中，最常用的方式还是合并连接，但是有一种情况最适合哈希连接，那就是一个小表和大表进行联合操作，尤其适合哪种大表中存在大量重复值的情况下。&lt;/p&gt;
&lt;p&gt;哈希算法真是个好东西！&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微软联机丛书&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/ms191158(SQL.90).aspx&quot; target=&quot;_blank&quot;&gt;逻辑运算符和物理运算符引用&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;参照书籍《SQL.Server.2005.技术内幕》系列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此篇文章先到此吧，简短一点，便于理解掌握，本篇主要介绍了查询计划中的联合操作运算符，下一篇我们分析SQL Server中的并行运算，在多核超线程云集的今天，来看SQL Server如何利用并行运算来最大化的利用现有硬件资源提升性能，有兴趣可提前关注，关于SQL Server性能调优的内容涉及面很广，后续文章中依次展开分析。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SQL Server这个软件一旦深入进去，你会发现它真的非常深，基本可以用深不见底来描述，如果想研究里面的性能调优这块，可以关注本系列内容，我们一起研究！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;而且到现在还有很多人对SQL Server这套产品有误解，或者说观点有待纠正，以前就遇到过客户直接当我面大谈神马SQL Server导入数据一多就宕机了….&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;神马SQL Server只能做小数据量的应用…神马不如Oracle云云….!!!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;还有一部分童鞋单纯的认为SQL Server是小儿科，没啥技术含量…简单的很….&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关于这些观点，我不想吐槽啥，我只想让那些真正了解SQL Server的朋友一起来为SQL Server证明点什么。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81184-b98707bf0.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81184-b98707bf0.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列基础篇（常用运算符总结）</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.jobbole.com/81176/&quot; target=&quot;_blank&quot;&gt;上一篇我们介绍了如何查看查询计划&lt;/a&gt;，本篇将介绍在我们查看的查询计划时的分析技巧，以及几种我们常用的运算符优化技巧，同样侧重基础知识的掌握。&lt;/p&gt;
&lt;p&gt;通过本篇可以了解我们平常所写的T-SQL语句，在SQL Server数据库系统中是如何分解执行的，数据结果如何通过各个运算符组织形成的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;基于SQL Server2008R2版本，利用微软的一个更简洁的案例库（Northwind）进行解析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、数据连接&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;数据连接是我们在写T-SQL语句的时候最常用的，通过两个表之间关联获取想要的数据。&lt;/p&gt;
&lt;p&gt;SQL Server默认支持三种物理连接运算符：嵌套循环连接、合并连接以及哈希连接。三种连接各有用途，各有特点，不同的场景会数据库会为我们选择最优的连接方式。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;a、嵌套循环连接（nested loops join)&lt;/p&gt;
&lt;p&gt;嵌套循环连接是最简单也是最基础的连接方式。两张表通过关键字进行关联，然后通过双层循环依次进行两张表的行进行关联，然后通过关键字进行筛选。&lt;/p&gt;
&lt;p&gt;可以参照下图进行理解分析&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0874fd611a6f3672c0d2c599d6a28a44.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;其实嵌套扫描是很简单的获取数据的方式，简单点就是两层循环过滤出结果值。&lt;/p&gt;
&lt;p&gt;我们可以通过如下代码加深理解&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;for each row R1 in the outer table
   for each row R2 int the inner table
       if R1 join with R2
       return (R1,R2)&lt;/pre&gt;
&lt;p&gt;举个列子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT o.OrderID
FROM Customers C JOIN Orders O
ON C.CustomerID=O.CustomerID
WHERE C.City=N&#39;London&#39;&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/05f41e19adbfb416d6bcaa2e85419ab9.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;以上这个图标就是嵌套循环连接的图标了。而且解释的很明确。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/70a0b415fcc526028e8e67b7c8d5d546.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这种方法的消耗就是外表和内表的乘积，其实就是我们所称呼的笛卡尔积。所以消耗的大小是随着两张表的数据量增大而增加的，尤其是内部表，因为它是多次重复扫描的，所以我们在实践中的采取的措施就是减少每个外表或者内表的行数来减少消耗。&lt;/p&gt;
&lt;p&gt;对于这种算法还有一种提高性能的方式，因为两张表是通过关键字进行关联的，所以在查询的时候对于底层的数据获取速度直接关乎着此算法的性能，这里优化的方式尽量使用两个表关键字为索引查询，提高查询速度。&lt;/p&gt;
&lt;p&gt;还有一点就是在嵌套循环连接中，在两张表关联的时候，对外表都是有筛选条件的，比如上面例子中【WHERE C.City=N’London’】就是对外表（Customers）的筛选，并且这里的City列在该表中存在索引，所以该语句的两个子查询都为索引查找（Index Seek）。&lt;/p&gt;
&lt;p&gt;但是，有些情况我们的查询条件不是索引所覆盖的，这时候，在嵌套循环连接下的子运算符就变成了索引扫描（Index scan）或者RID查找。&lt;/p&gt;
&lt;p&gt;举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT E1.EmployeeID,COUNT(*)
FROM Employees E1 JOIN Employees E2
ON E1.HireDate&amp;lt;E2.HireDate
GROUP BY E1.EmployeeID&lt;/pre&gt;
&lt;p&gt;以上代码是从职工表中获取出每位职工入职前的人员数。我们看一下该查询的执行计划&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/10c3ce0032fbfdc625752099b274c37e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里很显然两个表的关联通过的是HireDate列进行，而此列又不为索引项所覆盖，所以两张表的获取只能通过全表的聚集索引扫描进行，如果这两张表数据量特别大的话，无疑又是一个非常耗性能的查询。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a56b0b56208dc3a14aac1d54014994c7.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;通过文本可以看出，该T-SQL的查询结果的获取是通过在嵌套循环运算符中，对两个表经过全表扫描之后形成的笛卡儿积进行过滤筛选的。这种方式其实不是一个最优的方式，因为我们获取的结果其实是可以先通过两个表过滤之后，再通过嵌套循环运算符获取结果，这样的话性能会好很多。&lt;/p&gt;
&lt;p&gt;我们尝试改一下这个语句&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT E1.EmployeeID,ECNT.CNT 
FROM Employees E1 CROSS APPLY
(
   SELECT COUNT(*) CNT
   FROM Employees E2
   WHERE E1.HireDate&amp;lt;E2.HireDate
)ECNT&lt;/pre&gt;
&lt;p&gt;通过上述代码查询的结果项，和上面的是一样的，只是我们根据外部表的结果对内部表进行了过滤，这样执行的时候就不需要获取全部数据项了。&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5b4fb491c63a22c116564037f41026c2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们查看下文本执行计划&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b96a531bed7d3f704aef2cbfb74e461a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们比较一下，前后两条语句的执行消耗，对比一下执行效率&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/e02f0191c46caa4f50b9b36dbd090fdd.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/4eb668c160b958ecee8f2ebdea64bebc.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;执行时间从1秒179毫秒减少至93毫秒。效果明显。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ff23cb3cc99abd5b5621a602e8bab060.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/555314ae6b3a71130a35352aec28c4e0.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;对比CPU消耗、内存、编译时间等总体消耗都有所降低，参考上图。&lt;/p&gt;
&lt;p&gt;所以对嵌套循环连接连接的优化方式就是集中在这几点：对两张表数据量的减少、连接关键字上建立索引、谓词查询条件上覆盖索引最好能减少符合谓词条件的记录数。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;b、合并连接(merge join)&lt;/p&gt;
&lt;p&gt;上面提到的嵌套循环连接方式存在着诸多的问题，尤其不适合两张表都是大表的情况下，因为它会产生N多次的全表扫描，很显然这种方式会严重的消耗资源。&lt;/p&gt;
&lt;p&gt;鉴于上述原因，在数据库里又提供了另外一种连接方式：合并连接。记住这里没有说SQL Server所提供的，是因为此连接算法是市面所有的RDBMS所共同使用的一种连接算法。&lt;/p&gt;
&lt;p&gt;合并连接是依次读取两张表的一行进行对比。如果两个行是相同的，则输出一个连接后的行并继续下一行的读取。如果行是不相同的，则舍弃两个输入中较少的那个并继续读取，一直到两个表中某一个表的行扫描结束，则执行完毕，所以该算法执行只会产生每张表一次扫描，并且不需要整张表扫描完就可以停止。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f3b087e8bd1d85315898e22614365d2a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;该算法要求按照两张表进行依次扫描对比，但是有两个前提条件：1、必须预先将两张表的对应列进行排序；2、对两张表进行合并连接的条件必须存在等值连接。&lt;/p&gt;
&lt;p&gt;我们可以通过以下代码进行理解&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;get first row R1 from input1
get first row R2 from input2
while not at the end of either input
begin
     if R1 joins with R2
         begin
              output(R1,R2)
              get next row R2 from input2
         end
     else if R1&amp;lt;R2   
             get next row R1 from input1
          else
             get next row R2 from input2
end&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;合并连接运算符总的消耗是和输入表中的行数成正比的，而且对表最多读取一次，这个和嵌套循环连接不一样。因此，合并连接对于大表的连接操作是一个比较好的选择项。&lt;/p&gt;
&lt;p&gt;对于合并连接可以从如下几点提高性能：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;两张表间的连接值内容列类型，如果两张表中的关联列都为唯一列，也就说都不存在重复值，这种关联性能是最好的，或者有一张表存在唯一列也可以，这种方式关联为一对多关联方式，这种方式也是我们最常用的，比我们经常使用的主从表关联查询；如果两张表中的关联列存在重复值，这样在两表进行关联的时候还需要借助第三张表来暂存重复的值，这第三张表叫做”worktable “是存放在Tempdb或者内存中，而这样性能就会有所影响。所以鉴于此，我们常做的优化方式有：关联连尽量采用聚集索引（唯一性）&lt;/li&gt;
&lt;li&gt;我们知道采用该种算法的前提是，两张表都经过排序，所以我们在应用的时候，最好优先使用排序后的表关联。如果没有排序，也要选择的关联项为索引覆盖项，因为大表的排序是一个很耗资源的过程，我们选择索引覆盖列进行排序性能要远远好于普通列的排序。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;我们来举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT O.CustomerID,C.CustomerID,C.ContactName 
FROM Orders O JOIN Customers C
ON O.CustomerID=C.CustomerID&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/eaf6913315c1808e552750fa6d57385f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们知道这段T-SQL语句中关联项用的是CustomerID，而此列为主键聚集索引，都是唯一的并且经过排序的，所以这里面没有显示的排序操作。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/46062d4dfd905b3a1b6e82b0def2e6f2.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9fc238c29a50d57a0e0e7f76b37bc011.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;而且凡是采用合并连接的所有输出结果项，都是已经经过排序的。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5d237a0209b5507fa45229ee3118b05a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们找一个稍复杂的情况，没有提前排序的利用合并查询的T-SQL&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT O.OrderID,C.CustomerID,C.ContactName
FROM Orders O JOIN Customers C
ON O.CustomerID=C.CustomerID AND O.ShipCity&amp;lt;&amp;gt;C.City
ORDER BY C.CustomerID&lt;/pre&gt;
&lt;p&gt;上述代码返回那些客户的发货订单不在客户本地的。&lt;br&gt;
&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a09453991d584a4363eeed7a7b545b39.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面的查询计划可以看出，排序的消耗总是巨大的，其实我们上面的语句按照逻辑应该是在合并连接获取数据后，才采用显示的按照CustomerID进行排序。&lt;/p&gt;
&lt;p&gt;但是因为合并连接运算符之前本身就需要排序，所以此处SQL Server采取了优先排序的策略，把排序操作提前到了合并连接之前进行，并且在合并连接之后，就不需要在做额外的排序了。&lt;/p&gt;
&lt;p&gt;这其实这里我们要求对查询结果排序，正好也利用了合并连接的特点。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;c、哈希连接(hash join)&lt;/p&gt;
&lt;p&gt;我们分析了上面的两种连接算法，两种算法各有特点，也各有自己的应用场景：嵌套循环连接适合于相对小的数据集连接，合并连接则应对与中型的数据集，但是又有它自己的缺点，比如要求必须有等值连接，并且需要预先排序等。&lt;/p&gt;
&lt;p&gt;那对于大型的数据集合的连接数据库是怎么应对的呢？那就是哈希连接算法的应用场景了。&lt;/p&gt;
&lt;p&gt;哈希连接对于大型数据集合的并行操作上都比其它方式要好很多，尤其适用于OLAP数据仓库的应用场景中。&lt;/p&gt;
&lt;p&gt;哈希连接很多地方和合并连接类似，比如都需要至少一个等值连接，同样支持所有的外连接操作。但不同于合并连接的是，哈希连接不需要预先对输入数据集合排序，我们知道对于大表的排序操作是一个很大的消耗，所以去除排序操作，哈希操作性能无疑会提升很多。&lt;/p&gt;
&lt;p&gt;哈希连接在执行的时候分为两个阶段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;构建阶段&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在构建阶段，哈希连接从一个表中读入所有的行，将等值连接键的行机型哈希话处理，然后创建形成一个内存哈希表，而将原来列中行数据依次放入不同的哈希桶中。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/78c0754b74ad0935ebb38511da47ee40.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;探索阶段&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在第一个阶段完成之后，开始进入第二个阶段探索阶段，该阶段哈希连接从第二个数据表中读入所有的行，同样也是在相同的等值连接键上进行哈希。哈希过程桶上一阶段，然后再从哈希表中探索匹配的行。&lt;/p&gt;
&lt;p&gt;上述的过程中，在第一个阶段的构建阶段是阻塞的，也就是说在，哈希连接必须读入和处理所有的构建输入，之后才能返回行。而且这一过程是需要一块内存存储提供支持，并且利用的是哈希函数，所以相应的也会消耗CPU等。&lt;/p&gt;
&lt;p&gt;并且上述流程过程中一般采用的是并发处理，充分利用资源，当然系统会对哈希的数量有所限制，如果数据量超大，也会发生内存溢出等问题，而对于这些问题的解决，SQL Server有它自身的处理方式。&lt;/p&gt;
&lt;p&gt;我们可通过以下代码进行理解&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;--构建阶段
for each row R1 in the build table
begin
   calculate hash value on R1 join key(s)
   insert R1 into the appropriate hash bucket
end
--探索阶段
for each row R2 in the probe table
begin
   calculate hash value on R2 join key(s)   
   for each row R1 in the corresponding hash bucket
       if R1 joins with R2
          output(R1,R2)
end&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;在哈希连接执行之前，SQL Server会估算需要多少内存来构建哈希表。基本估算的方式就是通过表的统计信息来估算，所以有时候统计信息不准确，会直接影响其运算性能。&lt;/p&gt;
&lt;p&gt;SQL Server默认会尽力预留足够的内存来保证哈希连接成功的构建，但是有时候内存不足的情况下，就必须采取将一小部分的哈希表分配到硬盘中，这里就存入到了tempdb库中，而这一过程会反复多次循环执行。&lt;/p&gt;
&lt;p&gt;举个列子来看看&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT O.OrderID,O.OrderDate,C.CustomerID,C.ContactName
FROM Orders O JOIN Customers C
ON O.CustomerID=C.CustomerID&amp;lt;img alt=&quot;&quot; src=&quot;http://ww1.sinaimg.cn/mw690/69ab9b51gw1en6z7bth1nj20hj05swf5.jpg&quot; /&amp;gt;&lt;/pre&gt;
&lt;p&gt;我们来分析上面的执行语句，上面的执行结果通过CustomerID列进行关联，理论将最合适的应该是采用合并连接操作，但是合并连接需要排序，但是我们在语句中没有指定Order by 选项，所以经过评估，此语句采用了哈希连接的方式进行了连接。&lt;/p&gt;
&lt;p&gt;我们给它加上一个显示的排序，它就选用合并连接作为最优的连接方式&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/aa672a5702c447f7a014cba691f6297b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们来总结一下这个算法的特点&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;和合并连接一样算法复杂度基本就是分别遍历两边的数据集各一遍&lt;/li&gt;
&lt;li&gt;它不需要对数据集事先排序，也不要求上面有什么索引，通过的是哈希算法进行处理&lt;/li&gt;
&lt;li&gt;基本采取并行的执行计划的方式&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是，该算法也有它自身的缺点，因为其利用的是哈希函数，所以运行时对CPU消耗高，同样对内存也比较大，但是它可以采用并行处理的方式，所以该算法用于超大数据表的连接查询上显示出自己独有的优势。&lt;/p&gt;
&lt;p&gt;关于哈希算法在哈希处理过程的时候对内存的占用和分配方式，是有它自己独有哈希方法，比如：左深度树、右深度树、浓密哈希连接树等，这里不做详细介绍了，只需要知道其使用方式就可以了。&lt;/p&gt;
&lt;p&gt;Hash Join并不是一种最优的连接算法，只是它对输入不优化，因为输入数据集特别大，并且对连接符上有没有索引也没要求。其实这也是一种不得已的选择，但是该算法又有它适应的场景，尤其在OLAP的数据仓库中，在一个系统资源相对充足的环境下，该算法就得到了它发挥的场景。&lt;/p&gt;
&lt;p&gt;当然前面所介绍的两种算法也并不是一无是处，在业务的OLTP系统库中，这两种轻量级的连接算法，以其自身的优越性也获得了认可。&lt;/p&gt;
&lt;p&gt;所以这三种算法，没有谁好谁坏，只有合适的场景应用合适的连接算法，这样才能发挥它自身的长处，而恰巧这些就是我们要掌握的技能。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;这三种连接算法我们也可以显示的指定，但是一般不建议这么做，因为默认SQL Server会为我们评估最优的连接方式进行操作，当然有时候它评估不对的时候就需要我们自己指定了，方法如下：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b1a5c562b85195a87687311a2eae36f2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/bda08be3a2a943778bea86fd4323102b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ccd05be9a08c5fed7b8cc0820bb8e42a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二、聚合操作&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;聚合也是我们在写T-SQL语句的时候经常遇到的，我们来分析一下一些常用的聚合操作运算符的特性和可优化项。&lt;/p&gt;
&lt;p&gt;a、标量聚合&lt;/p&gt;
&lt;p&gt;标量聚合是一种常用的数据聚合方式，比如我们写的语句中利用的以下聚合函数：MAX()、MIN()、AVG()、COUNT()、SUM()&lt;/p&gt;
&lt;p&gt;以上的这些数据结果项的输出基本都是通过流聚合的方式产生，并且这个运算符也被称为：标量聚合&lt;/p&gt;
&lt;p&gt;先来看一个列子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT COUNT(*) FROM Orders&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0f4963b4042b2c62b7a6ad061f51a6b6.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面的图表就是流聚合的运算符了。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/dce72423a51e37772c4c6be82f43ba92.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上图还有一个计算标量的运算符，这是因为在流聚合产生的结果项数据类型为Bigint类型，而默认输出为int类型，所以增加了一个类型转换的运算符。&lt;/p&gt;
&lt;p&gt;我们来看一个不需要转换的&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT MIN(OrderDate),MAX(OrderDate) FROM Orders&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1c6a46e576d11b887f98de044df2ed32.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;看一下求平均数的运算符&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT AVG(Freight) FROM Orders&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/040d82d11f03f5b39ac529a78438f85b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;求平均数的时候，在SQL Server执行的时候也给我们添加了一个case when分类，防止分母为0的情况发生。&lt;/p&gt;
&lt;p&gt;我们来看DISTINCT下的情况下，执行计划&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT COUNT(DISTINCT ShipCity) FROM Orders
SELECT COUNT(DISTINCT OrderID) FROM Orders&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/94e9167165195a5173aafce85fe84d13.jpg&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a1fb0e6e0b53a85cd8552c515c548578.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;上面相同的语句，但是产生了不同的执行计划，只是因为发生在不同列的数量汇总上，因为OrderID不存在重复列，所以SQL Server不需要排序直接流聚合就可以产生汇总值，而ShipCity不同它会有重复的值，所以只能经过排序后再流聚合依次获取汇总值。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;其实，流聚合这种算法最常用的方式是分组（GROUP BY）计算，上面的标量计算也是利用这个特性，只不过把整体形成了一个大组进行聚合。&lt;/p&gt;
&lt;p&gt;我么通过如下代码理解&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;clear the current aggredate results
clear the current group by columns
for each input row
begin
    if the input row does not match the current group by columns
    begin
       output the current aggreagate results(if any)
       clear the current aggreagate results
       set the current group by columns to the input row
    end
   update the aggregate results with the input row
end&lt;/pre&gt;
&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;流聚合运算符其实过程很简单，维护一个聚合组和聚合值，依次扫描表中的数据，如果能匹配聚合组则忽略，如果不匹配，则加入到聚合组中并且更新聚合值结果项。&lt;/p&gt;
&lt;p&gt;举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT ShipAddress,ShipCity,COUNT(*)
FROM Orders
GROUP BY ShipAddress,ShipCity&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b2d5176fd70d3bd98facb16af6d93bde.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里使用了流聚合，并且之前先对两列进行排序，排序的消耗总是很大。&lt;/p&gt;
&lt;p&gt;如下代码就不会产生排序&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT CustomerID,COUNT(*)
FROM Orders
GROUP BY CustomerID&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b9b6b10d4b05788e11294b1808770069.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;所以这里我们已经总结出对于流聚合的一种优化方式：尽量避免排序产生，而要避免排序就需要将分组（Group by）字段在索引覆盖范围内。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;b、哈希聚合&lt;/p&gt;
&lt;p&gt;上述的流聚合的方式需要提前排序，我们知道排序是一个非常大的消耗过程，所以不适合大表的分组聚合操作，为了解决这个问题，又引入了另外一种聚合运算：哈希聚合&lt;/p&gt;
&lt;p&gt;所谓的哈希聚合内部的方法和本篇前面提到的哈希连接机制一样。&lt;/p&gt;
&lt;p&gt;哈希聚合不需要排序和过大的内存消耗，并且很容易并行执行计划，利用多CPU同步进行，但是有一个缺点就是：这一过程是阻塞的，也就说哈希聚合不会产生任何结果直到完整的输入。&lt;/p&gt;
&lt;p&gt;所以在大数据表中采用哈希聚合是一个很好的应用场景。&lt;/p&gt;
&lt;p&gt;通过如下代码加深理解&lt;/p&gt;
&lt;div&gt;
&lt;div&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;for each input row
begin
   calculate hash value on group by columns
   check for a matching row in the hash table
   if maching row not found
      insert a new row into the hash table
   else
      update the matching row with the input row
end
--最后输出结果
ouput all rows in the hash table&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;简单点将就是在进行运算匹配前，先将分组列进行哈希处理，分配至不同的哈希桶中，然后再依次匹配，最后才输出结果。&lt;/p&gt;
&lt;p&gt;举个例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT ShipCountry,COUNT(*)
FROM Orders
GROUP BY ShipCountry&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0479f31e25076cbc44ef65acc4e08465.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;这个语句很有意思，我们利用了ShipCountry进行了分组，我们知道该列没有被索引覆盖，按照道理，其实选择流聚合应该也是不错的方式，跟上面我们列举的列子一样，先对这个字段进行排序，然后利用流聚合形成结果项输出。&lt;/p&gt;
&lt;p&gt;但是，为什么这个语句SQL Server为我们选择了哈希匹配作为了最优的算法呢！！！&lt;/p&gt;
&lt;p&gt;我么来比较两个分组字段：ShipCountry和前面的ShipAddress&lt;/p&gt;
&lt;p&gt;前面是国家，后面是地址，国家是很多重复的，并且只有少数的唯一值。而地址就不一样了，离散型的分布，我们知道排序是很耗资源的一件事情，但是利用哈希匹配只需要将不同的列值进行提取就可以，所以相比性能而言，无疑哈希匹配算法在这里是略胜一筹的算法。&lt;/p&gt;
&lt;p&gt;而上面关于这两列内容分布类型SQL Server是怎样知道的？这就是SQL Server的强大的统计信息在支撑了。&lt;/p&gt;
&lt;p&gt;在SQL Server中并不是固定的语句就会形成特定的计划，并且生成的特定计划也不是总是最优的，这和数据库现有数据表中的内容分布、数据量、数据类型等诸多因素有关，而记录这些详细信息的就是统计信息。&lt;/p&gt;
&lt;p&gt;所有的最优计划的选择都是基于现有统计信息来评估，如果我们的统计信息未及时更新，那么所评估出来最优的执行计划将不是最好的，有时候反而是最烂的。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;参考文献&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微软联机丛书&lt;a href=&quot;http://msdn.microsoft.com/zh-cn/library/ms191158(SQL.90).aspx&quot; target=&quot;_blank&quot;&gt;逻辑运算符和物理运算符引用&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;参照书籍《SQL.Server.2005.技术内幕》系列&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此篇文章先到此吧，本篇主要介绍了关于T-SQL语句调优从执行计划下手，并介绍了三个常见的连接运算符和聚合操作符，下一篇将着重介绍我们其它最常用的一些运算符和调优技巧，包括：CURD等运算符、联合运算符、索引运算、并行运算等吧，关于SQL Server性能调优的内容涉及面很广，后续文章中依次展开分析。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81182-05c6e8f15.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81182-05c6e8f15.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>SQL Server调优系列基础篇</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;关于SQL Server调优系列是一个庞大的内容体系，非一言两语能够分析清楚，本篇先就在SQL 调优中所最常用的查询计划进行解析，力图做好基础的掌握，夯实基本功！而后再谈谈整体的语句调优。&lt;/p&gt;
&lt;p&gt;通过本篇了解如何阅读和理解查询计划、并且列举一系列最常用的查询执行运算符。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;技术准备&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;基于SQL Server2008R2版本，利用微软的一个更简洁的案例库（Northwind）进行解析。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、区别不同的运算符&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在所有T-SQL语句在执行的时候，都会将语句分解为一些基本的结构单元，这些结构单元统称为：运算符。每一个运算符都实现一个单独的基本操作，比如：表扫描、索引查找、索引扫描、过滤等。每个运算符可以循环迭代，也可以延续子运算符，这样就可以组成查询树，即：查询计划。&lt;/p&gt;
&lt;p&gt;每个T-SQL语句都会通过多种运算符进行组合形成不同的查询计划，并且这些查询计划对于结果的筛选都是有效的，但在执行的时候，SQL Server的查询优化器会自动为我们找到一个最优的。&lt;/p&gt;
&lt;p&gt;每一个运算符都会有源数据的传入和结果数据的输出，源数据的输入可以来源于其它的运算符或者直接从数据源表中读取，经过本身的运算进行结果的输出。所以每一个运算符是独立的。互不关心的。&lt;/p&gt;
&lt;p&gt;如下例子&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SELECT COUNT(*) FROM Orders&lt;/pre&gt;
&lt;p&gt;此语句会生成两个简单的运算符&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/7a0247d9ef3142d616a23e9995b11524.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;当然，在SQL Server中上述的两个运算符有它自己的表达方式，Count(*)是流聚合运算符进行的。&lt;/p&gt;
&lt;p&gt;每一个运算符会有三个属性影响其执行的效率&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、内存消耗&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所有的运算符都需要一定量的固定内存用以完成执行。当一个T-SQL语句经过编译后生成查询计划后，SQL Server会为认为最优的查询计划尝试去固定内存，目的是为了再次执行的时候不需要再重新申请内存而浪费时间，加快执行速度。&lt;/p&gt;
&lt;p&gt;然后，有一些运算符需要额外的内存空间来存储行数据，这样的运算符所需要的内存量通常就和处理的数据行数成正比。如果出现如下几种情况则会导致内存不能申请到，而影响执行性能&lt;/p&gt;
&lt;p&gt;a、如果服务器上正在执行其它的类似的内存消耗巨大的查询，导致系统内存剩余不足的时候，当前的查询就得延迟进行，直接影响性能。&lt;/p&gt;
&lt;p&gt;b、当并发量过大的的情况下，多个查询竞争有限的内存资源，服务器会适当的控制并发和减少吞吐量来维护机器性能，这时候同样也会影响性能&lt;/p&gt;
&lt;p&gt;c、如果当前申请的到可用内存很少的情况下，SQL Server会在执行过程中和磁盘进行交换数据，通常是使用Tempdb临时库进行操作，而这个过程会很慢。更有甚者，会耗尽Tempdb上的磁盘空间以失败结束&lt;/p&gt;
&lt;p&gt;通常比较消耗内存的运算符主要有分类、哈希连接以及哈希聚合等连接操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、阻断运算和非阻断运算&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所谓阻断和非阻断的区别就是：运算符是否在输入数据的时候能够直接输出结果数据。&lt;/p&gt;
&lt;p&gt;a、当一个运算符在消耗输入行的同时生成输出行，这种运算符就是非阻断式的。&lt;/p&gt;
&lt;p&gt;比如我们经常使用的 Select Top …操作，此操作就是输入行的同时进行输出行操作，所以此操作就是非阻断式的。&lt;/p&gt;
&lt;p&gt;b、当一个运算符所产生的输出结果需要等待所有的数据输入的时候，这个操作运算就是阻断运算的。&lt;/p&gt;
&lt;p&gt;比如上面我们举的例子Count(*)操作，此操作就需要等待所有的数据行输入才能计算出，所以为阻断式运算，另外还有分组计算。&lt;/p&gt;
&lt;p&gt;提示：并不是所有的阻断式操作就需要消耗内存，比如Count(*)就为阻断式，但它不消耗内存，但大部分阻断式操作都会消耗内存。&lt;/p&gt;
&lt;p&gt;在大部分的OLTP系统中，我们要尽量的使用非阻断式操作来代替阻断式操作，这样才能更好的提高相应时间，比如有时候我们用EXISTS子查询来判断，比用SELECT count(*)&amp;gt;0的速度要理想的多。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二、查看查询计划&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;在SQL Server2005版本以上，系统提供了三种展示方式：图像方式、文本方式和XML方式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、图像方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;图像方式这种方式是最为常见的一种方式，清晰、简洁、易懂。非常适合入门级，当然也有它自身的缺点比如复杂的T-SQL语句会产生较大的图像，查看必须收缩操作，比较麻烦。&lt;/p&gt;
&lt;p&gt;SSMS默认给我们提供了查看该查询计划的便捷按钮，需要查看某一条语句的时候，只需要点击上就可以&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d9ddfeef25f1607c7886d8a1064212f5.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们来看一个图像方式展示的查询计划图&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/69cec43308e06e63af202b13f465dc0a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;以上查询语句所产生的实际执行计划，将其分成了各个不同的运算符进行组合，从最右侧的聚集索引扫描（index scan）然后经过一系列的运算符加工形成最左侧的结果输出（select）。&lt;/p&gt;
&lt;p&gt;需要注意的是图中箭头的方向指向的是数据的流向，箭头线的粗细表示了数据量的多少。&lt;/p&gt;
&lt;p&gt;在图形化执行计划中，每一个不同的运算符都有它自身的属性值，我们可以把鼠标移至运算符图标上查看&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/33eb87e7910d7d74402698af9caa5956.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;当然也可以直接在图标上右键，查看属性，进入到属性面板，查看更详细的属性值&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b98f80451b3edbb618164c5ae07488a2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;关于这里面各个运算符的详细指标值，我们在后面介绍，不过这里面有几个关键的值这里可以说是先稍微提一下，关于影响此语句的整体的性能参数，我们可以选择最开始的Select运算符，右键查看属性值&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/41ac1c29c6e9532f27093ec28786134c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;此运算符包含了整条语句的编译时间、所需内存、缓存计划大小、并行度、内存授权、编译执行所需要的参数以及变量值等信息。&lt;/p&gt;
&lt;p&gt;此方式作为一种相对直观的方式展示给用户，所以在我们语句调优中占据很大的指导地位，我们知道一条T-SQL语句可能会生成很多不同的执行计划，而SQL Server会帮助我们选择最优的执行计划，当然我们也可以利用它选择的执行计划去调整自己的语句达到优化的目的。&lt;/p&gt;
&lt;p&gt;鉴于以上目标，SSMS为我们提供了“评估执行计划”选项，此选项只为评估指导使用，并未实际执行，所以它不包含实际行等具体信息&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5b2a274822fdcc5a4a951a17e5e9dba1.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2、文本方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此方式在SSMS中默认没有提供快捷键，我们需要自己用语句开启，开启的方式有两种&lt;/p&gt;
&lt;p&gt;a、只开启执行计划，不包括详细的评估值&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SET SHOWPLAN_TEXT ON&lt;/pre&gt;
&lt;p&gt;b、开启所有的执行计划明细，包括各个属性的评估值&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SET SHOWPLAN_ALL ON&lt;/pre&gt;
&lt;p&gt;文本方式展现的方式，没有了明确的箭头指示，改用竖线（|）标示子运算符和当前运算的子父关系。并且数据流方向都是从子运算符流向父运算符的，虽然文本展现方式不够直观，但是如果掌握了文本的阅读方式，此方式会更易阅读，尤其在涉及很大的大型计划的时候，此方式更容易保存、处理、搜索和比较。&lt;/p&gt;
&lt;p&gt;我们来看一个列子&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/bf6240c7315f2be978d4250f41ff2268.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;此种方式输出的形式为文本方式，我们可以拷贝至文本编辑器中分析，方便于查找分析等操作&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/45ba5b511e44b6fa9274568e0cb29146.jpg&quot;&gt; 以上是文本查询计划的分析方式，简单点的就是从最里面的运算符开始执行，数据流方向也是依次从子运算符流向父运算符。&lt;/p&gt;
&lt;p&gt;上面的方式看起来有点图像方式，分析起来简单更易用。但是或许缺少的是每个运算符的属性运算信息，我们通过b方法里来查看明细&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/085fbae0143af20ed9a12583119892c2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;利用此方式可以直观的分析出每个运算符操作的属性评估值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3、XML方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;XML展现查询计划的方式是SQL Server2005中新加入的功能，此方式结合了文本方式和图形计划方式的优点。利用XML元素的方式展现查询计划。&lt;/p&gt;
&lt;p&gt;更主要的特点是利用XML方式是一种规范的方式，可以利用编程的方式进行标准XML操作，利于查询。并且在SQL Server2005中还加入的XML的数据类型，并且内置了XQuery功能进行查询。此方式尤其对与超大型的查询计划查看非常的方便。&lt;/p&gt;
&lt;p&gt;通过以下语句开启&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;SET STATISTICS XML ON&lt;/pre&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f9b5a64352f5f92f7e09d7146674bd46.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们可以点击输出的XML进行查看&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f7666d75f178b2e7872f91308fe64e3d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;XML方式展现了非常详细的查询计划信息，我们可以简单的分析下&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;StmtSimple：描述了T-SQL的执行文本，并且详细分析了该语句的类型，以及各个属性的评估值。&lt;/li&gt;
&lt;li&gt;StatementSetOptions：描述该语句的各种属性值的Set值&lt;/li&gt;
&lt;li&gt;QueryPlan：是详细的执行计划，包括执行计划的并行的线程数、编译时间、内存占有量等&lt;/li&gt;
&lt;li&gt;OutputList：输出参数列表&lt;/li&gt;
&lt;li&gt;在中间这部分就是具体的不同的执行运算符的信息了，并且包括详细的预估值等&lt;/li&gt;
&lt;li&gt;ParameterList：输出参数列表&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;XML方式提供的信息是最为全面的，并且在SQL Server内部存储的查询计划类型也为XML数据类型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三、分析查询计划&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;当我们拿到一个语句的查询计划，我们应该会分析里面的执行计划的含义，以及各个运算符的属性值，学会如何调整各个运算符的属性值来整体的提高该语句的运行效率。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1、扫描以及查找&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于扫描（scan）和查找（seek）这两种方式是数据库里面从基础数据表里获取的数据的基本方式。&lt;/p&gt;
&lt;p&gt;a、当一张表为堆表（没有任何索引）的时候或者获取的数据列不存在任何索引来供查找，此种数据的获取只能通过全表扫描过滤获取，如果存在索引项会通过索引项的扫描来获取数据，提高获取数据的速度。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ef796e7e79e2bb244d9de3c14d503077.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3c83430dbd1ed96aeb395cae8dc170dd.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;该方法是最为简单的获取数据的方式&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ba8c7ba0bfb9dd6e7bd5a95b906db01f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;b、如果当前搜寻的数据行存在索引项，那么会采取索引查找（seek）进行数据检索。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5bc4cb43325dff2280546bf351a5722d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;该条语句就是执行的索引查找，因为在Orders表中的OrderDate列存在非聚集索引项。这里顺便提一下如果引入静态变量，SQL Server会自动参数化该值，目的是为了减少编译次数，重复利用执行计划。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1013258f6d033168e3d86fc4dbab9d6d.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;由于查找只是搜寻符合条件的这些页进行输出操作，所以查找效率只和符合条件的行数、页数成正比，和整个表中的总行数没有关系。&lt;/p&gt;
&lt;p&gt;c、当所选的索引列不包含输出列的时候，也就是说要筛选出的列项不为索引所覆盖，对于这种情况又引出了另外一种查找方式&lt;/p&gt;
&lt;p&gt;书签查找（Bookmark Lookup）&lt;/p&gt;
&lt;p&gt;其实该方式是扫描和查找之间的一个折中方式，我们知道，如果通过聚集索引扫描，则会获取所有的列，但是这涉及表中的每一行数据，影响性能，相反如果只是通过聚集索引方式进行查找，则有一些列不能获取得到，如果这些列正是我们需要的，这就是不准确的，所以，鉴于此，引入了折中的方式：书签查找（Bookmark Lookup)&lt;/p&gt;
&lt;p&gt;简单点讲：书签查找就是通过索引页节点数据查找相关的列数据。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d0e8879ecc4ac6cf213b0a1fd786b61c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们来看一个具体的查询列子&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/48252f25ec3834f1f1f15afe7850ad2b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;这里需要解释一下，在SQL Server2005 SP2版本以上，书签查找也被称为键查找，其实是一个概念。&lt;/p&gt;
&lt;p&gt;这种方式有一些弊端，就是在进行书签查找的时候，如果通过非聚集索引的叶节点查找到聚集索引数据，这种情况通过聚集索引能够快速的获取到数据，如果非聚集索引关键字和聚集索引关键字不存在任何关联，这种情况下，书签查找就会执行随机的I/O操作到聚集索引或者堆表中，而这种情况是非常耗时的，相比而言顺序I/O扫描都要比随机I/O扫描性能好很多。&lt;/p&gt;
&lt;p&gt;为了解决上面所述的问题，在SQL Server2005以后的版本中，在创建index的时候引入了INCLUDE关键字。通过创建索引的时候，直接将书签要查找的项直接包含进去，这样就不会发生随机I/O操作。此种方式的缺点会造成索引存储增大一部分，但相比带来的好处，基本可以忽略不计。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a60f7d60c3a7299cd68770ec28e9dd72.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结语&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此篇文章先到此吧，本篇主要介绍了关于T-SQL语句调优从执行计划该如下下手，并介绍了几个常见的简单运算符，下一篇将着重介绍我们最常用的一些运算符和调优技巧，包括：连接运算符、聚合运算符、联合运算符、并行运算等吧，关于SQL Server性能调优的内容涉及面很广，后续文章中依次展开分析。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81176-ff22b67f4.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81176-ff22b67f4.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>实现键值对存储（五）：哈希表实现</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/75842/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（0）：目录&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/75844/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（1）：什么是键值对存储，为什么要实现它&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/77750/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（2）：以现有键值对存储为模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/78869/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（3）：Kyoto Cabinet和LevelDB的架构比较分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/81083/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（4）：API设计&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在本文中，我将会研究C++中哈希表的实际实现以理解其瓶颈。哈希函数是CPU密集型的并且应该维持而优化。然而，大部分哈希表的内部机制只关心内存效率和I/O访问，这将是本文主要注意的东西。我将会研究三个不同的哈希表的C++实现，既有内存中的又有硬盘上的，并看看数据是怎么组织和访问的。本文将包括：&lt;/p&gt;
&lt;p&gt;1.哈希表&lt;br&gt;
1.1 哈希表简介&lt;br&gt;
1.2 哈希函数&lt;br&gt;
2.实现&lt;br&gt;
2.1 TR1的unordered_map&lt;br&gt;
2.2 SparseHash的dense_hash_map&lt;br&gt;
2.3 Kyoto Cabinet的HashDB&lt;br&gt;
3.结论&lt;br&gt;
4.参考文献&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/4ab340f93b16d29fab6f7212c680c0ee.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h1&gt;1.哈希表&lt;/h1&gt;
&lt;p&gt;&lt;a name=&quot;ci_title1&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;1.1 哈希表简介&lt;/h2&gt;
&lt;blockquote&gt;&lt;/blockquote&gt;
&lt;p&gt;哈希表可以高效的访问关联数据。每个条目都有一对对应的&lt;em&gt;键名&lt;/em&gt;和&lt;em&gt;键值&lt;/em&gt;，并且能仅通过键名来快速的取回和赋值。为了达到这个目的，键名通过&lt;em&gt;哈希函数&lt;/em&gt;进行哈希，以将键名从原始形式转换为整数。此整数之后作为索引来得到要访问的条目的值所在的bucket在&lt;em&gt;bucket数组&lt;/em&gt;中的地址。很多键名可以被哈希为相同的值，这表示这些key在bucket数组中回出现碰撞。有数种方法解决&lt;em&gt;碰撞&lt;/em&gt;，如使用链表的&lt;em&gt;分离链表&lt;/em&gt;（&lt;em&gt;separate chaining&lt;/em&gt; 亦称&lt;em&gt;开链&lt;/em&gt;或&lt;em&gt;单独链表&lt;/em&gt;）或&lt;em&gt;自平衡二叉树&lt;/em&gt;或线性或者二次探测的&lt;em&gt;开放寻址&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;从现在开始，我默认你知道什么是哈希表。如果你认为自己需要温习一下知识，Wikipedia的“Hash table”词条&lt;a href=&quot;#ref&quot;&gt;[1]&lt;/a&gt;（及其底部的扩展链接一节）和Cormen 等人写的Introduction to Algorithms一书中Hash table一章&lt;a href=&quot;#ref&quot;&gt;[2]&lt;/a&gt;都是很好的参考文献。&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;ci_title2&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;1.2 哈希函数&lt;/h2&gt;
&lt;p&gt;哈希函数的选择相当重要。一个好哈希函数的基本需求是输出的哈希值比较均匀。这样可以使碰撞的发生最小化，同时使得各个bucket中碰撞的条目比较平均。&lt;/p&gt;
&lt;p&gt;可用的哈希函数有很多，除非你确切的知道数据会变成什么样子，最安全的方法是找一个能够将随机数据分布均匀的哈希函数，如果可能的话符合雪崩效应&lt;a href=&quot;#ref&quot;&gt;[3]&lt;/a&gt;。有少数人对哈希函数做过比较&lt;a href=&quot;#ref&quot;&gt;[4]&lt;/a&gt; &lt;a href=&quot;#ref&quot;&gt;[5]&lt;/a&gt; &lt;a href=&quot;#ref&quot;&gt;[6]&lt;/a&gt; &lt;a href=&quot;#ref&quot;&gt;[7]&lt;/a&gt;，而他们的结论是MurmurHash3 &lt;a href=&quot;#ref%22&quot;&gt;[8]&lt;/a&gt;和CityHash &lt;a href=&quot;#ref&quot;&gt;[9]&lt;/a&gt; 是在写本文的时候最好的哈希函数。&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;ci_title3&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;2.实现&lt;/h1&gt;
&lt;p&gt;和哈希函数的比较一样，只有很少比较各个C++的内存哈希表库性能的博文。我见到的最出名的是Nick Welch 的&lt;em&gt;“Hash Table Benchmarks&lt;/em&gt;” &lt;a href=&quot;#ref&quot;&gt;[10]&lt;/a&gt;，和Jeff Preshing 的“&lt;em&gt;Hash Table Performance Test&lt;/em&gt;s” &lt;a href=&quot;#ref%22&quot;&gt;[11]&lt;/a&gt;。而其他文章也值得一看&lt;a href=&quot;#ref&quot;&gt;[12]&lt;/a&gt; &lt;a href=&quot;#ref&quot;&gt;[13]&lt;/a&gt; &lt;a href=&quot;#ref&quot;&gt;[14]&lt;/a&gt;。从这些比较中，我发现两个研究起来比较有意思的部分：GCC的TR1的unordered_map和SparseHash 库（以前叫Google SparseHash）的dense_hash_map，我将会在下文中介绍他们。另外，我同样会描述Kyoto Cabinet中HashDB的数据结构。显然因为unordered_map 和dense_hash_map是内存哈希表，不会像HashDB那样和我的键值对存储相关。尽管如此，稍微看一下其内部数据结构的组织和其内存模式也是很有意思的。&lt;/p&gt;
&lt;p&gt;在下述三个哈希表库的描述中，我的通用示例是把一组城市名作为键名其各自的GPS坐标作为键值。unordered_map的源代码可以在GCC代码中作为libstdc++-v3的一部分找到。我将会着眼于GCC v4.8.0的libstdc++-v3 release 6.0.18&lt;a href=&quot;#ref&quot;&gt;[15]&lt;/a&gt;，SparseHash v2.0.2中的dense_hash_map&lt;a href=&quot;#ref&quot;&gt;[16]&lt;/a&gt;，和Kyoto Cabinet v1.2.76中的HashDB&lt;a href=&quot;#ref&quot;&gt;[17]&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Matthew Austern的“&lt;em&gt;A Proposal to Add Hash Tables to the Standard Library (revision 4)&lt;/em&gt;”一文&lt;a href=&quot;#ref&quot;&gt;[18]&lt;/a&gt;和SparseHash的“&lt;em&gt;Implementation notes&lt;/em&gt;”页面&lt;a href=&quot;#ref&quot;&gt;[19]&lt;/a&gt;也有很有意思的关于哈希表实现的讨论。&lt;/p&gt;
&lt;h2&gt;2.1 TR1中的unordered_map&lt;/h2&gt;
&lt;p&gt;TR1的unordered_map提供了一个用链表（分离链）解决碰撞的哈希表。Bucket数组位于堆中，并且基于哈希表的负载系数自动调整大小。而bucket的链表则是用叫做&lt;code&gt;_Hash_node&lt;/code&gt;的节点结构体创建。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* from gcc-4.8.0/libstdc++-v3/include/tr1/hashtable_policy.h */ 
template
  struct _Hash_node&amp;lt;_Value, false&amp;gt;
  {
    _Value       _M_v;
    _Hash_node*  _M_next;
  };&lt;/pre&gt;
&lt;p&gt;如果键和值都是整型，其可以直接存储在&lt;code&gt;_M_v&lt;/code&gt;结构体中。否则将会存储指针，同时需要额外的内存。Bucket数组是在堆中一次性分配的，但并不分配节点的空间，节点的空间是通过各自调用C++内存分配器来分配的。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* from gcc-4.8.0/libstdc++-v3/include/tr1/hashtable.h */ 
Node* _M_allocate_node(const value_type&amp;amp; __v)
    {
      _Node* __n = _M_node_allocator.allocate(1);
      __try
    {
      _M_get_Value_allocator().construct(&amp;amp;__n-&amp;gt;_M_v, __v);
      __n-&amp;gt;_M_next = 0;
      return __n;
    }
      __catch(...)
    {
      _M_node_allocator.deallocate(__n, 1);
      __throw_exception_again;&lt;/pre&gt;
&lt;p&gt;因为这些节点是各自分配的，分配过程中可能浪费大量的内存。这取决于编译器和操作系统使用的内存分配过程。我甚至还没说每次分配中系统执行的调用。SGI哈希表的原始实现为这些节点做了一些资源预分配工作，但这个方法没有保留在TR1的 unordered_map实现中。&lt;/p&gt;
&lt;p&gt;下文的图5.1展示了TR1中unordered_map的内存和访问模式。让我们来看看当我们访问和键名“Johannesburg”相关的GPS坐标的时候会发生什么。这个键名被哈希并映射到了bucket #0。在那我们跳到了此bucket的链表的第一个节点（bucket #0左边的橙色箭头），我们可以访问堆中存储了键“Johannesburg”所属数据的内存区域（节点右侧的黑色箭头）。如果键名所指向的第一个节点不可用，就必须遍历其他的节点来访问。&lt;/p&gt;
&lt;p&gt;至于CPU性能，不能指望所有的数据都在处理器的同一个缓存行中。实际上，基于bucket数组的大小，初始bucket和初始节点不会在同一个缓存行中，而和节点相关的外部数据同样不太可能在同一个缓存行中。而随后的节点机器相关数据同样不会在同一个缓存行中并且需要从RAM中取回。如果你不熟悉CPU优化和缓存行，维基上的“CPU Cache”文章是一个很好的介绍&lt;a href=&quot;#ref&quot;&gt;[20]&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/4641e18d4587c0050af836b594a9c6be.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;图5.1&lt;/p&gt;
&lt;h2&gt;2.2 SparseHash的dense_hash_map&lt;/h2&gt;
&lt;p&gt;SparseHash库提供了两个哈希表实现，sparse_hash_map和dense_hash_map。sparse_hash_map在低成本下提供了出色的内存占用，并使用一个特定的数据结构sparsetable来打到这个目的。在SparseHash的“Implementation notes”页面&lt;a href=&quot;#ref&quot;&gt;19&lt;/a&gt;可以找到更多关于sparsetables 和sparse_hash_map的信息。在此我只讨论dense_hash_map。&lt;/p&gt;
&lt;p&gt;dense_hash_map用二次内部探测处理碰撞。和unordered_map一样，bucket数组也是在堆中一次分配，并基于哈希表的负载因子调整大小。bucket数组的元素是&lt;code&gt;std::pair&lt;/code&gt;的实例，其中&lt;code&gt;Key&lt;/code&gt;和&lt;code&gt;T&lt;/code&gt;分别是键名和键值的模版参数。在64位架构下储存字符串的时候，pair的实例大小是16字节。&lt;/p&gt;
&lt;p&gt;下文的图5.2是dense_hash_map内存和访问模式的展示。如果我们要寻找“Johannesburg”的坐标，我们一开始会进入bucket #0，其中有“Paris”（译注：图上实际应为“Dubai”）的数据（bucket #0右侧的黑色箭头）。因此必须探测然后跳转到bucket (i + 1) = (0 + 1) = 1（bucket #0左侧的橙色箭头），然后就能在bucket #1中找到“Johannesburg”的数据。这看上去和unordered_map中做的事情差不多，但其实完全不同。当然，和unordered_map一样，键名和键值都必须存储在分配于堆中的内存，这将导致对键名和键值的寻找会使缓存行无效化。但为碰撞的条目寻找一个bucket相对较快一些。实际上既然每个pair都是16字节而大多数处理器上的缓存行都是64字节，每次探测就像是在同一个缓存行上。这将急剧提高运算速度，与之相反的是unordered_map中的链表需要在RAM中跳转以寻找余下的节点。&lt;/p&gt;
&lt;p&gt;二次内部探测提供的缓存行优化使得dense_hash_map成为所有内存哈希性能测试中的赢家（至少是在我目前读过的这些中）。你应该花点时间来看看Nick Welch的文章“Hash Table Benchmarks” &lt;a href=&quot;#ref&quot;&gt;[10]&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/d46a2dac88be675429c619cb30a3b2b6.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;图5.2&lt;/p&gt;
&lt;h2&gt;2.3 Kyoto Cabinet的HashDB&lt;/h2&gt;
&lt;p&gt;Kyoto Cabinet实现了很多数据结构，其中就有哈希表。这个哈希表HashDB虽然有一个选项可以用来把他用作代替&lt;code&gt;std::map&lt;/code&gt;的内存哈希表，但其是设计用于在硬盘上持久化的。哈希表的元数据和用户数据一起用文件系统依次存储在硬盘上唯一的文件中。&lt;br&gt;
Kyoto Cabinet使用每个bucket中独立的二叉树处理碰撞。Bucket数组长度固定且不改变大小，无视负载因子的状态。这是Kyoto Cabinet的哈希表实现的主要缺陷。实际上，如果数据库创建的时候定义的bucket数组的长度低于实际需求，当条目开始碰撞的时候性能会急剧下降。&lt;/p&gt;
&lt;p&gt;允许硬盘上的哈希表实现改变bucket数组大小是很难的。首先，其需要bucket数组和条目存储到两个不同的文件中，其大小会各自独立的增长。第二，因为调整bucket数组大小需要将键名重新哈希到新bucket数组的新位置，这需要从硬盘中读取所有条目的键名，这对于相当大的数据库来说代价太高以至于几乎不可能。避免这种重新哈希过程的一种方法是，存储哈希后键名的时候每个条目预留4或8个字节（取决于哈希是长度32还是64 bit）。因为这些麻烦事，固定长度的bucket数组更简单，而Kyoto Cabinet中采用了这个方法。&lt;/p&gt;
&lt;p&gt;图5.3显示出文件中存储的一个HashDB的结构。我是从&lt;code&gt;calc_meta()&lt;/code&gt;方法的代码，和kchashdb.h尾部HashDB类中属性的注释中得到的这个内部结构。此文件以如下几个部分组织：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;头部有数据库所有的元数据&lt;/li&gt;
&lt;li&gt;包含数据区域中可用空间的空块池&lt;/li&gt;
&lt;li&gt;bucket数组&lt;/li&gt;
&lt;li&gt;记录（数据区域）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一条记录包含一个条目（键值对），以及此独立链的二叉树节点。这里是Record结构体：&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* from kyotocabinet-1.2.76/kchashdb.h */ 
  /**
   * Record data.
   */
  struct Record {
    int64_t off;                         ///&amp;lt; offset
    size_t rsiz;                         ///&amp;lt; whole size
    size_t psiz;                         ///&amp;lt; size of the padding
    size_t ksiz;                         ///&amp;lt; size of the key
    size_t vsiz;                         ///&amp;lt; size of the value
    int64_t left;                        ///&amp;lt; address of the left child record
    int64_t right;                       ///&amp;lt; address of the right child record
    const char* kbuf;                    ///&amp;lt; pointer to the key
    const char* vbuf;                    ///&amp;lt; pointer to the value
    int64_t boff;                        ///&amp;lt; offset of the body
    char* bbuf;                          ///&amp;lt; buffer of the body
  };&lt;/pre&gt;
&lt;p&gt;图5.4可以看到记录在硬盘上的组织。我从kchashdb.h中的&lt;code&gt;write_record()&lt;/code&gt;方法中得到组织方法。注意其和Record结构体不同：保存在硬盘上的目标是最小化硬盘占用，然而结构体的目标是使记录在编程的时候用起来比较方便。图5.4的所有变量都有固定长度，除了&lt;code&gt;key&lt;/code&gt;、&lt;code&gt;value&lt;/code&gt;、 和&lt;code&gt;padding&lt;/code&gt;，其当然是取决于数据条目中数据的尺寸。变量&lt;code&gt;left&lt;/code&gt; 和&lt;code&gt;righ&lt;/code&gt;t是二叉树节点的一部分，储存文件中其他记录的offset。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/b2ed0471f7ae7023f703ff0705f7ba2c.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;图5.3&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/429b4576d15cf69216323f483eb93613.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;图5.4如果我们要访问键名”Paris”的键值，一开始要获得相关bucket的初始记录，在本例中是bucket #0.。然后跳转到此bucket二叉树的头节点（bucket #0右侧的橙色箭头），其保存键名为”Johannesburg”.的数据。键名为”Paris”的数据需要通过当前节点的右侧节点来访问（”Johannesburg”记录右侧的黑色箭头）。二叉树需要一个可比较的类型来对节点分类。这里用的可比较类型是用&lt;code&gt;fold_hash()&lt;/code&gt;方法将哈希过的键名缩减得到的。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* from kyotocabinet-1.2.76/kchashdb.h */ 
uint32_t fold_hash(uint64_t hash) {
  _assert_(true);
  return (((hash &amp;amp; 0xffff000000000000ULL) &amp;gt;&amp;gt; 48) | ((hash &amp;amp; 0x0000ffff00000000ULL) &amp;gt;&amp;gt; 16)) ^
      (((hash &amp;amp; 0x000000000000ffffULL) &amp;lt;&amp;lt; 16) | ((hash &amp;amp; 0x00000000ffff0000ULL) &amp;gt;&amp;gt; 16));
}&lt;/pre&gt;
&lt;p&gt;把数据条目和节点一起存储在单一记录中，乍一看像是设计失误，但其实是相当聪明的。为了存储一个条目的数据，总是需要保持三种不同的数据：bucket、碰撞和条目。既然bucket数组中的bucket必须顺序存储，其需要就这样存储并且没有任何该进的方法。假设我们保存的不是整型而是不能存储在bucket中的字符或可变长度字节数组，这使其必须访问此bucket数组区域之外的其他内存。这样当添加一个新条目的时候，需要即保存冲突数据结构的数据，又要保存该条目键名和键值的数据。&lt;/p&gt;
&lt;p&gt;如果冲突和条目数据分开保存，其需要访问硬盘两次，再加上必须的对bucket的访问。如果要设置新值，其需要总计3次写入，并且写入的位置可能相差很远。这表示是在硬盘上的随机写入，这差不多是I/O的最糟糕的情况了。现在既然Kyoto Cabinet的HashDB中节点数据和条目数据存储在一起，其就可以只用一次写入写到硬盘中。当然，仍然必须访问bucket，但如果bucket数组足够小，就可以通过操作系统将其从硬盘中缓存到RAM中。如规范中”Effective Implementation of Hash Database”一节&lt;a href=&quot;#ref&quot;&gt;[17]&lt;/a&gt;声明的，Kyoto Cabinet可能采用这种方式。&lt;/p&gt;
&lt;p&gt;然而在硬盘上用二叉树存储条目需要注意的一点是，其会降低读取速度，至少当碰撞出现的时候会是这样。实际上，因为节点和条目存储在一起，处理一个bucket中的碰撞实际上是在一个二叉树中寻找要找的条目，这可能需要大量的对硬盘的随机读取。这可以让我们理解当条目的数量超过bucket数量时Kyoto Cabinet的性能急剧下降的原因。&lt;/p&gt;
&lt;p&gt;最后，因为所有的东西都是存在文件中，Kyoto Cabinet是自己处理内存管理，而非像unordered_map 和dense_hash_map那样交给操作系统处理。FreeBlock结构体保存着和文件中空闲空间的信息，其基本上是offset和大小，如下：&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* from kyotocabinet-1.2.76/kchashdb.h */ 
  /**
   * Free block data.
   */
  struct FreeBlock {
    int64_t off;                         ///&amp;lt; offset
    size_t rsiz;                         ///&amp;lt; record size
    /** comparing operator */
    bool operator &amp;lt;(const FreeBlock&amp;amp; obj) const {
      _assert_(true);
      if (rsiz &amp;lt; obj.rsiz) return true;
      if (rsiz == obj.rsiz &amp;amp;&amp;amp; off &amp;gt; obj.off) return true;
      return false;
    }
  };&lt;/pre&gt;
&lt;p&gt;所有的FreeBlock实例都加载在std::set中，其可以像&lt;code&gt;fetch_free_block()&lt;/code&gt;方法中那样使用std::set的upper_bound()方法来释放内存块，从而实现“最佳拟合”的内存分配策略。当可用空间显得过分细碎或者FreeBlock池中没有空间了，文件将进行碎片整理。此碎片整理过程通过移动各条记录来减少数据库文件的整体大小。&lt;/p&gt;
&lt;h1&gt;3.结论&lt;/h1&gt;
&lt;p&gt;本文中，我展示了三个不同哈希表库的数据组织和内存访问模式。TR1的unordered_map和SparseHash的dense_hash_map是在内存中的，而Kyoto Cabinet的HashDB是在硬盘上的。此三者用不同的访问处理碰撞，并对性能有不同的英雄。将bucket数据、碰撞数据和条目数据各自分开将影响性能，这是unordered_map中出现的情况。如dense_hash_map及其二次内部探测那样，将碰撞数据和bucket存储在一起；或者像HashDB那样，将碰撞数据和条目数据存储在一起都可以大幅提高速度。此两者都可以提高写入速度，但将碰撞数据和bucket存储在一起可以使读取更快。&lt;/p&gt;
&lt;p&gt;如果让我说从这些哈希表中学到的最重要的东西是什么的话，我会说在设计哈希表的数据组织的时候，首选的解决方案是将碰撞数据和bucket数据存储在一起。因为即便是在硬盘上，bucket数组和碰撞数据也会相当小，足够它们存储在RAM中，随机读取的花费将会比在硬盘上低得多。&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;ref&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;4.参考文献&lt;/h1&gt;
&lt;p&gt;[1] http://en.wikipedia.org/wiki/Hash_table&lt;br&gt;
[2] http://www.amazon.com/Introduction-Algorithms-Thomas-H-Cormen/dp/0262033844/&lt;br&gt;
[3] http://en.wikipedia.org/wiki/Avalanche_effect&lt;br&gt;
[4] http://blog.reverberate.org/2012/01/state-of-hash-functions-2012.html&lt;br&gt;
[5] http://www.strchr.com/hash_functions&lt;br&gt;
[6] http://programmers.stackexchange.com/questions/49550/which-hashing-algorithm-is-best-for-uniqueness-and-speed/145633#145633&lt;br&gt;
[7] http://blog.aggregateknowledge.com/2012/02/02/choosing-a-good-hash-function-part-3/&lt;br&gt;
[8] https://sites.google.com/site/murmurhash/&lt;br&gt;
[9] http://google-opensource.blogspot.fr/2011/04/introducing-cityhash.html&lt;br&gt;
[10] http://incise.org/hash-table-benchmarks.html&lt;br&gt;
[11] http://preshing.com/20110603/hash-table-performance-tests&lt;br&gt;
[12] http://attractivechaos.wordpress.com/2008/08/28/comparison-of-hash-table-libraries/&lt;br&gt;
[13] http://attractivechaos.wordpress.com/2008/10/07/another-look-at-my-old-benchmark/&lt;br&gt;
[14] http://blog.aggregateknowledge.com/2011/11/27/big-memory-part-3-5-google-sparsehash/&lt;br&gt;
[15] http://gcc.gnu.org/&lt;br&gt;
[16] https://code.google.com/p/sparsehash/&lt;br&gt;
[17] http://fallabs.com/kyotocabinet/spex.html&lt;br&gt;
[18] http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2003/n1456.html&lt;br&gt;
[1\9] http://sparsehash.googlecode.com/svn/trunk/doc/implementation.html&lt;br&gt;
[20] http://en.wikipedia.org/wiki/CPU_cache&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81091-62ce72541.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81091-62ce72541.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>实现键值对存储（四）：API设计</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;为开发者打造的Linux视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/75842/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（0）：目录&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/75844/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（1）：什么是键值对存储，为什么要实现它&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/77750/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（2）：以现有键值对存储为模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://blog.jobbole.com/78869/&quot; target=&quot;_blank&quot;&gt;实现键值对存储（3）：Kyoto Cabinet和LevelDB的架构比较分析&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我终于为这个键值对存储项目确定了一个名字，从现在开始我将叫它&lt;span style=&quot;text-decoration: line-through;&quot;&gt;FelixDB&lt;/span&gt; &lt;strong&gt;KingDB&lt;/strong&gt;。（译注：改成这么土的名字也是醉了）&lt;/p&gt;
&lt;p&gt;在本文中，我将对带着大家看一看四个键值对存储和数据库系统的API：LevelDB, Kyoto Cabinet, BerkekeyDB 和 SQLite3。对于其API中的每个主要功能，我将会比较他们的命名习惯和方法原型，以平衡其优缺点并为正在开发的键值对存储KingDB设计API。本文将包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;API设计的一般准则&lt;/li&gt;
&lt;li&gt;定义KingDB公共API的功能&lt;/li&gt;
&lt;li&gt;比较现有数据库的API&lt;br&gt;
3.1 打开和关闭数据库&lt;br&gt;
3.2 读写操作&lt;br&gt;
3.3 遍历&lt;br&gt;
3.4 参数处理&lt;br&gt;
3.5 错误管理&lt;/li&gt;
&lt;li&gt;结论&lt;/li&gt;
&lt;li&gt;参考文献&lt;/li&gt;
&lt;/ol&gt;
&lt;h1&gt;1.API设计的一般准则&lt;/h1&gt;
&lt;p&gt;设计一个好的API很难，相当难。但我在这说的不是什么新东西，而只是在重复之前很多人告诉我的东西。到目前为止我发现的最好的资料是Joshua Bloch的演讲“How to Design a Good API &amp;amp; Why it Matters（如何设计一个好的API及为什么这很重要）”&lt;a href=&quot;#ref&quot;&gt;[1]&lt;/a&gt;，及其摘要版本&lt;a href=&quot;#ref&quot;&gt;[2]&lt;/a&gt;。如果你还没有看过这个演讲，我强烈建议你找时间去看一下。在这个演讲中，Bloch清晰的陈述了听众需要记住的两个很重要的东西。我复制了摘要版本的要点并添加了一些评论：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;strong&gt;不确定的时候，先放一边。&lt;/strong&gt;当不确定某功能、类、方法或参数是否要添加在API中的时候，不要添加。&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;不要让用户做库可以做的事情。&lt;/strong&gt;如果你的API让客户执行一系列函数调用的时候，需要将每个函数的输出塞到下一个函数的输入里，那你应该在API中添加一个函数来执行这一系列的函数调用。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;另一个关于API设计的好资源是Joshua Bloch写的《Effective Java》&lt;a href=&quot;#ref&quot;&gt;4&lt;/a&gt;和Scott Meyers写的《Effective C++》&lt;a href=&quot;#ref&quot;&gt;3&lt;/a&gt;第四章“Designs and Declarations”。&lt;/p&gt;
&lt;p&gt;这些资源对于当前阶段的这个键值对存储项目来说十分重要，尽管我觉得这些资源没有包含一个很重要的因素：用户期望。将API从草图上设计出来是很难的，但这个键值对存储的例子来说，是有例可循的。用户一直和他们的键值对存储或数据库系统的API打交道。因此，当面对一个新的键值对存储的时候，用户希望有一个类似的环境，而不关心这潜规则只会提高用户对新API的学习曲线，并让用户不高兴。&lt;/p&gt;
&lt;p&gt;鉴于这个原因，即便我牢记上文列出的这些资料中的所有好建议，但我仍认为我必须尽可能多的复制已有库的API，因为这可以在用户使用我正创建的API时更简单。&lt;/p&gt;
&lt;h1&gt;2.定义KingDB公共API的功能&lt;/h1&gt;
&lt;p&gt;考虑到这只是万里长征的第一步，我打算实现一个最小且可靠的键值对存储，我当然不会包含所有的，像Kyoto Cabinet 和LevelDB那样的成熟项目提供的高级功能。我打算先让基本功能实现，然后我将逐渐增加其他功能。对于我来说，基本功能严格限制在：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;打开和关闭数据库&lt;/li&gt;
&lt;li&gt;读写数据库&lt;/li&gt;
&lt;li&gt;遍历数据库中所有的键值对集合&lt;/li&gt;
&lt;li&gt;提供参数调整的方法&lt;/li&gt;
&lt;li&gt;提供一个合适的错误通知接口&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我意识到这些功能对于一些用例来说过于局限了，但暂时应该对付的过来。我不打算添加任何事务机制、分类查询、或原子操作。同样，现在我不打算提供快照功能。&lt;/p&gt;
&lt;h1&gt;3.比较现有数据库的API&lt;/h1&gt;
&lt;p&gt;为了比较现有数据库的C++ API，我将会比较每个功能的示例代码。 这些示例代码是修改自或直接取自于官方代码“Fundamental Specifications of Kyoto Cabinet” &lt;a href=&quot;#ref&quot;&gt;[5]&lt;/a&gt;, “LevelDB’s Detailed Documentation” &lt;a href=&quot;#ref&quot;&gt;[6]&lt;/a&gt;, “Getting Started with Berkeley DB” &lt;a href=&quot;#ref%22&quot;&gt;[7]&lt;/a&gt;, 和 “SQLite in 5 minutes or less” &lt;a href=&quot;#ref&quot;&gt;[8]&lt;/a&gt;。 我同样会使用不同的颜色来标示来自不同的API。&lt;/p&gt;
&lt;h2&gt;3.1 打开和关闭数据库&lt;/h2&gt;
&lt;p&gt;下述示例代码显示出研究的系统是如何打开数据库的。为了更清晰的显示代码原理，选项设置和错误管理没有在此显示，并且会在下述各节中解释更多的细节。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* LevelDB */
leveldb::DB* db;
leveldb::DB::Open(leveldb::Options, &quot;/tmp/testdb&quot;, &amp;amp;db);
...
delete db;&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Kyoto Cabinet */
HashDB db;
db.open(&quot;dbfile.kch&quot;, HashDB::OWRITER | HashDB::OCREATE);
...
db.close()&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* SQLite3 */
sqlite3 *db;
sqlite3_open(&quot;askyb.db&quot;, &amp;amp;db);
...
sqlite3_close(db);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Berkeley DB */
Db db(NULL, 0);
db.open(NULL, &quot;my_db.db&quot;, NULL, DB_BTREE, DB_CREATE, 0);
...
db.close(0);&lt;/pre&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;在打开数据库部分出现了两种清晰的模式。一方面，LevelDB 和SQLite3的API请求创建一个数据库对象的指针（句柄）。然后调用打开函数的时候将这个指针的引用作为参数，以定位对象的内存空间，然后设置这个数据库对象。另一方面，Kyoto Cabinet 和Berkeley DB的API以实例化一个数据库对象为开始，然后调对象的用open()方法来设置这个数据库对象。&lt;/p&gt;
&lt;p&gt;说到关闭数据库部分，LevelDB只需要请求删除指针就行了，但SQLite3必须调用关闭函数。Kyoto Cabinet 和BerkeleyDB的数据库对象自身有一个close()方法。&lt;/p&gt;
&lt;p&gt;我相信像LevelDB 和SQLite3那样强制使用数据库对象的指针，然后将指针传递给打开函数是很“C风格”的。另外，我认为LevelDB处理关闭的方法—通过删除指针—是一个设计缺陷。因为这会导致API的&lt;strong&gt;不对称&lt;/strong&gt;。在API中，函数的对称应该尽可能的对称，因为这样更加直观和逻辑。“如果我调用了open() 那我就应该调用close()”的想法比“如果我调用了open() 那我就应该删除指针”的想法合乎逻辑一万倍。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;设计决策&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因此我决定使用在KingDB上的是类似于Kyoto Cabinet 和Berkeley DB的，先实例化一个数据库对象，然后调用对象的Open() 和Close()方法。至于命名，我仍使用传统的Open() 和Close()。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2&gt;3.2 读写&lt;/h2&gt;
&lt;p&gt;在本节，我比较他们读写功能的API。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* LevelDB */
std::string value;
db-&amp;amp;gt;Get(leveldb::ReadOptions(), &quot;key1&quot;, &amp;amp;amp;value);
db-&amp;amp;gt;Put(leveldb::WriteOptions(), &quot;key2&quot;, value);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Kyoto Cabinet */
string value;
db.get(&quot;key1&quot;, &amp;amp;amp;value);
db.set(&quot;key2&quot;, &quot;value&quot;);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* SQLite3 */
int szErrMsg;
char *query = “INSERT INTO table col1, col2 VALUES (‘value1’, ‘value2’)”;
sqlite3_exec(db, query, NULL, 0, &amp;amp;amp;szErrMsg);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Berkeley DB */
/* reading */
Dbt key, data;

key.set_data(&amp;amp;amp;money);
key.set_size(sizeof(float));

data.set_data(description);
data.set_ulen(DESCRIPTION_SIZE + 1);
data.set_flags(DB_DBT_USERMEM);

db.get(NULL, &amp;amp;amp;key, &amp;amp;amp;data, 0);

/* writing */
char *description = &quot;Grocery bill.&quot;;
float money = 122.45;

Dbt key(&amp;amp;amp;money, sizeof(float));
Dbt data(description, strlen(description) + 1);

db.put(NULL, &amp;amp;amp;key, &amp;amp;amp;data, DB_NOOVERWRITE);

int const DESCRIPTION_SIZE = 199;
float money = 122.45;
char description[DESCRIPTION_SIZE + 1];&lt;/pre&gt;
&lt;p&gt;我不会考虑SQLite3的设计，因为其是基于SQL的，因此其读写是通过SQL请求进行的，而非方法调用。Berkeley DB请求Dbt类对象的创建，并在上面进行一大堆设置，因此我也不会考虑这个设计。剩下的只有LevelDB 和Kyoto Cabinet，而他们有很漂亮的getter/setter对称接口。LevelDB 有Get() 和Put(), 而Kyoto Cabinet 有get() 和set()。Setter方法的原型——Put() 和set()十分相似：键名是值传递，而键值是传递的指针使得调用时可以更改。键值并不通过调用返回，返回值是给错误管理使用的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;设计决策&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于KingDB，我打算使用和LevelDB 及Kyoto Cabinet相似的方法，对于setter方法使用一个相似的原型，即用值传递键值而用指针传递键值。至于命名，一开始我觉得Get() 和Set()是最好的选择，但仔细思考之后我更倾向于LevelDB那样，使用Get() 和Put()。其原因是Get/Set 和Get/Put都很对称，但“Get” 和 “Set”两个词太相似，只差了一个字母。因此阅读代码的时候使用“Get” 和“Put”会更加清晰且更易辨认，因此我会使用Get/Put。&lt;/p&gt;
&lt;h2&gt;3.3 遍历&lt;/h2&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* LevelDB */
leveldb::Iterator* it = db-&amp;amp;gt;NewIterator(leveldb::ReadOptions());
for (it-&amp;amp;gt;SeekToFirst(); it-&amp;amp;gt;Valid(); it-&amp;amp;gt;Next()) {
  cout &amp;amp;lt;&amp;amp;lt; it-&amp;amp;gt;key().ToString() &amp;amp;lt;&amp;amp;lt; &quot;: &quot;  &amp;amp;lt;&amp;amp;lt; it-&amp;amp;gt;value().ToString() &amp;amp;lt;&amp;amp;lt; endl;
}
delete it;&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Kyoto Cabinet */
DB::Cursor* cur = db.cursor();
cur-&amp;amp;gt;jump();
string ckey, cvalue;
while (cur-&amp;amp;gt;get(&amp;amp;amp;ckey, &amp;amp;amp;cvalue, true)) {
  cout &amp;amp;lt;&amp;amp;lt; ckey &amp;amp;lt;&amp;amp;lt; &quot;:&quot; &amp;amp;lt;&amp;amp;lt; cvalue &amp;amp;lt;&amp;amp;lt; endl;
}
delete cur;&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* SQLite3 */
static int callback(void *NotUsed, int argc, char **argv, char **szColName) {
  for(int i = 0; i &amp;amp;lt; argc; i++) {
    printf(&quot;%s = %s\n&quot;, szColName[i], argv[i] ? argv[i] : &quot;NULL&quot;);
  }
  printf(&quot;\n&quot;);
  return 0;
}

char *query = “SELECT * FROM table”;
sqlite3_exec(db, query, callback, 0, &amp;amp;amp;szErrMsg);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Berkeley DB */
Dbc *cursorp;
db.cursor(NULL, &amp;amp;amp;cursorp, 0);
Dbt key, data;
while (cursorp-&amp;amp;gt;get(&amp;amp;amp;key, &amp;amp;amp;data, DB_NEXT) == 0) {
  // do things
}
cursorp-&amp;amp;gt;close();&lt;/pre&gt;
&lt;p&gt;在上一节中，SQLite3不被考虑是因为其不满足键值对存储的需求。但看看它是如何将一个SELECT请求发送到数据库，然后在取回来的每一行上调用回调函数是比较有趣的。大多数MySQL 和 PostgreSQL的API用循环并调用一个能够填充本地变量的函数来做到，而非这样使用一个回调函数。我发现这种回调函数比较棘手，因为这对于那些想执行合计操作或对取回来的行进行计算的用户来说，会让事情变得复杂。但这是另一方面的讨论，现在回到我们的键值对存储上来！&lt;/p&gt;
&lt;p&gt;这里有两种方法：使用游标或者使用遍历器。Kyoto Cabinet 和BerkeleyDB使用游标，一开始创建一个指向游标对象的指针并实例化对象，然后在while循环中重复调用游标的get()方法来获取数据库中所有的值。LevelDB使用遍历器设计模式，一开始创建一个指向遍历器对象的指针并实例化对象（这部分和游标一样），但是使用一个for循环来遍历集合中的项目。注意这里的while和for循环只是习惯：游标可以使用for循环而遍历器也可以使用while循环。其主要的不同是，在游标中，键和值是指针传递然后在游标的get()方法中填充内容，但在迭代器中，键和值是通过迭代器方法的返回值来访问的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;设计决策&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;同样，游标和其while循环是相当“C风格”的。我发现迭代器的方法更加清晰并更符合“C++风格”，因为这正是C++中STL的集合的访问方式。因此对于KingDB来说，我选择使用LevelDB那样的遍历器。至于命名，我简单的复制了LevelDB中的方法名。&lt;/p&gt;
&lt;h2&gt;3.4 参数处理&lt;/h2&gt;
&lt;p&gt;参数在IKVS系列文章中第三部分3.4节已经简要叙述了，但我还想在这提一下。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* LevelDB */
leveldb::DB* db;
leveldb::Options options;
options.create_if_missing = true;
options.compression = leveldb::kNoCompression;
leveldb::DB::Open(options, &quot;/tmp/testdb&quot;, &amp;amp;amp;db);
...
leveldb::WriteOptions write_options;
write_options.sync = true;
db-&amp;amp;gt;Put(write_options, &quot;key&quot;, &quot;value&quot;);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Kyoto Cabinet */
db.tune_options(GrassDB::TCCOMPESS);
db.tune_buckets(500LL * 1000);
db.tune_page(32768);
db.tune_page_cache(1LL &amp;amp;lt;&amp;amp;lt; 20);
db.open(...);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* SQLite3 */ 
sqlite3_config(SQLITE_CONFIG_MULTITHREAD);
sqlite3_config(SQLITE_CONFIG_MEMSTATUS, 1);
sqlite3_config(SQLITE_CONFIG_LOG, SqliteLogger, NULL);
sqlite3_initialize();
sqlite3_open(...);&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Berkeley DB */
db.set_flags(DB_DUPSORT);
db.set_bt_compare(compare_fct);
db.open(NULL, file_name, NULL, DB_BTREE, DB_CREATE, 0);&lt;/pre&gt;
&lt;p&gt;SQLite3是通过sqlite3_config()修改全局参数，然后在所有后续连接建立的时候应用。Kyoto Cabinet 和Berkeley DB中，选项是在调用open()之前通过调用数据库对象的方法来设置选项的，和SQlite3的做法比较相似。在这些方法之上，更通用的选项是通过open()方法的参数来设置的（见上文3.1节）。这表示选项被分为两部分，一些通过方法的调用来设置，而另一些是通过open()的调用来设置。&lt;/p&gt;
&lt;p&gt;LevelDB的做法不大一样。选项是在自己的类中一起定义，而参数是通过这些类的属性来更改。之后这些设置类的对象以方法参数的形式传递，并总是第一个参数。例如LevelDB数据对象的open()方法的第一个参数是leveldb::Options类的对象，而Get()和Put()方法的第一个参数分别是leveldb::ReadOptions 和leveldb::WriteOptions。这种设计的一个好处是在同时创建多个数据库的情况下可以很简单的共享设置，尽管在Kyoto Cabinet 和 Berkeley DB的例子中可以为一组设置创建一个方法，然后通过调用这个方法来设置这组设定。像LevelDB那样把设置放到一个特定的类中真正的优势在于，其接口更稳定，因为扩展设置只需要修改这个选项类，而不用修改数据库对象的任何方法。&lt;/p&gt;
&lt;p&gt;尽管我想用这种选项类，但我必须说的是LevelDB这种总是将选项作为第一个参数在各个方法中传递的方式我不是很习惯。如果没有需要修改的选项，这导致代码中需要使用默认选项，就像这样：&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;db.Put(leveldb::WriteOptions, &quot;key&quot;, &quot;value&quot;);&lt;/pre&gt;
&lt;p&gt;这可能导致代码膨胀，而另一种可能是将选项作为最后一个参数，然后为这个参数设定一个缺省值，使得不需要设置选项的时候可以省掉这项。而另一种源自于C++的解决方式是函数的重载，有数个带有原型的方法使其可以省略掉选项的对象。把选项放到参数的最后对于我来说看上去更符合逻辑，因为其是可能省略的。但我相信LevelDB的作者把选项作为第一个参数是有很好的原因的。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;设计决策&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对于参数处理，我觉得将选项作为类是最简洁的方式，同时其符合面向对象设计。&lt;/p&gt;
&lt;p&gt;对于KingDB来说，我会像LevelDB那样使用独立的类来处理选项，不过我会将作为方法的最后一个参数。我或许以后能明白将选项作为最后一个参数是真正正确的方法——或者有谁能帮我解释下——但现在我坚持将其放到最后。最后，命名子啊这儿不是很重要，因此Options, ReadOption 和WriteOption都可以。&lt;/p&gt;
&lt;h2&gt;3.5 错误管理&lt;/h2&gt;
&lt;p&gt;在IKVS系列第三部分3.6节，有关于错误管理的一些讨论，基本上是说用户看不到的代码是如何管理错误的。本节再次讨论这个话题但稍有不同，不讨论库中错误的细节，而是关于错误发生后是怎么报告给使用公共接口的用户的。&lt;/p&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* LevelDB */
leveldb::Status s = db-&amp;amp;gt;Put(leveldb::WriteOptions(), &quot;key&quot;, &quot;value&quot;);
if (!s.ok()) {
  cerr &amp;amp;lt;&amp;amp;lt; s.ToString() &amp;amp;lt;&amp;amp;lt; endl;
}&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Kyoto Cabinet */
if (!db.set(&quot;baz&quot;, &quot;jump&quot;)) {
  cerr &amp;amp;lt;&amp;amp;lt; &quot;set error: &quot; &amp;amp;lt;&amp;amp;lt; db.error().name() &amp;amp;lt;&amp;amp;lt; endl;
}&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* SQLite3 */
int rc = sqlite3_exec(db, query, callback, 0, &amp;amp;amp;zErrMsg);
if (rc != SQLITE_OK) {
  fprintf(stderr, &quot;SQL error: %s\n&quot;, zErrMsg);
  sqlite3_free(zErrMsg);
}&lt;/pre&gt;
&lt;pre class=&quot;brush: cpp; gutter: true&quot;&gt;/* Berkeley DB */
int ret = my_database.put(NULL, &amp;amp;amp;key, &amp;amp;amp;data, DB_NOOVERWRITE);
if (ret == DB_KEYEXIST) {
  my_database.err(ret, &quot;Put failed because key %f already exists&quot;, money);
}&lt;/pre&gt;
&lt;p&gt;Kyoto Cabinet, Berkeley DB 和SQLite3使用相同的方法处理错误，即其方法返回一个整型的错误代码。如在IKVS系列第三部分3.6节所述，Kyoto Cabinet内部将值设置在数据库对象中，这就是为何上述示例代码中，错误信息是从db.error().name()取出的。&lt;/p&gt;
&lt;p&gt;LevelDB有个一特别的Status类，包含错误类型和提供了关于此错误更多信息的消息。LevelDB库中的所有方法都返回了此类的一个对象，这使错误测试和将错误传递给系统各部分以进行进一步的检查更加简单。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;设计决策&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;返回错误代码而避免使用C++的异常处理机制是十分正确的，然而整形并不足以携带有意义的信息。Kyoto Cabinet, Berkeley DB 和SQLite3都有其自己的存储错误信息的方法，然而即便是在在Kyoto Cabinet 和Berkeley例子中，创建了错误管理和数据库类的强耦合，，仍然会为取得信息添加额外的步骤。像LevelDB那样使用一个Status类可以避免使用C++异常处理，同时也避免了和架构其他部分的耦合。&lt;/p&gt;
&lt;h1&gt;4.结论&lt;/h1&gt;
&lt;p&gt;API的预设比较有意思，因为去看不同的工程师如何解决相同的问题总是很有意思的。这同样让我意识到Kyoto Cabinet 和Berkeley DB的API有多么相似。Kyoto Cabinet 的作者Mikio Hirabayashi清楚地声明了他的键值对存储是基于Berkeley DB的，而在看完API相似性之后这一点更加清晰了。&lt;/p&gt;
&lt;p&gt;LevelDB的设计相当好，但我还是对于一些我认为可以以其他方式实现的细节有些意见。例如数据库打开和关闭以及方法原型。&lt;/p&gt;
&lt;p&gt;我吸取了每个系统的一点长处，而我现在对于KingDB的API设计的各个选择感觉更加自信了。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;ref&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;5.参考文献&lt;/h1&gt;
&lt;p&gt;[1] http://www.infoq.com/presentations/effective-api-design&lt;br&gt;
[2] http://www.infoq.com/articles/API-Design-Joshua-Bloch&lt;br&gt;
[3] http://www.amazon.com/Effective-Specific-Improve-Programs-Designs/dp/0321334876&lt;br&gt;
[4] http://www.amazon.com/Effective-Java-Edition-Joshua-Bloch/dp/0321356683&lt;br&gt;
[5] http://fallabs.com/kyotocabinet/spex.html&lt;br&gt;
[6] http://leveldb.googlecode.com/svn/trunk/doc/index.html&lt;br&gt;
[7] http://docs.oracle.com/cd/E17076_02/html/gsg/CXX/index.html&lt;br&gt;
[8] http://www.sqlite.org/quickstart.html&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12-81083-a39d9afd4.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12-81083-a39d9afd4.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>What Happened to NSMethodSignature?</title>
        <description>

						
						

						&lt;p class=&quot;update&quot;&gt;UPDATE: We’ve added the Request.playground file to this post so you can download it and easily experiment with the code yourself.&lt;/p&gt;
&lt;p&gt;Bringing the Cocoa frameworks to Swift gave us a unique opportunity to look at our APIs with a fresh perspective. We found classes that we didn&#39;t feel fit with the goals of Swift, most often due to the priority we give to safety.  For instance, some classes related to dynamic method invocation are not exposed in Swift, namely &lt;span class=&quot;keyword&quot;&gt;NSInvocation&lt;/span&gt; and &lt;span class=&quot;keyword&quot;&gt;NSMethodSignature&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We recently received a bug report from a developer who noticed this absence. This developer was using &lt;span class=&quot;keyword&quot;&gt;NSMethodSignature&lt;/span&gt; in Objective-C to introspect the types of method arguments, and in the process of migrating this code to Swift, noticed that &lt;span class=&quot;keyword&quot;&gt;NSMethodSignature&lt;/span&gt; is not available. The code being migrated could accept HTTP handlers of varying signatures, such as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&lt;span class=&quot;key&quot;&gt;func&lt;/span&gt; handleRequest(request: &lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, queryStringArguments: [&lt;span class=&quot;title&quot;&gt;String&lt;/span&gt;: &lt;span class=&quot;title&quot;&gt;String&lt;/span&gt;]) { }
&lt;span class=&quot;key&quot;&gt;func&lt;/span&gt; handleRequest(request: &lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, jsonBody: &lt;span class=&quot;title&quot;&gt;JSON&lt;/span&gt;) { }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In Objective-C, &lt;span class=&quot;keyword&quot;&gt;NSMethodSignature&lt;/span&gt; can be used to determine that the API of the first method would require a &lt;span class=&quot;keyword&quot;&gt;[String: String]&lt;/span&gt; argument, and the second method would require a &lt;span class=&quot;keyword&quot;&gt;JSON&lt;/span&gt; value. However, Swift is a powerful language and can easily handle this scenario without using &lt;span class=&quot;keyword&quot;&gt;NSMethodSignature&lt;/span&gt;, and in a way that doesn&#39;t undermine the help that the compiler provides for type and memory safety.&lt;/p&gt;
&lt;p&gt;Here is an alternative way to solve the same problem in Swift:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&lt;span class=&quot;key&quot;&gt;struct&lt;/span&gt; HTTPRequest {
	&lt;span class=&quot;comment&quot;&gt;// ...&lt;/span&gt;
}

&lt;span class=&quot;key&quot;&gt;protocol&lt;/span&gt; HTTPHandlerType {
	&lt;span class=&quot;key&quot;&gt;typealias&lt;/span&gt; Data

	&lt;span class=&quot;comment&quot;&gt;/// :returns: true if the request was handled; false otherwise&lt;/span&gt;
	&lt;span class=&quot;key&quot;&gt;func&lt;/span&gt; handle(request: &lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, data: &lt;span class=&quot;title&quot;&gt;Data&lt;/span&gt;) -&amp;gt; &lt;span class=&quot;title&quot;&gt;Bool&lt;/span&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First, we&#39;ll use a protocol to define that whatever is going to handle our &lt;span class=&quot;keyword&quot;&gt;HTTPRequest&lt;/span&gt; does so via this interface. This protocol is very simple, with only a single method.&lt;/p&gt;
&lt;p&gt;Why use a protocol here, instead of subclassing an &lt;span class=&quot;keyword&quot;&gt;HTTPHandler&lt;/span&gt; class? Because protocols give the flexibility of leaving the implementation details up to the clients of this code. If we were to make an &lt;span class=&quot;keyword&quot;&gt;HTTPHandler&lt;/span&gt; class, we would require clients to also use classes, forcing upon them the semantics of reference types. However, by using a protocol, clients can decide for themselves the appropriate type to use in their code, whether it be class, struct, or even enum.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&lt;span class=&quot;key&quot;&gt;class&lt;/span&gt; HTTPServer {
	&lt;span class=&quot;key&quot;&gt;func&lt;/span&gt; addHandler&amp;lt;T: HTTPHandlerType&amp;gt;(handler: &lt;span class=&quot;title&quot;&gt;T&lt;/span&gt;) {
		handlers.append { (request: &lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, args: &lt;span class=&quot;title&quot;&gt;Any&lt;/span&gt;) -&amp;gt; Bool &lt;span class=&quot;key&quot;&gt;in&lt;/span&gt;
			&lt;span class=&quot;key&quot;&gt;if let&lt;/span&gt; typedArgs = args &lt;span class=&quot;key&quot;&gt;as&lt;/span&gt;? &lt;span class=&quot;pointer&quot;&gt;T&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Data&lt;/span&gt; {
				&lt;span class=&quot;key&quot;&gt;return&lt;/span&gt; handler.handle(request, data: typedArgs)
			}
			&lt;span class=&quot;key&quot;&gt;return false&lt;/span&gt;
		}
	}

	&lt;span class=&quot;comment&quot;&gt;// ...&lt;/span&gt;
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, our &lt;span class=&quot;keyword&quot;&gt;HTTPServer&lt;/span&gt; class has a generic method that accepts an &lt;span class=&quot;keyword&quot;&gt;HTTPHandlerType&lt;/span&gt; as a parameter. By using the handler&#39;s associated type, it can perform the conditional downcast of the &lt;span class=&quot;keyword&quot;&gt;args&lt;/span&gt; parameter to determine if this handler should be given an opportunity to handle the request. Here we can see the benefit of defining &lt;span class=&quot;keyword&quot;&gt;HTTPHandlerType&lt;/span&gt; as a protocol. The &lt;span class=&quot;keyword&quot;&gt;HTTPServer&lt;/span&gt; doesn&#39;t need to know &lt;em&gt;how&lt;/em&gt; the handler is reacting to the request, nor does it even need to care about the nature of the handler itself. All it needs to know is that the value can handle requests.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&lt;span class=&quot;key&quot;&gt;class&lt;/span&gt; HTTPServer {
	&lt;span class=&quot;comment&quot;&gt;// ...&lt;/span&gt;

	&lt;span class=&quot;key&quot;&gt;private var&lt;/span&gt; handlers: [(&lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, &lt;span class=&quot;title&quot;&gt;Any&lt;/span&gt;) -&amp;gt; &lt;span class=&quot;title&quot;&gt;Bool&lt;/span&gt;] = []

	&lt;span class=&quot;key&quot;&gt;func&lt;/span&gt; dispatch(req: &lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, args: &lt;span class=&quot;title&quot;&gt;Any&lt;/span&gt;) -&amp;gt; &lt;span class=&quot;title&quot;&gt;Bool&lt;/span&gt; {
		&lt;span class=&quot;key&quot;&gt;for&lt;/span&gt; handler &lt;span class=&quot;key&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;pointer&quot;&gt;handlers&lt;/span&gt; {
			&lt;span class=&quot;key&quot;&gt;if&lt;/span&gt; handler(req, args) {
				&lt;span class=&quot;key&quot;&gt;return true&lt;/span&gt;
			}
		}
		&lt;span class=&quot;key&quot;&gt;return false&lt;/span&gt;
	}
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When our &lt;span class=&quot;keyword&quot;&gt;HTTPServer&lt;/span&gt; receives a request, it will iterate through its handlers and see if any can deal with the request.&lt;/p&gt;
&lt;p&gt;Now we can easily create a custom &lt;span class=&quot;keyword&quot;&gt;HTTPHandlerType&lt;/span&gt; with varying argument types and register it with the &lt;span class=&quot;keyword&quot;&gt;HTTPServer&lt;/span&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&lt;span class=&quot;key&quot;&gt;class&lt;/span&gt; MyHandler : &lt;span class=&quot;pointer&quot;&gt;HTTPHandlerType&lt;/span&gt; {
	&lt;span class=&quot;key&quot;&gt;func&lt;/span&gt; handle(request: &lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;, data: &lt;span class=&quot;title&quot;&gt;Int&lt;/span&gt;) -&amp;gt; &lt;span class=&quot;title&quot;&gt;Bool&lt;/span&gt; {
		&lt;span class=&quot;key&quot;&gt;return&lt;/span&gt; data &amp;gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;
	}
}

&lt;span class=&quot;key&quot;&gt;let&lt;/span&gt; server = &lt;span class=&quot;pointer&quot;&gt;HTTPServer&lt;/span&gt;()
&lt;span class=&quot;pointer&quot;&gt;server&lt;/span&gt;.&lt;span class=&quot;enum&quot;&gt;addHandler&lt;/span&gt;(&lt;span class=&quot;pointer&quot;&gt;MyHandler&lt;/span&gt;())
&lt;span class=&quot;pointer&quot;&gt;server&lt;/span&gt;.dispatch(&lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;(...), args: &lt;span class=&quot;string&quot;&gt;&quot;x&quot;&lt;/span&gt;) &lt;span class=&quot;comment&quot;&gt;// returns false&lt;/span&gt;
&lt;span class=&quot;pointer&quot;&gt;server&lt;/span&gt;.dispatch(&lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;(...), args: &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;)   &lt;span class=&quot;comment&quot;&gt;// returns false&lt;/span&gt;
&lt;span class=&quot;pointer&quot;&gt;server&lt;/span&gt;.dispatch(&lt;span class=&quot;pointer&quot;&gt;HTTPRequest&lt;/span&gt;(...), args: &lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;)  &lt;span class=&quot;comment&quot;&gt;// returns true&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a combination of protocols and generics, we have written Swift code to elegantly create and register HTTP handlers of varying types. This approach also lets the compiler guarantee type safety, while ensuring excellent runtime performance.&lt;/p&gt;

						
												&lt;ul class=&quot;links small padding-top-20&quot;&gt;
														&lt;li class=&quot;download&quot;&gt;&lt;a href=&quot;/swift/blog/downloads/Request.zip&quot;&gt;Request.playground&lt;/a&gt;&lt;/li&gt;
													&lt;/ul&gt;
						

												
											

</description>
        <pubDate>Fri, 12 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-12--id=19-96752c478.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-12--id=19-96752c478.html</guid>
        
        
        <category>apple_swift</category>
        
      </item>
    
      <item>
        <title>超酷算法：Levenshtein自动机</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p align=&quot;left&quot;&gt;在上一期的超酷算法中，我们聊到了BK树，这是一种非常聪明的索引结构，能够在搜索过程中进行模糊匹配，它基于编辑距离（Levenshtein distance），或者任何其它服从三角不等式的度量标准。今天，我将继续介绍另一种方法，它能够在常规索引中进行模糊匹配搜索，我们将它称之为Levenshtein自动机。&lt;/p&gt;
&lt;h1&gt;简介&lt;/h1&gt;
&lt;p&gt;Levenshtein自动机背后的基本理念是：能够构建一个有限状态自动机，准确识别出和某个目标单词相距在给定编辑距离内的所有字符串集合。之后就好办了，我们可以输入任意单词，自动机能够判断这个单词到目标单词的距离是否大于我们在构建时指定的距离，并选择接收或拒绝。更进一步说，根据FSA的自然特性，这项工作可以在O(n)时间内完成，取决于测试字符串的长度。与此相比，标准动态编程距离向量算法需要消耗O(mn)时间，m和n分别是两个输入单词的长度。因此很显然，起码Levenshtein向量机提供了一种更快的方式，供我们针对一个目标单词和最大距离，检查所有的单词，这是一个不错的改进的开端。&lt;br&gt;
当然，如果Levenshtein向量机只有优点，那这篇文章将会很短。我们将会谈到很多，不过我们先来看一下Levenshtein向量机究竟是何物，以及我们如何建立一个Levenshtein自动机。&lt;/p&gt;
&lt;h1&gt;构建与评价&lt;/h1&gt;
&lt;p align=&quot;left&quot;&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/979c4cce37819656ccc8e8f203276919.png&quot; rel=&quot;lightbox[80659]&quot; title=&quot;超酷算法：Levenshtein自动机&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-80663&quot; alt=&quot;levenstein-nfa-food&quot; src=&quot;/images/jobbole.com/2e670a18ce556bc41d7a6af4143c225d.jpg&quot;&gt;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;上图展示了针对单词food的Levenshtein自动机的NFA（译者注：非确定性有限自动机），其最大编辑距离为2。你可以看到，它很普通，构建过程也非常直观。初始状态在左下部分，我们使用n&lt;sup&gt;e&lt;/sup&gt;记法对状态进行命名，n是指到目前为止被处理过的特性的数量，e是指错误的个数。水平线表示没有被修改的特性，垂直线表示插入的值，而两条对角线则分别表示交换（标记a*）和删除。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;我们来看一下如何通过一个给定的输入单词和最大编辑距离构建一个NFA，由于整个NFA类是非常标准化的，因此我就不赘述其源码了，如果你需要更多细节，请看&lt;a href=&quot;http://gist.github.com/491973&quot;&gt;Gist&lt;/a&gt;。以下是基于Python的相关方法：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;def levenshtein_automata(term, k):
  nfa = NFA((0, 0))
  for i, c in enumerate(term):
    for e in range(k + 1):
      # Correct character
      nfa.add_transition((i, e), c, (i + 1, e))
      if e &amp;lt; k:
        # Deletion
        nfa.add_transition((i, e), NFA.ANY, (i, e + 1))
        # Insertion
        nfa.add_transition((i, e), NFA.EPSILON, (i + 1, e + 1))
        # Substitution
        nfa.add_transition((i, e), NFA.ANY, (i + 1, e + 1))
  for e in range(k + 1):
    if e &amp;lt; k:
      nfa.add_transition((len(term), e), NFA.ANY, (len(term), e + 1))
    nfa.add_final_state((len(term), e))
  return nfa&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;这应该很容易实现，基本上我们用了一种最直接了当的方式构建前图中表示的变换，同时也指出了最终正确的状态集。状态标签是元组，而不是字符串，这与我们前面的描述是一致的。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;由于这是一个NFA，可以有多个活跃状态，它们表示目前被处理过的字符串的可能解释。举个例子，考虑一下，在处理字符f和x之后的活跃状态：&lt;br&gt;
&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/3682a608e5f46e40f44bbfd6a42c5f1b.png&quot; rel=&quot;lightbox[80659]&quot; title=&quot;超酷算法：Levenshtein自动机&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-80664&quot; alt=&quot;levenstein-nfa-food-fx&quot; src=&quot;/images/jobbole.com/19167bafc87acf89bff84640194770ff.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;这表明，在前两个字符f和x一致的情况下，会存在若干可能的变化：一次替换，如fxod；一次插入，如fxood；两次插入，如fxfood；或者一次交换和一次删除，如fxd。同时，这也会引入了一些冗余的情况，如一次删除和一次插入，结果也是fxod。随着越来越多的字符被处理，其中一些可能性会慢慢消失，而另一些可能性会逐渐产生。如果，在处理完整个单词的所有字符后，在当前状态集中存在一个接收状态（bolded state），那么就表明存在一种方式，能够将通过两次或更少次的变换，将输入单词转化为目标单词，那么我们就可以将该单词视为是有效的。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;实际上，要直接评价一个NFA，从计算的角度来讲是极其昂贵的，因为会存在多个活跃状态和epsilon变换（不需要输入符号的变换），所以通常的做法是首先使用powerset构建法将NFA转换为DFA（译者注：确定性有限自动机）。使用这个算法能够构建出一个DFA，使每一个状态都对应原来NFA中的一个活跃状态集。在这里我们不会涉及powerset的细节，因为这有点扯远了。以下是一个例子，展示了在一个容差下，单词food的NFA所对应的DFA：&lt;br&gt;
&lt;a href=&quot;http://jbcdn2.b0.upaiyun.com/2014/12/243afd6875cd002f29536238499132c2.png&quot; rel=&quot;lightbox[80659]&quot; title=&quot;超酷算法：Levenshtein自动机&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-80665&quot; alt=&quot;levenstein-dfa-food&quot; src=&quot;/images/jobbole.com/d89c2910c066835ba29c6c6d1c8ac55e.jpg&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;记住，我们是在一个容差下描述DFA的，因为要找出完全匹配我们提到的NFA所对应的DFA实在是太复杂了！以上DFA能准确接收与单词food相距一个或更少编辑距离的单词集。试试看，选择任意一个单词，通过DFA跟踪它的路径，如果你最终能到达一个接收状态，则这个单词是有效的。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;我不会把power构建的源码贴在这里，同样的，如果你感兴趣，可以在&lt;a href=&quot;http://gist.github.com/491973&quot;&gt;GIST&lt;/a&gt;里找到。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;我们暂时回到执行效率的问题上来，你可能想知道Levenshtein DFA构建的效率怎么样。我们可以在O(kn)时间内构建NFA，k是指编辑距离，n是指目标单词的长度。将其变换为DFA的最坏情况需要O(2^n)时间，所以极端情况下会需要O(2^kn)运行时间！不过情况并没有那么糟糕，有两个原因：首先，Levenshtein自动机并不会充斥着2^n这种最坏情况的DFA构建；其次，一些智慧的计算机科学家已经提出了一些算法，能够在O(n)时间内直接构建出DFA，甚至还有人[&lt;a href=&quot;http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata#schulz2002fast&quot;&gt;SCHULZ2002FAST&lt;/a&gt;]完全避开了DFA构建，使用了一种基于表格的评价方法！&lt;/p&gt;
&lt;h1&gt;索引&lt;/h1&gt;
&lt;p align=&quot;left&quot;&gt;既然我们已经证实可以构建一个Levenshtein自动机，并演示了其工作原理，下面我们来看一看如何使用这项技术高效地模糊匹配搜索索引。第一个观点，同时也是很多论文[&lt;a href=&quot;http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata#schulz2002fast&quot;&gt;SCHULZ2002FAST&lt;/a&gt;] [&lt;a href=&quot;http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata#mihov2004fast&quot;&gt;MIHOV2004FAST&lt;/a&gt;]所采用的方法，就是去观测一本字典，即你所要搜索的记录集，它自身可以被视为是一个DFA。事实上，他们经常被存储为一种字典树或有向非循环字图，这两种结构都可以被视为是DFA的特例。假设字典和标准（Levenshtein自动机）都表示为DFA，之后我们就可以高效地通过这两个DFA，准确地在字典中找到符合标准的单词集，过程非常简单，如下：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;def intersect(dfa1, dfa2):
  stack = [(&quot;&quot;, dfa1.start_state, dfa2.start_state)]
  while stack:
    s, state1, state2 = stack.pop()
    for edge in set(dfa1.edges(state1)).intersect(dfa2.edges(state2)):
      state1 = dfa1.next(state1, edge)
      state2 = dfa2.next(state2, edge)
      if state1 and state2:
        s = s + edge
        stack.append((s, state1, state2))
        if dfa1.is_final(state1) and dfa2.is_final(state2):
          yield s&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;好了，我们按照两个DFA共有的边界同时进行遍历，并记录遍历的路径轨迹。只要两个DFA处于最终状态，单词在输出集内，我们就将其输出。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;如果你的索引是以DFA（或字典树，或有向非循环字图）的形式存储的话，这非常完美，但遗憾的是许多索引并不是：如果在内存中，它们很可能位于一个排序列表中；如果在磁盘上，它们很可能位于BTree或类似结构中。有没有办法可以让我们修改方案适应这些排序索引，继而继续提供一种速度极快的方法？事实证明是有的。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;这里的关键点在于，根据我们目前以DFA表示的标准，我们可以，对于一个不匹配的输入字符串，找到下一个（按字母排序）匹配的字符串。凭直觉来说，这相当容易：我们基于DFA去评估输入字符串，直到我们无法进一步处理为止，比如说没有针对下一个字符的有效变换，之后，我们可以反复遵照字母排序的最小标签的边界，直到到达终态。在这里我们应用了两个特殊事件：首先，在第一次变换中，我们需要遵照按字母排序的最小标签，同时这些标签要大于在准备步骤中没有有效变换的特性。第二，如果我们达到了一个状态而其没有有效的外边界，那么我们要回溯到之前的状态，并重试。这差不多是解决迷宫问题的一种“循墙”算法，应用在DFA上。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;以此举例，参照food(1)的DFA，我们来思考一下输入单词foogle。我们可以有效处理前4个单词，留下状态3&lt;sup&gt;1&lt;/sup&gt;4&lt;sup&gt;1&lt;/sup&gt;，这里唯一的外边界是d，下一个字符是l，因此我们可以向前回溯一步，到2&lt;sup&gt;1&lt;/sup&gt;3&lt;sup&gt;0&lt;/sup&gt;3&lt;sup&gt;1&lt;/sup&gt;4&lt;sup&gt;1&lt;/sup&gt;，现在下一个字符是g，有一个外边界f，所以我们接收这个边界，留下接收状态（事实上，和之前的状态是一样的，只不过路径不同），输出单词为fooh，这是在DFA中按字母排序在foogle之后的单词。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;以下是python代码，展示了在DFA类上的一个方法。和前面一样，我不会写出整个DFA的样板代码，它们都在&lt;a href=&quot;http://blog.notdot.net/2010/07/&quot;&gt;这里&lt;/a&gt;。&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;def next_valid_string(self, input):
    state = self.start_state
    stack = []

    # Evaluate the DFA as far as possible
    for i, x in enumerate(input):
      stack.append((input[:i], state, x))
      state = self.next_state(state, x)
      if not state: break
    else:
      stack.append((input[:i+1], state, None))

    if self.is_final(state):
      # Input word is already valid
      return input

    # Perform a &#39;wall following&#39; search for the lexicographically smallest
    # accepting state.
    while stack:
      path, state, x = stack.pop()
      x = self.find_next_edge(state, x)
      if x:
        path += x
        state = self.next_state(state, x)
        if self.is_final(state):
          return path
        stack.append((path, state, None))
    return None&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;在这个方法的第一部分，我们以常见的方式评价DFA，记录下访问过的状态，这些状态包括它们的路径以及我们尝试寻找遵循它们的边界。之后，假设没有找到一个准确的匹配项，那么就进行一次回溯，尝试去寻找一个可以到达接收状态的最小变换集。关于这个方法的一般性说明，请继续阅读……&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;同时我们还需要一个工具函数find_next_edge，找出一个状态中按字母排序比指定输入大的最小外边界：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;def find_next_edge(self, s, x):
    if x is None:
      x = u&#39;&#39;
    else:
      x = unichr(ord(x) + 1)
    state_transitions = self.transitions.get(s, {})
    if x in state_transitions or s in self.defaults:
      return x
    labels = sorted(state_transitions.keys())
    pos = bisect.bisect_left(labels, x)
    if pos &amp;lt; len(labels):
      return labels[pos]
    return None&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;经过一些预处理，这可以更高效，打个比方，我们可以对每个字符和第一个大于它的外边界建立一个映射关系，而不是在茫茫大海中进行二进制检索。再强调一次，我会把这些优化工作作为练习题留给读者。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;既然我们已经找到了这一过程，那么我们就可以最终描述如何使用这一过程进行索引搜索，算法出人意料的简单：&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;1. 取得索引中的第一个元素，或者，比索引任意有效字符串更小的一个字符串，将其称之为“当前”字符串。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;2. 将“当前”字符串传入我们之前谈到的DFA算法，得到“下一个”字符串。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;3. 如果“下一个”字符串和“当前”字符串相等，那么你已经找到了一个匹配，将其输出，再从索引中获取下一个元素作为“当前”元素，重复步骤2。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;4. 如果“下一个”字符串和“当前”字符串不相等，那么在你的索引中搜索大于等于“下一个”字符串的第一个字符串，将其作为“当前”元素，重复步骤2。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;以下是用Python实现这一过程的代码：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;def find_all_matches(word, k, lookup_func):
  &quot;&quot;&quot;Uses lookup_func to find all words within levenshtein distance k of word.

  Args:
    word: The word to look up
    k: Maximum edit distance
    lookup_func: A single argument function that returns the first word in the
      database that is greater than or equal to the input argument.
  Yields:
    Every matching word within levenshtein distance k from the database.
  &quot;&quot;&quot;
  lev = levenshtein_automata(word, k).to_dfa()
  match = lev.next_valid_string(u&#39;&#39;)
  while match:
    next = lookup_func(match)
    if not next:
      return
    if match == next:
      yield match
      next = next + u&#39;&#39;
    match = lev.next_valid_string(next)&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;理解这一算法的一种方式是将Levenshtein DFA和索引都视为排序列表，那么以上过程就类似于App引擎中的“拉链合并连接”策略。我们重复地在一侧查找字符串，再跳转到另一侧的合适位置，等等。结果是，我们省去了大量不匹配的索引实体，以及大量不匹配的Levenshtein字符串，节省了枚举它们的工作量。这些描述表明，这一过程有潜力避免去评估所有的索引实体，或所有的候选Levenshtein字符串。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;补充说明一下，所有的DFA针对任意字符串都可以找到按字母排序的最小后继，这句话是错误的。比如说，考虑一下DFA中字符串a的后继，识别模式为a+b，答案是没有这样的后继，它必须由无限多的a字符跟随单个b字符构成！不过我们可以基于以上过程做一些简单的修改，比如返回一个字符串，确保它是DFA可以识别的下一个字符串的一个前缀，这能满足我们的需求。由于Levenshtein DFA总是有限的，因此我们总是会得到一个有限长度的后继（当然，除了最后一个字符串），我们把这样的扩展留给读者作为练习题。使用这种方法，会产生一些很有意思的应用程序，比如索引化正则表达式搜索。&lt;/p&gt;
&lt;h1&gt;测试&lt;/h1&gt;
&lt;p align=&quot;left&quot;&gt;首先，我们理论联系实际，定义一个简单的Matcher类，其中实现了一个lookup_func方法，它会被find_all_matches方法调用：&lt;/p&gt;
&lt;pre class=&quot;brush: python; gutter: true&quot;&gt;class Matcher(object):
  def __init__(self, l):
    self.l = l
    self.probes = 0

  def __call__(self, w):
    self.probes += 1
    pos = bisect.bisect_left(self.l, w)
    if pos &amp;lt; len(self.l):
      return self.l[pos]
    else:
      return None&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;记住，在此我们实现一个可调用的类的唯一理由是：我们想要从程序中提取一些信息，比如探针的个数。通常来说，一个常规或嵌套函数已经足够完美，现在，我们需要一个简单的数据集，让我们加载web2字典：&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt;&amp;gt;&amp;gt;&amp;gt; words = [x.strip().lower().decode(&#39;utf-8&#39;) for x in open(&#39;/usr/share/dict/web2&#39;)]
&amp;gt;&amp;gt;&amp;gt; words.sort()
&amp;gt;&amp;gt;&amp;gt; len(words)
234936&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;我们也可以使用几个子集测试随着数据规模的变化，会发生什么：&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt;&amp;gt;&amp;gt;&amp;gt; words10 = [x for x in words if random.random() &amp;lt;= 0.1]
&amp;gt;&amp;gt;&amp;gt; words100 = [x for x in words if random.random() &amp;lt;= 0.01]&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;这里，我们看到了实践结果：&lt;/p&gt;
&lt;pre class=&quot;brush: text; gutter: true&quot;&gt;&amp;gt;&amp;gt;&amp;gt; m = Matcher(words)
&amp;gt;&amp;gt;&amp;gt; list(automata.find_all_matches(&#39;nice&#39;, 1, m))
[u&#39;anice&#39;, u&#39;bice&#39;, u&#39;dice&#39;, u&#39;fice&#39;, u&#39;ice&#39;, u&#39;mice&#39;, u&#39;nace&#39;, u&#39;nice&#39;, u&#39;niche&#39;, u&#39;nick&#39;, u&#39;nide&#39;, u&#39;niece&#39;, u&#39;nife&#39;, u&#39;nile&#39;, u&#39;nine&#39;, u&#39;niue&#39;, u&#39;pice&#39;, u&#39;rice&#39;, u&#39;sice&#39;, u&#39;tice&#39;, u&#39;unice&#39;, u&#39;vice&#39;, u&#39;wice&#39;]
&amp;gt;&amp;gt;&amp;gt; len(_)
23
&amp;gt;&amp;gt;&amp;gt; m.probes
142&lt;/pre&gt;
&lt;p align=&quot;left&quot;&gt;大赞啊！在拥有235000个单词的字典中找到了针对nice的23个模拟匹配，需要142个探针。注意，如果我们假设一个字母表包含26个字母，那么会有4+26*4+26*5=238个字符串在一个Levenshtein距离内是有效的，因此与详尽的测试相比，我们做出了合理的节省。考虑到有更大的字母表，更长的字符串，或更大的编辑距离，这种节省的效果应该会更明显。如果我们使用不同种类的输入去测试，看一下探针的个数随着单词长度和字典大小的变化情况，可能会更受启发：&lt;/p&gt;
&lt;table border=&quot;1&quot; cellpadding=&quot;0&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p align=&quot;left&quot;&gt;在这个表中，”max strings”表示与输入字符串在编辑距离内的字符串总数；small，med，full dict表示所有三种字典（包含web2字典的1%，10%和100%）所需要的探针个数。所有对应的行，至少在10个字符以内，都需要与第五行差不多的探针个数。我们采用的输入字符串的例子是由单词’abracadabra’的前缀构成的。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;我们可以立即看出一些端倪：&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;1. 对于很短的字符串和很大的字典，探针的个数并没有低很多，即使低一些，和有效字符串的最大个数相比也是小巫见大巫，所以这并没有节省什么。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;2. 随着字符串越来越长，探针的个数的增长出人意料的比预期结果慢，结果就是对于10个字符，我们仅仅需要探测821中的161个（大约20%）可能结果。对于一般的单词长度（在web2字典中，97%的单词至少有5个字符长），与朴素的检查每个字符串变化相比，我们已经节省了可观的代价。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;3. 虽然样本字典的大小以不同的数量级区分，但是探针的个数增长却不太明显，这是一项令人鼓舞的证据，它表明该方法可以很好的扩展到非常大的索引数量级上。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;我们再来看一下根据不同的编辑距离阈值，情况会有何变化，你同样能得到一些启发。下面是相同的表格，最大编辑距离为2：&lt;/p&gt;
&lt;table border=&quot;1&quot; cellpadding=&quot;0&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;td&gt;

&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p align=&quot;left&quot;&gt;前途一片光明：在编辑距离为2的情况下，虽然我们被迫需要加入很多探针，但是与候选字符串的数量相比，仍然是很小的代价。对于一个长度为5、编辑距离为2的单词，需要使用3377个探针，但是比起做69258次（对每一个匹配字符串）或做234936次（对字典里的每个单词），这显然少得多了！&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;我们来做一个快速比较，对于一个长度为5的字符串，编辑距离为1（与上面的例子一样），一个标准的BK树实现，基于相同的字典，需要检查5858个节点，同时，相同的情况下，我们把编辑距离改为2，则需要检查58928个节点！应当承认，如果结构合理的话，这些节点中很多都应处于相同的磁盘页，但是依然存在惊人的查找数量级的差异。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;最后一点：我们在这篇文章中参考的第二篇论文，[&lt;a href=&quot;http://blog.notdot.net/2010/07/Damn-Cool-Algorithms-Levenshtein-Automata#mihov2004fast&quot;&gt;MIHOV2004FAST&lt;/a&gt;]描述了一个非常棒的结构：一个广义的Levenshtein自动机。这是一种DFA，它能在线性时间内判断，任意一组单词对互相之间的距离是否小于给定的编辑距离。改造一下我们前面的方案，使其能适应这种自动机，这也是我们留给读者的练习。&lt;/p&gt;
&lt;p align=&quot;left&quot;&gt;这篇文章是涉及的完整的源代码都可以在&lt;a href=&quot;http://gist.github.com/491973&quot;&gt;这里&lt;/a&gt;找到。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Wed, 10 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-10-80659-8f286134e.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-10-80659-8f286134e.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>HBase SSD优化案例：读策略优化和中断多核绑定</title>
        <description>

                &lt;p&gt;没有开场白，直接切主题！各位把这篇当成是报告来阅读吧：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;应用IO模型：&lt;/strong&gt;大量读线程同时访问多块SSD，请求均为4KB随机读，并且被请求的数据有一定间隔连续性；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;服务器硬件配置：&lt;/strong&gt;LSI SAS 2308直连卡 + 8块SSD&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;优化前应用QPS：27K&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一轮优化：读策略优化&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过 /sys/block/sdx/queue/read_ahead_kb 观察到预读大小为128KB，进一步观察iostat情况：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/preopt_iostat.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-1781&quot; alt=&quot;preopt_iostat&quot; src=&quot;/images/noops.me/94d5b0edaa24c4a356c857a423e1cc35.jpg&quot; width=&quot;850&quot; height=&quot;523&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;观察到每块SSD的rMB/s十分高，平均已经达到了250MB/s+，初步判断是由于read_ahead_kb的设置影响了应用的读效率（即预先读取了过多不必要的数据）。遂将read_ahead_kb设置为0，观察iostat情况如下：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/preopt_iostat_rak0.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-1782&quot; alt=&quot;preopt_iostat_rak0&quot; src=&quot;/images/noops.me/36ecc992eed341f504b30a09820bd099.jpg&quot; width=&quot;858&quot; height=&quot;646&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;而应用QPS却下降至25K！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;分析原因：由于之前有预读功能存在，因此部分数据已经被预先读取而减轻了SSD的访问压力。将read_ahead_kb设置为0后，所有的读访问均通过随机读实现，一定程度上加重了SSD的访问压力（可以观察到之前%util大约在60~80%之间波动，而预读改成0之后%util则在80~90%之间波动）&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;尝试16K预读&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过IO模型了解到每次请求的数据大小为4KB，因此将read_ahead_kb设置为16KB进行尝试，&lt;span style=&quot;color: #ff0000;&quot;&gt;结果QPS由25K猛增到34K！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;观察iostat情况如下：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/preopt_iostat_rak16.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-1783&quot; alt=&quot;preopt_iostat_rak16&quot; src=&quot;/images/noops.me/d11439c036071bcc7447fb7e60f60450.jpg&quot; width=&quot;858&quot; height=&quot;647&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;%util降了不少，而且通过rrqm/s可以发现出现了一部分读合并的请求，这说明优化确有成效。&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;此时&lt;/span&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;CPU_WA也由原来的平均30%下降到20%，这说明处理器等待IO的时间减少了，进一步验证了IO优化的有效性。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二轮优化：直连卡中断多核绑定&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;考虑到SSD的随机读写能力较强（通过上面的iostat可以发现），在多盘环境下每秒产生的IO请求数也已接近100K，了解到LSI SAS 2308芯片的IOPs处理极限大约在250K左右，因此判断直连卡控制芯片本身并不存在瓶颈。&lt;/p&gt;
&lt;p&gt;其实我们担心更多的是如此大量的IO请求数必定会产生庞大数量的中断请求，如果中断请求全部落在处理器的一个核心上，可能会对单核造成较高的压力，甚至将单核压力打死。因此单核的中断请求的处理能力就有可能成为整个IO系统的瓶颈所在，于是我们通过mpstat观察每个核心上的中断数：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/mpstat_preopt.png&quot;&gt;&lt;img alt=&quot;mpstat_preopt&quot; src=&quot;/images/noops.me/08dfaec1aaee7dfe5f109e5532aaf575.jpg&quot; width=&quot;219&quot; height=&quot;349&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以发现第二个核心中断数已经达到了十分恐怖的80K！再来观察实际的处理器核心压力情况，为了能够更加直观地了解，我们用了比较准确的i7z工具来观察：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/i7z_preopt.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-1785&quot; alt=&quot;i7z_preopt&quot; src=&quot;/images/noops.me/93111b8ebcfd0fda1f13ded5f2cecfc3.jpg&quot; width=&quot;698&quot; height=&quot;180&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;果然不出所料，Core 1的Halt（idle）已经到了1，充分说明第二个核心确实已经满载。&lt;/p&gt;
&lt;p&gt;那么通过观察/proc/interrupt的情况再来进一步验证我们的假设，：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/inter.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-1786&quot; alt=&quot;inter&quot; src=&quot;/images/noops.me/9b55ac6011fd50bd15aca0dcb063514d.jpg&quot; width=&quot;756&quot; height=&quot;775&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我们截取了片段，可以发现mpt2sas0-misx的大部分压力都集中在了CPU 1上，并且我们发现直连卡模式是支持多队列的（注意观察irq号从107至122，mpt2sas驱动总共有16个中断号），因此我们将实际在处理中断的irq号107至118分别绑定至不同的核心上（这里就不再赘述有关多核绑定的原理，有兴趣的同学可以百度搜索以上命令的含义）：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/smp.png&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-1787&quot; alt=&quot;smp&quot; src=&quot;/images/noops.me/adc68b30e71a0d71bc8ccb2d04475615.jpg&quot; width=&quot;313&quot; height=&quot;158&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;随后我们惊奇地观察到应用的&lt;span style=&quot;color: #ff0000;&quot;&gt;QPS由34K再次猛增至39K！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;&lt;span style=&quot;color: #000000;&quot;&gt;通过观察mpstat发现大量的中断被平均分散到了不同的处理器核心上：&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://noops.me/wp-content/uploads/2014/12/mpstat_after.png&quot;&gt;&lt;img alt=&quot;mpstat_after&quot; src=&quot;/images/noops.me/3cb3e08b38a142113205e283e2f428de.jpg&quot; width=&quot;213&quot; height=&quot;344&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #ff0000;&quot;&gt;并且CPU_WA也由平均20%下降到15%，io wait被进一步优化！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;优化总结：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过以上两个优化方法将应用的QPS由27K优化至39K，并且处理器的iowait由30%下降至15%，优化收效显著；&lt;/li&gt;
&lt;li&gt;SSD的优化要根据实际的应用IO模型和设备的理论极限值进行综合考虑，同时还要考虑到各个层面的瓶颈（包括内核、IO策略、磁盘接口速率、连接控制芯片等）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt; &lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
            

</description>
        <pubDate>Wed, 10 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-10--p=1778-c0a873ab4.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-10--p=1778-c0a873ab4.html</guid>
        
        
        <category>noops</category>
        
      </item>
    
      <item>
        <title>如何研究学习一个机器学习算法</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;机器学习算法都是一个个复杂的体系，需要通过研究来理解。学习算法的静态描述是一个好的开始，但是这并不足以使我们理解算法的行为，我们需要在动态中来理解算法。&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;机器学习算法的运行实验，会使你对于不同类型问题得出的实验结论，并对实验结论与算法参数两者的因果关系有一个直观认识。&lt;/p&gt;
&lt;p&gt;在这篇文章中，你将会知道怎么研究学习一个机器学习算法。你将会学到5个简单步骤，你可以用来设计和完成你的第一个机器学习算法实验&lt;/p&gt;
&lt;p&gt;你会发现机器学习实验不光是学者们的专利，你也可以；你也会知道实验是通往精通的必经之路，因为你可以从经验中学到因果关系的知识， 这是其它地方学不到的。&lt;/p&gt;
&lt;h2&gt;什么是研究机器学习算法&lt;/h2&gt;
&lt;p&gt;当研究一个机器学习算法的时候，你的目标是找到可得到好结果的机器算法行为，这些结果是可以推广到多个问题或者多个类型的问题上。&lt;/p&gt;
&lt;p&gt;你通过对算法状态做系统研究来研究学习机器学习算法。这项工作通过设计和运行可控实验来完成&lt;/p&gt;
&lt;p&gt;一旦你完成了一项实验，你可以对结论作出解释和提交。这些结论会让你得以管窥在算法变化中因果关系。这就是算法行为和你获得的结论间的关系。&lt;/p&gt;
&lt;h2&gt;怎样研究学习机器学习算法&lt;/h2&gt;
&lt;p&gt;在这一部分，我们将学到5个简单的步骤，你可以通过它来研究学习一个机器算法&lt;/p&gt;
&lt;h3&gt;1.选择一个算法&lt;/h3&gt;
&lt;p&gt;选择一个你有疑问的算法&lt;/p&gt;
&lt;p&gt;这个算法可能是你正在某个问题上应用的，或者你发现在其他环境中表现很好，将来你想使用&lt;/p&gt;
&lt;p&gt;就实验的意图来说，使用现成的算法是有帮助的。这会给你一个底线：存在bug几率最低&lt;/p&gt;
&lt;p&gt;自己实现一个算法可能是了解算法过程的一个好的方式，但是，实验期间，会引入额外的变量，比如bug，和大量必须为算法所做的微观决策&lt;/p&gt;
&lt;h3&gt;2.确定一个问题&lt;/h3&gt;
&lt;p&gt;你必须有一个你试图寻找答案的研究问题。问题越明确，问题越有用&lt;/p&gt;
&lt;p&gt;给出的示例问题包括以下几个方面：&lt;/p&gt;
&lt;p&gt;KNN算法中，作为样本空间中的一部分的K值在增大时有什么影响？&lt;/p&gt;
&lt;p&gt;在SVM算法中，选择不同的核函数在二分类问题上有什么影响 ？&lt;/p&gt;
&lt;p&gt;在二分类问题中，逻辑回归上的不同参数的缩放有什么影响 ？&lt;/p&gt;
&lt;p&gt;在随机森林模型中，在训练集上增加任意属性对在分类准确性上有什么影响？&lt;/p&gt;
&lt;p&gt;针对算法，设计你想回答的问题。仔细考虑，然后列出5个逐渐演变的问题，并且深入推敲那个最精确的&lt;/p&gt;
&lt;h3&gt;3.设计实验&lt;/h3&gt;
&lt;p&gt;从你的问题中挑选出关键元素然后组成你的实验内容。 例如，拿上面的示例问题为例：“二元分类问题中逻辑回归上的不同的参数缩放有什么影响？”&lt;/p&gt;
&lt;p&gt;你从这个问题中挑出来用来设计实验的元素是：&lt;/p&gt;
&lt;p&gt;属性缩放法：你可以采用像正态化、标准化，将某一属性提升至乘方、取对数等方法&lt;/p&gt;
&lt;p&gt;逻辑回归：你想使用哪种已经实现的逻辑回归。&lt;/p&gt;
&lt;p&gt;二元分类问题：存在数值属性不同的二分类问题标准。需要准备多种问题，其中一些问题的规模是相同的（像电离层），然而其他一些问题的属性有不同的缩放值（像糖尿病问题）。&lt;/p&gt;
&lt;p&gt;性能： 类似分类准确性的模型性能分数是需要的&lt;/p&gt;
&lt;p&gt;花时间仔细挑选你问题中的组成元素以便为你的问题给出最佳解答。&lt;/p&gt;
&lt;h3&gt;4. 进行试验并且报告你的结论&lt;/h3&gt;
&lt;p&gt;完成你的实验&lt;/p&gt;
&lt;p&gt;如果算法是随机的，你需要多次重复实验操作并且记录一个平均数和标准偏差&lt;/p&gt;
&lt;p&gt;如果你试图寻找在不同实验（比如带有不同的参数）之间结果的差异，你可能想要使用一种统计工具来标明差异是否统计上显著的（就像学生的t检验）&lt;/p&gt;
&lt;p&gt;一些工具像R和scikit-learn/SciPy完成这些类型的实验，但是你需要把它们组合在一起，并且为实验写脚本。其他工具像Weka带有图形用户界面，你所使用的工具不要影响问题和你实验设计的严密&lt;/p&gt;
&lt;p&gt;总结你的实验结论。你可能想使用图表。单独呈现结果是不够的，他们只是数字。你必须将数字和问题联系起来，并且通过你的实验设计提取出它们的意义&lt;/p&gt;
&lt;p&gt;对实验问题来说，实验结果又暗示着什么呢？&lt;/p&gt;
&lt;p&gt;保持怀疑的态度。你的结论上有留什么样的漏洞和局限呢。不要逃避这一部分。知道局限性和知道实验结果一样重要&lt;/p&gt;
&lt;h3&gt;5. 重复&lt;/h3&gt;
&lt;p&gt;重复操作&lt;/p&gt;
&lt;p&gt;继续研究你选择的算法。你甚至想要重复带有不同参数或者不同的测试数据集的同一个实验。你可能想要处理你试验中的局限性&lt;/p&gt;
&lt;p&gt;不要只停留在一个算法上，开始建立知识体系和对算法的直觉&lt;/p&gt;
&lt;p&gt;通过使用一些简单工具，提出好的问题，保持严谨和怀疑的态度，你对机器算法行为的理解很快就会到达世界级的水平&lt;/p&gt;
&lt;h2&gt;研究学习算法不仅仅是学者才能做的&lt;/h2&gt;
&lt;p&gt;你也可以学习研究机器学习算法。&lt;/p&gt;
&lt;p&gt;你不需要一个很高的学位，你不需要用研究的方式训练，你也不需要成为一名学者&lt;/p&gt;
&lt;p&gt;对每个拥有计算机和浓厚兴趣的人来说，机器学习算法的系统研究学习是开放的。事实上，如果你主修机器学习，你一定会适应机器学习算法的系统研究。知识根本不会自己出来，你需要靠自己的经验去得到&lt;/p&gt;
&lt;p&gt;当谈论你的发现的适用性时，你需要保持怀疑和谨慎&lt;/p&gt;
&lt;p&gt;你不一定提出独一无二的问题。通过研究一般的问题，你也将会收获很多，例如根据一些一般的标准数据集总结出一个参数的普遍影响。你保不住会发现某些具有最优方法的常例的局限性甚至反例。&lt;/p&gt;
&lt;h2&gt;行动步骤&lt;/h2&gt;
&lt;p&gt;在本篇文章中，通过可控实验你知道了研究学习机器学习算法行为的重要性。你掌握了简单的5个步骤，你可以在一个机器学习算法上设计和运行你的第一项实验&lt;/p&gt;
&lt;p&gt;采取行动。使用你在这篇博文中学到的步骤，来完成你的第一个机器学习实验。一旦你完成了一个，甚至是很小的一个，你将会获得自信，工具、能力来完成第二个以及更多&lt;/p&gt;

&lt;/div&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Tue, 09 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-09-80658-c67556c21.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-09-80658-c67556c21.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>Kibana 中几个不同的 filtering</title>
        <description>

  
  &lt;div style=&quot;background-color: #FFF;&quot;&gt;
    &lt;p&gt;用过 kibana 的都知道，kibana 的图表上，可以直接点击某个值，就能自动添加这个过滤条件到 filtering 里，然后整个 dashboard 上所有的图表都会刷新成在这个过滤条件下的新状态。但是如果你要想自己手动添加 filtering 的时候，就会发现，自己添加的，写法好像跟自动生成的长得不太一样。&lt;/p&gt;
&lt;p&gt;而今天，我在同事的提醒下，发现更进一步的情况，即使都是通过点击图表添加上的 filtering，其实长得也不一样，如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/chenlinux.com/14899b570407acac411b3be94628b0a4.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;在 histogram 面板上拖拽鼠标，生成的是 range filtering&lt;/li&gt;
  &lt;li&gt;在 terms 面板上点击某个值，生成的是 term filtering&lt;/li&gt;
  &lt;li&gt;在 table 面板左侧列表上点击某个字段，浮出的小面板里点击某个值，生成的是 query filtering&lt;/li&gt;
  &lt;li&gt;在 filtering 手工添加，生成的是 query_string filtering&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这几个页面上的不同，反应在实际的请求 JSON 里又有什么区别呢？&lt;/p&gt;
&lt;p&gt;我们可以点开面板右上角的 inspect 按钮看生成的 curl 命令。其中 filtering 部分如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;s2&quot;&gt;&quot;filter&quot;&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&quot;bool&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&quot;must&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&quot;range&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&quot;@timestamp&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&quot;from&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1418009781101&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&quot;to&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;now&quot;&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&quot;terms&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&quot;_type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
                &lt;span class=&quot;s2&quot;&gt;&quot;mweibo_webinf&quot;&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&quot;fquery&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&quot;query&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&quot;query_string&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&quot;query&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;host:(\&quot;web093.mweibo.tc.sinanode.com\&quot;)&quot;&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&quot;_cache&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&quot;fquery&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&quot;query&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                &lt;span class=&quot;nt&quot;&gt;&quot;query_string&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                  &lt;span class=&quot;nt&quot;&gt;&quot;query&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;host:\&quot;web093.mweibo.tc.sinanode.com\&quot;&quot;&lt;/span&gt;
                &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&quot;_cache&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
            &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;前面两个不出意外，都是很标准的 api 示例的样子。比较特殊的是后面两个：&lt;/p&gt;
&lt;p&gt;第三个其实就是通过 table 左侧字段菜单点出来的，虽然通过鼠标点击操作，只可能生成一个单一的键值查询，但这里却给加上了一对小括号！这是完全没有必要的，简直可以怀疑是不是当初开发人员手抖了……&lt;/p&gt;
&lt;p&gt;当然，并不是说这种生成完全没有用。比方说，其实你本来是打算查询来自两台机器的日志。如果没想到用括号，可能直接在 query_string 里就写 &lt;code&gt;host:&quot;web001&quot; OR host:&quot;web002&quot;&lt;/code&gt; 了。但是在这个 query filtering 里，因为页面上已经有单独填字段的地方了。那就只用在 query 那栏写 &lt;code&gt;&quot;web001&quot; OR &quot;web002&quot;&lt;/code&gt; 好了。&lt;/p&gt;
&lt;p&gt;以上。不过我依然怀疑是开发人员手抖。&lt;/p&gt;
    &lt;hr&gt;
    
    &lt;hr&gt;
  &lt;!-- JiaThis Button BEGIN --&gt;
&lt;div class=&quot;jiathis_style&quot;&gt;
&lt;span class=&quot;jiathis_txt&quot;&gt;分享到：&lt;/span&gt;
&lt;a class=&quot;jiathis_button_tsina&quot;&gt;新浪微博&lt;/a&gt;
&lt;a class=&quot;jiathis_button_weixin&quot;&gt;微信&lt;/a&gt;
&lt;a class=&quot;jiathis_button_renren&quot;&gt;人人网&lt;/a&gt;
&lt;a class=&quot;jiathis_button_ydnote&quot;&gt;有道云笔记&lt;/a&gt;
&lt;a class=&quot;jiathis_button_gmail&quot;&gt;Gmail邮箱&lt;/a&gt;
&lt;a class=&quot;jiathis_button_twitter&quot;&gt;Twitter&lt;/a&gt;
&lt;a class=&quot;jiathis_button_googleplus&quot;&gt;Google+&lt;/a&gt;
&lt;a class=&quot;jiathis_button_hi&quot;&gt;百度空间&lt;/a&gt;
&lt;a class=&quot;jiathis_button_fb&quot;&gt;Facebook&lt;/a&gt;
&lt;a class=&quot;jiathis_button_douban&quot;&gt;豆瓣&lt;/a&gt;
&lt;a href=&quot;http://www.jiathis.com/share?uid=1589850&quot; class=&quot;jiathis jiathis_txt jiathis_separator jtico jtico_jiathis&quot; target=&quot;_blank&quot;&gt;更多&lt;/a&gt;
&lt;a class=&quot;jiathis_counter_style&quot;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var jiathis_config={
	data_track_clickback:true,
	summary:&quot;&quot;,
	ralateuid:{
		&quot;tsina&quot;:&quot;1035836154&quot;
	},
	shortUrl:false,
	hideMore:false
}
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://v3.jiathis.com/code/jia.js?uid=1589850&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;!-- JiaThis Button END --&gt;
&lt;!-- UY BEGIN --&gt;


&lt;!-- UY END --&gt;
  &lt;/div&gt;

</description>
        <pubDate>Mon, 08 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-08-difference-filterings-kibana-a2d6b87c1.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-08-difference-filterings-kibana-a2d6b87c1.html</guid>
        
        
        <category>chenlinux</category>
        
      </item>
    
      <item>
        <title>lucene字典实现原理</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;h2&gt;1 lucene字典&lt;/h2&gt;
&lt;p&gt;使用lucene进行查询不可避免都会使用到其提供的字典功能，即根据给定的term找到该term所对应的倒排文档id列表等信息。实际上lucene索引文件后缀名为tim和tip的文件实现的就是lucene的字典功能。&lt;/p&gt;
&lt;p&gt;怎么实现一个字典呢？我们马上想到排序数组，即term字典是一个已经按字母顺序排序好的数组，数组每一项存放着term和对应的倒排文档id列表。每次载入索引的时候只要将term数组载入内存，通过二分查找即可。这种方法查询时间复杂度为Log(N)，N指的是term数目，占用的空间大小是O(N*str(term))。排序数组的缺点是消耗内存，即需要完整存储每一个term，当term数目多达上千万时，占用的内存将不可接受。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ed396eee2b81ca658b91a74f448f3152.jpg&quot;&gt;&lt;/p&gt;
&lt;h2&gt;2 常用字典数据结构&lt;/h2&gt;
&lt;p&gt;很多数据结构均能完成字典功能，总结如下。&lt;/p&gt;
&lt;table border=&quot;0&quot; align=&quot;center&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;数据结构&lt;/td&gt;
&lt;td&gt;优缺点&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;排序列表Array/List&lt;/td&gt;
&lt;td&gt;使用二分法查找，不平衡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;HashMap/TreeMap&lt;/td&gt;
&lt;td&gt;性能高，内存消耗大，几乎是原始数据的三倍&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Skip List&lt;/td&gt;
&lt;td&gt;跳跃表，可快速查找词语，在lucene、redis、Hbase等均有实现。相对于TreeMap等结构，特别适合高并发场景（&lt;a href=&quot;http://kenby.iteye.com/blog/1187303&quot; target=&quot;_blank&quot;&gt;Skip List介绍&lt;/a&gt;）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Trie&lt;/td&gt;
&lt;td&gt;适合英文词典，如果系统中存在大量字符串且这些字符串基本没有公共前缀，则相应的trie树将非常消耗内存（&lt;a href=&quot;http://dongxicheng.org/structure/trietree/&quot; target=&quot;_blank&quot;&gt;数据结构之trie树&lt;/a&gt;）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Double Array Trie&lt;/td&gt;
&lt;td&gt;适合做中文词典，内存占用小，很多分词工具均采用此种算法（&lt;a href=&quot;http://blog.csdn.net/zhoubl668/article/details/6957830&quot; target=&quot;_blank&quot;&gt;深入双数组Trie&lt;/a&gt;）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ternary Search Tree&lt;/td&gt;
&lt;td&gt;三叉树，每一个node有3个节点，兼具省空间和查询快的优点（&lt;a href=&quot;http://www.drdobbs.com/database/ternary-search-trees/184410528&quot; target=&quot;_blank&quot;&gt;Ternary Search Tree&lt;/a&gt;）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Finite State Transducers (FST)&lt;/td&gt;
&lt;td&gt;一种有限状态转移机，Lucene 4有开源实现，并大量使用&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2&gt;3 FST原理简析&lt;/h2&gt;
&lt;p&gt;lucene从4开始大量使用的数据结构是FST（Finite State Transducer）。FST有两个优点：1）空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；2）查询速度快。O(len(str))的查询时间复杂度。&lt;/p&gt;
&lt;p&gt;下面简单描述下FST的构造过程（工具演示：&lt;a href=&quot;http://examples.mikemccandless.com/fst.py?terms=&amp;amp;cmd=Build+it%21&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;http://examples.mikemccandless.com/fst.py?terms=&amp;amp;cmd=Build+it%21&lt;/a&gt;）。我们对“cat”、 “deep”、 “do”、 “dog” 、“dogs”这5个单词进行插入构建FST（注：必须已排序）。&lt;/p&gt;
&lt;p&gt;1）插入“cat”&lt;/p&gt;
&lt;p&gt;插入cat，每个字母形成一条边，其中t边指向终点。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/2e46d77b80c98301e4aae11323fd6937.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;2）插入“deep”&lt;/p&gt;
&lt;p&gt;与前一个单词“cat”进行最大前缀匹配，发现没有匹配则直接插入，P边指向终点。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b39384cd2beadb9dab8a91b23d975172.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;3）插入“do”&lt;/p&gt;
&lt;p&gt;与前一个单词“deep”进行最大前缀匹配，发现是d，则在d边后增加新边o，o边指向终点。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/03c1805dbc52eb7acb89df31c251ec58.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;4）插入“dog”&lt;/p&gt;
&lt;p&gt;与前一个单词“do”进行最大前缀匹配，发现是do，则在o边后增加新边g，g边指向终点。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/33384eee0778924bd343f4455fd97361.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;5）插入“dogs”&lt;/p&gt;
&lt;p&gt;与前一个单词“dog”进行最大前缀匹配，发现是dog，则在g后增加新边s，s边指向终点。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5961235dd059ff3f4ddac1dc3bad7cee.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;最终我们得到了如上一个有向无环图。利用该结构可以很方便的进行查询，如给定一个term “dog”，我们可以通过上述结构很方便的查询存不存在，甚至我们在构建过程中可以将单词与某一数字、单词进行关联，从而实现key-value的映射。&lt;/p&gt;
&lt;h2&gt;4 FST使用与性能评测&lt;/h2&gt;
&lt;p&gt;我们可以将FST当做Key-Value数据结构来进行使用，特别在对内存开销要求少的应用场景。Lucene已经为我们提供了开源的FST工具，下面的代码是使用说明。&lt;/p&gt;
&lt;p&gt;FST压缩率一般在3倍~20倍之间，相对于TreeMap/HashMap的膨胀3倍，内存节省就有9倍到60倍！（摘自：&lt;a href=&quot;http://blog.csdn.net/whinah/article/details/9980893&quot;&gt;把自动机用作 Key-Value 存储&lt;/a&gt;），那FST在性能方面真的能满足要求吗？&lt;/p&gt;
&lt;p&gt;下面是我在苹果笔记本（i7处理器）进行的简单测试，性能虽不如TreeMap和HashMap，但也算良好，能够满足大部分应用的需求。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6b7b96210b41b9b36904db3b47acdec5.jpg&quot;&gt;&lt;/p&gt;
&lt;h2&gt;参考文献&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://sbp810050504.blog.51cto.com/2799422/1361551&quot;&gt;http://sbp810050504.blog.51cto.com/2799422/1361551&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.sina.com.cn/s/blog_4bec92980101hvdd.html&quot;&gt;http://blog.sina.com.cn/s/blog_4bec92980101hvdd.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.mikemccandless.com/2013/06/build-your-own-finite-state-transducer.html&quot;&gt;http://blog.mikemccandless.com/2013/06/build-your-own-finite-state-transducer.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://examples.mikemccandless.com/fst.py?terms=mop%2F0%0D%0Amoth%2F1%0D%0Apop%2F2%0D%0Astar%2F3%0D%0Astop%2F4%0D%0Atop%2F5%0D%0Atqqq%2F6&amp;amp;cmd=Build+it%21&quot;&gt;http://examples.mikemccandless.com/fst.py?terms=mop%2F0%0D%0Amoth%2F1%0D%0Apop%2F2%0D%0Astar%2F3%0D%0Astop%2F4%0D%0Atop%2F5%0D%0Atqqq%2F6&amp;amp;cmd=Build+it%21&lt;/a&gt;&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 05 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-05-80669-5c2685236.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-05-80669-5c2685236.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>GeoHash核心原理解析</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;&lt;strong&gt;引子&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;机机是个好动又好学的孩子，平日里就喜欢拿着手机地图点点按按来查询一些好玩的东西。某一天机机到北海公园游玩，肚肚饿了，于是乎打开手机地图，搜索北海公园附近的餐馆，并选了其中一家用餐。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/7afa18a198d79a2260074d375bffb5f2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;饭饱之后机机开始反思了，地图后台如何根据自己所在位置查询来查询附近餐馆的呢？苦思冥想了半天，机机想出了个方法：计算所在位置P与北京所有餐馆的距离，然后返回距离&amp;lt;=1000米的餐馆。小得意了一会儿，机机发现北京的餐馆何其多啊，这样计算不得了，于是想了，既然知道经纬度了，那它应该知道自己在西城区，那应该计算所在位置P与西城区所有餐馆的距离啊，机机运用了递归的思想，想到了西城区也很多餐馆啊，应该计算所在位置P与所在街道所有餐馆的距离，这样计算量又小了，效率也提升了。&lt;/p&gt;
&lt;p&gt;机机的计算思想很朴素，就是通过过滤的方法来减小参与计算的餐馆数目，从某种角度上讲，机机在使用索引技术。&lt;/p&gt;
&lt;p&gt;一提到索引，大家脑子里马上浮现出B树索引，因为大量的数据库（如MySQL、oracle、PostgreSQL等）都在使用B树。B树索引本质上是对索引字段进行排序，然后通过类似二分查找的方法进行快速查找，即它要求索引的字段是可排序的，一般而言，可排序的是一维字段，比如时间、年龄、薪水等等。但是对于空间上的一个点（二维，包括经度和纬度），如何排序呢？又如何索引呢？解决的方法很多，下文介绍一种方法来解决这一问题。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;思想：&lt;/strong&gt;如果能通过某种方法将二维的点数据转换成一维的数据，那样不就可以继续使用B树索引了嘛。那这种方法真的存在嘛，答案是肯定的。目前很火的GeoHash算法就是运用了上述思想，下面我们就开始GeoHash之旅吧。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;一、感性认识GeoHash&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先来点感性认识，&lt;a href=&quot;http://openlocation.org/geohash/geohash-js/&quot;&gt;http://openlocation.org/geohash/geohash-js/&lt;/a&gt; 提供了在地图上显示geohash编码的功能。&lt;/p&gt;
&lt;p&gt;1）GeoHash将二维的经纬度转换成字符串，比如下图展示了北京9个区域的GeoHash字符串，分别是WX4ER，WX4G2、WX4G3等等，每一个字符串代表了某一矩形区域。也就是说，这个矩形区域内所有的点（经纬度坐标）都共享相同的GeoHash字符串，这样既可以保护隐私（只表示大概区域位置而不是具体的点），又比较容易做缓存，&lt;strong&gt;比如左上角这个区域内的用户不断发送位置信息请求餐馆数据&lt;/strong&gt;，由于这些用户的GeoHash字符串都是WX4ER，所以可以把WX4ER当作key，把该区域的餐馆信息当作value来进行缓存，而如果不使用GeoHash的话，由于区域内的用户传来的经纬度是各不相同的，很难做缓存。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/d5979331c6687f825735d8ecf03d0194.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;2）字符串越长，表示的范围越精确。如图所示，5位的编码能表示10平方千米范围的矩形区域，而6位编码能表示更精细的区域（约0.34平方千米）&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/90cd8ef33b58c3c015e85d56c1b72ccc.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;3）字符串相似的表示距离相近（特殊情况后文阐述），这样可以利用字符串的前缀匹配来查询附近的POI信息。如下两个图所示，一个在城区，一个在郊区，城区的GeoHash字符串之间比较相似，郊区的字符串之间也比较相似，而城区和郊区的GeoHash字符串相似程度要低些。&lt;/p&gt;
&lt;table cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/16103d5db3378ff113c88d63fd432103.jpg&quot;&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1ed7d3ebe0672aa6879d8d842dff66db.jpg&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;城区&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;郊区&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;通过上面的介绍我们知道了GeoHash就是一种将经纬度转换成字符串的方法，并且使得在大部分情况下，字符串前缀匹配越多的距离越近，回到我们的案例，根据所在位置查询来查询附近餐馆时，只需要将所在位置经纬度转换成GeoHash字符串，并与各个餐馆的GeoHash字符串进行前缀匹配，匹配越多的距离越近。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;二、GeoHash算法的步骤&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面以北海公园为例介绍GeoHash算法的计算步骤&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/bf26fb42a420cf2857dcbf9fa08bc9fe.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;2.1. 根据经纬度计算GeoHash二进制编码&lt;/p&gt;
&lt;p&gt;地球纬度区间是[-90,90]， 北海公园的纬度是39.928167，可以通过下面算法对纬度39.928167进行逼近编码:&lt;/p&gt;
&lt;p&gt;1）区间[-90,90]进行二分为[-90,0),[0,90]，称为左右区间，可以确定39.928167属于右区间[0,90]，给标记为1；&lt;/p&gt;
&lt;p&gt;2）接着将区间[0,90]进行二分为 [0,45),[45,90]，可以确定39.928167属于左区间 [0,45)，给标记为0；&lt;/p&gt;
&lt;p&gt;3）递归上述过程39.928167总是属于某个区间[a,b]。随着每次迭代区间[a,b]总在缩小，并越来越逼近39.928167；&lt;/p&gt;
&lt;p&gt;4）如果给定的纬度x（39.928167）属于左区间，则记录0，如果属于右区间则记录1，这样随着算法的进行会产生一个序列1011100，序列的长度跟给定的区间划分次数有关。&lt;/p&gt;
&lt;p&gt;根据纬度算编码&lt;/p&gt;
&lt;table cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;strong&gt;bit&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;strong&gt;min&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;strong&gt;mid&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;strong&gt;max&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;-90.000&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;0.000&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;90.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;0.000&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;45.000&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;90.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;0.000&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;22.500&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;45.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;22.500&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;33.750&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;45.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;33.7500&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;39.375&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;45.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;39.375&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;42.188&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;45.000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;39.375&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;40.7815&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;42.188&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;39.375&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;40.07825&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;40.7815&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;39.375&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;39.726625&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;40.07825&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;39.726625&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;39.9024375&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;40.07825&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;同理，地球经度区间是[-180,180]，可以对经度116.389550进行编码。&lt;/p&gt;
&lt;p&gt;根据经度算编码&lt;/p&gt;
&lt;table cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;strong&gt;bit&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;strong&gt;min&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;strong&gt;mid&lt;/strong&gt;&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;&lt;strong&gt;max&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;-180&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;0.000&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;180&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;0.000&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;90&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;180&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;90&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;135&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;180&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;90&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;112.5&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;135&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;112.5&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;123.75&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;135&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;112.5&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;118.125&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;123.75&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;112.5&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;115.3125&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;118.125&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;0&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;115.3125&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;116.71875&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;118.125&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;115.3125&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;116.015625&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;116.71875&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;1&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;116.015625&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;116.3671875&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;116.71875&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;2.2. 组码&lt;/p&gt;
&lt;p&gt;通过上述计算，纬度产生的编码为10111 00011，经度产生的编码为11010 01011。偶数位放经度，奇数位放纬度，把2串编码组合生成新串：11100 11101 00100 01111。&lt;/p&gt;
&lt;p&gt;最后使用用0-9、b-z（去掉a, i, l, o）这32个字母进行base32编码，首先将11100 11101 00100 01111转成十进制，对应着28、29、4、15，十进制对应的编码就是wx4g。同理，将编码转换成经纬度的解码算法与之相反，具体不再赘述。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/aacf4c88e9178db201e6d668ae7915a2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三、GeoHash Base32编码长度与精度&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下表摘自维基百科：&lt;a href=&quot;http://en.wikipedia.org/wiki/Geohash&quot;&gt;http://en.wikipedia.org/wiki/Geohash&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;可以看出，当geohash base32编码长度为8时，精度在19米左右，而当编码长度为9时，精度在2米左右，编码长度需要根据数据情况进行选择。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5a015f8e4f82ad6e78f16f4c5c888f9b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;三、GeoHash算法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上文讲了GeoHash的计算步骤，仅仅说明是什么而没有说明为什么？为什么分别给经度和维度编码？为什么需要将经纬度两串编码交叉组合成一串编码？本节试图回答这一问题。&lt;/p&gt;
&lt;p&gt;如图所示，我们将二进制编码的结果填写到空间中，当将空间划分为四块时候，编码的顺序分别是左下角00，左上角01，右下脚10，右上角11，也就是类似于Z的曲线，当我们递归的将各个块分解成更小的子块时，编码的顺序是自相似的（分形），每一个子快也形成Z曲线，这种类型的曲线被称为Peano空间填充曲线。&lt;/p&gt;
&lt;p&gt;这种类型的空间填充曲线的优点是将二维空间转换成一维曲线（事实上是分形维），对大部分而言，编码相似的距离也相近， 但Peano空间填充曲线最大的缺点就是突变性，有些编码相邻但距离却相差很远，比如0111与1000，编码是相邻的，但距离相差很大。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/c4374a13b76a2b1b4927f29791e1b008.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;除Peano空间填充曲线外，还有很多空间填充曲线，如图所示，其中效果公认较好是Hilbert空间填充曲线，相较于Peano曲线而言，Hilbert曲线没有较大的突变。为什么GeoHash不选择Hilbert空间填充曲线呢？可能是Peano曲线思路以及计算上比较简单吧，事实上，Peano曲线就是一种四叉树线性编码方式。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9faa21acf707c7c82a9cdd6fafe4441b.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;四、使用注意点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1）由于GeoHash是将区域划分为一个个规则矩形，并对每个矩形进行编码，这样在查询附近POI信息时会导致以下问题，比如红色的点是我们的位置，绿色的两个点分别是附近的两个餐馆，但是在查询的时候会发现距离较远餐馆的GeoHash编码与我们一样（因为在同一个GeoHash区域块上），而较近餐馆的GeoHash编码与我们不一致。这个问题往往产生在边界处。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/a893348090a6cf901006a2707ef0efcc.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;解决的思路很简单，我们查询时，除了使用定位点的GeoHash编码进行匹配外，还使用周围8个区域的GeoHash编码，这样可以避免这个问题。&lt;/p&gt;
&lt;p&gt;2）我们已经知道现有的GeoHash算法使用的是Peano空间填充曲线，这种曲线会产生突变，造成了编码虽然相似但距离可能相差很大的问题，因此在查询附近餐馆时候，首先筛选GeoHash编码相似的POI点，然后进行实际距离计算。&lt;/p&gt;
&lt;p&gt;参考文献：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Geohash&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;http://en.wikipedia.org/wiki/Geohash&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://openlocation.org/geohash/geohash-js/&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;http://openlocation.org/geohash/geohash-js/&lt;/a&gt;&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 05 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-05-80633-053c66af0.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-05-80633-053c66af0.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>递归与尾递归（C语言）</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;p&gt;在计算机科学领域中，递归式通过递归函数来实现的。程序调用自身的编程技巧称为递归（ recursion）。&lt;/p&gt;
&lt;p&gt;一个过程或函数在其定义或说明中有直接或间接调用自身的一种方法，它通常把一个大型复杂的问题层层转化为一个与原问题相似的规模较小的问题来求解，递归策略只需少量的程序就可描述出解题过程所需要的多次重复计算，大大地减少了程序的代码量。递归的能力在于用有限的语句来定义对象的无限集合。&lt;/p&gt;
&lt;p&gt;一般来说，递归需要有：边界条件、递归前进段和递归返回段。&lt;/p&gt;
&lt;p&gt;当边界条件不满足时，递归前进；当边界条件满足时，递归返回。&lt;/p&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;p&gt;(1) 递归就是在过程或函数里调用自身；&lt;/p&gt;
&lt;p&gt;(2) 在使用递归策略时，必须有一个明确的递归结束条件，称为递归出口。&lt;/p&gt;
&lt;h2&gt;基本递归&lt;/h2&gt;
&lt;p&gt;问题：计算n！&lt;/p&gt;
&lt;p&gt;数学上的计算公式为：n！=n×(n-1)×(n-2)……2×1&lt;/p&gt;
&lt;p&gt;使用递归的方式，可以定义为：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3962bea3804e41cc6e833f338bf01852.jpg&quot; width=&quot;234&quot; height=&quot;48&quot;&gt;&lt;/p&gt;
&lt;p&gt;以递归的方式计算4！&lt;/p&gt;
&lt;p&gt;F(4)=4×F(3)　　　　　　　　　　　　递归阶段&lt;/p&gt;
&lt;p&gt;F(3)=3×F(2)&lt;/p&gt;
&lt;p&gt;F(2)=2×F(1)&lt;/p&gt;
&lt;p&gt;F(1)=1　　终止条件&lt;/p&gt;
&lt;p&gt;F(2)=(2)×(1)　　　 回归阶段&lt;/p&gt;
&lt;p&gt;F(3)=(3)×(2)&lt;/p&gt;
&lt;p&gt;F(4)=(4)×(6)&lt;/p&gt;
&lt;p&gt;24　　　　　　　　　　　　　　　　  递归完成&lt;/p&gt;
&lt;p&gt;以递归方式实现阶乘函数的实现：&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;int fact(int n) {
    if(n &amp;lt; 0)
        return 0;
    else if (n == 0 || n == 1)
        return 1;
    else
        return n * fact(n - 1);
}&lt;/pre&gt;
&lt;p&gt;下面来详细分析递归的工作原理&lt;/p&gt;
&lt;p&gt;先看看C语言中函数的执行方式，需要了解一些关于C程序在内存中的组织方式：&lt;/p&gt;
&lt;p style=&quot;padding-left: 30px;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;&lt;strong&gt;BSS段:&lt;/strong&gt;（bss segment）通常是指用来存放程序中未初始化的全局变量的一块内存区域。BSS是英文Block Started by Symbol的简称。BSS段属于静态内存分配。&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;padding-left: 30px;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;&lt;strong&gt;数据段&lt;/strong&gt; ：数据段（data segment）通常是指用来存放程序中已初始化的全局变量的一块内存区域。数据段属于静态内存分配。&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;padding-left: 30px;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;&lt;strong&gt;代码段：&lt;/strong&gt; 代码段（code segment/text segment）通常是指用来存放 程序执行代码的一块内存区域。这部分区域的大小在程序运行前就已经确定，并且内存区域通常属于只读 , 某些架构也允许代码段为可写，即允许修改程序。在代码段中，也有可能包含一些只读的常数变量 ，例如字符串常量等。程序段为程序代码在内存中的映射.一个程序可以在内存中多有个副本.&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;padding-left: 30px;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;&lt;strong&gt;堆（heap）&lt;/strong&gt; ：堆是用于存放进程运行中被动态分配的内存段，它的大小并不固定，可动态扩张或缩减。当进程调用malloc/free等函数分配内存时，新分配的内存就被动态添加到堆上（堆被扩张）/释放的内存从堆中被剔除（堆被缩减）&lt;/span&gt;&lt;/p&gt;
&lt;p style=&quot;padding-left: 30px;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;&lt;strong&gt;栈(stack)&lt;/strong&gt; ：栈又称堆栈， 存放程序的局部变量（但不包括static声明的变量， static 意味着 在数据段中存放变量）。除此以外，在函数被调用时，栈用来传递参数和返回值。由于栈的后进先出特点，所以栈特别方便用来保存/恢复调用现场。从这个意义上讲，我们可以把堆栈看成一个寄存、交换临时数据的内存区。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;堆的增长方向为从低地址到高地址向上增长，而栈的增长方向刚好相反（实际情况与CPU的体系结构有关）&lt;/p&gt;
&lt;p&gt;当C程序中调用了一个函数时，栈中会分配一块空间来保存与这个调用相关的信息，每一个调用都被当作是活跃的。栈上的那块存储空间称为活跃记录或者栈帧&lt;/p&gt;
&lt;p&gt;栈帧由5个区域组成：输入参数、返回值空间、计算表达式时用到的临时存储空间、函数调用时保存的状态信息以及输出参数，参见下图：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/d5d1a34579decb86ab234409140454fc.jpg&quot; width=&quot;422&quot; height=&quot;400&quot;&gt;&lt;/p&gt;
&lt;p&gt;可以使用下面的程序来检验:&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;#include &amp;lt;stdio.h&amp;gt;
int g1=0, g2=0, g3=0;
int max(int i)
{
    int m1 = 0, m2, m3 = 0, *p_max;
    static n1_max = 0, n2_max, n3_max = 0;
    p_max = (int*)malloc(10);
    printf(&quot;打印max程序地址\n&quot;);
    printf(&quot;in max: 0x%08x\n\n&quot;,max);
    printf(&quot;打印max传入参数地址\n&quot;);
    printf(&quot;in max: 0x%08x\n\n&quot;,&amp;amp;i);
    printf(&quot;打印max函数中静态变量地址\n&quot;);
    printf(&quot;0x%08x\n&quot;,&amp;amp;n1_max); //打印各本地变量的内存地址
    printf(&quot;0x%08x\n&quot;,&amp;amp;n2_max);
    printf(&quot;0x%08x\n\n&quot;,&amp;amp;n3_max);
    printf(&quot;打印max函数中局部变量地址\n&quot;);
    printf(&quot;0x%08x\n&quot;,&amp;amp;m1); //打印各本地变量的内存地址
    printf(&quot;0x%08x\n&quot;,&amp;amp;m2);
    printf(&quot;0x%08x\n\n&quot;,&amp;amp;m3);
    printf(&quot;打印max函数中malloc分配地址\n&quot;);
    printf(&quot;0x%08x\n\n&quot;,p_max); //打印各本地变量的内存地址
    if(i) return 1;
    else return 0;
}
int main(int argc, char **argv)
{
    static int s1=0, s2, s3=0;
    int v1=0, v2, v3=0;
    int *p;    
    p = (int*)malloc(10);
    printf(&quot;打印各全局变量(已初始化)的内存地址\n&quot;);
    printf(&quot;0x%08x\n&quot;,&amp;amp;g1); //打印各全局变量的内存地址
    printf(&quot;0x%08x\n&quot;,&amp;amp;g2);
    printf(&quot;0x%08x\n\n&quot;,&amp;amp;g3);
    printf(&quot;======================\n&quot;);
    printf(&quot;打印程序初始程序main地址\n&quot;);
    printf(&quot;main: 0x%08x\n\n&quot;, main);
    printf(&quot;打印主参地址\n&quot;);
    printf(&quot;argv: 0x%08x\n\n&quot;,argv);
    printf(&quot;打印各静态变量的内存地址\n&quot;);
    printf(&quot;0x%08x\n&quot;,&amp;amp;s1); //打印各静态变量的内存地址
    printf(&quot;0x%08x\n&quot;,&amp;amp;s2);
    printf(&quot;0x%08x\n\n&quot;,&amp;amp;s3);
    printf(&quot;打印各局部变量的内存地址\n&quot;);
    printf(&quot;0x%08x\n&quot;,&amp;amp;v1); //打印各本地变量的内存地址
    printf(&quot;0x%08x\n&quot;,&amp;amp;v2);
    printf(&quot;0x%08x\n\n&quot;,&amp;amp;v3);
    printf(&quot;打印malloc分配的堆地址\n&quot;);
    printf(&quot;malloc: 0x%08x\n\n&quot;,p);
    printf(&quot;======================\n&quot;);
    max(v1);
    printf(&quot;======================\n&quot;);
    printf(&quot;打印子函数起始地址\n&quot;);
    printf(&quot;max: 0x%08x\n\n&quot;,max);
    return 0;
}&lt;/pre&gt;
&lt;p&gt;栈是用来存储函数调用信息的绝好方案，然而栈也有一些缺点：&lt;/p&gt;
&lt;p&gt;栈维护了每个函数调用的信息直到函数返回后才释放，这需要占用相当大的空间，尤其是在程序中使用了许多的递归调用的情况下。除此之外，因为有大量的信息需要保存和恢复，因此生成和销毁活跃记录需要消耗一定的时间。我们需要考虑采用迭代的方案。幸运的是我们可以采用一种称为尾递归的特殊递归方式来避免前面提到的这些缺点。&lt;/p&gt;
&lt;h2&gt;尾递归&lt;/h2&gt;
&lt;h3&gt;定义&lt;/h3&gt;
&lt;p&gt;如果一个函数中所有递归形式的调用都出现在函数的末尾，我们称这个递归函数是尾递归的。当递归调用是整个函数体中最后执行的语句且它的返回值不属于表达式的一部分时，这个递归调用就是尾递归。尾递归函数的特点是在回归过程中不用做任何操作，这个特性很重要，因为大多数现代的编译器会利用这种特点自动生成优化的代码。&lt;/p&gt;
&lt;h3&gt;原理&lt;/h3&gt;
&lt;p&gt;当编译器检测到一个函数调用是尾递归的时候，它就覆盖当前的活动记录而不是在栈中去创建一个新的。编译器可以做到这点，因为递归调用是当前活跃期内最后一条待执行的语句，于是当这个调用返回时栈帧中并没有其他事情可做，因此也就没有保存栈帧的必要了。通过覆盖当前的栈帧而不是在其之上重新添加一个，这样所使用的栈空间就大大缩减了，这使得实际的运行效率会变得更高。虽然编译器能够优化尾递归造成的栈溢出问题，但是在编程中，我们还是应该尽量避免尾递归的出现，因为所有的尾递归都是可以用简单的goto循环替代的。&lt;/p&gt;
&lt;h3&gt;实例&lt;/h3&gt;
&lt;p&gt;为了理解尾递归是如何工作的，让我们再次以递归的形式计算阶乘。首先，这可以很容易让我们理解为什么之前所定义的递归不是尾递归。回忆之前对计算n!的定义：在每个活跃期计算n倍的(n－1)!的值，让n=n－1并持续这个过程直到n=1为止。这种定义不是尾递归的，因为每个活跃期的返回值都依赖于用n乘以下一个活跃期的返回值，因此每次调用产生的栈帧将不得不保存在栈上直到下一个子调用的返回值确定。现在让我们考虑以尾递归的形式来定义计算n!的过程。&lt;/p&gt;
&lt;p&gt;这种定义还需要接受第二个参数a，除此之外并没有太大区别。a（初始化为1）维护递归层次的深度。这就让我们避免了每次还需要将返回值再乘以n。然而，在每次递归调用中，令a=na并且n=n－1。继续递归调用，直到n=1，这满足结束条件，此时直接返回a即可。&lt;/p&gt;
&lt;p&gt;代码实例给出了一个C函数facttail，它接受一个整数n并以尾递归的形式计算n!。这个函数还接受一个参数a，a的初始值为1。facttail使用a来维护递归层次的深度，除此之外它和fact很相似。读者可以注意一下函数的具体实现和尾递归定义的相似之处。&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;int facttail(int n, int a)
{
    if (n &amp;lt; 0)
        return 0;
    else if (n == 0)
        return 1;
    else if (n == 1)
        return a;
    else
        return facttail(n - 1, n * a);
}&lt;/pre&gt;
&lt;p&gt;示例中的函数是尾递归的，因为对facttail的单次递归调用是函数返回前最后执行的一条语句。在facttail中碰巧最后一条语句也是对facttail的调用，但这并不是必需的。换句话说，在递归调用之后还可以有其他的语句执行，只是它们只能在递归调用没有执行时才可以执行。&lt;/p&gt;
&lt;p&gt;尾递归是极其重要的，不用尾递归，函数的堆栈耗用难以估量，需要保存很多中间函数的堆栈。比如f(n, sum) = f(n-1) + value(n) + sum; 会保存n个函数调用堆栈，而使用尾递归f(n, sum) = f(n-1, sum+value(n)); 这样则只保留后一个函数堆栈即可，之前的可优化删去。&lt;/p&gt;
&lt;p&gt;也许在C语言中有很多的特例，但编程语言不只有C语言，在函数式语言Erlang中（亦是栈语言），如果想要保持语言的高并发特性，就必须用尾递归来替代传统的递归。&lt;/p&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Fri, 05 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-05-80626-1f2cf131d.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-05-80626-1f2cf131d.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>MapReduce原理与设计思想</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;专为开发者打造的Linux学习视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;h2&gt;简单解释 MapReduce 算法&lt;/h2&gt;
&lt;h3&gt;一个有趣的例子&lt;/h3&gt;
&lt;p&gt;你想数出一摞牌中有多少张黑桃。直观方式是一张一张检查并且数出有多少张是黑桃？&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/b60cddbec830e74627a9c9f35f204705.jpg&quot; width=&quot;550&quot; height=&quot;360&quot;&gt;&lt;/p&gt;
&lt;p&gt;MapReduce方法则是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;给在座的所有玩家中分配这摞牌&lt;/li&gt;
&lt;li&gt;让每个玩家数自己手中的牌有几张是黑桃，然后把这个数目汇报给你&lt;/li&gt;
&lt;li&gt;你把所有玩家告诉你的数字加起来，得到最后的结论&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;拆分&lt;/h3&gt;
&lt;p&gt;MapReduce合并了两种经典函数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;strong&gt;映射（Mapping）&lt;/strong&gt;对集合里的每个目标应用同一个操作。即，如果你想把表单里每个单元格乘以二，那么把这个函数单独地应用在每个单元格上的操作就属于mapping。&lt;/li&gt;
&lt;li&gt;
&lt;strong&gt;化简（Reducing ）&lt;/strong&gt;遍历集合中的元素来返回一个综合的结果。即，输出表单里一列数字的和这个任务属于reducing。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;重新审视上面的例子&lt;/h3&gt;
&lt;p&gt;重新审视我们原来那个分散纸牌的例子，我们有MapReduce数据分析的基本方法。友情提示：这不是个严谨的例子。在这个例子里，人代表计算机，因为他们同时工作，所以他们是个&lt;strong&gt;集群&lt;/strong&gt;。在大多数实际应用中，我们假设数据已经在每台计算机上了 – 也就是说把牌分发出去并不是MapReduce的一步。（事实上，在计算机集群中如何存储文件是Hadoop的真正核心。）&lt;/p&gt;
&lt;p&gt;通过把牌分给多个玩家并且让他们各自数数，你就在&lt;strong&gt;并行&lt;/strong&gt;执行运算，因为每个玩家都在同时计数。这同时把这项工作变成了&lt;strong&gt;分布式的&lt;/strong&gt;，因为多个不同的人在解决同一个问题的过程中并不需要知道他们的邻居在干什么。&lt;/p&gt;
&lt;p&gt;通过告诉每个人去数数，你对一项检查每张牌的任务进行了映射。 你不会让他们把黑桃牌递给你，而是让他们把你想要的东西化简为一个数字。&lt;/p&gt;
&lt;p&gt;另外一个有意思的情况是牌分配得有多均匀。MapReduce假设数据是&lt;strong&gt;洗过的&lt;/strong&gt;（&lt;strong&gt;shuffled&lt;/strong&gt;）- 如果所有黑桃都分到了一个人手上，那他数牌的过程可能比其他人要慢很多。&lt;/p&gt;
&lt;p&gt;如果有足够的人的话，问一些更有趣的问题就相当简单了 - 比如“一摞牌的平均值（二十一点算法）是什么”。你可以通过合并“所有牌的值的和是什么”及“我们有多少张牌”这两个问题来得到答案。用这个和除以牌的张数就得到了平均值。&lt;/p&gt;
&lt;p&gt;MapReduce算法的机制要远比这复杂得多，但是主体思想是一致的 – 通过分散计算来分析大量数据。无论是Facebook、NASA，还是小创业公司，MapReduce都是目前分析互联网级别数据的主流方法。&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2&gt;Hadoop中的MapReduce&lt;/h2&gt;
&lt;p&gt;大规模数据处理时，MapReduce在三个层面上的基本构思&lt;/p&gt;
&lt;p&gt;如何对付大数据处理：分而治之&lt;/p&gt;
&lt;p&gt;对相互间不具有计算依赖关系的大数据，实现并行最自然的办法就是采取分而治之的策略&lt;/p&gt;
&lt;p&gt;上升到抽象模型：Mapper与Reducer&lt;/p&gt;
&lt;p&gt;MPI等并行计算方法缺少高层并行编程模型，为了克服这一缺陷，MapReduce借鉴了Lisp函数式语言中的思想，用Map和Reduce两个函数提供了高层的并行编程抽象模型&lt;/p&gt;
&lt;p&gt;上升到构架：统一构架，为程序员隐藏系统层细节&lt;/p&gt;
&lt;p&gt;MPI等并行计算方法缺少统一的计算框架支持，程序员需要考虑数据存储、划分、分发、结果收集、错误恢复等诸多细节；为此，MapReduce设计并提供了统一的计算框架，为程序员隐藏了绝大多数系统层面的处理细节&lt;/p&gt;
&lt;h3&gt;1.对付大数据处理-分而治之&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;什么样的计算任务可进行并行化计算？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;并行计算的第一个重要问题是如何划分计算任务或者计算数据以便对划分的子任务或数据块同时进行计算。但一些计算问题恰恰无法进行这样的划分！&lt;/p&gt;
&lt;p&gt;Nine women cannot have a baby in one month!&lt;/p&gt;
&lt;p&gt;例如：Fibonacci函数:  F&lt;sub&gt;k+2&lt;/sub&gt; = F&lt;sub&gt;k&lt;/sub&gt; + F&lt;sub&gt;k+1&lt;/sub&gt;&lt;/p&gt;
&lt;p&gt;前后数据项之间存在很强的依赖关系！只能串行计算！&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;结论：不可分拆的计算任务或相互间有依赖关系的数据无法进行并行计算！&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;大数据的并行化计算&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;一个大数据若可以分为具有同样计算过程的数据块，并且这些数据块之间不存在数据依赖关系，则提高处理速度的最好办法就是并行计算&lt;/p&gt;
&lt;p&gt;例如：假设有一个巨大的2维数据需要处理(比如求每个元素的开立方)，其中对每个元素的处理是相同的,并且数据元素间不存在数据依赖关系,可以考虑不同的划分方法将其划分为子数组,由一组处理器并行处理&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/4c8ceccae33bab57038a648a3c1a36fd.jpg&quot; width=&quot;377&quot; height=&quot;142&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/58a8b2e1c6f6605239b2b731d68358b0.jpg&quot; width=&quot;547&quot; height=&quot;364&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/bb4bfb86c2380d14d006e824ead734a2.jpg&quot; width=&quot;501&quot; height=&quot;312&quot;&gt;&lt;/p&gt;
&lt;h3&gt;2.构建抽象模型-Map和Reduce&lt;/h3&gt;
&lt;p&gt;借鉴函数式设计语言Lisp的设计思想&lt;/p&gt;
&lt;p&gt;函数式程序设计(functional programming)语言Lisp是一种列表处理 语言(List processing)，是一种应用于人工智能处理的符号式语言，由MIT的人工智能专家、图灵奖获得者John McCarthy于1958年设计发明。&lt;/p&gt;
&lt;p&gt;Lisp定义了可对列表元素进行整体处理的各种操作，如：&lt;/p&gt;
&lt;p&gt;如：(add #(1 2 3 4) #(4 3 2 1))   将产生结果： #(5 5 5 5)&lt;/p&gt;
&lt;p&gt;Lisp中也提供了类似于Map和Reduce的操作&lt;/p&gt;
&lt;p&gt;如: (map ‘vector #+ #(1 2 3 4 5)  #(10 11 12 13 14))&lt;/p&gt;
&lt;p&gt;通过定义加法map运算将2个向量相加产生结果#(11 13 15 17 19)&lt;/p&gt;
&lt;p&gt;(reduce #’+ #(11  13  15  17  19)) 通过加法归并产生累加结果75&lt;/p&gt;
&lt;p&gt;Map: 对一组数据元素进行某种重复式的处理&lt;/p&gt;
&lt;p&gt;Reduce: 对Map的中间结果进行某种进一步的结果整&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/fb4e7641f8a76dc4f38a65ae8f0c4072.jpg&quot; width=&quot;549&quot; height=&quot;271&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键思想：为大数据处理过程中的两个主要处理操作提供一种抽象机制&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;MapReduce中的Map和Reduce操作的抽象描述&lt;/p&gt;
&lt;p&gt;MapReduce借鉴了函数式程序设计语言Lisp中的思想，定义了如下的Map和Reduce两个抽象的编程接口，由用户去编程实现:&lt;/p&gt;
&lt;div&gt;&lt;strong&gt;map&lt;/strong&gt;: &lt;strong&gt;(k1; v1) →&lt;/strong&gt; &lt;strong&gt;[(k2; v2)]&lt;/strong&gt;
&lt;/div&gt;
&lt;p&gt;输入：键值对(k1; v1)表示的数据&lt;/p&gt;
&lt;p&gt;处理：文档数据记录(如文本文件中的行，或数据表格中的行)将以“键值对”形式传入map函数；map函数将处理这些键值对，并以另一种键值对形式输出处理的一组键值对中间结果　　　[(k2; v2)]&lt;/p&gt;
&lt;p&gt;输出：键值对[(k2; v2)]表示的一组中间数据&lt;/p&gt;
&lt;div&gt;&lt;strong&gt;reduce&lt;/strong&gt;:&lt;strong&gt; (k2; [v2])&lt;/strong&gt; &lt;strong&gt;→ [(k3; v3)]&lt;/strong&gt;
&lt;/div&gt;
&lt;p&gt;输入： 由map输出的一组键值对[(k2; v2)] 将被进行合并处理将同样主键下的不同数值合并到一个列表[v2]中，故reduce的输入为(k2; [v2])&lt;/p&gt;
&lt;p&gt;处理：对传入的中间结果列表数据进行某种整理或进一步的处理,并产生最终的某种形式的结果输出[(k3; v3)] 。&lt;/p&gt;
&lt;p&gt;输出：最终输出结果[(k3; v3)]&lt;/p&gt;
&lt;p&gt;Map和Reduce为程序员提供了一个清晰的操作接口抽象描述&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/319b1e8e2a43f47bdcd123fd854eafae.jpg&quot; width=&quot;515&quot; height=&quot;353&quot;&gt;&lt;/p&gt;
&lt;p&gt;各个map函数对所划分的数据并行处理，从不同的输入数据产生不同的中间结果输出&lt;/p&gt;
&lt;p&gt;各个reduce也各自并行计算，各自负责处理不同的中间结果数据集合进行reduce处理之前,必须等到所有的map函数做完，因此,在进入reduce前需要有一个同步障(barrier);这个阶段也负责对map的中间结果数据进行收集整理(aggregation &amp;amp; shuffle)处理,以便reduce更有效地计算最终结果最终汇总所有reduce的输出结果即可获得最终结果&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基于MapReduce的处理过程示例&lt;/strong&gt;–&lt;strong&gt;文档词频统计：WordCount&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;设有4组原始文本数据：&lt;/p&gt;
&lt;p&gt;Text 1: the weather is good         Text 2: today is good&lt;/p&gt;
&lt;p&gt;Text 3: good weather is good      Text 4: today has good weather&lt;/p&gt;
&lt;p&gt;传统的串行处理方式(Java)：&lt;/p&gt;
&lt;pre class=&quot;brush: java; gutter: true&quot;&gt;String[] text = new String[] { “hello world”, “hello every one”, “say hello to everyone in the world” ｝;
HashTable ht = new HashTable();    
for(i = 0; i &amp;lt; 3; ++i) {
    StringTokenizer st = new StringTokenizer(text[i]); 
    while (st.hasMoreTokens()) {  
        String word = st.nextToken();
        if(!ht.containsKey(word)) {  
            ht.put(word, new Integer(1));
        } else {
            int wc = ((Integer)ht.get(word)).intValue() +1;// 计数加1
            ht.put(word, new Integer(wc));
        }
    }
}
for (Iterator itr=ht.KeySet().iterator();  itr.hasNext(); ) {
    String word = (String)itr.next(); 
    System.out.print(word+ “: ”+ (Integer)ht.get(word)+“;   ”);&lt;/pre&gt;
&lt;p&gt;输出：good:  5;   has: 1;  is: 3;   the: 1;   today: 2;    weather: 3&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;基于MapReduce的处理过程示例&lt;/strong&gt;–&lt;strong&gt;文档词频统计：WordCount&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MapReduce处理方式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用4个map节点：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;map节点1:&lt;/p&gt;
&lt;p&gt;输入：(text1, “the weather is good”)&lt;/p&gt;
&lt;p&gt;输出：(the, 1), (weather, 1), (is, 1), (good, 1)&lt;/p&gt;
&lt;p&gt;map节点2:&lt;/p&gt;
&lt;p&gt;输入：(text2, “today is good”)&lt;/p&gt;
&lt;p&gt;输出：(today, 1), (is, 1), (good, 1)&lt;/p&gt;
&lt;p&gt;map节点3:&lt;/p&gt;
&lt;p&gt;输入：(text3, “good weather is good”)&lt;/p&gt;
&lt;p&gt;输出：(good, 1), (weather, 1), (is, 1), (good, 1)&lt;/p&gt;
&lt;p&gt;map节点4:&lt;/p&gt;
&lt;p&gt;输入：(text3, “today has good weather”)&lt;/p&gt;
&lt;p&gt;输出：(today, 1), (has, 1), (good, 1), (weather, 1)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用3个reduce节点：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/7f02b9f4e0d173eebcd1fbdbaa692897.jpg&quot; width=&quot;518&quot; height=&quot;287&quot;&gt;&lt;/p&gt;
&lt;p&gt;MapReduce处理方式&lt;/p&gt;
&lt;p&gt;MapReduce伪代码(实现Map和Reduce两个函数)：&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignnone&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/ad61d00a7356add51e680b7ca128e90f.jpg&quot; width=&quot;552&quot; height=&quot;358&quot;&gt;&lt;/p&gt;
&lt;pre class=&quot;brush: c; gutter: true&quot;&gt;Class Mapper method map(String input_key, String input_value):
  // input_key: text document name 
  // input_value: document contents 
  for each word w in input_value: 
      EmitIntermediate(w, &quot;1&quot;); 

Class Reducer method reduce(String output_key, Iterator intermediate_values): 
  // output_key: a word 
  // output_values: a list of counts 
  int result = 0; 
  for each v in intermediate_values: 
      result += ParseInt(v);
  Emit(output_key， result);&lt;/pre&gt;
&lt;h3&gt;3.上升到构架-自动并行化并隐藏低层细节&lt;/h3&gt;
&lt;p&gt;如何提供统一的计算框架&lt;/p&gt;
&lt;p&gt;MapReduce提供一个统一的计算框架，可完成：&lt;/p&gt;
&lt;p&gt;计算任务的划分和调度&lt;/p&gt;
&lt;p&gt;数据的分布存储和划分&lt;/p&gt;
&lt;p&gt;处理数据与计算任务的同步&lt;/p&gt;
&lt;p&gt;结果数据的收集整理(sorting, combining, partitioning,…)&lt;/p&gt;
&lt;p&gt;系统通信、负载平衡、计算性能优化处理&lt;/p&gt;
&lt;p&gt;处理系统节点出错检测和失效恢复&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;strong&gt;MapReduce最大的亮点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过抽象模型和计算框架把需要做什么(what need to do)与具体怎么做(how to do)分开了，为程序员提供一个抽象和高层的编程接口和框架&lt;/p&gt;
&lt;p&gt;程序员仅需要关心其应用层的具体计算问题，仅需编写少量的处理应用本身计算问题的程序代码&lt;/p&gt;
&lt;p&gt;如何具体完成这个并行计算任务所相关的诸多系统层细节被隐藏起来,交给计算框架去处理：从分布代码的执行，到大到数千小到单个节点集群的自动调度使用&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;&lt;strong&gt;MapReduce提供的主要功能&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;任务调度：提交的一个计算作业(job)将被划分为很多个计算任务(tasks), 任务调度功能主要负责为这些划分后的计算任务分配和调度计算节点(map节点或reducer节点); 同时负责监控这些节点的执行状态, 并负责map节点执行的同步控制(barrier); 也负责进行一些计算性能优化处理, 如对最慢的计算任务采用多备份执行、选最快完成者作为结果&lt;/p&gt;

&lt;/div&gt;
&lt;div&gt;
&lt;div&gt;出错处理：以低端商用服务器构成的大规模MapReduce计算集群中,节点硬件(主机、磁盘、内存等)出错和软件有bug是常态，因此,MapReducer需要能检测并隔离出错节点，并调度分配新的节点接管出错节点的计算任务&lt;/div&gt;
&lt;div&gt;分布式数据存储与文件管理：海量数据处理需要一个良好的分布数据存储和文件管理系统支撑,该文件系统能够把海量数据分布存储在各个节点的本地磁盘上,但保持整个数据在逻辑上成为一个完整的数据文件；为了提供数据存储容错机制,该文件系统还要提供数据块的多备份存储管理能力&lt;/div&gt;
&lt;div&gt;Combiner和Partitioner:为了减少数据通信开销,中间结果数据进入reduce节点前需要进行合并(combine)处理,把具有同样主键的数据合并到一起避免重复传送; 一个reducer节点所处理的数据可能会来自多个map节点, 因此, map节点输出的中间结果需使用一定的策略进行适当的划分(partitioner)处理，保证相关数据发送到同一个reducer节点&lt;/div&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;p&gt;&lt;strong&gt;基于Map和Reduce的并行计算模型&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;4.MapReduce的主要设计思想和特征&lt;/h3&gt;
&lt;p&gt;1、向“外”横向扩展，而非向“上”纵向扩展（Scale “out”, not “up”）&lt;/p&gt;
&lt;p&gt;即MapReduce集群的构筑选用价格便宜、易于扩展的大量低端商用服务器，而非价格昂贵、不易扩展的高端服务器（SMP）低端服务器市场与高容量Desktop PC有重叠的市场，因此，由于相互间价格的竞争、可互换的部件、和规模经济效应，使得低端服务器保持较低的价格基于TPC-C在2007年底的性能评估结果,一个低端服务器平台与高端的共享存储器结构的服务器平台相比,其性价比大约要高4倍;如果把外存价格除外,低端服务器性价比大约提高12倍对于大规模数据处理，由于有大量数据存储需要，显而易见，基于低端服务器的集群远比基于高端服务器的集群优越，这就是为什么MapReduce并行计算集群会基于低端服务器实现&lt;/p&gt;
&lt;p&gt;2、失效被认为是常态（Assume failures are common）&lt;/p&gt;
&lt;p&gt;MapReduce集群中使用大量的低端服务器(Google目前在全球共使用百万台以上的服务器节点),因此，节点硬件失效和软件出错是常态，因而：一个良好设计、具有容错性的并行计算系统不能因为节点失效而影响计算服务的质量，任何节点失效都不应当导致结果的不一致或不确定性；任何一个节点失效时，其它节点要能够无缝接管失效节点的计算任务；当失效节点恢复后应能自动无缝加入集群，而不需要管理员人工进行系统配置MapReduce并行计算软件框架使用了多种有效的机制，如节点自动重启技术，使集群和计算框架具有对付节点失效的健壮性，能有效处理失效节点的检测和恢复。&lt;/p&gt;
&lt;p&gt;3、把处理向数据迁移（Moving processing to the data）&lt;/p&gt;
&lt;p&gt;　　传统高性能计算系统通常有很多处理器节点与一些外存储器节点相连，如用区域存储网络(SAN,Storage Area Network)连接的磁盘阵列，因此，大规模数据处理时外存文件数据I/O访问会成为一个制约系统性能的瓶颈。为了减少大规模数据并行计算系统中的数据通信开销，代之以把数据传送到处理节点(数据向处理器或代码迁移)，应当考虑将处理向数据靠拢和迁移。MapReduce采用了数据/代码互定位的技术方法，计算节点将首先将尽量负责计算其本地存储的数据,以发挥数据本地化特点(locality),仅当节点无法处理本地数据时，再采用就近原则寻找其它可用计算节点，并把数据传送到该可用计算节点。&lt;/p&gt;
&lt;div&gt;
&lt;p&gt;4、顺序处理数据、避免随机访问数据（Process data sequentially and avoid random access）&lt;/p&gt;
&lt;p&gt;　大规模数据处理的特点决定了大量的数据记录不可能存放在内存、而只可能放在外存中进行处理。磁盘的顺序访问和随即访问在性能上有巨大的差异&lt;/p&gt;
&lt;p&gt;例：100亿(1010)个数据记录(每记录100B,共计1TB)的数据库&lt;/p&gt;
&lt;p&gt;更新1%的记录(一定是随机访问)需要1个月时间；而顺序访问并重写所有数据记录仅需1天时间！&lt;/p&gt;
&lt;div&gt;　MapReduce设计为面向大数据集批处理的并行计算系统，所有计算都被组织成很长的流式操作，以便能利用分布在集群中大量节点上磁盘集合的高传输带宽。&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;5、为应用开发者隐藏系统层细节（Hide system-level details from the application developer）&lt;/p&gt;
&lt;p&gt;　　软件工程实践指南中，专业程序员认为之所以写程序困难，是因为程序员需要记住太多的编程细节(从变量名到复杂算法的边界情况处理)，这对大脑记忆是一个巨大的认知负担,需要高度集中注意力而并行程序编写有更多困难，如需要考虑多线程中诸如同步等复杂繁琐的细节，由于并发执行中的不可预测性，程序的调试查错也十分困难；大规模数据处理时程序员需要考虑诸如数据分布存储管理、数据分发、数据通信和同步、计算结果收集等诸多细节问题MapReduce提供了一种抽象机制将程序员与系统层细节隔离开来，程序员仅需描述需要计算什么(what to compute), 而具体怎么去做(how to compute)就交由系统的执行框架处理，这样程序员可从系统层细节中解放出来，而致力于其应用本身计算问题的算法设计&lt;/p&gt;
&lt;p&gt;6、平滑无缝的可扩展性（Seamless scalability）&lt;/p&gt;
&lt;p&gt;主要包括两层意义上的扩展性：数据扩展和系统规模扩展。理想的软件算法应当能随着数据规模的扩大而表现出持续的有效性，性能上的下降程度应与数据规模扩大的倍数相当在集群规模上，要求算法的计算性能应能随着节点数的增加保持接近线性程度的增长绝大多数现有的单机算法都达不到以上理想的要求；把中间结果数据维护在内存中的单机算法在大规模数据处理时很快失效；从单机到基于大规模集群的并行计算从根本上需要完全不同的算法设计奇妙的是，MapReduce几乎能实现以上理想的扩展性特征。  多项研究发现基于MapReduce的计算性能可随节点数目增长保持近似于线性的增长&lt;/p&gt;
&lt;p&gt; &lt;/p&gt;
&lt;h2&gt;参考资料&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;1、&lt;a href=&quot;http://blog.jobbole.com/79255/&quot; target=&quot;_blank&quot;&gt;http://blog.jobbole.com/79255/&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;2、《MapReduce简介》&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;

</description>
        <pubDate>Fri, 05 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-05-80619-b677084ff.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-05-80619-b677084ff.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>【大型网站技术实践】初级篇：借助Nginx搭建反向代理服务器</title>
        <description>

        &lt;!-- div style=&quot;margin-bottom: 10px;&quot;&gt;
            &lt;script language=javascript&gt;
                var randomNumLuobo = Math.round(Math.random()*1);
                var imageLuobo=new Array(2);
                imageLuobo[0]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                imageLuobo[1]=&quot;http://jbcdn2.b0.upaiyun.com/2014/11/luobo-620x60.png&quot;;
                var imageUrlLuobo=imageLuobo[randomNumLuobo];
                var urlsLuobo=new Array(2);
                urlsLuobo[0]=&quot;http://www.luobo360.com&quot;;
                urlsLuobo[1]=&quot;http://www.luobo360.com&quot;;
                var urlLuobo = urlsLuobo[randomNumLuobo];
                var adHTML = &quot;&lt;a href=&#39;&quot;+urlLuobo+&quot;&#39; target=&#39;_blank&#39;&gt;&lt;img src=&#39;&quot;+imageUrlLuobo+&quot;&#39; border=&#39;0&#39;&gt;&lt;/a&gt;&quot;;
                document.write(adHTML);
            &lt;/script&gt;
        &lt;/div --&gt;

        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;div class=&quot;featured-courses&quot;&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/172?from=jobboleblog&quot;&gt;jQuery源码解析（架构与依赖模块）&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/202?from=jobboleblog&quot;&gt;深入浅出 Java 多线程&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline-block;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/69&quot;&gt;MVC架构模式分析与设计&lt;/a&gt;&lt;/li&gt;
&lt;li style=&quot;width: 310px;display: inline;&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.imooc.com/learn/181&quot;&gt;为开发者打造的Linux视频教程&lt;/a&gt;&lt;/li&gt;
&lt;/div&gt;
&lt;/div&gt;
		
		
&lt;h1&gt;一、反向代理：Web服务器的“经纪人”&lt;/h1&gt;
&lt;h2&gt;1.1 反向代理初印象&lt;/h2&gt;
&lt;p&gt;反向代理（Reverse Proxy）方式是指以&lt;strong&gt;代理服务器来&lt;/strong&gt;接受internet上的连接请求，然后将&lt;strong&gt;请求转发&lt;/strong&gt;给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为&lt;em&gt;&lt;strong&gt;一个服务器&lt;/strong&gt;&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/367cc3be33f59d5459e1b82a6172de16.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;从上图可以看出：反向代理服务器位于&lt;strong&gt;网站机房&lt;/strong&gt;，代理网站Web服务器接收Http请求，对请求进行转发。&lt;/p&gt;
&lt;h2&gt;1.2 反向代理的作用&lt;/h2&gt;
&lt;p&gt;①&lt;strong&gt;保护网站安全：&lt;/strong&gt;任何来自Internet的请求都必须先经过代理服务器；&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/1c442057a97b75fc01cdc606604cab98.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;②&lt;strong&gt;通过配置缓存功能加速Web请求：&lt;/strong&gt;可以缓存真实Web服务器上的某些静态资源，减轻真实Web服务器的负载压力；&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9e6f6b3da5a92a0550b5ec6e2c17d36a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;③&lt;strong&gt;实现负载均衡：&lt;/strong&gt;充当负载均衡服务器均衡地分发请求，平衡集群中各个服务器的负载压力；&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/f1032f43caaa59559bdb6f3d3189fa4d.jpg&quot;&gt;&lt;/p&gt;
&lt;h1&gt;二、初识Nginx：简单却不平凡&lt;/h1&gt;
&lt;h2&gt;2.1 Nginx是神马？&lt;/h2&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/44e151e44278e535826e67b8e975b683.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;Nginx是一款&lt;strong&gt;轻量级&lt;/strong&gt;的网页服务器、反向代理器以及电子邮件代理服务器。其将源代码以类BSD许可证的形式发布，因它的稳定性、丰富的功能集、示例配置文件和低系统资源的消耗而闻名。&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;&lt;strong&gt;Source：&lt;/strong&gt;Nginx（发音同engine x），它是由俄罗斯程序员&lt;strong&gt;Igor Sysoev&lt;/strong&gt;所开发的。起初是供俄国大型的门户网站及搜索引擎&lt;strong&gt;Rambler&lt;/strong&gt;（俄语：Рамблер）使用。此软件BSD-like协议下发行，可以在UNIX、GNU/Linux、BSD、Mac OS X、Solaris，以及Microsoft Windows等操作系统中运行。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;说到Web服务器，Apache服务器和IIS服务器是两大巨头；但是运行速度更快、更灵活的对手：&lt;strong&gt;Nginx &lt;/strong&gt;正在迎头赶上。&lt;/p&gt;
&lt;h2&gt;2.2 Nginx的应用现状&lt;/h2&gt;
&lt;p&gt;Nginx 已经在俄罗斯最大的门户网站── &lt;strong&gt;Rambler Media&lt;/strong&gt;（&lt;a href=&quot;http://www.rambler.ru/&quot;&gt;www.rambler.ru&lt;/a&gt;）上运行了3年时间，同时俄罗斯超过20%的虚拟主机平台采用Nginx作为反向代理服务器。&lt;/p&gt;
&lt;p&gt;在国内，已经有 淘宝、新浪博客、新浪播客、网易新闻、六间房、56.com、Discuz!、水木社区、豆瓣、YUPOO、海内、迅雷在线 等多家网站使用 Nginx 作为Web服务器或反向代理服务器。&lt;/p&gt;
&lt;h2&gt;2.3 Nginx的核心特点&lt;/h2&gt;
&lt;p&gt;（1）&lt;strong&gt;跨平台：&lt;/strong&gt;Nginx 可以在大多数 Unix like OS编译运行，而且也有Windows的移植版本；&lt;/p&gt;
&lt;p&gt;（2）&lt;strong&gt;配置异常简单：&lt;/strong&gt;非常容易上手。配置风格跟程序开发一样，神一般的配置；&lt;/p&gt;
&lt;p&gt;（3）&lt;strong&gt;非阻塞、高并发连接：&lt;/strong&gt;数据复制时，磁盘I/O的第一阶段是非阻塞的。官方测试能够支撑&lt;strong&gt;5万&lt;/strong&gt;并发连接，在实际生产环境中跑到&lt;strong&gt;2～3&lt;/strong&gt;万并发连接数。（这得益于Nginx使用了最新的epoll模型）；&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;&lt;strong&gt;PS：&lt;/strong&gt;对于一个Web服务器来说，首先看一个请求的基本过程：建立连接—接收数据—发送数据，在系统底层看来 ：上述过程（建立连接—接收数据—发送数据）在系统底层就是&lt;strong&gt;读写事件&lt;/strong&gt;。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;①如果采用&lt;strong&gt;阻塞调用&lt;/strong&gt;的方式，当读写事件没有准备好时，必然不能够进行读写事件，那么久只好等待，等事件准备好了，才能进行读写事件，那么请求就会被耽搁 。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;②既然没有准备好阻塞调用不行，那么采用&lt;strong&gt;非阻塞调用&lt;/strong&gt;方式。非阻塞就是：事件马上返回，告诉你事件还没准备好呢，你慌什么，过会再来吧。好吧，你过一会，再来检查一下事件，直到事件准备好了为止，在这期间，你就可以先去做其它事情，然后再来看看事件好了没。虽然不阻塞了，但你得&lt;strong&gt;不时地过来检查&lt;/strong&gt;一下事件的状态，你可以做更多的事情了，但带来的&lt;strong&gt;开销&lt;/strong&gt;也是不小的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;（4）&lt;strong&gt;事件驱动：&lt;/strong&gt;通信机制采用&lt;strong&gt;epoll&lt;/strong&gt;模型，支持更大的并发连接。&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;①非阻塞通过不断检查事件的状态来判断是否进行读写操作，这样带来的开销很大，因此就有了&lt;strong&gt;异步非阻塞的事件处理机制&lt;/strong&gt;。这种机制让你可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了，就返回。这种机制解决了上面阻塞调用与非阻塞调用的两个问题。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;②以&lt;strong&gt;epoll模型&lt;/strong&gt;为例：当事件没有准备好时，就放入epoll(队列)里面。如果有事件准备好了，那么就去处理；如果事件返回的是EAGAIN，那么继续将其放入epoll里面。从而，只要有事件准备好了，我们就去处理它，只有当所有事件都没有准备好时，才在epoll里面等着。这样，我们就可以并发处理大量的并发了，当然，这里的并发请求，是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，切换也是因为异步事件未准备好，而主动让出的。这里的切换是没有任何代价，你可以理解为循环处理多个准备好的事件，事实上就是这样的。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;③与多线程方式相比，这种事件处理方式是有很大的优势的，&lt;strong&gt;不需要创建线程&lt;/strong&gt;，每个请求占用的内存也很少，&lt;strong&gt;没有上下文切换&lt;/strong&gt;，事件处理非常的轻量级，并发数再多也不会导致无谓的资源浪费（上下文切换）。对于IIS服务器，每个请求会独占一个工作线程，当并发数上到几千时，就同时有几千的线程在处理请求了。这对操作系统来说，是个不小的挑战：因为线程带来的内存占用非常大，线程的上下文切换带来的cpu开销很大，自然性能就上不去，从而导致在高并发场景下性能下降严重。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;&lt;strong&gt;总结：&lt;em&gt;通过异步非阻塞的事件处理机制，Nginx实现由进程循环处理多个准备好的事件，从而实现高并发和轻量级&lt;/em&gt;&lt;/strong&gt;。 &lt;/span&gt;&lt;/p&gt;
&lt;p&gt;（5）&lt;strong&gt;Master/Worker结构&lt;/strong&gt;：一个master进程，生成一个或多个worker进程。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/30b7395c02b7d8504c0f78b53e53f446.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;&lt;strong&gt;PS：&lt;/strong&gt;Master-Worker设计模式核心思想是&lt;strong&gt;将原来串行的逻辑并行化&lt;/strong&gt;，并将逻辑拆分成很多独立模块并行执行。其中主要包含两个主要组件Master和Worker，Master主要将逻辑进行拆分，拆分为互相独立的部分，同时维护了Worker队列，将每个独立部分下发到多个Worker并行执行，Worker主要进行实际逻辑计算，并将结果返回给Master。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;&lt;strong&gt;问：&lt;/strong&gt;nginx采用这种进程模型有什么好处？&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span style=&quot;color: #888888;&quot;&gt;&lt;strong&gt;答：&lt;/strong&gt;采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，Master进程则很快重新启动新的Worker进程。当然，Worker进程的异常退出，肯定是程序有bug了，异常退出，会导致当前Worker上的所有请求失败，不过不会影响到所有请求，所以降低了风险。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;（6）&lt;strong&gt;内存消耗小：&lt;/strong&gt;处理大并发的请求内存消耗非常小。在3万并发连接下，开启的10个Nginx 进程才消耗150M内存（15M*10=150M）。&lt;/p&gt;
&lt;p&gt;（7）&lt;strong&gt;内置的健康检查功能：&lt;/strong&gt;如果 Nginx 代理的后端的某台 Web 服务器宕机了，不会影响前端访问。&lt;/p&gt;
&lt;p&gt;（8）&lt;strong&gt;节省带宽：&lt;/strong&gt;支持 GZIP 压缩，可以添加浏览器本地缓存的 Header 头。&lt;/p&gt;
&lt;p&gt;（9）&lt;strong&gt;稳定性高：&lt;/strong&gt;用于反向代理，宕机的概率微乎其微。&lt;/p&gt;
&lt;h1&gt;三、构建实战：Nginx+IIS构筑Web服务器集群的负载均衡&lt;/h1&gt;
&lt;p&gt;这里我们主要在Windows环境下，通过将同一个Web网站部署到不同服务器的IIS上，再通过一个统一的Nginx反响代理服务器对外提供统一访问接入，实现一个最简化的反向代理和负载均衡服务。但是，&lt;strong&gt;受限于实验条件&lt;/strong&gt;，我们这里主要在一台计算机上进行反向代理、IIS集群的模拟，具体的实验环境如下图所示：我们将nginx服务和web网站都部署在一台计算机上，nginx监听http80端口，而web网站分别以不同的端口号（这里是8050及8060）部署在同一个IIS服务器上，用户访问localhost时，nginx作为反向代理将请求均衡地转发给两个IIS中不同端口的Web应用程序进行处理。虽然实验环境很简单而且有限，但是对于一个简单的负载均衡效果而言，本文是可以达到并且展示的。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/911bd23b76aaea8fb54b32cd7a195107.jpg&quot;&gt;&lt;/p&gt;
&lt;h2&gt;3.1 准备一个ASP.NET网站部署到IIS服务器集群中&lt;/h2&gt;
&lt;p&gt;（1）在VS中新建一个ASP.NET Web应用程序，但是为了在一台计算机上展示效果，我们将这个Web程序复制一份，并修改两个Web程序的Default.aspx，让其的首页显示不同的一点信息。这里Web1展示的是“The First Web：”，而Web2展示的则是“The Second Web”。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/b55f9c59a9bbff9592292df05b23ff09.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（2）调试运行，看看两个网站的效果如何？&lt;/p&gt;
&lt;p&gt;①Web1的展示效果：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/5b972aead905cb9181c11ee8a3d9885a.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;②Web2的展示效果：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/ac4064849bf86a99b3f5aa5f095cb93f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;③部署到IIS中，分配不同的端口号：这里我选择了Web1:8050，Web2:8060&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6d2d16d12c0ef85eaa441135f8b0b09e.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（3）&lt;strong&gt;总结：&lt;em&gt;在真实环境中，构建Web应用服务器集群的实现是将同一个Web应用程序部署到Web服务器集群中的多个Web服务器上&lt;/em&gt;&lt;/strong&gt;。&lt;/p&gt;
&lt;h2&gt;3.2 下载Nginx并部署到服务器中作为自启动的Windows服务&lt;/h2&gt;
&lt;p&gt;（1）到Nginx官网下载Nginx的Windows版本：&lt;a href=&quot;http://nginx.org/en/download.html&quot; target=&quot;_blank&quot;&gt;http://nginx.org/en/download.html&lt;/a&gt;（这里我们使用nginx/Windows-1.4.7版本进行实验，本文底部有下载地址）&lt;/p&gt;
&lt;p&gt;（2）解压到磁盘任意目录，例如这里我解压到了：D:\Servers\nginx-1.4.7&lt;/p&gt;
&lt;p&gt;（3）启动、停止和重新加载服务：通过cmd以守护进程方式启动nginx.exe：&lt;strong&gt;start nginx.exe&lt;/strong&gt;，停止服务：&lt;strong&gt;nginx -s stop&lt;/strong&gt;，重新加载配置：&lt;strong&gt;nginx -s  reload&lt;/strong&gt;；&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/6b70619e8240eae82b1cc0bb3c8d3279.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（4）每次以cmd方式启动Nginx服务不符合实际要求，于是我们想到将其注册为Windows服务，并设置为自动启动模式。这里，我们使用一个不错的小程序：“Windows Service Wrapper”，将nginx.exe注册为Windows服务，具体的步凑如下：&lt;/p&gt;
&lt;p&gt;①下载最新版的 Windows Service Wrapper 程序，比如我下载的名称是 “winsw-1.8-bin.exe”（本文底部有下载地址），然后把它命名成你想要的名字（比如: “nginx-service.exe”，当然，你也可以不改名）&lt;/p&gt;
&lt;p&gt;②将重命名后的 nginx-service.exe 复制到 nginx 的安装目录（比如，我这里是 “D:\Servers\nginx-1.4.7″）&lt;/p&gt;
&lt;p&gt;③在同一个目录下创建一个Windows Service Wrapper 的XML配置文件，名称必须与第一步重命名时使用的名称一致（比如我这里是 “nginx-service.xml”,  如果，你没有重命名，则应该是 “winsw-1.8-bin.xml”），这个XML的内容如下：&lt;/p&gt;
&lt;pre class=&quot;brush: xml; gutter: true&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&amp;gt;
&amp;lt;service&amp;gt;
&amp;lt;id&amp;gt;nginx&amp;lt;/id&amp;gt;
&amp;lt;name&amp;gt;Nginx Service&amp;lt;/name&amp;gt;
&amp;lt;description&amp;gt;High Performance Nginx Service&amp;lt;/description&amp;gt;
&amp;lt;executable&amp;gt;D:\Servers\nginx-1.4.7\nginx.exe&amp;lt;/executable&amp;gt;
&amp;lt;logpath&amp;gt;D:\Servers\nginx-1.4.7\&amp;lt;/logpath&amp;gt;
&amp;lt;logmode&amp;gt;roll&amp;lt;/logmode&amp;gt;
&amp;lt;depend&amp;gt;&amp;lt;/depend&amp;gt;
&amp;lt;startargument&amp;gt;-p D:\Servers\nginx-1.4.7&amp;lt;/startargument&amp;gt;
&amp;lt;stopargument&amp;gt;-p D:\Servers\nginx-1.4.7 -s stop&amp;lt;/stopargument&amp;gt;
&amp;lt;/service&amp;gt;&lt;/pre&gt;
&lt;p&gt;④在命令行下执行以下命令，以便将其注册成Windows服务：&lt;strong&gt;nginx-service.exe install&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/06fba4076791ec620053ca9d1069a557.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;⑤接下来就可以在Windows服务列表看到Nginx服务了，这里我们可以将其设置为自动启动了：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/2c98e6f2aa36f46997d17e0673c26f9f.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（5）&lt;strong&gt;总结：&lt;em&gt;在Windows环境中，要对外提供的Windows服务一般都要将其启动类型设置为自动&lt;/em&gt;&lt;/strong&gt;。&lt;/p&gt;
&lt;h2&gt;3.3 修改Nginx核心配置文件nginx.conf&lt;/h2&gt;
&lt;p&gt;（1）进程数与每个进程的最大连接数：&lt;/p&gt;
&lt;div&gt;
&lt;ul&gt;
&lt;li&gt;nginx进程数，建议设置为等于CPU总核心数&lt;/li&gt;
&lt;li&gt;单个进程最大连接数，那么该服务器的最大连接数=连接数*进程数&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div&gt;
&lt;div&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/610ebb6f902d11404223eff8346992a1.jpg&quot;&gt;&lt;/div&gt;
&lt;div&gt;
&lt;p&gt;（2）Nginx的基本配置：&lt;/p&gt;
&lt;div&gt;
&lt;ul&gt;
&lt;li&gt;监听端口一般都为http端口：80;&lt;/li&gt;
&lt;li&gt;域名可以有多个，用空格隔开：例如 server_name www.ha97.com ha97.com;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9e9203413331acaa151b8890c14ddc4f.jpg&quot;&gt;&lt;/div&gt;
&lt;div&gt;
&lt;p&gt;（3）负载均衡列表基本配置：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;location / {}：对aspx后缀的进行负载均衡请求，假如我们要对所有的aspx后缀的文件进行负载均衡时，可以这样写：location ~ .*\.aspx$ {}&lt;/li&gt;
&lt;li&gt;proxy_pass：请求转向自定义的服务器列表，这里我们将请求都转向标识为http://cuitccol.com的负载均衡服务器列表；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3ea03bc8d529edf06c02128fa1ecb11c.jpg&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在负载均衡服务器列表的配置中，weight是权重，可以根据机器配置定义权重（如果某台服务器的硬件配置十分好，可以处理更多的请求，那么可以为其设置一个比较高的weight；而有一台的服务器的硬件配置比较差，那么可以将前一台的weight配置为weight=2，后一台差的配置为weight=1）。weigth参数表示权值，权值越高被分配到的几率越大；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/4aefe8606bb3d9884df9c88f9b3054f2.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（4）&lt;strong&gt;总结：&lt;em&gt;最基本的Nginx配置差不多就是上面这些内容，当然仅仅是最基础的配置&lt;/em&gt;&lt;em&gt;。&lt;/em&gt;&lt;/strong&gt;（详细的配置内容请下载底部的nginx-1.4.7详细查看）&lt;/p&gt;
&lt;h2&gt;3.4 添加Nginx对于静态文件的缓存配置&lt;/h2&gt;
&lt;p&gt;为了提高响应速度，减轻真实服务器的负载，对于静态资源我们可以在反向代理服务器中进行缓存，这也是反向代理服务器的一个重要的作用。&lt;/p&gt;
&lt;p&gt;（1）缓存静态资源之图片文件&lt;/p&gt;
&lt;p&gt;root /nginx-1.4.7/staticresources/image：对于配置中提到的jpg/png等文件均定为到/nginx-1.4.7/staticresources/image文件夹中进行寻找匹配并将文件返回；&lt;/p&gt;
&lt;p&gt;expires 7d：过期时效为7天，静态文件不怎么更新，过期时效可以设大一点，如果频繁更新，则可以设置得小一点；&lt;/p&gt;
&lt;p&gt;TIPS：下面的样式、脚本缓存配置同这里一样，只是定位的文件夹不一样而已，不再赘述。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/e351438b8fdcf8f31945606421491afb.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（2）缓存静态资源之样式文件&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/2510ce256c7170f9db15a79f0aa3d6dd.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（3）缓存静态资源之脚本文件&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/becd43064e435df970e92ae2d1725707.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（4）在nginx服务文件夹中创建静态资源文件夹，并要缓存的静态文件拷贝进去：这里我主要将Web程序中用到的image、css以及js文件拷贝了进去；&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/641989eed04b77306cb12e3ec1690925.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;（5）&lt;strong&gt;总结：&lt;em&gt;通过配置静态文件的缓存设置，对于这些静态文件的请求可以直接从反向代理服务器中直接返回，而无需再将这些静态资源请求转发到具体的Web服务器进行处理了，可以提高响应速度，减轻真实Web服务器的负载压力&lt;/em&gt;&lt;/strong&gt;。&lt;/p&gt;
&lt;h2&gt;3.5 简单测试Nginx反向代理实现负载均衡效果&lt;/h2&gt;
&lt;p&gt;（1）第一次访问http://localhost/Default.aspx时从127.0.0.1:8050处理响应返回结果&lt;/p&gt;
&lt;p&gt;（2）第二次访问http://localhost/Default.aspx时从127.0.0.1:8060处理响应返回结果&lt;/p&gt;
&lt;p&gt;（3）多次访问http://localhost/Default.aspx时的截屏：&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/3148d9a8e24240ea420536384323a2d0.jpg&quot;&gt;&lt;/p&gt;
&lt;h1&gt;学习小结&lt;/h1&gt;
&lt;p&gt;在本文中，借助了Nginx这个神器简单地在Windows环境下搭建了一个反向代理服务，并模拟了一个IIS服务器集群的负载均衡效果。从这个DEMO中，我们可以简单地感受到反向代理为我们所做的事情，并体会负载均衡是怎么一回事。但是，在目前大多数的应用中，都会将Nginx部署在Linux服务器中，并且会做一些针对负载均衡的优化配置，这里我们所做的仅仅就是一个小小的使用而已（just修改一下配置文件）。不过，万丈高楼平地起，前期的小小体会，也会帮助我们向后期的深入学习奠定一点点的基础。&lt;/p&gt;
&lt;p&gt;突然在QQ空间里看到了朋友送的礼物，猛然发现今天居然是我的阳历生日，好吧，我祝我自己生日快乐，希望自己在未来的日子中能够做更多的实践，分享更多的内容。当然，如果你觉得本文还可以，那也麻烦点个赞，不要吝啬你的鼠标左键哟。&lt;/p&gt;
&lt;h1&gt;参考资料&lt;/h1&gt;
&lt;p&gt;（1）丁胖胖，《图解正向代理、反向代理与透明代理》：&lt;a href=&quot;http://z00w00.blog.51cto.com/515114/1031287&quot; target=&quot;_blank&quot;&gt;http://z00w00.blog.51cto.com/515114/1031287&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;（2）特种兵-AK47，《正向代理与反向代理的区别》：&lt;a href=&quot;http://blog.csdn.net/m13666368773/article/details/8060481&quot; target=&quot;_blank&quot;&gt;http://blog.csdn.net/m13666368773/article/details/8060481&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;（3）百度百科，Nginx：&lt;a href=&quot;http://baike.baidu.com/view/926025.htm?fr=aladdin&quot; target=&quot;_blank&quot;&gt;http://baike.baidu.com/view/926025.htm?fr=aladdin&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;（4）51CTO，《Nginx安装配置与服务搭建专题》：&lt;a href=&quot;http://os.51cto.com/art/201111/304611.htm&quot; target=&quot;_blank&quot;&gt;http://os.51cto.com/art/201111/304611.htm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;（5）红黑联盟，《Nginx配置文件nginx.conf中文详解总结》：&lt;a href=&quot;http://www.2cto.com/os/201212/176520.html&quot; target=&quot;_blank&quot;&gt;http://www.2cto.com/os/201212/176520.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;（6）360doc，《Linux下同步模式、异步模式、阻塞调用与非阻塞调用总结》：&lt;a href=&quot;http://www.360doc.com/content/13/0117/12/5073814_260691714.shtml&quot; target=&quot;_blank&quot;&gt;http://www.360doc.com/content/13/0117/12/5073814_260691714.shtml&lt;/a&gt; （&lt;strong&gt;好文一篇，值得阅读&lt;/strong&gt;）&lt;/p&gt;
&lt;p&gt;（7）e路相扶，《同步、异步、阻塞与非阻塞》：&lt;a href=&quot;http://www.cnblogs.com/zhangjun516/archive/2013/04/17/3025902.html&quot; target=&quot;_blank&quot;&gt;http://www.cnblogs.com/zhangjun516/archive/2013/04/17/3025902.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;（8）feitianxuxue，《处理大并发之对异步非阻塞的理解》：&lt;a href=&quot;http://blog.csdn.net/feitianxuxue/article/details/8936802&quot; target=&quot;_blank&quot;&gt;http://blog.csdn.net/feitianxuxue/article/details/8936802&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;附件下载&lt;/h1&gt;
&lt;p&gt;（1）nginx-1.4.7：&lt;a href=&quot;http://pan.baidu.com/s/1dD2C2zB&quot; target=&quot;_blank&quot;&gt;http://pan.baidu.com/s/1dD2C2zB&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;（2）winsw-1.8-bin.exe：&lt;a href=&quot;http://pan.baidu.com/s/1kTihzk7&quot; target=&quot;_blank&quot;&gt;http://pan.baidu.com/s/1kTihzk7&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;

        
        			&lt;div class=&quot;textwidget&quot;&gt;
&lt;/div&gt;
		

	

</description>
        <pubDate>Thu, 04 Dec 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-12-04-80600-dfcc18970.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-12-04-80600-dfcc18970.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>利用脚本灵活定制 Elasticsearch 中的聚合效果</title>
        <description>

  
  &lt;div style=&quot;background-color: #FFF;&quot;&gt;
    &lt;p&gt;这几天阅读 Splunk 书，发现 Splunk 作为一个不需要提前结构化数据的处理工具，在自动发现的 “interesting fields” 以外，也提供了在页面通过正则临时产生新字段的能力。类似下面这样：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sourcetype=&quot;impl_splunk_gen&quot;
  | rex &quot;ip=(?P&amp;lt;subnet&amp;gt;\d+\.\d+\.\d+)\.\d+&quot;
  | chart values(subnet) by user network
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;这就蛮让人流口水的了。毕竟谁也不可能保证自己在结构化的时候做到了万事俱备。不过，ELK 虽然建议大家在 logstash 里通过 grok 来预处理，其实本身也是有这个能力的。今天稍微测试了一下，通过 ES 的 &lt;strong&gt;scripting&lt;/strong&gt; 模块，完全可以实现这个效果。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;测试在 Elasticsearch 1.4.1 上进行。较低的版本可能在支持的语言方面稍有差异。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;因为 scripting 在早先 1.2 的时候出过安全问题，所以后来就都不再允许直接通过 POST 的内容里提交 scripting 代码了。现在有两种方式，一种是在 elasticsearch-1.4.1/config/ 目录下新建一个 scripts 目录，然后把准备要用的脚本都放在这个目录里，ES 会自动探测并加载编译；另一种是开启动态 scripting 功能，再通过 &lt;code&gt;/_script&lt;/code&gt; 接口上传脚本。&lt;/p&gt;
&lt;p&gt;下面示例两种实现获取 client_ip 字段的 C 段的统计的方式：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;通过简单的切割合并&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;创建 &lt;code&gt;config/scripts/split.groovy&lt;/code&gt; 文件，内容如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fieldname&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;&#39;.&#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;..-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;&#39;.&#39;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;稍等一下，看到 ES 的日志显示探测到并且编译成功后。就可以发送请求了：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl &#39;127.0.0.1:9200/logstash-2014.11.27/_search?pretty&amp;amp;size=0&#39; -d &#39;{
    &quot;aggs&quot; : {
        &quot;ipaddr&quot; : {
            &quot;terms&quot; : {
                &quot;script&quot; : &quot;split&quot;,
                &quot;params&quot; : {
                    &quot;fieldname&quot;: &quot;client_ip.raw&quot;
                }
            }
        }
    }
}&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;注意这里一定要传递是 “not_analyzed” 的 字段过去！&lt;/strong&gt; ES 流程上是先过分词器再到 scripting 模块的，这里要是切一下，到你脚本里就不知道长啥样了……&lt;/p&gt;
&lt;p&gt;结果如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&quot;took&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&quot;timed_out&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&quot;_shards&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&quot;total&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&quot;successful&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&quot;failed&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&quot;hits&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&quot;total&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;786&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&quot;max_score&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&quot;hits&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&quot;aggregations&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&quot;ipaddr&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&quot;doc_count_error_upper_bound&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&quot;sum_other_doc_count&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&quot;buckets&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&quot;key&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;127.0.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&quot;doc_count&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;786&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;ol&gt;
  &lt;li&gt;通过正则捕获&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;前面的方式虽然达到目的，但是不像 splunk 的做法那么通用，所以更高级的是这样：&lt;/p&gt;
&lt;p&gt;创建 &lt;code&gt;config/scripts/regex.groovy&lt;/code&gt; 文件，内容如下：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;n&quot;&gt;matcher&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fieldname&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=~&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pattern&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;}/&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;matcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;matches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;matcher&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;同样等识别编译，然后发送这样的请求：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl &#39;127.0.0.1:9200/logstash-2014.11.27/_search?pretty&amp;amp;size=0&#39; -d &#39;{
    &quot;aggs&quot; : {
        &quot;ipaddr&quot; : {
            &quot;terms&quot; : {
                &quot;script&quot; : &quot;regex&quot;,
                &quot;params&quot; : {
                    &quot;fieldname&quot;: &quot;client_ip.raw&quot;,
                    &quot;pattern&quot;: &quot;^((?:\d{1,3}\.?){3})\.\d{1,3}$&quot;
                }
            }
        }
    }
}&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;得到一模一样的结果。&lt;/p&gt;
&lt;p&gt;下一次试验一下在脚本中尝试加载其他库做更复杂处理的话，会如何呢？&lt;/p&gt;
    &lt;hr&gt;
    
    &lt;hr&gt;
  &lt;!-- JiaThis Button BEGIN --&gt;
&lt;div class=&quot;jiathis_style&quot;&gt;
&lt;span class=&quot;jiathis_txt&quot;&gt;分享到：&lt;/span&gt;
&lt;a class=&quot;jiathis_button_tsina&quot;&gt;新浪微博&lt;/a&gt;
&lt;a class=&quot;jiathis_button_weixin&quot;&gt;微信&lt;/a&gt;
&lt;a class=&quot;jiathis_button_renren&quot;&gt;人人网&lt;/a&gt;
&lt;a class=&quot;jiathis_button_ydnote&quot;&gt;有道云笔记&lt;/a&gt;
&lt;a class=&quot;jiathis_button_gmail&quot;&gt;Gmail邮箱&lt;/a&gt;
&lt;a class=&quot;jiathis_button_twitter&quot;&gt;Twitter&lt;/a&gt;
&lt;a class=&quot;jiathis_button_googleplus&quot;&gt;Google+&lt;/a&gt;
&lt;a class=&quot;jiathis_button_hi&quot;&gt;百度空间&lt;/a&gt;
&lt;a class=&quot;jiathis_button_fb&quot;&gt;Facebook&lt;/a&gt;
&lt;a class=&quot;jiathis_button_douban&quot;&gt;豆瓣&lt;/a&gt;
&lt;a href=&quot;http://www.jiathis.com/share?uid=1589850&quot; class=&quot;jiathis jiathis_txt jiathis_separator jtico jtico_jiathis&quot; target=&quot;_blank&quot;&gt;更多&lt;/a&gt;
&lt;a class=&quot;jiathis_counter_style&quot;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var jiathis_config={
	data_track_clickback:true,
	summary:&quot;&quot;,
	ralateuid:{
		&quot;tsina&quot;:&quot;1035836154&quot;
	},
	shortUrl:false,
	hideMore:false
}
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://v3.jiathis.com/code/jia.js?uid=1589850&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;!-- JiaThis Button END --&gt;
&lt;!-- UY BEGIN --&gt;


&lt;!-- UY END --&gt;
  &lt;/div&gt;

</description>
        <pubDate>Thu, 27 Nov 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-11-27-elasticsearch-scripts-aggregations-f36ea8008.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-11-27-elasticsearch-scripts-aggregations-f36ea8008.html</guid>
        
        
        <category>chenlinux</category>
        
      </item>
    
      <item>
        <title>一致性哈希算法原理设计</title>
        <description>

        &lt;div style=&quot;margin-bottom: 10px;&quot;&gt;
            
        &lt;/div&gt;

		
&lt;h2&gt;
&lt;strong&gt;一&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;strong&gt;前言&lt;/strong&gt;
&lt;/h2&gt;
&lt;p&gt;一致性哈希(Consistent Hashing)，最早由MIT的Karger于1997年提出，主要用于解决易变的分布式Web系统中，由于宕机和扩容导致的服务震荡。现在这个算法思路被大量应用，并且在实践中得到了很大的发展。&lt;/p&gt;
&lt;h2&gt;
&lt;strong&gt;二&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;strong&gt;算法设计&lt;/strong&gt;
&lt;/h2&gt;
&lt;h3&gt;
&lt;strong&gt;1.&lt;/strong&gt;&lt;strong&gt;问题来源&lt;/strong&gt;
&lt;/h3&gt;
&lt;p&gt;一个由6台服务器组成的服务，每台Server负责存储1/6的数据，当Server1出现宕机之后，服务重新恢复可用时的场景。&lt;/p&gt;
&lt;p&gt;如下表格可以很清楚的看到，当Server1宕机时，Hash1的服务完全不可用了，所以需要ReHash由剩余5台机器提供所有的数据服务，但由于每台机器负责的数据段大小不相同，那么需要在不同的服务器之间大量迁移数据，并且数据迁移完成之前服务会不可用。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/4d3b8c16ea17c275abcfb5e1a820ebb1.jpg&quot;&gt;&lt;/p&gt;
&lt;h3&gt;
&lt;strong&gt;2.&lt;/strong&gt;&lt;strong&gt;经典一致性哈希算法&lt;/strong&gt;
&lt;/h3&gt;
&lt;p&gt;针对ReHash的弊端，Karger提出了一种算法，算法的核心是”虚拟节点”。&lt;/p&gt;
&lt;p&gt;将所有的数据映射成一组大于服务器数量的虚拟节点，虚拟节点再映射到真实的服务器。所以当服务器宕机时，由于虚拟节点的数量固定不变，所有不需要ReHash，而只需要将服务不可用的虚拟节点重新迁移，这样只需要迁移宕机节点的数据。&lt;/p&gt;
&lt;p&gt;经典的算法中，宕机服务器的下一个真实节点将提供服务。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/fb21aa9e4634d16b2729d713ed5e431d.jpg&quot;&gt;&lt;/p&gt;
&lt;h2&gt;
&lt;strong&gt;三&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;strong&gt;算法改进&lt;/strong&gt;
&lt;/h2&gt;
&lt;h3&gt;
&lt;strong&gt;1.&lt;/strong&gt;&lt;strong&gt;经典一致性哈希算法的问题&lt;/strong&gt;
&lt;/h3&gt;
&lt;p&gt;经典的算法只是解决了ReHash算法的缺陷，当本身并不完美。主要存在以下几个问题：&lt;/p&gt;
&lt;p&gt;(1)Server1宕机会导致Server2的服务承受一倍的数据服务，且如果Server1就此退役，那么整个系统的负载完全不均衡了。&lt;/p&gt;
&lt;p&gt;(2)如果所有的Server都能承受一倍的数据读写，那么如果在正常情况下所有的数据写两份到不同的服务器，主备或者负载均衡，宕机时直接读备份节点的数据，根本不需要出现经典算法中的数据迁移。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/77df1326e4f9b97aab8488ae9a64bfe0.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong style=&quot;font-style: normal;&quot;&gt;2.Dynamo&lt;/strong&gt;&lt;strong style=&quot;font-style: normal;&quot;&gt;改进实践&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Amazon的大数据存储平台”Dynamo”使用了一致性哈希，但它并没有使用经典算法，而是使用了故障节点ReHash的思路。&lt;/p&gt;
&lt;p&gt;系统将所有的虚拟节点和真实服务器的对应关系保存到一个配置系统，当某些虚拟节点的服务不可用时，重新配置这些虚拟节点的服务到其他真实服务器，这样既不用大量迁移数据，也保证了所有服务器的负载相对均衡。&lt;/p&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;92&quot;&gt;虚拟节点&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;92&quot;&gt;0-4/5&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;92&quot;&gt;10-14/6&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;92&quot;&gt;15-19/7&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;92&quot;&gt;20-24/8&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;92&quot;&gt;24-29/9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;92&quot;&gt;恢复&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;92&quot;&gt;Server0&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;92&quot;&gt;Server2&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;92&quot;&gt;Server3&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;92&quot;&gt;Server4&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;92&quot;&gt;Server5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;
&lt;strong&gt;四&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;strong&gt;算法扩展&lt;/strong&gt;
&lt;/h3&gt;
&lt;p&gt;一致性哈希算法本身是用于解决服务器宕机与扩容的问题，但”虚拟节点”的算法思想有所发展，一些分布式的系统用于实现系统的负载均衡和最优访问策略。&lt;/p&gt;
&lt;p&gt;在真实的系统情况下，相同部署的两套系统可能不能提供相同的服务，主要原因：&lt;/p&gt;
&lt;p&gt;(1)硬件个体差异导致服务器性能不同。&lt;/p&gt;
&lt;p&gt;(2)机房交换机和网络带宽导致IDC服务器之间的网络通信效率不同。&lt;/p&gt;
&lt;p&gt;(3)用户使用不同的网络运营商导致电信IDC和联通IDC提供的服务性能不同。&lt;/p&gt;
&lt;p&gt;(4)服务器所在网络或机房遭遇攻击。&lt;/p&gt;
&lt;p&gt;所以完全相同的两套系统可能也需要提供差异化的服务，通过使用虚拟节点可以灵活的动态调整，达到系统服务的最优化。&lt;/p&gt;
&lt;p&gt;对于由2个节点，每个节点3台服务器组成的分布式系统，S0-1为分布式系统1的Server0，系统配置管理员可以根据系统真实的服务效率动态的调整虚拟节点与真实服务器的映射关系，也可以由客户系统自身根据响应率或响应时间等情况调整自身的访问策略。&lt;/p&gt;
&lt;table border=&quot;1&quot; cellspacing=&quot;0&quot; cellpadding=&quot;0&quot;&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;虚拟节点&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;0-2&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;3-4&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;5-7&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;8-9&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;10-12&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;13-14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;服务器&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;S0-1&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;S0-2&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;S1-1&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;S1-2&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;S2-1&lt;/td&gt;
&lt;td valign=&quot;top&quot; width=&quot;79&quot;&gt;S2-2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;
&lt;strong&gt;五&lt;/strong&gt;&lt;strong&gt;.Reference&lt;/strong&gt;
&lt;/h3&gt;
&lt;p&gt;(1)&lt;a href=&quot;http://zh.wikipedia.org/wiki/%E4%B8%80%E8%87%B4%E5%93%88%E5%B8%8C&quot;&gt;一致哈希(wiki)&lt;/a&gt;&lt;br&gt;
(2)&lt;a href=&quot;http://en.wikipedia.org/wiki/Consistent_hashing&quot;&gt;Consistent hashing&lt;/a&gt;&lt;br&gt;
(3)&lt;a href=&quot;http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf&quot;&gt;Dynamo: Amazon’s Highly Available Key-value Store&lt;/a&gt;&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Wed, 26 Nov 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-11-26-80334-4aea8dc6b.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-11-26-80334-4aea8dc6b.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>利用动态仪表板实现kibana单图表导出功能</title>
        <description>

  
  &lt;div style=&quot;background-color: #FFF;&quot;&gt;
    &lt;p&gt;昨天和朋友聊天，说监控报表的话题，他们认为 kibana 的仪表板形式，还是偏重技术人员做监控的 screen 思路，对 erp 之类的报表不是很友好。要想跟其他系统结合，或者说嵌入到其他系统中，就必须得有单个图表的导出，或者 URL 引用方式。当时我直觉上的反应，就是这个没问题，可以通过 javascript 动态仪表板这个高级功能完成。回来试了一下，比我想的稍微复杂一点点，还是可以很轻松完成的。&lt;/p&gt;
&lt;p&gt;读过&lt;a href=&quot;http://kibana.logstash.es/content/dashboard-schema.html&quot;&gt;仪表板纲要&lt;/a&gt;一文，或者自己看过源代码中 &lt;code&gt;src/app/dashboards/logstash.json&lt;/code&gt; 文件的人，应该都知道 kibana 中有些在页面配置界面里看不到的隐藏配置选项。其中很符合我们这次需求的，就有 &lt;code&gt;editable&lt;/code&gt;, &lt;code&gt;collapsable&lt;/code&gt; 等。所以，首先第一步，我们可以在自己的 &lt;code&gt;panel.js&lt;/code&gt;(直接从 logstash.js 复制过来) 中，把这些关掉：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;nx&quot;&gt;dashboard&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;rows&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;editable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;         &lt;span class=&quot;c1&quot;&gt;//不显示每行的编辑按钮&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;collapsable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;//不显示每行的折叠按钮&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Events&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;400px&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;panels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;editable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;//不显示面板的编辑按钮&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;events over time&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;histogram&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;time_field&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ARGS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;timefield&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;||&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;@timestamp&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;auto_int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;span&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;dashboard&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;editable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;//不显示仪表板的编辑按钮&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;dashboard&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;panel_hints&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;//不显示面板的添加按钮&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后要解决面板上方的 query 框和 filtering 框。这个同样在纲要介绍里说了，这两个特殊的面板是放在垂幕(pulldows)里的。所以，直接关掉垂幕就好了：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;nx&quot;&gt;dashboard&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;pulldowns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[];&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;然后再往上是顶部栏。顶部栏里有时间选择器，这个跟垂幕一样是可以关掉的：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;nx&quot;&gt;dashboard&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;nav&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[];&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;好了，javascript 里可以关掉的，都已经关了。&lt;/p&gt;
&lt;p&gt;但是运行起来，发现顶部栏里虽然是没有时间选择器和配置编辑按钮了，本身这个黑色条带和 logo 图什么的，却依然存在！这时候我想起来有时候 config.js 没写对，&lt;code&gt;/_nodes&lt;/code&gt; 获取失败的时候，打开的页面就是背景色外加这个顶条 —— 也就是说，这部分代码是写在 &lt;code&gt;index.html&lt;/code&gt; 里的，不受 &lt;code&gt;app/dashboards/panel.js&lt;/code&gt; 控制。&lt;/p&gt;
&lt;p&gt;所以这里就得去修改一下 &lt;code&gt;index.html&lt;/code&gt; 了。不过为了保持兼容性，我这里没有直接删除顶部栏的代码，而是用了 angularjs 中很常用的 &lt;code&gt;ng-show&lt;/code&gt; 指令：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-html&quot; data-lang=&quot;html&quot;&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;ng-cloak&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;navbar navbar-static-top&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;ng-show=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;dashboard.current.nav.length&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;因为之前关闭时间选择器的时候，已经把这个 nav 数组定义为空了，所以只要判断一下数组长度即可。&lt;/p&gt;
&lt;p&gt;效果如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/chenlinux.com/3747fb3af94787b878445fd191c7a181.jpg&quot; alt=&quot;single panel&quot;&gt;&lt;/p&gt;
&lt;p&gt;因为 &lt;code&gt;dashboard.services&lt;/code&gt; 的定义没有做修改，所以这个其实照样支持你用鼠标拉动选择时间范围，支持你在 URL 后面加上 &lt;code&gt;?query=status:404&amp;amp;from=1h&lt;/code&gt; 这样的参数，效果都是对的。只不过不会再让你看到这些文字显示在页面上了。&lt;/p&gt;
&lt;p&gt;如果要求再高一点，其实完全可以在 &lt;code&gt;ARGS&lt;/code&gt; 里处理更复杂的参数，比如直接 &lt;code&gt;?type=terms&amp;amp;field=host&amp;amp;value_field=requesttime&lt;/code&gt; 就生成 &lt;code&gt;dashboard.rows[0].panels[0]&lt;/code&gt; 里的对应参数，达到自动控制图表类型和效果的目的。&lt;/p&gt;
    &lt;hr&gt;
    
    &lt;hr&gt;
  &lt;!-- JiaThis Button BEGIN --&gt;
&lt;div class=&quot;jiathis_style&quot;&gt;
&lt;span class=&quot;jiathis_txt&quot;&gt;分享到：&lt;/span&gt;
&lt;a class=&quot;jiathis_button_tsina&quot;&gt;新浪微博&lt;/a&gt;
&lt;a class=&quot;jiathis_button_weixin&quot;&gt;微信&lt;/a&gt;
&lt;a class=&quot;jiathis_button_renren&quot;&gt;人人网&lt;/a&gt;
&lt;a class=&quot;jiathis_button_ydnote&quot;&gt;有道云笔记&lt;/a&gt;
&lt;a class=&quot;jiathis_button_gmail&quot;&gt;Gmail邮箱&lt;/a&gt;
&lt;a class=&quot;jiathis_button_twitter&quot;&gt;Twitter&lt;/a&gt;
&lt;a class=&quot;jiathis_button_googleplus&quot;&gt;Google+&lt;/a&gt;
&lt;a class=&quot;jiathis_button_hi&quot;&gt;百度空间&lt;/a&gt;
&lt;a class=&quot;jiathis_button_fb&quot;&gt;Facebook&lt;/a&gt;
&lt;a class=&quot;jiathis_button_douban&quot;&gt;豆瓣&lt;/a&gt;
&lt;a href=&quot;http://www.jiathis.com/share?uid=1589850&quot; class=&quot;jiathis jiathis_txt jiathis_separator jtico jtico_jiathis&quot; target=&quot;_blank&quot;&gt;更多&lt;/a&gt;
&lt;a class=&quot;jiathis_counter_style&quot;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var jiathis_config={
	data_track_clickback:true,
	summary:&quot;&quot;,
	ralateuid:{
		&quot;tsina&quot;:&quot;1035836154&quot;
	},
	shortUrl:false,
	hideMore:false
}
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://v3.jiathis.com/code/jia.js?uid=1589850&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;!-- JiaThis Button END --&gt;
&lt;!-- UY BEGIN --&gt;


&lt;!-- UY END --&gt;
  &lt;/div&gt;

</description>
        <pubDate>Sun, 23 Nov 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-11-23-kibana-panel-only-dashboard-3474bf0cc.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-11-23-kibana-panel-only-dashboard-3474bf0cc.html</guid>
        
        
        <category>chenlinux</category>
        
      </item>
    
      <item>
        <title>Linux Performance Tools 2014</title>
        <description>

&lt;p&gt;Last month I gave an updated Linux Performance Tools talk for &lt;a href=&quot;http://events.linuxfoundation.org/events/archive/2014/linuxcon-europe&quot;&gt;LinuxCon Europe 2014&lt;/a&gt; in Düsseldorf. This included static performance tuning, as well as other updates. My performance observability tools diagram now includes rdmsr, after my post on &lt;a href=&quot;/blog/2014-09-15/the-msrs-of-ec2.html&quot;&gt;The MSRs of EC2&lt;/a&gt;, where I discovered that MSRs could be useful:&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;
&lt;center&gt;&lt;a href=&quot;/Perf/linux_observability_tools.png&quot;&gt;&lt;img src=&quot;/images/brendangregg.com/386f03345157c7fac26406e42798f874.jpg&quot; width=&quot;500&quot; height=&quot;350&quot;&gt;&lt;/a&gt;&lt;/center&gt;

&lt;p&gt;I keep this diagram updated on &lt;a href=&quot;/linuxperf.html&quot;&gt;linuxperf&lt;/a&gt;. The slides from my talk are on (&lt;a href=&quot;http://www.slideshare.net/brendangregg/linux-performance-tools-2014&quot;&gt;slideshare&lt;/a&gt;):&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;
&lt;center&gt;&lt;iframe src=&quot;http://www.slideshare.net/slideshow/embed_code/40240208&quot; width=&quot;427&quot; height=&quot;356&quot; frameborder=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; scrolling=&quot;no&quot; style=&quot;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&quot; allowfullscreen&gt; &lt;/iframe&gt;&lt;/center&gt;

&lt;p&gt;As I didn&#39;t see an official video camera in the room, I had my friends at &lt;a href=&quot;http://www.efficios.com/&quot;&gt;EfficOS&lt;/a&gt; film it, who also filmed the &lt;a href=&quot;http://lwn.net/Articles/622033/rss&quot;&gt;Tracing Summit&lt;/a&gt;. This is on (&lt;a href=&quot;https://www.youtube.com/watch?v=SN7Z0eCn0VY&quot;&gt;youtube&lt;/a&gt;):&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;
&lt;center&gt;&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;http://www.youtube.com/embed/SN7Z0eCn0VY&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;/center&gt;

&lt;p&gt;The main objective of my talk was to give you exposure to what exists in the field of Linux performance tools – to turn unknown unknowns into known unknowns. &lt;/p&gt;

&lt;div style=&quot;float:right;padding-left:10px;padding-bottom:5px&quot;&gt;
&lt;img src=&quot;/images/brendangregg.com/40960fcd9a650b461bf8cd7271ebe119.jpg&quot; width=&quot;250&quot; height=&quot;161&quot;&gt;&lt;br&gt;&lt;center&gt;&lt;font size=&quot;-1&quot;&gt;&lt;i&gt;Photo by &lt;a href=&quot;https://www.flickr.com/photos/linuxfoundation/15348354449/&quot;&gt;Linux Foundation&lt;/a&gt;&lt;/i&gt;&lt;/font&gt;&lt;/center&gt;
&lt;/div&gt;

&lt;p&gt;In my earlier &lt;a href=&quot;/blog/2014-08-23/linux-perf-tools-linuxcon-na-2014.html&quot;&gt;LinuxCon North America&lt;/a&gt; talk, I had three main collections of performance tools, with a diagram for each: for observability, benchmarking, and tuning tools. For this LinuxCon Europe talk, I introduced a fourth main category: static performance tuning tools.&lt;/p&gt;

&lt;p&gt;I learned about static performance tuning from a paper by Richard Elling in 2000: the idea is to check the static configured state of the system, &lt;em&gt;without load&lt;/em&gt;, to look for a class of issues not found by other tools. This includes things like checking how full the filesystems are, the routing table, and network interface auto-negotiation. I feel the addition of this group of tools makes this talk complete: I&#39;m summarizing all the main tools in one short talk.&lt;/p&gt;

&lt;p&gt;At LinuxCon Europe I also saw a great talk by Ben Maurer on &lt;a href=&quot;http://events.linuxfoundation.org/sites/events/files/slides/lpc.pdf&quot;&gt;Scaling Userspace @ Facebook&lt;/a&gt; (slides), where he discussed some serious systems performance analysis on Linux that they have been doing. It&#39;s impressive, interesting, and deep work. Sadly I didn&#39;t see a video camera to capture it.&lt;/p&gt;

&lt;p&gt;Steven Rostedt from Red Hat gave a stunning talk on &lt;a href=&quot;http://www.linuxplumbersconf.org/2014/ocw//system/presentations/1773/original/ftrace-kernel-hooks-2014.pdf&quot;&gt;Ftrace Kernel Hooks: More than just tracing&lt;/a&gt; (slides). This might be the most technical talk I&#39;ve ever seen! I found it particularly interesting as I&#39;ve been doing a lot with ftrace, an undiscovered gem of Linux, including using it for my &lt;a href=&quot;https://github.com/brendangregg/perf-tools&quot;&gt;perf-tools&lt;/a&gt; collection. I heard this talk was videoed, although I haven&#39;t seen the video yet.&lt;/p&gt;

&lt;p&gt;I also saw Rikki Endsley, also now at Red Hat, give a talk on &lt;a href=&quot;http://lccoelce14.sched.org/event/e883537a4136e09a421beb97440ee59b?iframe=no&amp;amp;w=&amp;amp;sidebar=yes&amp;amp;bg=no#.VHD-NmTF9o8&quot;&gt;Confessions of a Reluctant Tweeter: Social Media for Open Source Communities&lt;/a&gt;. Rikki has contributed much to our industry, and it&#39;s interesting to hear her expertise on open source marketing in general. I had spoken about marketing earlier in the week at the Tracing Summit, where Linux technologies like ftrace could really benefit from more exposure.&lt;/p&gt;

&lt;p&gt;Thanks to those who attended my talk, and the Linux Foundation for organizing another great event!&lt;/p&gt;


</description>
        <pubDate>Sat, 22 Nov 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-11-22-linux-perf-tools-2014.html-100c15b15.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-11-22-linux-perf-tools-2014.html-100c15b15.html</guid>
        
        
        <category>brendangregg</category>
        
      </item>
    
      <item>
        <title>用 phantomjs 截图</title>
        <description>

  
  &lt;div style=&quot;background-color: #FFF;&quot;&gt;
    &lt;p&gt;昨儿给 kibana 加上了 table 面板数据导出成 CSV 的功能。朋友们就问了，那其他面板的图表怎么导出保存呢？其实直接截图就好了嘛……&lt;/p&gt;
&lt;p&gt;FireFox 有插件用来截全网页图。不过如果作为定期的工作，这么搞还是比较麻烦的，需要脚本化下来。这时候就可以用上 phantomjs 软件了。phantomjs 是一个基于 webkit 引擎做的 js 脚本库。可以通过 js 程序操作 webkit 浏览器引擎，实现各种浏览器功能。&lt;/p&gt;
&lt;p&gt;因为用了 webkit ，所以软件编译起来挺麻烦的，建议是直接从官方下载二进制包用得了。&lt;/p&gt;
&lt;p&gt;想要给 kibana 页面截图，几行代码就够了：&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;page&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;webpage&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;create&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;address&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;http://kibana.dip.sina.com.cn/#/dashboard/elasticsearch/h5_view&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;kibana.png&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;page&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;viewportSize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1366&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;nx&quot;&gt;page&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!==&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&#39;success&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&#39;Unable to load the address!&#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;phantom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;window&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;setTimeout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nx&quot;&gt;page&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;render&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
            &lt;span class=&quot;nx&quot;&gt;phantom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;exit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;这里两个要点：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;要设置 &lt;code&gt;viewportSize&lt;/code&gt; 里的宽度，否则效果会变成单个 panel 依次往下排列。&lt;/li&gt;
  &lt;li&gt;要设置 &lt;code&gt;setTimeout&lt;/code&gt;，否则在获取完 index.html 后就直接返回了，只能看到一个大白板。用 phantomjs 截取 angularjs 这类单页 MVC 框架应用时一定要设置这个。&lt;/li&gt;
&lt;/ol&gt;
    &lt;hr&gt;
    
    &lt;hr&gt;
  &lt;!-- JiaThis Button BEGIN --&gt;
&lt;div class=&quot;jiathis_style&quot;&gt;
&lt;span class=&quot;jiathis_txt&quot;&gt;分享到：&lt;/span&gt;
&lt;a class=&quot;jiathis_button_tsina&quot;&gt;新浪微博&lt;/a&gt;
&lt;a class=&quot;jiathis_button_weixin&quot;&gt;微信&lt;/a&gt;
&lt;a class=&quot;jiathis_button_renren&quot;&gt;人人网&lt;/a&gt;
&lt;a class=&quot;jiathis_button_ydnote&quot;&gt;有道云笔记&lt;/a&gt;
&lt;a class=&quot;jiathis_button_gmail&quot;&gt;Gmail邮箱&lt;/a&gt;
&lt;a class=&quot;jiathis_button_twitter&quot;&gt;Twitter&lt;/a&gt;
&lt;a class=&quot;jiathis_button_googleplus&quot;&gt;Google+&lt;/a&gt;
&lt;a class=&quot;jiathis_button_hi&quot;&gt;百度空间&lt;/a&gt;
&lt;a class=&quot;jiathis_button_fb&quot;&gt;Facebook&lt;/a&gt;
&lt;a class=&quot;jiathis_button_douban&quot;&gt;豆瓣&lt;/a&gt;
&lt;a href=&quot;http://www.jiathis.com/share?uid=1589850&quot; class=&quot;jiathis jiathis_txt jiathis_separator jtico jtico_jiathis&quot; target=&quot;_blank&quot;&gt;更多&lt;/a&gt;
&lt;a class=&quot;jiathis_counter_style&quot;&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;script type=&quot;text/javascript&quot;&gt;
var jiathis_config={
	data_track_clickback:true,
	summary:&quot;&quot;,
	ralateuid:{
		&quot;tsina&quot;:&quot;1035836154&quot;
	},
	shortUrl:false,
	hideMore:false
}
&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot; src=&quot;http://v3.jiathis.com/code/jia.js?uid=1589850&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;!-- JiaThis Button END --&gt;
&lt;!-- UY BEGIN --&gt;


&lt;!-- UY END --&gt;
  &lt;/div&gt;

</description>
        <pubDate>Thu, 20 Nov 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-11-20-phantomjs-snapshot-63b00217f.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-11-20-phantomjs-snapshot-63b00217f.html</guid>
        
        
        <category>chenlinux</category>
        
      </item>
    
      <item>
        <title>计算机算法：数据压缩之相对编码（4）</title>
        <description>
&lt;p&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 28px; font-style: normal; font-weight: bold; line-height: 42px;&quot;&gt;概述&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;相对编码是另一种数据压缩算法。&lt;a href=&quot;http://blog.jobbole.com/79758/&quot; target=&quot;_blank&quot;&gt;游程编码&lt;/a&gt;、&lt;a href=&quot;http://blog.jobbole.com/79760/&quot; target=&quot;_blank&quot;&gt;位图编码&lt;/a&gt;以及&lt;a href=&quot;http://blog.jobbole.com/79952/&quot; target=&quot;_blank&quot;&gt;图编码和模式替换&lt;/a&gt;都基于减少重复数据实现，而相对编码目标略有不同。的确，游程编码要查找连续重复出现的元素，模式替换和位图编码要“映射”重复出现的位置。&lt;/p&gt;
&lt;p&gt;这些算法的唯一问题在于输入数据并非总是由重复元素组成。很明显，如果输入数据流包含许多重复元素，必定能减少。然而，这并不意味着没有重复元素的数据就不能压缩。这取决于数据。假设我们要压缩的数据如下。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;1, 2, 3, 4, 5, 6, 7&lt;/pre&gt;
&lt;p&gt;难以想象这个数据流能被压缩。压缩字母时可能存在同样的问题。的确，字母是构成单词的基础，是构成单词的最小单元而且很难再压缩。&lt;/p&gt;
&lt;p&gt;幸运的是，事实并非如此。相对编码可以处理非重复数据。让我们看看下面的输入流——一段给定的年份（90年的）。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;1991,1991,1999,1998,1991,1993,1992,1992&lt;/pre&gt;
&lt;p&gt;这里有39个字符，我们能够压缩它们。我们通常使用的方法是去掉前面的“19”。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;91,91,99,98,91,93,92,92&lt;/pre&gt;
&lt;p&gt;现在我们得到一个更短的字符串，但在保留第一个年份的基础上可以更进一步的压缩。其余的年份均相对于该年份。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;91,0,8,7,0,2,1,1&lt;/pre&gt;
&lt;p&gt;此时传输的数据量减少了很多（从39降至16——超过50%）。然而，我们首先需要考虑一些问题，因为数据流的格式不会总是如此巧合。下面字符流会怎样？&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;91,94,95,95,98,100,101,102,105,110&lt;/pre&gt;
&lt;p&gt;我们看到数值100在区间的中间，使用该值作为相对编码的基准很方便。那么上面的数据流就变成如下：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;-9,-6,-5,-5,-2,100,1,2,5,10&lt;/pre&gt;
&lt;p&gt;问题在于决定哪一个数值作为基准值并不容易。如果数据以不同方式排列会怎样。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;96,97,98,99,100,101,102,103,999,1000,1001,1002&lt;/pre&gt;
&lt;p&gt;此时，数值“100”不能作为基准值，因为以该值为基准将得到如下结果：&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;-4,-3,-2,-1,100,1,2,3,899,900,901,902&lt;/pre&gt;
&lt;p&gt;对某基准值附近的相对值分组将会更加方便。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;(-4,-3,-2,-1,100,1,2,3)(-1,1000,1,2)&lt;/pre&gt;
&lt;p&gt;然而，找出基准值并不那么容易。编码格式也并不那么重要。但是下面提到的这种情况，这种编码却很有用。&lt;/p&gt;
&lt;h1&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 28px; font-style: normal; font-weight: bold; line-height: 42px;&quot;&gt;实现&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;该算法的实现取决于特定的任务和数据流格式。假设我们要使用JSON从web服务器传输年份数据流到浏览器，下面是一段简单的PHP片段。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;// JSON: [1991,1991,1999,1998,1999,1998,1995,1997,1994,1993]
$years = array(1991,1991,1999,1998,1999,1998,1995,1997,1994,1993);

function relative_encoding($input)
{
       $output = array();
       $inputLength = count($input);

       $base = $input[0];

       $output[] = $base;

       for ($i = 1; $i &amp;lt; $inputLength; $i++) {
               $output[] = $input[$i] - $base;
       }

       return $output;
}

// JSON: [1991,0,8,7,8,7,4,6,3,2]
echo json_encode(relative_encoding($years));&lt;/pre&gt;
&lt;h1&gt;应用&lt;/h1&gt;
&lt;p&gt;该算法在很多情况都很有效，以下是其中一例。网络上有很多地图应用。例如&lt;a href=&quot;http://maps.google.com/&quot;&gt;谷歌地图&lt;/a&gt;，&lt;a href=&quot;http://maps.yahoo.com/&quot;&gt;雅虎地图&lt;/a&gt;，&lt;a href=&quot;http://www.bing.com/maps/&quot;&gt;必应地图&lt;/a&gt;就是非常有名的应用，同时也有非常有用的开源项目&lt;a href=&quot;http://www.openstreetmap.org/&quot;&gt;OpenStreetMap&lt;/a&gt;。成千上万的网站使用这些应用。&lt;/p&gt;
&lt;p&gt;典型的使用案例是使用JSON从服务器传输大量地理坐标到浏览器。的确，地球上任何地理坐标点都相对于非洲西海岸附近的（0,0）点而言，在一定范围内，当有大量标记时，我们可以使用相对编码来传输信息。&lt;/p&gt;
&lt;p&gt;例如，下图为标识了一些点的旧金山地图。它们的坐标都是相对于地球的（0,0）点而言。&lt;/p&gt;
&lt;p&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/3fad8a15b90e48d724e1bb8036fefbda.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;地图标记相对于地球的（0,0）点而言，有时没什么效果。&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;更加有效方式是相对市中心对那些标记进行编码，这样可以节省空间。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/c19fa5a1a690d2a4f79e6929703d618a.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;span style=&quot;color: #888888;&quot;&gt;在一定范围内对地图标记使用相对编码非常有效！&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;然而，这种压缩类型可能会非常棘手，比如拖动地图和更新坐标数组时。此外，如果需要加载多个城市，我们必须对坐标进行分组。所以，在实现时必须谨慎。但另一方面，这也会很有用——例如在初始化加载地图时可以减少数据量，缩短加载时间。&lt;/p&gt;
&lt;p&gt;使用相对编码，我们只要保存相对基准值（数据）的偏移量——就像版本控制系统一样，这样可以降低传输和加载的数据。这里有一个图形的例子。第一种情况下，我们看到以下图标中的每一项都是单独保存。它与相邻元素无关，可以独立与其他元素存在。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/92bd70c5fdd5339a160b1c40eb0a84ee.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;我们能只保存第一个元素，其余元素都相对与该元素，如下图标所示。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/0911a3a6c537f407a0dd5814589baa3b.jpg&quot;&gt;&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Thu, 20 Nov 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-11-20-79761-28f044a97.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-11-20-79761-28f044a97.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
      <item>
        <title>计算机算法：数据压缩之前缀编码（5）</title>
        <description>

        &lt;div style=&quot;margin-bottom: 10px;&quot;&gt;
            
        &lt;/div&gt;

		
&lt;p&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 28px; font-style: normal; font-weight: bold; line-height: 42px;&quot;&gt;概述&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;前缀编码，有时也被称为前向编码，是另一个通过移除冗余数据来降低数据量的算法。思想非常简单，但算法实现比较困难。要了解原因，首先我们来看一看它的原理。&lt;/p&gt;
&lt;p&gt;请看下面的字典。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;use
used
useful
usefully
usefulness
useless
uselessly
uselessness&lt;/pre&gt;
&lt;p&gt;为了不使用纯文本保存这些单词或者在网络上传输，我们可以用前缀编码进行压缩（编码）。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&quot;&quot; src=&quot;/images/jobbole.com/9130b42244a4abbf7fda5aad945efbe9.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;很明显，每一个单词都以表中的第一个单词“use”为前缀。所以我们很容易将它们压缩成下面的数组。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;$data = array(
0 =&amp;gt; &#39;use&#39;,
1 =&amp;gt; &#39;0d&#39;,
2 =&amp;gt; &#39;0ful&#39;,
3 =&amp;gt; &#39;0fully&#39;,
4 =&amp;gt; &#39;0less&#39;,
5 =&amp;gt; &#39;0lessly&#39;,
6 =&amp;gt; &#39;0lessness&#39;,
);&lt;/pre&gt;
&lt;p&gt;显然这并不是最佳的压缩结果，在不仅仅使用第一个词作为前缀的情况下，我们可以更进一步压缩。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;$data = array(
0 =&amp;gt; &#39;use&#39;,
1 =&amp;gt; &#39;0d&#39;,
2 =&amp;gt; &#39;0ful&#39;,
3 =&amp;gt; &#39;2ly&#39;,
4 =&amp;gt; &#39;0less&#39;,
5 =&amp;gt; &#39;4ly&#39;,
6 =&amp;gt; &#39;4ness&#39;,
);&lt;/pre&gt;
&lt;p&gt;此时的压缩更好，好消息是解码是一个相对简单的过程。但棘手的部分在于压缩本身。问题是选择合适的前缀非常困难。第一个例程的前缀选择很简单，但事实上，大多时候数据很混乱。的确，对于随机产生的数据压缩过程将非常困难，算法过程不仅很慢，而且难以实现。&lt;/p&gt;
&lt;p&gt;好的方面是，如果我们事先知道数据的格式，该算法可以用于多种情况。那么，让我们看看下面三个例子，该算法可能会很方便。&lt;/p&gt;
&lt;h1&gt;应用&lt;/h1&gt;
&lt;p&gt;以下是三个前缀编码的例子。前面我说随机数据的压缩过程会很难，如果你事先知道输入数据的格式，这将会是一个很好的练习。&lt;/p&gt;
&lt;h2&gt;日期和时间前缀&lt;/h2&gt;
&lt;p&gt;我们通常会忽略年份的前两个数字，例如我们通常不会写1995或1996，而是使用更短的——‘95’和‘96’。这样年份就被编码成更短的字符串。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;input: (1991, 1992, 1993, 1994, 1995, 1996)
output: (91, 92, 93, 94, 95, 96)&lt;/pre&gt;
&lt;p&gt;问题在于输入流发生很小的变动，解码就会出错。如果我们加上21世纪的年份，我们将失去数据的唯一性。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;input: (1998, 1992, 1999, 2011, 2012)
output: (98, 92, 99, 11, 12)&lt;/pre&gt;
&lt;p&gt;此时，解码器肯会将最后两个数值解码成(1911, 1912)，因为“19”被认为是前缀。所以，我们事先必须知道前缀与每一个数值绝对平等。如果没有编码格式，必须不同。例如我们可以使用一些特殊标识和前缀一起编码。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;input: (1998, 1992, 1932, 1924, 2001, 2012)
output: (#19, 98, 92, 32, 24, #20, 01, 12)&lt;/pre&gt;
&lt;p&gt;一旦解码器读到#字符，它就知道下面的数为前缀。&lt;/p&gt;
&lt;p&gt;事实上，这种方法可用于日期和时间格式的编码。假设我们有一些日期时间值，而且我们知道所有数据都是在同一天。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;2012-01-31 15:33:45
2012-01-31 16:12:11
2012-01-31 17:32:35
2012-01-31 18:54:34&lt;/pre&gt;
&lt;p&gt;显然，我们可以忽略这些字符串的时间部分，仅发送（保存）时间。当然，我们必须确定所有的这些数值都是在同一天。如果不是，我们可以使用上例中的方法。&lt;/p&gt;
&lt;h2&gt;电话号码&lt;/h2&gt;
&lt;p&gt;电话号码是前缀编码的典型应用。不仅仅是国际代码，移动网络运营商的电话号码也使用前缀编码。如果我们要传输电话号码，假设是英国的，我们可以用一些更短的东西替换开头的“+44”。&lt;/p&gt;
&lt;p&gt;如果你要给移动设备编写电话簿，你可以通过前缀编码压缩数据，节省部分空间，这样用户将拥有更多空间，也可以在手机上存储更多电话号码。&lt;/p&gt;
&lt;p&gt;电话号码前缀也适用于数据库标准化。这样你可以将它们存储在单独的数据库表中，不用电话簿中唯一的号码。&lt;/p&gt;
&lt;h2&gt;地理坐标&lt;/h2&gt;
&lt;p&gt;对于我之前帖子中使用的例子，可以在一定范围内去掉通用前缀来发送地理坐标。的确，在必须传送大量坐标到地图应用时，你可以预期这些标记在一定范围内彼此间相当靠近。&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;img id=&quot;pic&quot; alt=&quot;&quot; src=&quot;/images/jobbole.com/cedae08dc44c077d2df50b7782b0b954.jpg&quot;&gt;&lt;/p&gt;
&lt;p style=&quot;text-align: center;&quot;&gt;&lt;em&gt;&lt;/em&gt;&lt;em&gt;在一定范围内，可以预期这些标记都有相同的前缀。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;那些点的坐标有共同的前缀，就像下面地铁站的例子一样。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;LatLon(40.762959,-73.985989)
LatLon(40.761886,-73.983629)
LatLon(40.762861,-73.981612)
LatLon(40.764616,-73.98056)&lt;/pre&gt;
&lt;p&gt;我们可以发现所有的地理坐标点有相同的前缀(40.76x, -73.98x)，所以我们只需要发送一次前缀。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;Prefix: (40.76, -73.98)
Data: 
LatLon(2959,5989)
LatLon(1886,3629)
LatLon(2861,1612)
LatLon(4616,056)&lt;/pre&gt;
&lt;p&gt;以上是前缀编码的三个例子，该算法在传输均匀数据是非常有用。&lt;/p&gt;
&lt;h1&gt;&lt;span style=&quot;font-family: &#39;Helvetica Neue&#39;, Helvetica, Arial, sans-serif; font-size: 28px; font-style: normal; font-weight: bold; line-height: 42px;&quot;&gt;后缀编码&lt;/span&gt;&lt;/h1&gt;
&lt;p&gt;后缀编码和前缀编码几乎相同，区别在于编码重复后缀。如下例，后缀编码替换最后重复的后缀，这非常有用。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;Johnson
Clarkson
Jackson&lt;/pre&gt;
&lt;p&gt;或者公司名称。&lt;/p&gt;
&lt;pre class=&quot;brush: actionscript3; gutter: true&quot;&gt;Apple Inc.
Google Inc.
Yahoo! Inc.&lt;/pre&gt;
&lt;p&gt;这里我们可以使用一些其他更短的东西来替换“Inc”。&lt;/p&gt;


&lt;!-- div id=&quot;ad1&quot;&gt;
&lt;/div --&gt;


	


	

</description>
        <pubDate>Thu, 20 Nov 2014 00:00:00 +0800</pubDate>
        <link>http://iftti.com/posts/2014/2014-11-20-79757-c5acf18ef.html</link>
        <guid isPermaLink="true">http://iftti.com/posts/2014/2014-11-20-79757-c5acf18ef.html</guid>
        
        
        <category>jobbole</category>
        
      </item>
    
  </channel>
</rss>
